{
    "id": "root",
    "title": "Textbook",
    "content": null,
    "summary": null,
    "children": [
        {
            "id": "chapter-1",
            "title": "Propositional Logic",
            "content": "1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\n1.2.3 Natural deduction in summary\nThe proof rules for natural deduction are summarised in Figure 1.2. The\nexplanation of the rules we have given so far in this chapter is declarative;\nwe have presented each rule and justiﬁed it in terms of our intuition about\nthe logical connectives. However, when you try to use the rules yourself,\nyou’ll ﬁnd yourself looking for a more procedural interpretation; what does\na rule do and how do you use it? For example,\nr ∧i says: to prove φ ∧ψ, you must ﬁrst prove φ and ψ separately and then use\nthe rule ∧i.\nr ∧e1 says: to prove φ, try proving φ ∧ψ and then use the rule ∧e1. Actually,\nthis doesn’t sound like very good advice because probably proving φ ∧ψ will\nbe harder than proving φ alone. However, you might ﬁnd that you already have\nφ ∧ψ lying around, so that’s when this rule is useful. Compare this with the\nexample sequent in Example 1.15.\nr ∨i1 says: to prove φ ∨ψ, try proving φ. Again, in general it is harder to prove\nφ than it is to prove φ ∨ψ, so this will usually be useful only if you’ve already\nmanaged to prove φ. For example, if you want to prove q |−p ∨q, you certainly\nwon’t be able simply to use the rule ∨i1, but ∨i2 will work.\nr ∨e has an excellent procedural interpretation. It says: if you have φ ∨ψ, and you\nwant to prove some χ, then try to prove χ from φ and from ψ in turn. (In those\nsubproofs, of course you can use the other prevailing premises as well.)\nr Similarly, →i says, if you want to prove φ →ψ, try proving ψ from φ (and the\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nour reasoning is concerned about the inference, and therefore the preserva-\ntion, of truth. Hence, there cannot be a direct way of inferring ¬φ, given\nφ.\nDeﬁnition 1.19 Contradictions are expressions of the form φ ∧¬φ or ¬φ ∧\nφ, where φ is any formula.\nExamples of such contradictions are r ∧¬r, (p →q) ∧¬(p →q) and ¬(r ∨\ns →q) ∧(r ∨s →q). Contradictions are a very important notion in logic.\nAs far as truth is concerned, they are all equivalent; that means we should\nbe able to prove the validity of\n¬(r ∨s →q) ∧(r ∨s →q) ⊣⊢(p →q) ∧¬(p →q)\n(1.2)\nsince both sides are contradictions. We’ll be able to prove this later, when\nwe have introduced the rules for negation.\nIndeed, it’s not just that contradictions can be derived from contradic-\ntions; actually, any formula can be derived from a contradiction. This can be\n1.2 Natural deduction\n21\nconfusing when you ﬁrst encounter it; why should we endorse the argument\np ∧¬p ⊢q, where\np : The moon is made of green cheese.\nq : I like pepperoni on my pizza.\nconsidering that our taste in pizza doesn’t have anything to do with the\nconstitution of the moon? On the face of it, such an endorsement may seem\nabsurd. Nevertheless, natural deduction does have this feature that any for-\nmula can be derived from a contradiction and therefore it makes this argu-\nment valid. The reason it takes this stance is that ⊢tells us all the things\nwe may infer, provided that we can assume the formulas to the left of it.\nThis process does not care whether such premises make any sense. This has\nat least the advantage that we can match ⊢to checks based on semantic\nintuitions which we formalise later by using truth tables: if all the premises\ncompute to ‘true’, then the conclusion must compute ‘true’ as well. In partic-\nan implication. Suppose that p →q and ¬q are the case. Then, if p holds\nwe can use →e to conclude that q holds. Thus, we then have that q and ¬q\nhold, which is impossible. Therefore, we may infer that p must be false. But\nthis can only mean that ¬p is true. We summarise this reasoning into the\nrule modus tollens, or MT for short:5\nφ →ψ\n¬ψ\n¬φ\nMT.\nAgain, let us see an example of this rule in the natural language setting:\n‘If Abraham Lincoln was Ethiopian, then he was African. Abraham\nLincoln was not African; therefore he was not Ethiopian.’\nExample 1.7 In the following proof of\np →(q →r), p, ¬r ⊢¬q\nwe use several of the rules introduced so far:\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq →r\n→e 1, 2\n5\n¬q\nMT 4, 3\n5 We will be able to derive this rule from other ones later on, but we introduce it here because it\nallows us already to do some pretty slick proofs. You may think of this rule as one on a higher\nlevel insofar as it does not mention the lower-level rules upon which it depends.\n1.2 Natural deduction\n11\nExamples 1.8 Here are two example proofs which combine the rule MT\nwith either ¬¬e or ¬¬i:\n1\n¬p →q\npremise\n2\n¬q\npremise\n3\n¬¬p\nMT 1, 2\n4\np\n¬¬e 3\nproves that the sequent ¬p →q, ¬q ⊢p is valid; and\n1\np →¬q\npremise\n2\nq\npremise\n3\n¬¬q\n¬¬i 2\n4\n¬p\nMT 1, 3\nshows the validity of the sequent p →¬q, q ⊢¬p.\nNote that the order of applying double negation rules and MT is diﬀerent\nin these examples; this order is driven by the structure of the particular\nsequent whose validity one is trying to show.\nThe rule implies introduction\nThe rule MT made it possible for us to\nshow that p →q, ¬q ⊢¬p is valid. But the validity of the sequent p →q ⊢\n¬q →¬p seems just as plausible. That sequent is, in a certain sense, saying\nthe same thing. Yet, so far we have no rule which builds implications that\ndo not already occur as premises in our proofs. The mechanics of such a rule\nare more involved than what we have seen so far. So let us proceed with\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nExample 1.4 Let’s use these rules to prove that p ∧q, r |−q ∧r is valid.\nWe start by writing down the premises; then we leave a gap and write the\n1.2 Natural deduction\n7\nconclusion:\np ∧q\nr\nq ∧r\nThe task of constructing the proof is to ﬁll the gap between the premises\nand the conclusion by applying a suitable sequence of proof rules. In this\ncase, we apply ∧e2 to the ﬁrst premise, giving us q. Then we apply ∧i to this\nq and to the second premise, r, giving us q ∧r. That’s it! We also usually\nnumber all the lines, and write in the justiﬁcation for each line, producing\nthis:\n1\np ∧q\npremise\n2\nr\npremise\n3\nq\n∧e2 1\n4\nq ∧r\n∧i 3, 2\nDemonstrate to yourself that you’ve understood this by trying to show on\nyour own that (p ∧q) ∧r, s ∧t |−q ∧s is valid. Notice that the φ and ψ can\nbe instantiated not just to atomic sentences, like p and q in the example we\njust gave, but also to compound sentences. Thus, from (p ∧q) ∧r we can\ndeduce p ∧q by applying ∧e1, instantiating φ to p ∧q and ψ to r.\nIf we applied these proof rules literally, then the proof above would actu-\nally be a tree with root q ∧r and leaves p ∧q and r, like this:\np ∧q\n∧e2\nq\nr\n∧i\nq ∧r\nHowever, we ﬂattened this tree into a linear presentation which necessitates\nthe use of pointers as seen in lines 3 and 4 above. These pointers allow\nus to recreate the actual proof tree. Throughout this text, we will use the\nﬂattened version of presenting proofs. That way you have to concentrate only\non ﬁnding a proof, not on how to ﬁt a growing tree onto a sheet of paper.\nIf a sequent is valid, there may be many diﬀerent ways of proving it. So if\nyou compare your solution to these exercises with those of others, they need\nnot coincide. The important thing to realise, though, is that any putative 1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25 1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nsumed or given as a premise some formula η1 ∨η2 in some line k′ with\nk′ < k, which was referred to via ∨e in the justiﬁcation of line k. Thus,\nwe have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within that\nproof, obtained by turning all assumptions of boxes that are open at\nline k′ into premises. In a similar way we obtain proofs of the sequents\nφ1, φ2, . . . , φn, η1 ⊢ψ and φ1, φ2, . . . , φn, η2 ⊢ψ from the case analysis of ∨e.\nBy our induction hypothesis, we conclude that the relations φ1, φ2, . . . , φn ⊨\nη1 ∨η2, φ1, φ2, . . . , φn, η1 ⊨ψ and φ1, φ2, . . . , φn, η2 ⊨ψ hold. But together\nthese three relations then force that φ1, φ2, . . . , φn ⊨ψ holds as well –\nwhy?\n3.\nYou can guess by now that the rest of the argument checks each possible proof\nrule in turn and ultimately boils down to verifying that our natural deduction\n1.4 Semantics of propositional logic\n49\nrules behave semantically in the same way as their corresponding truth tables\nevaluate. We leave the details as an exercise.\n2\nThe soundness of propositional logic is useful in ensuring the non-existence of\na proof for a given sequent. Let’s say you try to prove that φ1, φ2, . . . , φ2 ⊢ψ\nis valid, but that your best eﬀorts won’t succeed. How could you be sure that\nno such proof can be found? After all, it might just be that you can’t ﬁnd\na proof even though there is one. It suﬃces to ﬁnd a valuation in which φi\nevaluate to T whereas ψ evaluates to F. Then, by deﬁnition of ⊨, we don’t\nhave φ1, φ2, . . . , φ2 ⊨ψ. Using soundness, this means that φ1, φ2, . . . , φ2 ⊢ψ\ncannot be valid. Therefore, this sequent does not have a proof. You will\npractice this method in the exercises.\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nφ ∨ψ\n∨i1\nψ\nφ ∨ψ\n∨i2\nφ ∨ψ\nφ\n...\nχ\nψ\n...\nχ\nχ\n∨e\n→\nφ\n...\nψ\nφ →ψ\n→i\nφ\nφ →ψ\nψ\n→e\n¬\nφ\n...\n⊥\n¬φ\n¬i\nφ\n¬φ\n⊥\n¬e\n⊥\n(no introduction rule for ⊥)\n⊥\nφ\n⊥e\n¬¬\n¬¬φ\nφ\n¬¬e\nSome useful derived rules:\nφ →ψ\n¬ψ\n¬φ\nMT\nφ\n¬¬φ\n¬¬i\n¬φ\n...\n⊥\nφ\nPBC\nφ ∨¬φ\nLEM\nFigure 1.2. Natural deduction rules for propositional logic.\n28\n1 Propositional logic\nAt any stage of a proof, it is permitted to introduce any formula as as-\nsumption, by choosing a proof rule that opens a box. As we saw, natural\ndeduction employs boxes to control the scope of assumptions. When an as-\nsumption is introduced, a box is opened. Discharging assumptions is achieved\nby closing a box according to the pattern of its particular proof rule. It’s\nuseful to make assumptions by opening boxes. But don’t forget you have to\nclose them in the manner prescribed by their proof rule.\nOK, but how do we actually go about constructing a proof?\nGiven a sequent, you write its premises at the top of your page and\nits conclusion at the bottom. Now, you’re trying to ﬁll in the gap,\nwhich involves working simultaneously on the premises (to bring them to-\nwards the conclusion) and on the conclusion (to massage it towards the\npremises).\nLook ﬁrst at the conclusion. If it is of the form φ →ψ, then apply6 the\nrule →i. This means drawing a box with φ at the top and ψ at the bottom.\nSo your proof, which started out like this:\n...\npremises\n...\nφ →ψ\nnow looks like this:\n...\npremises\n...\nφ\nassumption\nψ\nφ →ψ\n→i\nYou still have to ﬁnd a way of ﬁlling in the gap between the φ and the ψ.\nBut you now have an extra formula to work with and you have simpliﬁed\nthe conclusion you are trying to reach.\n6 Except in situations such as p →(q →¬r), p ⊢q →¬r where →e produces a simpler proof.\n1.2 Natural deduction\n29\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules. the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne of proof, which states rules for transforming valid sequents into valid sequents.\nFor example, if we have already a proof for the sequent Γ, φ ⊢ψ, then we ob-\ntain a proof of the sequent Γ ⊢φ →ψ by augmenting this very proof with one\napplication of the rule →i. The new approach expresses this as an inference rule\nbetween sequents:\nΓ, φ ⊢ψ\nΓ ⊢φ →ψ →i.\nThe rule ‘assumption’ is written as\nφ ⊢φ assumption\ni.e. the premise is empty. Such rules are called axioms.\n(a) Express all remaining proof rules of Figure 1.2 in such a form. (Hint: some\nof your rules may have more than one premise.)\n(b) Explain why proofs of Γ ⊢ψ in this new system have a tree-like structure\nwith Γ ⊢ψ as root.\n(c) Prove p ∨(p ∧q) ⊢p in your new proof system.\n1.7 Exercises\n81\n7. Show that\n√\n2 cannot be a rational number. Proceed by proof by contradiction:\nassume that\n√\n2 is a fraction k/l with integers k and l ̸= 0. On squaring both sides\nwe get 2 = k2/l2, or equivalently 2l2 = k2. We may assume that any common 2\nfactors of k and l have been cancelled. Can you now argue that 2l2 has a diﬀerent\nnumber of 2 factors from k2? Why would that be a contradiction and to what?\n8. There is an alternative approach to treating negation. One could simply ban the\noperator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally,\nsuch a logic cannot rely on the natural deduction rules for negation. Which of\nthe rules ¬i, ¬e, ¬¬e and ¬¬i can you simulate with the remaining proof rules\nby letting ¬φ be φ →⊥?\n9. Let us introduce a new connective φ ↔ψ which should abbreviate (φ →ψ) ∧\n(ψ →φ). Design introduction and elimination rules for ↔and show that they\nare derived rules if φ ↔ψ is interpreted as (φ →ψ) ∧(ψ →φ).\nExercises 1.3\nIn order to facilitate reading these exercises we assume below the usual\nconventions about binding priorities agreed upon in Convention 1.3.\n1. Given the following formulas, draw their corresponding parse tree:\n(a) p\n(b)\n*\np ∧q\n(c) p ∧¬q →¬p\n(d)\n*\np ∧(¬q →¬p)\n(e) p →(¬q ∨(q →p))\n(f) reality (they are true), or they don’t (they are false).\nIf we combine declarative sentences p and q with a logical connective, say\n∧, then the truth value of p ∧q is determined by three things: the truth value\nof p, the truth value of q and the meaning of ∧. The meaning of ∧is captured\nby the observation that p ∧q is true iﬀp and q are both true; otherwise p ∧q\nis false. Thus, as far as ∧is concerned, it needs only to know whether p and\nq are true, it does not need to know what p and q are actually saying about\nthe world out there. This is also the case for all the other logical connectives\nand is the reason why we can compute the truth value of a formula just by\nknowing the truth values of the atomic propositions occurring in it.\nDeﬁnition 1.28 1.\nThe set of truth values contains two elements T and F, where\nT represents ‘true’ and F represents ‘false’.\n2.\nA valuation or model of a formula φ is an assignment of each propositional atom\nin φ to a truth value.\nExample 1.29 The map which assigns T to q and F to p is a valuation for\np ∨¬q. Please list the remaining three valuations for this formula.\nWe can think of the meaning of ∧as a function of two arguments; each\nargument is a truth value and the result is again such a truth value. We\nspecify this function in a table, called the truth table for conjunction, which\nyou can see in Figure 1.5. In the ﬁrst column, labelled φ, we list all possible\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nFigure 1.5. The truth table for conjunction, the logical connective ∧.\n38\n1 Propositional logic\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nφ\nψ\nφ ∨ψ\nT\nT\nT\nT\nF\nT\nF\nT\nT\nF\nF\nF\nφ\nψ\nφ →ψ\nT\nT\nT\nT\nF\nF\nF\nT\nT\nF\nF\nT\nφ\n¬φ\nT\nF\nF\nT\n⊤\nT\n⊥\nF\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nvalues in the ﬁrst two columns really exhaust all those possibilities (TT, TF,\nFT and FF). In the third column, we list the result of φ ∧ψ according to the\ntruth values of φ and ψ. So in the ﬁrst line, where φ and ψ have value T,\nthe result is T again. In all other lines, the result is F since at least one of\nthe propositions φ or ψ has value F.\nIn Figure 1.6 you ﬁnd the truth tables for all logical connectives of propo-\nsitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the\nmirror image of conjunction if we swap T and F, namely, a disjunction re-\nturns F iﬀboth arguments are equal to F, otherwise (= at least one of the\narguments equals T) it returns T. The behaviour of implication is not quite\nas intuitive. Think of the meaning of →as checking whether truth is being\npreserved. Clearly, this is not the case when we have T →F, since we infer\nsomething that is false from something that is true. So the second entry\nin the column φ →ψ equals F. On the other hand, T →T obviously pre-\nserves truth, but so do the cases F →T and F →F, because there is no truth\nto be preserved in the ﬁrst place as the assumption of the implication is\nfalse.\nIf you feel slightly uncomfortable with the semantics (= the meaning)\nof →, then it might be good to think of φ →ψ as an abbreviation of the\nformula ¬φ ∨ψ as far as meaning is concerned; these two formulas are very\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nany other variable y to l(y).\nFinally, we are able to give a semantics to formulas of predicate logic. For\npropositional logic, we did this by computing a truth value. Clearly, it suﬃces\nto know in which cases this value is T.\n128\n2 Predicate logic\nDeﬁnition 2.18 Given a model M for a pair (F, P) and given an environ-\nment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula\nφ over the pair (F, P) and look-up table l by structural induction on φ. If\nM ⊨l φ holds, we say that φ computes to T in the model M with respect to\nthe environment l.\nP:\nIf φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, t2, . . . , tn in\nour set A by replacing all variables with their values according to l. In this way\nwe compute concrete values a1, a2, . . . , an of A for each of these terms, where\nwe interpret any function symbol f ∈F by f M. Now M ⊨l P(t1, t2, . . . , tn)\nholds iﬀ(a1, a2, . . . , an) is in the set P M.\n∀x:\nThe relation M ⊨l ∀x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for all a ∈A.\n∃x:\nDually, M ⊨l ∃x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for some a ∈A.\n¬:\nThe relation M ⊨l ¬ψ holds iﬀit is not the case that M ⊨l ψ holds.\n∨:\nThe relation M ⊨l ψ1 ∨ψ2 holds iﬀM ⊨l ψ1 or M ⊨l ψ2 holds.\n∧:\nThe relation M ⊨l ψ1 ∧ψ2 holds iﬀM ⊨l ψ1 and M ⊨l ψ2 hold.\n→:\nThe relation M ⊨l ψ1 →ψ2 holds iﬀM ⊨l ψ2 holds whenever M ⊨l ψ1 holds.\nWe sometimes write M ̸⊨l φ to denote that M ⊨l φ does not hold.\nThere is a straightforward inductive argument on the height of the parse\ntree of a formula which says that M ⊨l φ holds iﬀM ⊨l′ φ holds, whenever\nl and l′ are two environments which are identical on the set of free variables\nof φ. In particular, if φ has no free variables at all, we then call φ a sentence;\nwe conclude that M ⊨l φ holds, or does not hold, regardless of the choice of\nl. Thus, for sentences φ we often elide l and write M ⊨φ since the choice of\nan environment l is then irrelevant.\nExample 2.19 Let us illustrate the deﬁnitions above by means of an-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\n(e) Cancer will not be cured unless its cause is determined and a new drug for\ncancer is found.\n(f) If interest rates go up, share prices go down.\n(g) If Smith has installed central heating, then he has sold his car or he has not\npaid his mortgage.\n(h)\n*\nToday it will rain or shine, but not both.\n(i)\n*\nIf Dick met Jane yesterday, they had a cup of coﬀee together, or they took\na walk in the park.\n(j) No shoes, no shirt, no service.\n(k) My sister wants a black and white cat.\n2. The formulas of propositional logic below implicitly assume the binding priorities\nof the logical connectives put forward in Convention 1.3. Make sure that you fully\nunderstand those conventions by reinserting as many brackets as possible. For\nexample, given p ∧q →r, change it to (p ∧q) →r since ∧binds more tightly\nthan →.\n(a)\n*\n¬p ∧q →r\n(b) (p →q) ∧¬(r ∨p →q)\n(c)\n*\n(p →q) →(r →s ∨t)\n(d) p ∨(¬q →p ∧r)\n(e)\n*\np ∨q →¬p ∧r\n(f) p ∨p →¬q\n(g)\n*\nWhy is the expression p ∨q ∧r problematic?\nExercises 1.2\n1. Prove the validity of the following sequents:\n(a) (p ∧q) ∧r, s ∧t ⊢q ∧s\n1.7 Exercises\n79\n(b) p ∧q ⊢q ∧p\n(c)\n*\n(p ∧q) ∧r ⊢p ∧(q ∧r)\n(d) p →(p →q), p ⊢q\n(e)\n*\nq →(p →r), ¬r, q ⊢¬p\n(f)\n*\n⊢(p ∧q) →p\n(g) p ⊢q →(p ∧q)\n(h)\n*\np ⊢(p →q) →q\n(i)\n*\n(p →r) ∧(q →r) ⊢p ∧q →r\n(j)\n*\nq →r ⊢(p →q) →(p →r)\n(k) p →(q →r), p →q ⊢p →r\n(l)\n*\np →q, r →s ⊢p ∨r →q ∨s\n(m) p ∨q ⊢r →(p ∨q) ∧r\n(n)\n*\n(p ∨(q →p)) ∧q ⊢p\n(o)\n*\np →q, r →s ⊢p ∧r →q ∧s\n(p) p →q ⊢((p ∧q) →p) ∧(p →(p ∧q))\n(q) ⊢q →(p →(p →(q →p)))\n(r)\n*\np →q ∧r ⊢(p →q) ∧(p →r)\n(s) (p →q) ∧(p →r) ⊢p →q ∧r\n(t) ⊢(p →q) →((r →s) →(p ∧r →q ∧s)); here you might be able to ‘recycle’\nand augment a proof from a previous exercise.\n(u) p →q ⊢¬q →¬p\n(v)\n*\np ∨(p ∧q) ⊢p\n(w) r, p →(r →q) ⊢p →(q ∧r)\n(x)\n*\np →(q ∨r), q →s, r →s ⊢p →s\n(y)\n*\n(p ∧q) ∨(p ∧r) ⊢p ∧(q ∨r).\n2. For the sequents below, show which ones are valid and which ones aren’t:\n(a)\n*\n¬p →¬q ⊢q →p\n(b)\n*\n¬p ∨¬q ⊢¬(p ∧q)\n(c)\n*\n¬p, p ∨q ⊢q\n(d)\n*\np ∨q, ¬q ∨r ⊢p ∨r\n(e)\n*\np →(q ∨r), ¬q, ¬r ⊢¬p without using the MT rule\n(f)\n*\nsuggesting that q is a logical consequence of p. We write p →q for that3. We\ncall p the assumption of p →q and q its conclusion.\nOf course, we are entitled to use these rules of constructing propositions\nrepeatedly. For example, we are now in a position to form the proposition\np ∧q →¬r ∨q\nwhich means that ‘if p and q then not r or q’. You might have noticed a\npotential ambiguity in this reading. One could have argued that this sentence\nhas the structure ‘p is the case and if q then . . . ’ A computer would require\nthe insertion of brackets, as in\n(p ∧q) →((¬r) ∨q)\n2 Its meaning should not be confused with the often implicit meaning of or in natural language\ndiscourse as either . . . or. In this text or always means at least one of them and should not be\nconfounded with exclusive or which states that exactly one of the two statements holds.\n3 The natural language meaning of ‘if . . . then . . . ’ often implicitly assumes a causal role of\nthe assumption somehow enabling its conclusion. The logical meaning of implication is a bit\ndiﬀerent, though, in the sense that it states the preservation of truth which might happen\nwithout any causal relationship. For example, ‘If all birds can ﬂy, then Bob Dole was never\npresident of the United States of America.’ is a true statement, but there is no known causal\nconnection between the ﬂying skills of penguins and eﬀective campaigning.\n1.2 Natural deduction\n5\nto disambiguate this assertion. However, we humans get annoyed by a pro-\nliferation of such brackets which is why we adopt certain conventions about\nthe binding priorities of these symbols.\nConvention 1.3 ¬ binds more tightly than ∨and ∧, and the latter two\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional done. Otherwise, we can use the inductive step, applied to n = 1, to infer\nthat 2 = 1 + 1 has property M(2). We can do that using →e, for we know\nthat 1 has the property in question. Now we use that same inductive step on\nn = 2 to infer that 3 has property M(3) and we repeat this until we reach\nn = k (see Figure 1.9). Therefore, we should have no objections about using\nthe principle of mathematical induction for natural numbers.\nReturning to Gauss’ example we claim that the sum 1 + 2 + 3 + 4 + · · · +\nn equals n · (n + 1)/2 for all natural numbers n.\nTheorem 1.31 The sum 1 + 2 + 3 + 4 + · · · + n equals n · (n + 1)/2 for all\nnatural numbers n.\n9 There is another way of ﬁnding the sum 1 + 2 + · · · + 100, which works like this: write the\nsum backwards, as 100 + 99 + · · · + 1. Now add the forwards and backwards versions, obtaining\n101 + 101 + · · · + 101 (100 times), which is 10100. Since we added the sum to itself, we now\ndivide by two to get the answer 5050. Gauss probably used this method; but the method of\nmathematical induction that we explore in this section is much more powerful and can be\napplied in a wide variety of situations.\n42\n1 Propositional logic\nWe prove M(1)\n...\n...\n1\n2\n3\n...\nn + 1\nn\nWe prove M(2) using M(1) and M(1) →M(2)\nWe prove M(3) using M(2) and M(2) →M(3)\nWe prove M(n) using M(n −1) and M(n −1) →M(n)\nWe prove M(n + 1) using M(n) and M(n) →M(n + 1)\nFigure 1.9. How the principle of mathematical induction works. By\nproving just two facts, M(1) and M(n) →M(n + 1) for a formal (and\nunconstrained) parameter n, we are able to deduce M(k) for each natural\nnumber k.\nProof: We use mathematical induction. In order to reveal the ﬁne structure\nof our proof we write LHSn for the expression 1 + 2 + 3 + 4 + · · · + n and\nRHSn for n · (n + 1)/2. Thus, we need to show LHSn = RHSn for all n ≥1.\nBase case: If n equals 1, then LHS1 is just 1 (there is only one summand),\nwhich happens to equal RHS1 = 1 · (1 + 1)/2.\nHere is a little anecdote about the German mathematician Gauss who, as a\npupil at age 8, did not pay attention in class (can you imagine?), with the\nresult that his teacher made him sum up all natural numbers from 1 to 100.\nThe story has it that Gauss came up with the correct answer 5050 within\nseconds, which infuriated his teacher. How did Gauss do it? Well, possibly\nhe knew that\n1 + 2 + 3 + 4 + · · · + n = n · (n + 1)\n2\n(1.5)\n1.4 Semantics of propositional logic\n41\nfor all natural numbers n.9 Thus, taking n = 100, Gauss could easily calcu-\nlate:\n1 + 2 + 3 + 4 + · · · + 100 = 100 · 101\n2\n= 5050.\nMathematical induction allows us to prove equations, such as the one\nin (1.5), for arbitrary n. More generally, it allows us to show that every\nnatural number satisﬁes a certain property. Suppose we have a property M\nwhich we think is true of all natural numbers. We write M(5) to say that\nthe property is true of 5, etc. Suppose that we know the following two things\nabout the property M:\n1.\nBase case: The natural number 1 has property M, i.e. we have a proof of\nM(1).\n2.\nInductive step: If n is a natural number which we assume to have property\nM(n), then we can show that n + 1 has property M(n + 1); i.e. we have a proof\nof M(n) →M(n + 1).\nDeﬁnition 1.30 The principle of mathematical induction says that, on the\ngrounds of these two pieces of information above, every natural number n\nhas property M(n). The assumption of M(n) in the inductive step is called\nthe induction hypothesis.\nWhy does this principle make sense? Well, take any natural number k.\nIf k equals 1, then k has property M(1) using the base case and so we are\ndone. Otherwise, we can use the inductive step, applied to n = 1, to infer\nthat 2 = 1 + 1 has property M(2). We can do that using →e, for we know\nthat 1 has the property in question. Now we use that same inductive step on\nn = 2 to infer that 3 has property M(3) and we repeat this until we reach 1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\nSo ¬p1, ¬p2 mean they (respectively) are wearing a white one. Informally\njustify each of the following premises in terms of the description of the\nproblem:\ni. K2K1 (p1 ∨p2)\nii. K2(¬p2 →K1 ¬p2)\niii. K2¬K1 p1.\n(c) Using natural deduction, prove from these premises that K2 p2.\n(d) Show that the third premise was essential, by exhibiting a model/world\nwhich satisﬁes the ﬁrst two, but not the conclusion.\n(e) Now is it easy to answer questions like ‘If man 2 were blind would he still be\nable to tell?’ and ‘if man 1 were blind, would man 2 still be able to tell?’?\n12. Recall our informal discussion on positive-knowledge formulas and negative-\nknowledge formulas. Give formal deﬁnitions of these notions.\n5.7 Bibliographic notes\nThe ﬁrst systematic approaches to modal logic were made by C. I. Lewis\nin the 1950s. The possible-worlds approach, which greatly simpliﬁed modal\nlogic and is now almost synonymous with it, was invented by S. Kripke.\nBooks devoted to modal logic include [Che80, Gol87, Pop94], where exten-\nsive references to the literature may be found. All these books discuss the\nsoundness and completeness of proof calculi for modal logics. They also in-\nvestigate which modal logics have the ﬁnite-model property: if a sequent\ndoes not have a proof, there is a ﬁnite model which demonstrates that. Not\nall modal logics enjoy this property, which is important for decidability.\nIntuitionistic propositional logic has the ﬁnite-model property; an anima-\ntion which generates such ﬁnite models (called PORGI) is available from\nA. Stoughton’s website2.\nThe idea of using modal logic to reason about knowledge is due to J.\nHintikka. A great deal of work on applying modal logic to multi-agent sys-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nsumed or given as a premise some formula η1 ∨η2 in some line k′ with\nk′ < k, which was referred to via ∨e in the justiﬁcation of line k. Thus,\nwe have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within that\nproof, obtained by turning all assumptions of boxes that are open at\nline k′ into premises. In a similar way we obtain proofs of the sequents\nφ1, φ2, . . . , φn, η1 ⊢ψ and φ1, φ2, . . . , φn, η2 ⊢ψ from the case analysis of ∨e.\nBy our induction hypothesis, we conclude that the relations φ1, φ2, . . . , φn ⊨\nη1 ∨η2, φ1, φ2, . . . , φn, η1 ⊨ψ and φ1, φ2, . . . , φn, η2 ⊨ψ hold. But together\nthese three relations then force that φ1, φ2, . . . , φn ⊨ψ holds as well –\nwhy?\n3.\nYou can guess by now that the rest of the argument checks each possible proof\nrule in turn and ultimately boils down to verifying that our natural deduction\n1.4 Semantics of propositional logic\n49\nrules behave semantically in the same way as their corresponding truth tables\nevaluate. We leave the details as an exercise.\n2\nThe soundness of propositional logic is useful in ensuring the non-existence of\na proof for a given sequent. Let’s say you try to prove that φ1, φ2, . . . , φ2 ⊢ψ\nis valid, but that your best eﬀorts won’t succeed. How could you be sure that\nno such proof can be found? After all, it might just be that you can’t ﬁnd\na proof even though there is one. It suﬃces to ﬁnd a valuation in which φi\nevaluate to T whereas ψ evaluates to F. Then, by deﬁnition of ⊨, we don’t\nhave φ1, φ2, . . . , φ2 ⊨ψ. Using soundness, this means that φ1, φ2, . . . , φ2 ⊢ψ\ncannot be valid. Therefore, this sequent does not have a proof. You will\npractice this method in the exercises.\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\nas instances of the axiom scheme K: 2(φ →ψ) →(2φ →2ψ) and of the\nschemes in (5.3). Many other formulas, such as\nr 2p →p\nr 2p →22p\nr ¬2p →2¬2p\nr 3⊤\nare not valid. For example, for each one of these, there is a world in the\nKripke model of Figure 5.3 which does not satisfy the formula. The world\nx1 satisﬁes 2p, but it does not satisfy p, so it does not satisfy 2p →p. If we\nadd R(x2, x1) to our model, then x1 still satisﬁes 2p but does not satisfy\n22p. Thus, x1 fails to satisfy 2p →22p. If we change L(x4) to {p, q}, then\nx4 does not satisfy ¬2p →2¬2p, because it satisﬁes ¬2p, but it does not\nsatisfy 2¬2p – the path R(x4, x5)R(x5, x4) serves as a counter example.\nFinally, x6 does not satisfy 3⊤, for this formula states that there is an\naccessible world satisfying ⊤, which is not the case.\nIf we are to build a logic capturing the concept of necessity, however, we\nmust surely have that 2p →p is valid; for anything which is necessarily true\nis also simply true. Similarly, we would expect 2p →p to be valid in the\ncase that 2p means ‘agent Q knows p,’ for anything which is known must\nalso be true. We cannot know something which is false. We can, however,\nbelieve falsehoods, so in the case of a logic of belief, we would not expect\n2p →p to be valid.\nPart of the job of logic engineering is to determine what formula schemes\nshould be valid and to craft the logic in such a way that precisely those ones\nare valid.\nTable 5.7 shows six interesting readings for 2 and eight formula schemes.\nFor each reading and each formula scheme, we decide whether we should\nexpect the scheme to be valid. Notice that we should only put a tick if the\n318\n5 Modal logics and agents\n2φ\n2φ →φ\n2φ →22φ\n3φ →23φ\n3⊤\n2φ →3φ\n2φ ∨2¬φ\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\nputational situations. If we disallow their usage in natural deduction proofs,\nwe obtain a logic, called intuitionistic propositional logic, together with its\nown proof theory. So far so good; but it is less clear what sort of semantics\none could have for such a logic – again with soundness and completeness in\nmind. This is where certain models of KT4 will do the job quite nicely. Recall\nthat correspondence theory implies that a model M = (W, R, L) of KT4 is\nsuch that R is reﬂexive and transitive. The only additional requirement we\nimpose on a model for intuitionistic propositional logic is that its labelling\nfunction L be monotone in R: R(x, y) implies that L(x) is a subset of L(y).\nThis models that the truth of atomic positive formulas persist throughout\nthe worlds that are reachable from a given world.\nDeﬁnition 5.19 A model of intuitionistic propositional logic is a model\nM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). Given\na propositional logic formula as in (1.3), we deﬁne x ⊩φ as in Deﬁnition 5.4\nexception for the clauses →and ¬. For φ1 →φ2 we deﬁne x ⊩φ1 →φ2 iﬀ\nfor all y with R(x, y) we have y ⊩φ2 whenever we have y ⊩φ1. For ¬φ we\ndeﬁne x ⊩¬φ iﬀfor all y with R(x, y) we have y ̸⊩φ.\nAs an example, consider the model W = {x, y} with accessibility relation\nR = {(x, x), (x, y), (y, y)}, which is indeed reﬂexive and transitive. For a la-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables 1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nseparate layers such that validity checks are easy. This is being done by\n1.\nusing the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of →from a\nformula and\n2.\nby specifying an algorithm that takes a formula without any →into a normal\nform (still without →) for which checking validity is easy.\nNaturally, we have to specify which forms of formulas we think of as being\n‘normal.’ Again, there are many such notions, but in this text we study only\ntwo important ones.\nDeﬁnition 1.42 A literal L is either an atom p or the negation of an atom\n¬p. A formula C is in conjunctive normal form (CNF) if it is a conjunction\nof clauses, where each clause D is a disjunction of literals:\nL ::= p | ¬p\nD ::= L | L ∨D\n(1.6)\nC ::= D | D ∧C.\n56\n1 Propositional logic\nExamples of formulas in conjunctive normal form are\n(i)\n(¬q ∨p ∨r) ∧(¬p ∨r) ∧q\n(ii)\n(p ∨r) ∧(¬p ∨r) ∧(p ∨¬r).\nIn the ﬁrst case, there are three clauses of type D: ¬q ∨p ∨r, ¬p ∨r, and q –\nwhich is a literal promoted to a clause by the ﬁrst rule of clauses in (1.6).\nNotice how we made implicit use of the associativity laws for ∧and ∨,\nsaying that φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η and φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η, since\nwe omitted some parentheses. The formula (¬(q ∨p) ∨r) ∧(q ∨r) is not in\nCNF since q ∨p is not a literal.\nWhy do we care at all about formulas φ in CNF? One of the reasons\nfor their usefulness is that they allow easy checks of validity which other-\nwise take times exponential in the number of atoms. For example, consider\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\nputational situations. If we disallow their usage in natural deduction proofs,\nwe obtain a logic, called intuitionistic propositional logic, together with its\nown proof theory. So far so good; but it is less clear what sort of semantics\none could have for such a logic – again with soundness and completeness in\nmind. This is where certain models of KT4 will do the job quite nicely. Recall\nthat correspondence theory implies that a model M = (W, R, L) of KT4 is\nsuch that R is reﬂexive and transitive. The only additional requirement we\nimpose on a model for intuitionistic propositional logic is that its labelling\nfunction L be monotone in R: R(x, y) implies that L(x) is a subset of L(y).\nThis models that the truth of atomic positive formulas persist throughout\nthe worlds that are reachable from a given world.\nDeﬁnition 5.19 A model of intuitionistic propositional logic is a model\nM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). Given\na propositional logic formula as in (1.3), we deﬁne x ⊩φ as in Deﬁnition 5.4\nexception for the clauses →and ¬. For φ1 →φ2 we deﬁne x ⊩φ1 →φ2 iﬀ\nfor all y with R(x, y) we have y ⊩φ2 whenever we have y ⊩φ1. For ¬φ we\ndeﬁne x ⊩¬φ iﬀfor all y with R(x, y) we have y ̸⊩φ.\nAs an example, consider the model W = {x, y} with accessibility relation\nR = {(x, x), (x, y), (y, y)}, which is indeed reﬂexive and transitive. For a la-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nthe truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nevaluate to F, then our induction hypothesis and the rule ∧i give us ˆp1, . . . , ˆpn ⊢\n¬φ1 ∧¬φ2 and we have to show ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2), which we leave as an\nexercise. Second, if φ1 and φ2 evaluate to T, then we obtain ˆp1, . . . , ˆpn ⊢φ1 ∧φ2,\nby our induction hypothesis, and we need a proof for φ1 ∧φ2 ⊢φ1 ∨φ2, which\nwe leave as an exercise. Third, if φ1 evaluates to F and φ2 to T, then we arrive\nat ˆp1, . . . , ˆpn ⊢¬φ1 ∧φ2, using our induction hypothesis, and need to establish\n¬φ1 ∧φ2 ⊢φ1 ∨φ2, which we leave as an exercise. Fourth, if φ1 evaluates to T\nand φ2 to F, then ˆp1, . . . , ˆpn ⊢φ1 ∧¬φ2 results from our induction hypothesis\nand all we need is a proof for φ1 ∧¬φ2 ⊢φ1 ∨φ2, which we leave as an\nexercise.\n2\nWe apply this technique to the formula ⊨φ1 →(φ2 →(φ3 →(. . . (φn →\nψ) . . . ))). Since it is a tautology it evaluates to T in all 2n lines of its truth\ntable; thus, the proposition above gives us 2n many proofs of ˆp1, ˆp2, . . . , ˆpn ⊢\nη, one for each of the cases that ˆpi is pi or ¬pi. Our job now is to assemble\nall these proofs into a single proof for η which does not use any premises.\nWe illustrate how to do this for an example, the tautology p ∧q →p.\nThe formula p ∧q →p has two propositional atoms p and q. By the propo-\nsition above, we are guaranteed to have a proof for each of the four sequents\np, q ⊢p ∧q →p\n¬p, q ⊢p ∧q →p\np, ¬q ⊢p ∧q →p\n¬p, ¬q ⊢p ∧q →p.\nUltimately, we want to prove p ∧q →p by appealing to the four proofs of\nthe sequents above. Thus, we somehow need to get rid of the premises on\n1.5 Normal forms\n53\nthe left-hand sides of these four sequents. This is the place where we rely on\nthe law of the excluded middle which states r ∨¬r, for any r. We use LEM\nfor all propositional atoms (here p and q) and then we separately assume all\nthe four cases, by using ∨e. That way we can invoke all four proofs of the\nsequents above and use the rule ∨e repeatedly until we have got rid of all our\nonly ﬁnitely many premises ∆from Γ. But then ∆⊢⊥is valid, too, and\nso ∆⊨⊥follows by soundness. But the latter contradicts the fact that all\nﬁnite subsets of Γ are consistent.\n2\nFrom this theorem one may derive a number of useful techniques. We men-\ntion a technique for ensuring the existence of models of inﬁnite size.\nTheorem 2.25 (L¨owenheim-Skolem Theorem) Let ψ be a sentence of\npredicate logic such for any natural number n ≥1 there is a model of ψ with\nat least n elements. Then ψ has a model with inﬁnitely many elements.\nPROOF:\nThe formula φn\ndef\n= ∃x1∃x2 . . . ∃xn\n\u0004\n1≤i<j≤n ¬(xi = xj) speciﬁes\nthat there are at least n elements. Consider the set of sentences Γ\ndef\n=\n{ψ} ∪{φn | n ≥1} and let ∆be any if its ﬁnite subsets. Let k ≥1 be such\nthat n ≤k for all n with φn ∈∆. Since the latter set is ﬁnite, such a k has to\nexist. By assumption, {ψ, φk} is satisﬁable; but φk →φn is valid for all n ≤k\n(why?). Therefore, ∆is satisﬁable as well. The compactness theorem then\nimplies that Γ is satisﬁable by some model M; in particular, M ⊨ψ holds.\nSince M satisﬁes φn for all n ≥1, it cannot have ﬁnitely many elements. 2\nWe can now show that reachability is not expressible in predicate logic.\nTheorem 2.26 Reachability is not expressible in predicate logic: there is\nno predicate-logic formula φ with u and v as its only free variables and R as\nits only predicate symbol (of arity 2) such that φ holds in directed graphs\niﬀthere is a path in that graph from the node associated to u to the node\nassociated to v.\nPROOF:\nSuppose there is a formula φ expressing the existence of a path\nfrom the node associated to u to the node associated to v. Let c and c′ be\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\n9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\n29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\n(a) ∃x.(x′ ↔(y + y′ · x))\n(b) ∀x.(x′ ↔(y + y′ · x))\n(c) ∃x′.(x′ ↔(y + y′ · x))\n(d) ∀x′.(x′ ↔(y + y′ · x)).\n5. Let ρ be a valuation with ρ(x′\n1) = 1 and ρ(x′\n2) = 0. Determine whether ρ ⊨f\nholds for the following:\n(a) x1[ˆx := ˆx′]\n(b) (x1 + x2)[ˆx := ˆx′]\n(c) (x1 · x2)[ˆx := ˆx′].\n6. Evaluate ρ ⊨(∃x1.(x1 + x2))[ˆx := ˆx′] and explain how the valuation ρ changes\nin that process. In particular, [ˆx := ˆx′] replaces xi by x′\ni, but why does this not\ninterfere with the binding quantiﬁer ∃x1?\n410\n6 Binary decision diagrams\n7. (a) How would you deﬁne the notion of semantic entailment for the relational\nmu-calculus?\n(b) Deﬁne formally when two formulas of the relational mu-calculus are seman-\ntically equivalent.\nExercises 6.15\n1. Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)\nholds, where ρ is\n(a) (x1, x2) ⇒(1, 0)\n(b) (x1, x2) ⇒(0, 1)\n(c) (x1, x2) ⇒(0, 0).\n2. Let S be {s0, s1}, with s0 →s0, s0 →s1 and s1 →s0 as possible transitions\nand L(s0) = {x1} and L(s1) = ∅. Compute the boolean function f EX (EX ¬x1).\n3. Equations (6.17) (page 395), (6.19) and (6.20) deﬁne f EF φ, f AF φ and f EG φ.\nWrite down a similar equation to deﬁne f AG φ.\n4. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately.\n5. Mimic the example checks on page 396 for the connective AU: consider the\nmodel of Figure 6.24 (page 384). Since [[E[(x1 ∨x2) U (¬x1 ∧¬x2)]]] equals the\nentire state set {s0, s1, s2}, your coding of f E[x1∨x2U¬x1∧¬x2] is correct if it\ncomputes 1 for all bit vectors diﬀerent from (1, 1).\n(a) Verify that your coding is indeed correct.\n(b) Find a boolean formula without ﬁxed points which is semantically equiva-\nlent to f E[(x1∨x2)U(¬x1∧¬x2)].\n6. (a) Use (6.20) on page 395 to compute f EG ¬x1 for the model in Figure 6.24.\n(b) Show that f EG ¬x1 faithfully models the set of all states which satisfy\nEG ¬x1.\n7. In the grammar (6.10) for the relational mu-calculus on page 390, it was stated\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nthe equivalence of formulas φ and ψ via ⊨: if φ semantically entails ψ and\nvice versa, then these formulas should be the same as far as our truth-table\nsemantics is concerned.\nDeﬁnition 1.40 Let φ and ψ be formulas of propositional logic. We say\nthat φ and ψ are semantically equivalent iﬀφ ⊨ψ and ψ ⊨φ hold. In that\ncase we write φ ≡ψ. Further, we call φ valid if ⊨φ holds.\nNote that we could also have deﬁned φ ≡ψ to mean that ⊨(φ →ψ) ∧\n(ψ →φ) holds; it amounts to the same concept. Indeed, because of soundness\nand completeness, semantic equivalence is identical to provable equivalence\n1.5 Normal forms\n55\n(Deﬁnition 1.25). Examples of equivalent formulas are\np →q ≡¬q →¬p\np →q ≡¬p ∨q\np ∧q →p ≡r ∨¬r\np ∧q →r ≡p →(q →r).\nRecall that a formula η is called a tautology if ⊨η holds, so the tautologies\nare exactly the valid formulas. The following lemma says that any decision\nprocedure for tautologies is in fact a decision procedure for the validity of\nsequents as well.\nLemma 1.41 Given formulas φ1, φ2, . . . , φn and ψ of propositional logic,\nφ1, φ2, . . . , φn ⊨ψ holds iﬀ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nProof: First, suppose that ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nIf φ1, φ2, . . . , φn are all true under some valuation, then ψ has to be true\nas well for that same valuation. Otherwise,\n⊨φ1 →(φ2 →(φ3 →· · · →\n(φn →ψ))) would not hold (compare this with Figure 1.11). Second, if\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nto be {(a, a), (b, b), (c, c)}. Hence the semantics of equality is easy, for it is\nalways modelled extensionally.\n2.5 Undecidability of predicate logic\nWe continue our introduction to predicate logic with some negative results.\nGiven a formula φ in propositional logic we can, at least in principle, de-\ntermine whether ⊨φ holds: if φ has n propositional atoms, then the truth\ntable of φ contains 2n lines; and ⊨φ holds if, and only if, the column for φ\n(of length 2n) contains only T entries.\nThe bad news is that such a mechanical procedure, working for all for-\nmulas φ, cannot be provided in predicate logic. We will give a formal proof\nof this negative result, though we rely on an informal (yet intuitive) notion\nof computability.\nThe problem of determining whether a predicate logic formula is valid is\nknown as a decision problem. A solution to a decision problem is a program\n(written in Java, C, or any other common language) that takes problem\ninstances as input and always terminates, producing a correct ‘yes’ or ‘no’\noutput. In the case of the decision problem for predicate logic, the input to\nthe program is an arbitrary formula φ of predicate logic and the program\n132\n2 Predicate logic\nis correct if it produces ‘yes’ whenever the input formula is valid and ‘no’\nwhenever it is not. Note that the program which solves a decision problem\nmust terminate for all well-formed input: a program which goes on thinking\nabout it for ever is not allowed. The decision problem at hand is this:\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced (¬p ∨¬q ∨r) ∧(p ∨¬q ∨¬r) ∧(p ∨¬q ∨r) ∧(p ∨q ∨¬r).\nIf we don’t have a full truth table at our disposal, but do know the structure\nof φ, then we would like to compute a version of φ in CNF. It should be\nclear by now that a full truth table of φ and an equivalent formula in\nCNF are pretty much the same thing as far as questions about validity are\nconcerned – although the formula in CNF may be much more compact.\n1.5.2 Conjunctive normal forms and validity\nWe have already seen the beneﬁts of conjunctive normal forms in that they\nallow for a fast and easy syntactic test of validity. Therefore, one wonders\nwhether any formula can be transformed into an equivalent formula in CNF.\nWe now develop an algorithm achieving just that. Note that, by Deﬁni-\ntion 1.40, a formula is valid iﬀany of its equivalent formulas is valid. We\nreduce the problem of determining whether any φ is valid to the problem\nof computing an equivalent ψ ≡φ such that ψ is in CNF and checking, via\nLemma 1.43, whether ψ is valid.\n1.5 Normal forms\n59\nBefore we sketch such a procedure, we make some general remarks about\nits possibilities and its realisability constraints. First of all, there could be\nmore or less eﬃcient ways of computing such normal forms. But even more\nso, there could be many possible correct outputs, for ψ1 ≡φ and ψ2 ≡φ\ndo not generally imply that ψ1 is the same as ψ2, even if ψ1 and ψ2 are in\nCNF. For example, take φ\ndef\n= p, ψ1\ndef\n= p and ψ2\ndef\n= p ∧(p ∨q); then convince\nyourself that φ ≡ψ2 holds. Having this ambiguity of equivalent conjunctive\nnormal forms, the computation of a CNF for φ with minimal ‘cost’ (where\n‘cost’ could for example be the number of conjuncts, or the height of φ’s\nparse tree) becomes a very important practical problem, an issue persued in\nChapter 6. Right now, we are content with stating a deterministic algorithm\nwhich always computes the same output CNF for a given input φ.\nThis algorithm, called CNF, should satisfy the following requirements:\n(1)\nto the distributivity laws, which entitle us to translate any disjunction of\nconjunctions into a conjunction of disjunctions. However, for this to result in\na CNF, we need to make certain that those disjunctions generated contain\nonly literals. We apply a strategy for using distributivity based on matching\npatterns in φ1 ∨φ2. This results in an independent algorithm called DISTR\nwhich will do all that work for us. Thus, we simply call DISTR with the pair\n(η1, η2) as input and pass along its result.\nAssuming that we already have written code for IMPL FREE, NNF and\nDISTR, we may now write pseudo code for CNF:\nfunction CNF (φ):\n/* precondition: φ implication free and in NNF */\n/* postcondition: CNF (φ) computes an equivalent CNF for φ */\nbegin function\ncase\nφ is a literal: return φ\nφ is φ1 ∧φ2 : return CNF (φ1) ∧CNF (φ2)\nφ is φ1 ∨φ2 : return DISTR (CNF (φ1), CNF (φ2))\nend case\nend function\n1.5 Normal forms\n61\nNotice how the calling of DISTR is done with the computed conjunctive nor-\nmal forms of φ1 and φ2. The routine DISTR has η1 and η2 as input parameters\nand does a case analysis on whether these inputs are conjunctions. What\nshould DISTR do if none of its input formulas is such a conjunction? Well,\nsince we are calling DISTR for inputs η1 and η2 which are in CNF, this can\nonly mean that η1 and η2 are literals, or disjunctions of literals. Thus, η1 ∨η2\nis in CNF.\nOtherwise, at least one of the formulas η1 and η2 is a conjunction. Since\none conjunction suﬃces for simplifying the problem, we have to decide which\nconjunct we want to transform if both formulas are conjunctions. That way\nwe maintain that our algorithm CNF is deterministic. So let us suppose that\nη1 is of the form η11 ∧η12. Then the distributive law says that η1 ∨η2 ≡\n(η11 ∨η2) ∧(η12 ∨η2). Since all participating formulas η11, η12 and η2 are\nin CNF, we may call DISTR again for the pairs (η11, η2) and (η12, η2), and\nthen simply form their conjunction. This is the key insight for writing the\nfunction DISTR.\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nseparate layers such that validity checks are easy. This is being done by\n1.\nusing the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of →from a\nformula and\n2.\nby specifying an algorithm that takes a formula without any →into a normal\nform (still without →) for which checking validity is easy.\nNaturally, we have to specify which forms of formulas we think of as being\n‘normal.’ Again, there are many such notions, but in this text we study only\ntwo important ones.\nDeﬁnition 1.42 A literal L is either an atom p or the negation of an atom\n¬p. A formula C is in conjunctive normal form (CNF) if it is a conjunction\nof clauses, where each clause D is a disjunction of literals:\nL ::= p | ¬p\nD ::= L | L ∨D\n(1.6)\nC ::= D | D ∧C.\n56\n1 Propositional logic\nExamples of formulas in conjunctive normal form are\n(i)\n(¬q ∨p ∨r) ∧(¬p ∨r) ∧q\n(ii)\n(p ∨r) ∧(¬p ∨r) ∧(p ∨¬r).\nIn the ﬁrst case, there are three clauses of type D: ¬q ∨p ∨r, ¬p ∨r, and q –\nwhich is a literal promoted to a clause by the ﬁrst rule of clauses in (1.6).\nNotice how we made implicit use of the associativity laws for ∧and ∨,\nsaying that φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η and φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η, since\nwe omitted some parentheses. The formula (¬(q ∨p) ∨r) ∧(q ∨r) is not in\nCNF since q ∨p is not a literal.\nWhy do we care at all about formulas φ in CNF? One of the reasons\nfor their usefulness is that they allow easy checks of validity which other-\nwise take times exponential in the number of atoms. For example, consider\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nof literals, or literals, we can settle the matter as follows.\nLemma 1.43 A disjunction of literals L1 ∨L2 ∨· · · ∨Lm is valid iﬀthere\nare 1 ≤i, j ≤m such that Li is ¬Lj.\nProof: If Li equals ¬Lj, then L1 ∨L2 ∨· · · ∨Lm evaluates to T for all\nvaluations. For example, the disjunct p ∨q ∨r ∨¬q can never be made false.\nTo see that the converse holds as well, assume that no literal Lk has a\nmatching negation in L1 ∨L2 ∨· · · ∨Lm. Then, for each k with 1 ≤k ≤n,\nwe assign F to Lk, if Lk is an atom; or T, if Lk is the negation of an atom.\nFor example, the disjunct ¬q ∨p ∨r can be made false by assigning F to p\nand r and T to q.\n2\nHence, we have an easy and fast check for the validity of ⊨φ, provided\nthat φ is in CNF; inspect all conjuncts ψk of φ and search for atoms in ψk\nsuch that ψk also contains their negation. If such a match is found for all\nconjuncts, we have ⊨φ. Otherwise (= some conjunct contains no pair Li and\n¬Li), φ is not valid by the lemma above. Thus, the formula (¬q ∨p ∨r) ∧\n(¬p ∨r) ∧q above is not valid. Note that the matching literal has to be found\nin the same conjunct ψk. Since there is no free lunch in this universe, we can\nexpect that the computation of a formula φ′ in CNF, which is equivalent to\na given formula φ, is a costly worst-case operation.\nBefore we study how to compute equivalent conjunctive normal forms, we\nintroduce another semantic concept closely related to that of validity.\n1.5 Normal forms\n57\nDeﬁnition 1.44 Given a formula φ in propositional logic, we say that φ is\nsatisﬁable if it has a valuation in which is evaluates to T.\nFor example, the formula p ∨q →p is satisﬁable since it computes T if we\nassign T to p. Clearly, p ∨q →p is not valid. Thus, satisﬁability is a weaker\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\n(e) Cancer will not be cured unless its cause is determined and a new drug for\ncancer is found.\n(f) If interest rates go up, share prices go down.\n(g) If Smith has installed central heating, then he has sold his car or he has not\npaid his mortgage.\n(h)\n*\nToday it will rain or shine, but not both.\n(i)\n*\nIf Dick met Jane yesterday, they had a cup of coﬀee together, or they took\na walk in the park.\n(j) No shoes, no shirt, no service.\n(k) My sister wants a black and white cat.\n2. The formulas of propositional logic below implicitly assume the binding priorities\nof the logical connectives put forward in Convention 1.3. Make sure that you fully\nunderstand those conventions by reinserting as many brackets as possible. For\nexample, given p ∧q →r, change it to (p ∧q) →r since ∧binds more tightly\nthan →.\n(a)\n*\n¬p ∧q →r\n(b) (p →q) ∧¬(r ∨p →q)\n(c)\n*\n(p →q) →(r →s ∨t)\n(d) p ∨(¬q →p ∧r)\n(e)\n*\np ∨q →¬p ∧r\n(f) p ∨p →¬q\n(g)\n*\nWhy is the expression p ∨q ∧r problematic?\nExercises 1.2\n1. Prove the validity of the following sequents:\n(a) (p ∧q) ∧r, s ∧t ⊢q ∧s\n1.7 Exercises\n79\n(b) p ∧q ⊢q ∧p\n(c)\n*\n(p ∧q) ∧r ⊢p ∧(q ∧r)\n(d) p →(p →q), p ⊢q\n(e)\n*\nq →(p →r), ¬r, q ⊢¬p\n(f)\n*\n⊢(p ∧q) →p\n(g) p ⊢q →(p ∧q)\n(h)\n*\np ⊢(p →q) →q\n(i)\n*\n(p →r) ∧(q →r) ⊢p ∧q →r\n(j)\n*\nq →r ⊢(p →q) →(p →r)\n(k) p →(q →r), p →q ⊢p →r\n(l)\n*\np →q, r →s ⊢p ∨r →q ∨s\n(m) p ∨q ⊢r →(p ∨q) ∧r\n(n)\n*\n(p ∨(q →p)) ∧q ⊢p\n(o)\n*\np →q, r →s ⊢p ∧r →q ∧s\n(p) p →q ⊢((p ∧q) →p) ∧(p →(p ∧q))\n(q) ⊢q →(p →(p →(q →p)))\n(r)\n*\np →q ∧r ⊢(p →q) ∧(p →r)\n(s) (p →q) ∧(p →r) ⊢p →q ∧r\n(t) ⊢(p →q) →((r →s) →(p ∧r →q ∧s)); here you might be able to ‘recycle’\nand augment a proof from a previous exercise.\n(u) p →q ⊢¬q →¬p\n(v)\n*\np ∨(p ∧q) ⊢p\n(w) r, p →(r →q) ⊢p →(q ∧r)\n(x)\n*\np →(q ∨r), q →s, r →s ⊢p →s\n(y)\n*\n(p ∧q) ∨(p ∧r) ⊢p ∧(q ∨r).\n2. For the sequents below, show which ones are valid and which ones aren’t:\n(a)\n*\n¬p →¬q ⊢q →p\n(b)\n*\n¬p ∨¬q ⊢¬(p ∧q)\n(c)\n*\n¬p, p ∨q ⊢q\n(d)\n*\np ∨q, ¬q ∨r ⊢p ∨r\n(e)\n*\np →(q ∨r), ¬q, ¬r ⊢¬p without using the MT rule\n(f)\n* ciding their satisﬁability. One such example is the class of Horn formu-\nlas; the name ‘Horn’ is derived from the logician A. Horn’s last name.\nWe shortly deﬁne them and give an algorithm for checking their satisﬁ-\nability.\nRecall that the logical constants ⊥(‘bottom’) and ⊤(‘top’) denote an\nunsatisﬁable formula, respectively, a tautology.\nDeﬁnition 1.46 A Horn formula is a formula φ of propositional logic if it\ncan be generated as an instance of H in this grammar:\nP ::= ⊥| ⊤| p\nA ::= P | P ∧A\nC ::= A →P\nH ::= C | C ∧H.\n(1.7)\nWe call each instance of C a Horn clause.\n66\n1 Propositional logic\nHorn formulas are conjunctions of Horn clauses. A Horn clause is an impli-\ncation whose assumption A is a conjunction of propositions of type P and\nwhose conclusion is also of type P. Examples of Horn formulas are\n(p ∧q ∧s →p) ∧(q ∧r →p) ∧(p ∧s →s)\n(p ∧q ∧s →⊥) ∧(q ∧r →p) ∧(⊤→s)\n(p2 ∧p3 ∧p5 →p13) ∧(⊤→p5) ∧(p5 ∧p11 →⊥).\nExamples of formulas which are not Horn formulas are\n(p ∧q ∧s →¬p) ∧(q ∧r →p) ∧(p ∧s →s)\n(p ∧q ∧s →⊥) ∧(¬q ∧r →p) ∧(⊤→s)\n(p2 ∧p3 ∧p5 →p13 ∧p27) ∧(⊤→p5) ∧(p5 ∧p11 →⊥)\n(p2 ∧p3 ∧p5 →p13 ∧p27) ∧(⊤→p5) ∧(p5 ∧p11 ∨⊥).\nThe ﬁrst formula is not a Horn formula since ¬p, the conclusion of the\nimplication of the ﬁrst conjunct, is not of type P. The second formula does\nnot qualify since the premise of the implication of the second conjunct,\n¬q ∧r, is not a conjunction of atoms, ⊥, or ⊤. The third formula is not a\nHorn formula since the conclusion of the implication of the ﬁrst conjunct,\np13 ∧p27, is not of type P. The fourth formula clearly is not a Horn formula\nsince it is not a conjunction of implications.\nThe algorithm we propose for deciding the satisﬁability of a Horn for-\nmula φ maintains a list of all occurrences of type P in φ and proceeds like\nthis:\n1.\nIt marks ⊤if it occurs in that list.\n2.\nIf there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ such that all Pj with 1 ≤j ≤\nki are marked, mark P ′ as well and go to 2. Otherwise (= there is no conjunct\ncorrect replies. First, if ⊥is marked, then there has to be some conjunct\nP1 ∧P2 ∧· · · ∧Pki →⊥of φ such that all Pi are marked as well. By (1.8)\nthat conjunct of φ evaluates to T →F = F whenever φ is true. As this is\nimpossible the reply ‘unsatisﬁable’ is correct. Second, if ⊥is not marked, we\nsimply assign T to all marked atoms and F to all unmarked atoms and use\nproof by contradiction to show that φ has to be true with respect to that\nvaluation.\nIf φ is not true under that valuation, it must make one of its principal\nconjuncts P1 ∧P2 ∧· · · ∧Pki →P ′ false. By the semantics of implication\nthis can only mean that all Pj are true and P ′ is false. By the deﬁnition of our\nvaluation, we then infer that all Pj are marked, so P1 ∧P2 ∧· · · ∧Pki →P ′\nis a conjunct of φ that would have been dealt with in one of the cycles of\nthe while-statement and so P ′ is marked, too. Since ⊥is not marked, P ′ has\nto be ⊤or some atom q. In any event, the conjunct is then true by (1.8), a\ncontradiction\n2\nNote that the proof by contradiction employed in the last proof was not\nreally needed. It just made the argument seem more natural to us. The\nliterature is full of such examples where one uses proof by contradiction\nmore out of psychological than proof-theoretical necessity.\n1.6 SAT solvers\nThe marking algorithm for Horn formulas computes marks as constraints\non all valuations that can make a formule true. By (1.8), all marked atoms\nhave to be true for any such valuation. We can extend this idea to general\nformulas φ by computing constraints saying which subformulas of φ require\na certain truth value for all valuations that make φ true:\n‘All marked subformulas evaluate to their mark value\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\n(a)\n*\n(p ∧q ∧w →⊥) ∧(t →⊥) ∧(r →p) ∧(⊤→r) ∧(⊤→q) ∧(u →\ns) ∧(⊤→u)\n(b) (p ∧q ∧w →⊥) ∧(t →⊥) ∧(r →p) ∧(⊤→r) ∧(⊤→q) ∧(r ∧u →\nw) ∧(u →s) ∧(⊤→u)\n(c) (p ∧q ∧s →p) ∧(q ∧r →p) ∧(p ∧s →s)\n(d) (p ∧q ∧s →⊥) ∧(q ∧r →p) ∧(⊤→s)\n(e) (p5 →p11) ∧(p2 ∧p3 ∧p5 →p13) ∧(⊤→p5) ∧(p5 ∧p11 →⊥)\n(f) (⊤→q) ∧(⊤→s) ∧(w →⊥) ∧(p ∧q ∧s →⊥) ∧(v →s) ∧(⊤→\nr) ∧(r →p)\n90\n1 Propositional logic\n(g)\n*\n(⊤→q) ∧(⊤→s) ∧(w →⊥) ∧(p ∧q ∧s →v) ∧(v →s) ∧(⊤→\nr) ∧(r →p).\n16. Explain why the algorithm HORN fails to work correctly if we change the concept\nof Horn formulas by extending the clause for P on page 65 to P ::= ⊥| ⊤|\np | ¬p?\n17. What can you say about the CNF of Horn formulas. More precisely, can you\nspecify syntactic criteria for a CNF that ensure that there is an equivalent Horn\nformula? Can you describe informally programs which would translate from one\nform of representation into another?\nExercises 1.6\n1. Use mathematical induction to show that, for all φ of (1.3) on page 33,\n(a) T(φ) can be generated by (1.10) on page 69,\n(b) T(φ) has the same set of valuations as φ, and\n(c) the set of valuations in which φ is true equals the set of valuations in which\nT(φ) is true.\n2.\n*\nShow that all rules of Figure 1.14 (page 71) are sound: if all current marks\nsatisfy the invariant (1.9) from page 68, then this invariant still holds if the\nderived constraint of that rule becomes an additional mark.\n3. In Figure 1.16 on page 73 we detected a contradiction which secured the validity\nof the sequent p ∧q →r ⊢p →q →r. Use the same method with the linear SAT\nsolver to show that the sequent ⊢(p →q) ∨(r →p) is valid. (This is interest-\ning since we proved this validity in natural deduction with a judicious choice\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nlaws to it, and extract a witness to the DAG’s satisﬁability. Explain in what\nsense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is\nnot valid.\n5. Explain in what sense the SAT solving technique, as presented in this chapter,\ncan be used to check whether formulas are tautologies.\n6. For φ from (1.10), can one reverse engineer φ from the DAG of T(φ)?\n7. Consider a modiﬁcation of our method which initially tags a DAG’s root node\nwith ‘1: F.’ In that case,\n(a) are the forcing laws still sound? If so, state the invariant.\n(b) what can we say about the formula(s) a DAG represents if\ni. we detect contradictory constraints?\nii. we compute consistent forced constraints for each node?\n8. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied\nto T(φ) –\nto the marking algorithm – applied to φ. Discuss similarities and\ndiﬀerences of these approaches.\n1.8 Bibliographic notes\n91\n9. Consider Figure 1.20 on page 77. Verify that\n(a) its test produces contradictory constraints\n(b) its cubic analysis does not decide satisﬁability, regardless of whether the\ntwo optimizations we described are present.\n10. Verify that the DAG of Figure 1.17 (page 74) is indeed the one obtained for\nT(φ), where φ is the formula in (1.11) on page 73.\n11.\n*\nAn implementor may be concerned with the possibility that the answers to the\ncubic SAT solver may depend on a particular order in which we test unmarked\nnodes or use the rules in Figure 1.14. Give a semi-formal argument for why the\nanalysis results don’t depend on such an order.\n12. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability\nof T(φ).\n13. Advanced Project: Write a complete implementation of the cubic SAT solver\nmula φ maintains a list of all occurrences of type P in φ and proceeds like\nthis:\n1.\nIt marks ⊤if it occurs in that list.\n2.\nIf there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ such that all Pj with 1 ≤j ≤\nki are marked, mark P ′ as well and go to 2. Otherwise (= there is no conjunct\nP1 ∧P2 ∧· · · ∧Pki →P ′ such that all Pj are marked) go to 3.\n3.\nIf ⊥is marked, print out ‘The Horn formula φ is unsatisﬁable.’ and stop. Oth-\nerwise, go to 4.\n4.\nPrint out ‘The Horn formula φ is satisﬁable.’ and stop.\nIn these instructions, the markings of formulas are shared by all other oc-\ncurrences of these formulas in the Horn formula. For example, once we\nmark p2 because of one of the criteria above, then all other occurrences\nof p2 are marked as well. We use pseudo code to specify this algorithm\nformally:\n1.5 Normal forms\n67\nfunction HORN (φ):\n/* precondition: φ is a Horn formula */\n/* postcondition: HORN (φ) decides the satisﬁability for φ */\nbegin function\nmark all occurrences of ⊤in φ;\nwhile there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ\nsuch that all Pj are marked but P ′ isn’t do\nmark P ′\nend while\nif ⊥is marked then return ‘unsatisﬁable’ else return ‘satisﬁable’\nend function\nWe need to make sure that this algorithm terminates on all Horn formulas\nφ as input and that its output (= its decision) is always correct.\nTheorem 1.47 The algorithm HORN is correct for the satisﬁability decision\nproblem of Horn formulas and has no more than n + 1 cycles in its while-\nstatement if n is the number of atoms in φ. In particular, HORN always\nterminates on correct input.\nProof: Let us ﬁrst consider the question of program termination. Notice\nthat entering the body of the while-statement has the eﬀect of marking an\nunmarked P which is not ⊤. Since this marking applies to all occurrences\nof P in φ, the while-statement can have at most one more cycle than there\nare atoms in φ.\nSince we guaranteed termination, it suﬃces to show that the answers\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nWhen we applied our linear SAT solver, we saw two possible outcomes:\nwe either detected contradictory constraints, meaning that no formula rep-\nresented by the DAG is satisﬁable (e.g. Fig. 1.16); or we managed to force\nconsistent constraints on all nodes, in which case all formulas represented by\nthis DAG are satisﬁable with those constraints as a witness (e.g. Fig. 1.13).\nUnfortunately, there is a third possibility: all forced constraints are consis-\ntent with each other, but not all nodes are constrained! We already remarked\nthat this occurs for formulas of the form ¬(φ1 ∧φ2).\n1.6 SAT solvers\n73\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n1: T\n2: F\n3: T\n4: T\n4: T\n5: F\n6: T\n5: F\n7: T\n8: F\n9: T\n11: F\n10: T\n10: T\n7: T\nits conjunction parent\n– a contradiction\nand ∧frr force F\nits children and\n∧ti force T\nFigure 1.16. The forcing rules, applied to the DAG of Figure 1.15,\ndetect contradictory constraints at the indicated node – implying that\nthe initial constraint ‘1:T’ cannot be realized. Thus, formulas represented\nby this DAG are not satisfiable.\nRecall that checking validity of formulas in CNF is very easy. We already\nhinted at the fact that checking satisﬁability of formulas in CNF is hard. To\nillustrate, consider the formula\n((p ∨(q ∨r)) ∧((p ∨¬q) ∧((q ∨¬r) ∧((r ∨¬p) ∧(¬p ∨(¬q ∨¬r))))))\n(1.11)\nin CNF – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula\nshould not be satisﬁable. The ﬁrst and last clause in (1.11) ‘say’ that at least\none of p, q, and r are false and true (respectively). The remaining three\nclauses, in their conjunction, ‘say’ that p, q, and r all have the same truth\nvalue. This cannot be satisﬁable, and a good SAT solver should discover\nunmarked P which is not ⊤. Since this marking applies to all occurrences\nof P in φ, the while-statement can have at most one more cycle than there\nare atoms in φ.\nSince we guaranteed termination, it suﬃces to show that the answers\ngiven by the algorithm HORN are always correct. To that end, it helps to\nreveal the functional role of those markings. Essentially, marking a P means\nthat that P has got to be true if the formula φ is ever going to be satisﬁable.\nWe use mathematical induction to show that\n‘All marked P are true for all valuations in which φ evaluates to T.’ (1.8)\nholds after any number of executions of the body of the while-statement\nabove. The base case, zero executions, is when the while-statement has not\nyet been entered but we already and only marked all occurrences of ⊤. Since\n⊤must be true in all valuations, (1.8) follows.\nIn the inductive step, we assume that (1.8) holds after k cycles of the\nwhile-statement. Then we need to show that same assertion for all marked\nP after k + 1 cycles. If we enter the (k + 1)th cycle, the condition of the\nwhile-statement is certainly true. Thus, there exists a conjunct P1 ∧P2 ∧\n· · · ∧Pki →P ′ of φ such that all Pj are marked. Let v be any valuation\n68\n1 Propositional logic\nin which φ is true. By our induction hypothesis, we know that all Pj and\ntherefore P1 ∧P2 ∧· · · ∧Pki have to be true in v as well. The conjunct P1 ∧\nP2 ∧· · · ∧Pki →P ′ of φ has be to true in v, too, from which we infer that\nP ′ has to be true in v.\nBy mathematical induction, we therefore secured that (1.8) holds no mat-\nter how many cycles that while-statement went through.\nFinally, we need to make sure that the if-statement above always renders\ncorrect replies. First, if ⊥is marked, then there has to be some conjunct\nP1 ∧P2 ∧· · · ∧Pki →⊥of φ such that all Pi are marked as well. By (1.8)\nthat conjunct of φ evaluates to T →F = F whenever φ is true. As this is\nimpossible the reply ‘unsatisﬁable’ is correct. Second, if ⊥is not marked, we\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver",
            "summary": "1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built u",
            "children": [
                {
                    "id": "chapter-1-section-1",
                    "title": "Declarative Sentences",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-2",
                    "title": "Natural Deduction",
                    "content": "1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\n1.2.3 Natural deduction in summary\nThe proof rules for natural deduction are summarised in Figure 1.2. The\nexplanation of the rules we have given so far in this chapter is declarative;\nwe have presented each rule and justiﬁed it in terms of our intuition about\nthe logical connectives. However, when you try to use the rules yourself,\nyou’ll ﬁnd yourself looking for a more procedural interpretation; what does\na rule do and how do you use it? For example,\nr ∧i says: to prove φ ∧ψ, you must ﬁrst prove φ and ψ separately and then use\nthe rule ∧i.\nr ∧e1 says: to prove φ, try proving φ ∧ψ and then use the rule ∧e1. Actually,\nthis doesn’t sound like very good advice because probably proving φ ∧ψ will\nbe harder than proving φ alone. However, you might ﬁnd that you already have\nφ ∧ψ lying around, so that’s when this rule is useful. Compare this with the\nexample sequent in Example 1.15.\nr ∨i1 says: to prove φ ∨ψ, try proving φ. Again, in general it is harder to prove\nφ than it is to prove φ ∨ψ, so this will usually be useful only if you’ve already\nmanaged to prove φ. For example, if you want to prove q |−p ∨q, you certainly\nwon’t be able simply to use the rule ∨i1, but ∨i2 will work.\nr ∨e has an excellent procedural interpretation. It says: if you have φ ∨ψ, and you\nwant to prove some χ, then try to prove χ from φ and from ψ in turn. (In those\nsubproofs, of course you can use the other prevailing premises as well.)\nr Similarly, →i says, if you want to prove φ →ψ, try proving ψ from φ (and the\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nour reasoning is concerned about the inference, and therefore the preserva-\ntion, of truth. Hence, there cannot be a direct way of inferring ¬φ, given\nφ.\nDeﬁnition 1.19 Contradictions are expressions of the form φ ∧¬φ or ¬φ ∧\nφ, where φ is any formula.\nExamples of such contradictions are r ∧¬r, (p →q) ∧¬(p →q) and ¬(r ∨\ns →q) ∧(r ∨s →q). Contradictions are a very important notion in logic.\nAs far as truth is concerned, they are all equivalent; that means we should\nbe able to prove the validity of\n¬(r ∨s →q) ∧(r ∨s →q) ⊣⊢(p →q) ∧¬(p →q)\n(1.2)\nsince both sides are contradictions. We’ll be able to prove this later, when\nwe have introduced the rules for negation.\nIndeed, it’s not just that contradictions can be derived from contradic-\ntions; actually, any formula can be derived from a contradiction. This can be\n1.2 Natural deduction\n21\nconfusing when you ﬁrst encounter it; why should we endorse the argument\np ∧¬p ⊢q, where\np : The moon is made of green cheese.\nq : I like pepperoni on my pizza.\nconsidering that our taste in pizza doesn’t have anything to do with the\nconstitution of the moon? On the face of it, such an endorsement may seem\nabsurd. Nevertheless, natural deduction does have this feature that any for-\nmula can be derived from a contradiction and therefore it makes this argu-\nment valid. The reason it takes this stance is that ⊢tells us all the things\nwe may infer, provided that we can assume the formulas to the left of it.\nThis process does not care whether such premises make any sense. This has\nat least the advantage that we can match ⊢to checks based on semantic\nintuitions which we formalise later by using truth tables: if all the premises\ncompute to ‘true’, then the conclusion must compute ‘true’ as well. In partic-\nan implication. Suppose that p →q and ¬q are the case. Then, if p holds\nwe can use →e to conclude that q holds. Thus, we then have that q and ¬q\nhold, which is impossible. Therefore, we may infer that p must be false. But\nthis can only mean that ¬p is true. We summarise this reasoning into the\nrule modus tollens, or MT for short:5\nφ →ψ\n¬ψ\n¬φ\nMT.\nAgain, let us see an example of this rule in the natural language setting:\n‘If Abraham Lincoln was Ethiopian, then he was African. Abraham\nLincoln was not African; therefore he was not Ethiopian.’\nExample 1.7 In the following proof of\np →(q →r), p, ¬r ⊢¬q\nwe use several of the rules introduced so far:\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq →r\n→e 1, 2\n5\n¬q\nMT 4, 3\n5 We will be able to derive this rule from other ones later on, but we introduce it here because it\nallows us already to do some pretty slick proofs. You may think of this rule as one on a higher\nlevel insofar as it does not mention the lower-level rules upon which it depends.\n1.2 Natural deduction\n11\nExamples 1.8 Here are two example proofs which combine the rule MT\nwith either ¬¬e or ¬¬i:\n1\n¬p →q\npremise\n2\n¬q\npremise\n3\n¬¬p\nMT 1, 2\n4\np\n¬¬e 3\nproves that the sequent ¬p →q, ¬q ⊢p is valid; and\n1\np →¬q\npremise\n2\nq\npremise\n3\n¬¬q\n¬¬i 2\n4\n¬p\nMT 1, 3\nshows the validity of the sequent p →¬q, q ⊢¬p.\nNote that the order of applying double negation rules and MT is diﬀerent\nin these examples; this order is driven by the structure of the particular\nsequent whose validity one is trying to show.\nThe rule implies introduction\nThe rule MT made it possible for us to\nshow that p →q, ¬q ⊢¬p is valid. But the validity of the sequent p →q ⊢\n¬q →¬p seems just as plausible. That sequent is, in a certain sense, saying\nthe same thing. Yet, so far we have no rule which builds implications that\ndo not already occur as premises in our proofs. The mechanics of such a rule\nare more involved than what we have seen so far. So let us proceed with\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nExample 1.4 Let’s use these rules to prove that p ∧q, r |−q ∧r is valid.\nWe start by writing down the premises; then we leave a gap and write the\n1.2 Natural deduction\n7\nconclusion:\np ∧q\nr\nq ∧r\nThe task of constructing the proof is to ﬁll the gap between the premises\nand the conclusion by applying a suitable sequence of proof rules. In this\ncase, we apply ∧e2 to the ﬁrst premise, giving us q. Then we apply ∧i to this\nq and to the second premise, r, giving us q ∧r. That’s it! We also usually\nnumber all the lines, and write in the justiﬁcation for each line, producing\nthis:\n1\np ∧q\npremise\n2\nr\npremise\n3\nq\n∧e2 1\n4\nq ∧r\n∧i 3, 2\nDemonstrate to yourself that you’ve understood this by trying to show on\nyour own that (p ∧q) ∧r, s ∧t |−q ∧s is valid. Notice that the φ and ψ can\nbe instantiated not just to atomic sentences, like p and q in the example we\njust gave, but also to compound sentences. Thus, from (p ∧q) ∧r we can\ndeduce p ∧q by applying ∧e1, instantiating φ to p ∧q and ψ to r.\nIf we applied these proof rules literally, then the proof above would actu-\nally be a tree with root q ∧r and leaves p ∧q and r, like this:\np ∧q\n∧e2\nq\nr\n∧i\nq ∧r\nHowever, we ﬂattened this tree into a linear presentation which necessitates\nthe use of pointers as seen in lines 3 and 4 above. These pointers allow\nus to recreate the actual proof tree. Throughout this text, we will use the\nﬂattened version of presenting proofs. That way you have to concentrate only\non ﬁnding a proof, not on how to ﬁt a growing tree onto a sheet of paper.\nIf a sequent is valid, there may be many diﬀerent ways of proving it. So if\nyou compare your solution to these exercises with those of others, they need\nnot coincide. The important thing to realise, though, is that any putative 1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25 1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nsumed or given as a premise some formula η1 ∨η2 in some line k′ with\nk′ < k, which was referred to via ∨e in the justiﬁcation of line k. Thus,\nwe have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within that\nproof, obtained by turning all assumptions of boxes that are open at\nline k′ into premises. In a similar way we obtain proofs of the sequents\nφ1, φ2, . . . , φn, η1 ⊢ψ and φ1, φ2, . . . , φn, η2 ⊢ψ from the case analysis of ∨e.\nBy our induction hypothesis, we conclude that the relations φ1, φ2, . . . , φn ⊨\nη1 ∨η2, φ1, φ2, . . . , φn, η1 ⊨ψ and φ1, φ2, . . . , φn, η2 ⊨ψ hold. But together\nthese three relations then force that φ1, φ2, . . . , φn ⊨ψ holds as well –\nwhy?\n3.\nYou can guess by now that the rest of the argument checks each possible proof\nrule in turn and ultimately boils down to verifying that our natural deduction\n1.4 Semantics of propositional logic\n49\nrules behave semantically in the same way as their corresponding truth tables\nevaluate. We leave the details as an exercise.\n2\nThe soundness of propositional logic is useful in ensuring the non-existence of\na proof for a given sequent. Let’s say you try to prove that φ1, φ2, . . . , φ2 ⊢ψ\nis valid, but that your best eﬀorts won’t succeed. How could you be sure that\nno such proof can be found? After all, it might just be that you can’t ﬁnd\na proof even though there is one. It suﬃces to ﬁnd a valuation in which φi\nevaluate to T whereas ψ evaluates to F. Then, by deﬁnition of ⊨, we don’t\nhave φ1, φ2, . . . , φ2 ⊨ψ. Using soundness, this means that φ1, φ2, . . . , φ2 ⊢ψ\ncannot be valid. Therefore, this sequent does not have a proof. You will\npractice this method in the exercises.\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nφ ∨ψ\n∨i1\nψ\nφ ∨ψ\n∨i2\nφ ∨ψ\nφ\n...\nχ\nψ\n...\nχ\nχ\n∨e\n→\nφ\n...\nψ\nφ →ψ\n→i\nφ\nφ →ψ\nψ\n→e\n¬\nφ\n...\n⊥\n¬φ\n¬i\nφ\n¬φ\n⊥\n¬e\n⊥\n(no introduction rule for ⊥)\n⊥\nφ\n⊥e\n¬¬\n¬¬φ\nφ\n¬¬e\nSome useful derived rules:\nφ →ψ\n¬ψ\n¬φ\nMT\nφ\n¬¬φ\n¬¬i\n¬φ\n...\n⊥\nφ\nPBC\nφ ∨¬φ\nLEM\nFigure 1.2. Natural deduction rules for propositional logic.\n28\n1 Propositional logic\nAt any stage of a proof, it is permitted to introduce any formula as as-\nsumption, by choosing a proof rule that opens a box. As we saw, natural\ndeduction employs boxes to control the scope of assumptions. When an as-\nsumption is introduced, a box is opened. Discharging assumptions is achieved\nby closing a box according to the pattern of its particular proof rule. It’s\nuseful to make assumptions by opening boxes. But don’t forget you have to\nclose them in the manner prescribed by their proof rule.\nOK, but how do we actually go about constructing a proof?\nGiven a sequent, you write its premises at the top of your page and\nits conclusion at the bottom. Now, you’re trying to ﬁll in the gap,\nwhich involves working simultaneously on the premises (to bring them to-\nwards the conclusion) and on the conclusion (to massage it towards the\npremises).\nLook ﬁrst at the conclusion. If it is of the form φ →ψ, then apply6 the\nrule →i. This means drawing a box with φ at the top and ψ at the bottom.\nSo your proof, which started out like this:\n...\npremises\n...\nφ →ψ\nnow looks like this:\n...\npremises\n...\nφ\nassumption\nψ\nφ →ψ\n→i\nYou still have to ﬁnd a way of ﬁlling in the gap between the φ and the ψ.\nBut you now have an extra formula to work with and you have simpliﬁed\nthe conclusion you are trying to reach.\n6 Except in situations such as p →(q →¬r), p ⊢q →¬r where →e produces a simpler proof.\n1.2 Natural deduction\n29\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules. the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne of proof, which states rules for transforming valid sequents into valid sequents.\nFor example, if we have already a proof for the sequent Γ, φ ⊢ψ, then we ob-\ntain a proof of the sequent Γ ⊢φ →ψ by augmenting this very proof with one\napplication of the rule →i. The new approach expresses this as an inference rule\nbetween sequents:\nΓ, φ ⊢ψ\nΓ ⊢φ →ψ →i.\nThe rule ‘assumption’ is written as\nφ ⊢φ assumption\ni.e. the premise is empty. Such rules are called axioms.\n(a) Express all remaining proof rules of Figure 1.2 in such a form. (Hint: some\nof your rules may have more than one premise.)\n(b) Explain why proofs of Γ ⊢ψ in this new system have a tree-like structure\nwith Γ ⊢ψ as root.\n(c) Prove p ∨(p ∧q) ⊢p in your new proof system.\n1.7 Exercises\n81\n7. Show that\n√\n2 cannot be a rational number. Proceed by proof by contradiction:\nassume that\n√\n2 is a fraction k/l with integers k and l ̸= 0. On squaring both sides\nwe get 2 = k2/l2, or equivalently 2l2 = k2. We may assume that any common 2\nfactors of k and l have been cancelled. Can you now argue that 2l2 has a diﬀerent\nnumber of 2 factors from k2? Why would that be a contradiction and to what?\n8. There is an alternative approach to treating negation. One could simply ban the\noperator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally,\nsuch a logic cannot rely on the natural deduction rules for negation. Which of\nthe rules ¬i, ¬e, ¬¬e and ¬¬i can you simulate with the remaining proof rules\nby letting ¬φ be φ →⊥?\n9. Let us introduce a new connective φ ↔ψ which should abbreviate (φ →ψ) ∧\n(ψ →φ). Design introduction and elimination rules for ↔and show that they\nare derived rules if φ ↔ψ is interpreted as (φ →ψ) ∧(ψ →φ).\nExercises 1.3\nIn order to facilitate reading these exercises we assume below the usual\nconventions about binding priorities agreed upon in Convention 1.3.\n1. Given the following formulas, draw their corresponding parse tree:\n(a) p\n(b)\n*\np ∧q\n(c) p ∧¬q →¬p\n(d)\n*\np ∧(¬q →¬p)\n(e) p →(¬q ∨(q →p))\n(f)",
                    "summary": "The elimination rules break (p) up into its atomic constituents p, qand r. The introduction rules then built up the formula p ∨(q ∨r). 1.1 Humanitarian deduction. 1.2 Natural deduction. 2. Humanitarian theory. 3. Theory of natural deduction. 4. Natural deduction theory. 5. The Theory of Natural Deduction. 6. The theory of natural deduction. 7. Natural deduction theory. 8. Natural deductives. 9. Natural deductions. 10. Natural  deduction  theory. 11. A ﬁnal rule is required in order to allow us to conclude a box with a for-mula which has already appeared earlier in the proof. The rule ‘copy’ allows us to repeat something that we know already. We need to do this in this example, because the rule →i requires that we end the inner box with p. The copy rule entitles us to copy formulas that appeared before,unless they depend on temporary assumptions whose box has already been closed. The following proof is a proof of the validity of the ‘converse’ (p ∧q) and you are encouraged to show it yourself. The proof is based on the following: The proof rules for natural deduction are summarised in Figure 1.2. The rules for negation involve the notion of contradiction. It can be diﬃcult to decide which instance of LEM would beneﬁt the progress of a proof. Can you re-do the example above with q ∨¬q as LEM? Can you do the same thing with q∨i? Can we use premises or any other ‘visible’ formulas, more than once? Can a proof be proved using a single negation or a series of negations? Can an argument be proved by using multiple negations or multiple premises? Can it be proven by using premises or other 'visible' formulas The rules have an excellent procedural interpretation. However, when you try to use the rules yourself, you’ll find yourself looking for a more procedural interpretation; what does                a rule do and how do you use it? For example, to prove φ, try proving φ and ψ separately and then use                the rule  in Example 1.15. The rules are written in the form of a list of rules, starting with the first one and ending with the last one. The first rule is called the ‘proving’ rule, the second is called ‘exercising’ the rules, and the third is ‘using the rules’. The basic rules of natural deduction:introduction, elimination, and derivation. Show that the following sequents are not valid by ﬁnding a valuation in which the truth values of the formulas to the left of ⊢are T and the truth value of the formula to the right of F is F. See Figure 1.2 on page 27 to see which cases are still missing, and to see how to use the rules in the rest of the book. See page 27 for the summary of the rules of deduction in the book, as well as a list of examples and examples of how to apply the rules to the real world. The book is published by Oxford University Press, London. Find a formula of propositional logic which contains only the atoms p, q and r and which is true only when p and q are false. Prove the validity of the following sequents needed to secure the completeness of the formula. Use mathematical induction on n to prove the theorem. Use the following examples of natural language to test the correctness of the formulas. For each example, give examples of sentences such that the premises are true, but the conclusion is false. For example, given the premises p,q and r, give the sentences: p →q ⊢p ∨q(d) p →(q ∨r) ≢(p →q) (d) (p →r) An adequate set of connectives for propositional logic is a set such that there is an equivalent formula with only connectives from that set. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an instance of LEM. Does ⊨φ hold for the φ below? Please justify your answer. Exercises 1.5 and 2.5 are based on the definition of the set {¬, ∨} and the set of propositional connectives. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This intention is right-associative: expressions of the form p →q →r denote p →(q → r) In Examples 1.1 and 1.2, we show how this works by applying the rules to the premises and the conclusion. We denote the intention we denote by the formula φ1, φ2, . . .       . ..   We denote our intention by φn, which we will call premises, and another formula, �  Constructing such a proof is a creative exercise, a bit like programming. It is notnecessarily obvious which rules to apply, and in what order, to obtain the desired conclusion. For Examples 1.1 and 1.2, we use Greek letters. Lower-case letters are used to stand for formulas, and upper-case Letters are used for sets of formulas. For example, p ⊢q. , φn ⋅n ≅n is a set of three formulas. Greek letters are used to express propositions. Propositional logic can be used to prove the existence of certain facts. The proof rule modus tollens (MT) can be derived from some of the other rules. The rules are: p, q ⊢p, r, ¬r, p |−q, p  ‘Gold is a metal’ and p  ‘Silver is a gold.’ The rules can be shown by the sequent p,q,r,p, ‘p’, “p” and ‘q’. The Greek word for ‘proof’ is ‘guideline’ or ‘propositional There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy;.and some purists would say that we should stick to a minimum set of rules, independent of each other. We don’t take such a purist view.Indeed, the two derived rules we now introduce are extremely useful. You will find that they crop up frequently when doing exercises in natural deduction, so it is worth giving them names as derived rules. For example, the rule ‘e, ¬e and ¬i’ can be derived from the rules “e” and “i”. The rules for negation involve the notion of contradiction. We have seen the rules ¬¬i and ¬E, but we haven’t seen any rules that introduce or eliminate single negations. The rules for contradiction are: If from ¬φ we obtain a contradiction, then we are entitled to deduce φ: PBC. The rule for contradiction is called reductio ad absurdum, which means ‘reduc-tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. We will use this rule more than once in our derivation of the rules for the proof of natural deduction. As far as truth is concerned, they are all equivalent. We’ll be able to prove this later, when we have introduced the rules for negation. Contradictions are a very important notion in logic. Any formula can be derived from a contradiction. This can be seen in natural deduction. Natural deduction can be confusing when you ﬁrst encounter it; why should we endorse the argument that the moon is made of green cheese? It may seem absurd, but natural deduction does have this feature that any for-reprehensible-mula can be derive from a contradictions and therefore it makes this argu-                ment valid. It’s not just that contradictions can be. derived from contradic- If all the premises compute to ‘true’, then the conclusion must compute ‘ true’ as well. We summarise this reasoning into therule modus tollens, or MT for short. If Abraham Lincoln was Ethiopian, then he was African. If p holds, we may infer that p must be false. But this can only mean that ¬p is true. If q holds, then we can use →e to conclude that q holds. This has the advantage that we can match ⊢to checks based on semantic                intuitions which we formalise later by using truth tables. The reason it takes this stance is that it does not care whether such premises make any sense. In the following proof of the rule, we use several of the rules introduced so far. We will be able to derive this rule from other ones later on, but we introduce it here because it allows us already to do some pretty slick proofs. The rule is: ‘Lincoln was not African; therefore he was not Ethiopian.’ We will use this rule in the next section of the book The rule MT implies introduction of new premises. The order of applying double negation rules and MT is diﬀerentin these examples. Yet, so far we have no rule which builds implications that do not already occur as premises in our proofs. The rule MT made it possible for us to show that p →q, ¬q ⊢¬p is valid, but the validity of the sequent p →¬q, q ⋅p seems just as plausible. That sequent is, in a certain sense, saying the same thing. We call the rule MT a Natural deduction. It does not mention the lower-level rules upon which it depends. In the second rule it is just the other way around: the conclusion ψ has to match the second conjunct ψ and φ can be any formula. It is important to engage in this kind of pattern matching before the application of proof rules. The mechanics of such a rule                are more involved than what we have seen so far. So let us proceed with the next section of the paper. We start by writing down the premises; then we leave a gap and write the                1.2 Natural deduction: P, R, q, r, p, r. The task of constructing the proof is to ﬁll the gap between the premises                and the conclusion by applying a suitable sequence of rules. If we applied these proof rules literally, then the proof above would actu-ally be a tree with root q and leaves p and r. However, we ﬂattened this tree into a linear presentation which necessitates the use of pointers as seen in lines 3 and 4 above. These pointers allow us to recreate the actual proof tree. Throughout this text, we will use the  version of presenting proofs that we used in the previous section. We also usuallynumber all the lines, and write in the justiﬁcation for each line, producing this:1p  p    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11. If a sequent is valid, there may be many diﬀerent ways of proving it. So if you compare your solution to these exercises with those of others, they need not coincide. That way you have to concentrate only on the proof, not on how to growing a tree onto a sheet of paper. The proof rule modus tollens (MT) is not a primitive rule of natural deduction, but can be derived from some of the other rules. For example, we can prove that the argument of Examples 1.1 and 1.2, which can be coded up by the sequent p ∧¬q →r, ¬r, p |−q, is valid. There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy;.and some purists would say that we should stick to a minimum set of rules, independent of each other. We don’t take such a purist view.Indeed, the two derived rules we now introduce are extremely useful. You will find that they crop up frequently when doing exercises in natural deduction, so it is worth giving them names as derived rules. For example, the rule ‘e, ¬e and ¬i’ can be derived from the rules “e” and “i”. PBC is proof by contradiction (PBC for short) The rule says: if from ¬φ we obtain a contradiction, then we are entitled to deduce φ. We are now able to prove this in the form of a natural deduction. The elimination rules break (p) up into its atomic constituents p, q and r. The introduction rules then built up the formula p ∨(q) (p, q) (q, r) (r, p) ( p,q) p (q), r (q) 1. PBC is a form of Natural deduction, or PBC, with two rules. The first one has the Latin name reductio ad absurdum. It means A ﬁnal rule is required in order to allow us to conclude a box with a for-mula which has already appeared earlier in the proof. The rule ‘copy’ allows us to repeat something that we know already. We need to do this in this example, because the rule →i requires that we end the inner box with p. The copy rule entitles us to copy formulas that appeared before,unless they depend on temporary assumptions whose box has already been closed. The following proof is a proof of the validity of the ‘converse’ (p ∧q) and you are encouraged to show it yourself. The proof is based on the following: We have seen the rules for negation, but we haven’t seen any rules that introduce or eliminate single negations. This detour is to be expected since we’ve seen the summary of natural deduction rules in Figure 1.2 on page 27. Do you need to include derived rules? Show that the following sequents are not valid by ﬁnding a valuation in which. the truth values of the formulas to the left of ⊢are T and the truth value of the formula to the right of. F is F. The rule is a little inelegant, but it is a small price to pay for the freedom of being able to use premises, or any other ‘visible Find a formula of propositional logic which contains only the atoms p, q and r and which is true only when p and q are false. Prove the validity of the following sequents needed to secure the completeness of the formula. Use mathematical induction on n to prove the theorem. Use the following examples of natural language to test the correctness of the formulas. For each example, give examples of sentences such that the premises are true, but the conclusion is false. For example, given the premises p,q and r, give the sentences: p →q ⊢p ∨q(d) p →(q ∨r) ≢(p →q) (d) (p →r) An adequate set of connectives for propositional logic is a set such that for every formula there is an equivalent formula with only connectives from that set. For example, the set {¬, ∨} is adequate for propositionally logic,Summed or given as a premise some formula in some line k′ with k < k, which was referred to via ∨e in the justiﬁcation of line k. We have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within thatproof, obtained by turning all assumptions of boxes that are open atline k′ into premises. The soundness of propositional logic is useful in ensuring the non-existence of a proof for a given sequent. The rest of the argument checks each possible proof in turn and ultimately boils down to verifying that our natural deduction is true. The rules behave semantically in the same way as their corresponding truth tables. We leave the details as an exercise and will return to the argument in a few weeks. We hope that this article has helped you understand some of the concepts behind propositional logic and its application to your own life. Back to the page you came from. The post was originally published in the online edition of the book ‘The Logic of Propositional Logic’, published by Oxford University Press. In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. We will first prove that there exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ. Then, we will show how to use this method in the exercises.4.1. Completeness of the rules of logic. We claim that x ̸⊩p  is an instance of LEM which we proved in Chapter 1 with the full natural deduction calculus. We do not have x ⊩ p, for p is not in the set L(x) which is empty. Theory LEM simply does not hold, since there is a world y with R(x, y) such that y ⊩p holds, for p ⊨L(y). The availability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. One can now deﬁne semantic entailment in the same manner as for modal grotesquelogics. Then, one can prove soundness and completeness of the reduced nat-                ural deduction system with respect to this semantic entailsment. But thoseproofs are beyond the scope of this book. Natural deduction proofs are linear representations of proof trees. The proof boxes have formulas and/or other boxes insidethem. There are rules which dictate how to construct proofs. When a box is closed – in accordance with a rule – we say that its assumption is discharged. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. Every formula must have some justiﬁcation to its right: a justi ﬉cation can be the name of a rule, or the word ‘assumption,’ or an instance of the proof rule copy. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This intention is right-associative: expressions of the form p →q →r denote p →(q → r) In Examples 1.1 and 1.2, we show how this works by applying the rules to the premises and the conclusion. We denote the intention we denote by the formula φ1, φ2, . . .       . ..   We denote our intention by φn, which we will call premises, and another formula, �  Constructing such a proof is a creative exercise, a bit like programming. It is notnecessarily obvious which rules to apply, and in what order, to obtain the desired conclusion. For Examples 1.1 and 1.2, we use Greek letters. Lower-case letters are used to stand for formulas, and upper-case Letters are used for sets of formulas. For example, p ⊢q. , φn ⋅n ≅n is a set of three formulas. The Greek alphabet is used to write the Greek language. Here are some of the more commonly used Greek letters, together with their pronunciation. We hope to convince you that the natural deduction rules of propositional logic are complete. We will discuss the Completeness of the rules of logic in the next section. The next section will discuss how to use these rules in the application of the Greek alphabet to the English language. The final section will cover the use of the English alphabet to understand the Greek word for ‘gold’ and ‘silver’ in English. The last section will focus on how to apply the Greek letter ‘p’ to the word “gold” in the English word ‘ The ﬁrst method involves a proof search, upon which the logic program-ming paradigm is based. The second method typically forces you to com-pute a truth table which is exponential in the size of occurring proposi-                tional atoms. Often it is much easier to show one of these two relationships (al-though neither of the two is universally better, or easier, to establish). The remainder of this section is concerned with an argument saying that if φ1, φ2, . . . , φn ⊨ψ holds, then φ 1, χ2, and χ3 are valid. The argument proceeds in three steps: The first two steps are quite easy; all the real work is done in the third one. We repre-sent parse trees for φ1, φ2, . . . , φn as triangles. The only way this parse tree can evaluate to F. is to use the formula of propositional logic φ called a tautology. We call this formula the \"propositional logic\" formula. The formula evaluates to T under all its valuations, i.e. iﬀ⊨φ is valid. Natural deduction employs boxes to control the scope of assumptions. Discharging assumptions is achieved by closing a box according to the pattern of its particular proof rule. At any stage of a proof, it is permitted to introduce any formula as as-astonishingsumption, by choosing a proof rule that opens a box. Natural deduction rules for propositional logic. Propositional logic rules for logical induction. Natural deductions for theorems. Natural deductive reasoning. Natural logic for theory of propositions. Theory of propositional Logic. Theorems for natural deduction. Natural reasoning for the theory of logic. The theory of logical induction for the Theory of Propositions. The logic of natural deduction for the philosophy of propositions. Given a sequent, you write its premises at the top of your page and its conclusion at the bottom. Now, you’re trying to ﬁll in the gap, which involves working simultaneously on the premises (to bring them to the conclusion) and on the conclusion (to massage it towards thepremises). If it is of the form φ → ω, then apply6 the proof rule. This means drawing a box with φ at the top and ψ at the bottom. You still have to find a way of filling in the gap between the φ and the ψ. But you now have an extra formula to work with and you have simpliﬁed the conclusion you are trying to reach. Except in situations such as p →(q →¬r) where →e produces a simpler proof. The proof rules are: Propositional logic, natural deduction, and logical inference. For example, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q. We want to infer that ‘Gold is a metal For each of the connectives, there is one or more rules to introduce it and one or two rules to eliminate it. We present about ﬁfteen of them in total. We will go through them in turn and then summarise at the end of this section.1 Rules for natural deduction for conjunction.2. The rules for conjunction for conjunction, for conjunction with conjunction, and for conjunction without conjunction.3. The rule for conjunc-unc-tion for conjunction and-introduction.4. The Rules for Natural Deduction for Conjunctions for Conjunction, for Conjugation with Conjunction, and Conjuration with Conjunctivity. The rules for and-elimination are these two: one for proof and the other for elimination. The exact nature of the second conjunct of the proof is irrelevant. It is important to engage in this kind of pattern matching before the application of proof rules to the truth-table semantics. In the exercises, we apply this to show that a se-quent does not have a proof: simply show that φ1, φ2, . . . , φ3 does not seman-                tically entail ψ; then soundness implies that the sequent ω1,    2, ””, “’’, ‘‘� Using natural deduction to decide the validity of instances of ⊢is only one of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,                notion of proofs for sequents. We now investigate various alternatives for deciding these formulas which are based on transforming these formulas syntac-uroustically into ‘equivalent’ ones upon which we can then settle the matter by purely syntactic or algorithmic means. The results of the study are published in the book ‘Theoretical Foundations of Natural Deduction’, which is published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. Two formulas are said to be equivalent if they have the same ‘meaning’ This suggestion is vague and needs to be reﬁned. For example, the truth table for p →q and r →r is four lines long, whereas the one for r ∨¬r consists of only two lines. However, both formulas are always true. This requires that we ﬁrst clarify what exactly we mean by equivalent formulas.1.5. Semantic equivalence, satisfiability and validity. 2. The concept of ‘satisfiability’. 3. The notion of “satisfaction”. This suggests that we deﬁne of proof, which states rules for transforming valid sequents into valid sequent. The new approach expresses this as an inference rule between sequents. The rule ‘assumption’ is written as the assumption is empty. Such rules are called axioms and are expressed in Figure 1.2 in a tree-like form. For example, if we have already a proof for the sequent Γ, we can augment it by augmenting this proof with one application of the rule →i.i. i.e. the premise is empty, and we have a proof of the same type for the other side of the coin. This is known as a proof by contradiction. An alternative approach to treating negation. One could simply ban the operator ¬ from propositional logic. Such a logic cannot rely on the natural deduction rules for Negation. Let us introduce a new connective φ ↔ψ. Design introduction and elimination rules for φ. We assume below the usualconventions about binding priorities agreed upon in Convention 1.3.1. We show that they are derived rules if φ is interpreted as ( φ →ψ) ( ω → φ) (φ → ω) (2l2) 2l2 has a diﬀerentnumber of 2 factors from k2. Why would that be a contradiction and to what? Given the following formulas, draw the corresponding parse tree. For example, the tree looks like the following: p (a) p (",
                    "children": [
                        {
                            "id": "chapter-1-section-2-subsection-1",
                            "title": "Rules for Natural Deduction",
                            "content": "1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\n1.2.3 Natural deduction in summary\nThe proof rules for natural deduction are summarised in Figure 1.2. The\nexplanation of the rules we have given so far in this chapter is declarative;\nwe have presented each rule and justiﬁed it in terms of our intuition about\nthe logical connectives. However, when you try to use the rules yourself,\nyou’ll ﬁnd yourself looking for a more procedural interpretation; what does\na rule do and how do you use it? For example,\nr ∧i says: to prove φ ∧ψ, you must ﬁrst prove φ and ψ separately and then use\nthe rule ∧i.\nr ∧e1 says: to prove φ, try proving φ ∧ψ and then use the rule ∧e1. Actually,\nthis doesn’t sound like very good advice because probably proving φ ∧ψ will\nbe harder than proving φ alone. However, you might ﬁnd that you already have\nφ ∧ψ lying around, so that’s when this rule is useful. Compare this with the\nexample sequent in Example 1.15.\nr ∨i1 says: to prove φ ∨ψ, try proving φ. Again, in general it is harder to prove\nφ than it is to prove φ ∨ψ, so this will usually be useful only if you’ve already\nmanaged to prove φ. For example, if you want to prove q |−p ∨q, you certainly\nwon’t be able simply to use the rule ∨i1, but ∨i2 will work.\nr ∨e has an excellent procedural interpretation. It says: if you have φ ∨ψ, and you\nwant to prove some χ, then try to prove χ from φ and from ψ in turn. (In those\nsubproofs, of course you can use the other prevailing premises as well.)\nr Similarly, →i says, if you want to prove φ →ψ, try proving ψ from φ (and the\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nour reasoning is concerned about the inference, and therefore the preserva-\ntion, of truth. Hence, there cannot be a direct way of inferring ¬φ, given\nφ.\nDeﬁnition 1.19 Contradictions are expressions of the form φ ∧¬φ or ¬φ ∧\nφ, where φ is any formula.\nExamples of such contradictions are r ∧¬r, (p →q) ∧¬(p →q) and ¬(r ∨\ns →q) ∧(r ∨s →q). Contradictions are a very important notion in logic.\nAs far as truth is concerned, they are all equivalent; that means we should\nbe able to prove the validity of\n¬(r ∨s →q) ∧(r ∨s →q) ⊣⊢(p →q) ∧¬(p →q)\n(1.2)\nsince both sides are contradictions. We’ll be able to prove this later, when\nwe have introduced the rules for negation.\nIndeed, it’s not just that contradictions can be derived from contradic-\ntions; actually, any formula can be derived from a contradiction. This can be\n1.2 Natural deduction\n21\nconfusing when you ﬁrst encounter it; why should we endorse the argument\np ∧¬p ⊢q, where\np : The moon is made of green cheese.\nq : I like pepperoni on my pizza.\nconsidering that our taste in pizza doesn’t have anything to do with the\nconstitution of the moon? On the face of it, such an endorsement may seem\nabsurd. Nevertheless, natural deduction does have this feature that any for-\nmula can be derived from a contradiction and therefore it makes this argu-\nment valid. The reason it takes this stance is that ⊢tells us all the things\nwe may infer, provided that we can assume the formulas to the left of it.\nThis process does not care whether such premises make any sense. This has\nat least the advantage that we can match ⊢to checks based on semantic\nintuitions which we formalise later by using truth tables: if all the premises\ncompute to ‘true’, then the conclusion must compute ‘true’ as well. In partic-\nan implication. Suppose that p →q and ¬q are the case. Then, if p holds\nwe can use →e to conclude that q holds. Thus, we then have that q and ¬q\nhold, which is impossible. Therefore, we may infer that p must be false. But\nthis can only mean that ¬p is true. We summarise this reasoning into the\nrule modus tollens, or MT for short:5\nφ →ψ\n¬ψ\n¬φ\nMT.\nAgain, let us see an example of this rule in the natural language setting:\n‘If Abraham Lincoln was Ethiopian, then he was African. Abraham\nLincoln was not African; therefore he was not Ethiopian.’\nExample 1.7 In the following proof of\np →(q →r), p, ¬r ⊢¬q\nwe use several of the rules introduced so far:\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq →r\n→e 1, 2\n5\n¬q\nMT 4, 3\n5 We will be able to derive this rule from other ones later on, but we introduce it here because it\nallows us already to do some pretty slick proofs. You may think of this rule as one on a higher\nlevel insofar as it does not mention the lower-level rules upon which it depends.\n1.2 Natural deduction\n11\nExamples 1.8 Here are two example proofs which combine the rule MT\nwith either ¬¬e or ¬¬i:\n1\n¬p →q\npremise\n2\n¬q\npremise\n3\n¬¬p\nMT 1, 2\n4\np\n¬¬e 3\nproves that the sequent ¬p →q, ¬q ⊢p is valid; and\n1\np →¬q\npremise\n2\nq\npremise\n3\n¬¬q\n¬¬i 2\n4\n¬p\nMT 1, 3\nshows the validity of the sequent p →¬q, q ⊢¬p.\nNote that the order of applying double negation rules and MT is diﬀerent\nin these examples; this order is driven by the structure of the particular\nsequent whose validity one is trying to show.\nThe rule implies introduction\nThe rule MT made it possible for us to\nshow that p →q, ¬q ⊢¬p is valid. But the validity of the sequent p →q ⊢\n¬q →¬p seems just as plausible. That sequent is, in a certain sense, saying\nthe same thing. Yet, so far we have no rule which builds implications that\ndo not already occur as premises in our proofs. The mechanics of such a rule\nare more involved than what we have seen so far. So let us proceed with\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nExample 1.4 Let’s use these rules to prove that p ∧q, r |−q ∧r is valid.\nWe start by writing down the premises; then we leave a gap and write the\n1.2 Natural deduction\n7\nconclusion:\np ∧q\nr\nq ∧r\nThe task of constructing the proof is to ﬁll the gap between the premises\nand the conclusion by applying a suitable sequence of proof rules. In this\ncase, we apply ∧e2 to the ﬁrst premise, giving us q. Then we apply ∧i to this\nq and to the second premise, r, giving us q ∧r. That’s it! We also usually\nnumber all the lines, and write in the justiﬁcation for each line, producing\nthis:\n1\np ∧q\npremise\n2\nr\npremise\n3\nq\n∧e2 1\n4\nq ∧r\n∧i 3, 2\nDemonstrate to yourself that you’ve understood this by trying to show on\nyour own that (p ∧q) ∧r, s ∧t |−q ∧s is valid. Notice that the φ and ψ can\nbe instantiated not just to atomic sentences, like p and q in the example we\njust gave, but also to compound sentences. Thus, from (p ∧q) ∧r we can\ndeduce p ∧q by applying ∧e1, instantiating φ to p ∧q and ψ to r.\nIf we applied these proof rules literally, then the proof above would actu-\nally be a tree with root q ∧r and leaves p ∧q and r, like this:\np ∧q\n∧e2\nq\nr\n∧i\nq ∧r\nHowever, we ﬂattened this tree into a linear presentation which necessitates\nthe use of pointers as seen in lines 3 and 4 above. These pointers allow\nus to recreate the actual proof tree. Throughout this text, we will use the\nﬂattened version of presenting proofs. That way you have to concentrate only\non ﬁnding a proof, not on how to ﬁt a growing tree onto a sheet of paper.\nIf a sequent is valid, there may be many diﬀerent ways of proving it. So if\nyou compare your solution to these exercises with those of others, they need\nnot coincide. The important thing to realise, though, is that any putative",
                            "summary": "The elimination rules break (p) up into its atomic constituents p, qand r. The introduction rules then built up the formula p ∨(q ∨r). 1.1 Humanitarian deduction. 1.2 Natural deduction. 2. Humanitarian theory. 3. Theory of natural deduction. 4. Natural deduction theory. 5. The Theory of Natural Deduction. 6. The theory of natural deduction. 7. Natural deduction theory. 8. Natural deductives. 9. Natural deductions. 10. Natural  deduction  theory. 11. A ﬁnal rule is required in order to allow us to conclude a box with a for-mula which has already appeared earlier in the proof. The rule ‘copy’ allows us to repeat something that we know already. We need to do this in this example, because the rule →i requires that we end the inner box with p. The copy rule entitles us to copy formulas that appeared before,unless they depend on temporary assumptions whose box has already been closed. The following proof is a proof of the validity of the ‘converse’ (p ∧q) and you are encouraged to show it yourself. The proof is based on the following: The proof rules for natural deduction are summarised in Figure 1.2. The rules for negation involve the notion of contradiction. It can be diﬃcult to decide which instance of LEM would beneﬁt the progress of a proof. Can you re-do the example above with q ∨¬q as LEM? Can you do the same thing with q∨i? Can we use premises or any other ‘visible’ formulas, more than once? Can a proof be proved using a single negation or a series of negations? Can an argument be proved by using multiple negations or multiple premises? Can it be proven by using premises or other 'visible' formulas The rules have an excellent procedural interpretation. However, when you try to use the rules yourself, you’ll find yourself looking for a more procedural interpretation; what does                a rule do and how do you use it? For example, to prove φ, try proving φ and ψ separately and then use                the rule  in Example 1.15. The rules are written in the form of a list of rules, starting with the first one and ending with the last one. The first rule is called the ‘proving’ rule, the second is called ‘exercising’ the rules, and the third is ‘using the rules’. The basic rules of natural deduction:introduction, elimination, and derivation. Show that the following sequents are not valid by ﬁnding a valuation in which the truth values of the formulas to the left of ⊢are T and the truth value of the formula to the right of F is F. See Figure 1.2 on page 27 to see which cases are still missing, and to see how to use the rules in the rest of the book. See page 27 for the summary of the rules of deduction in the book, as well as a list of examples and examples of how to apply the rules to the real world. The book is published by Oxford University Press, London. Find a formula of propositional logic which contains only the atoms p, q and r and which is true only when p and q are false. Prove the validity of the following sequents needed to secure the completeness of the formula. Use mathematical induction on n to prove the theorem. Use the following examples of natural language to test the correctness of the formulas. For each example, give examples of sentences such that the premises are true, but the conclusion is false. For example, given the premises p,q and r, give the sentences: p →q ⊢p ∨q(d) p →(q ∨r) ≢(p →q) (d) (p →r) An adequate set of connectives for propositional logic is a set such that there is an equivalent formula with only connectives from that set. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an instance of LEM. Does ⊨φ hold for the φ below? Please justify your answer. Exercises 1.5 and 2.5 are based on the definition of the set {¬, ∨} and the set of propositional connectives. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This intention is right-associative: expressions of the form p →q →r denote p →(q → r) In Examples 1.1 and 1.2, we show how this works by applying the rules to the premises and the conclusion. We denote the intention we denote by the formula φ1, φ2, . . .       . ..   We denote our intention by φn, which we will call premises, and another formula, �  Constructing such a proof is a creative exercise, a bit like programming. It is notnecessarily obvious which rules to apply, and in what order, to obtain the desired conclusion. For Examples 1.1 and 1.2, we use Greek letters. Lower-case letters are used to stand for formulas, and upper-case Letters are used for sets of formulas. For example, p ⊢q. , φn ⋅n ≅n is a set of three formulas. Greek letters are used to express propositions. Propositional logic can be used to prove the existence of certain facts. The proof rule modus tollens (MT) can be derived from some of the other rules. The rules are: p, q ⊢p, r, ¬r, p |−q, p  ‘Gold is a metal’ and p  ‘Silver is a gold.’ The rules can be shown by the sequent p,q,r,p, ‘p’, “p” and ‘q’. The Greek word for ‘proof’ is ‘guideline’ or ‘propositional There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy;.and some purists would say that we should stick to a minimum set of rules, independent of each other. We don’t take such a purist view.Indeed, the two derived rules we now introduce are extremely useful. You will find that they crop up frequently when doing exercises in natural deduction, so it is worth giving them names as derived rules. For example, the rule ‘e, ¬e and ¬i’ can be derived from the rules “e” and “i”. The rules for negation involve the notion of contradiction. We have seen the rules ¬¬i and ¬E, but we haven’t seen any rules that introduce or eliminate single negations. The rules for contradiction are: If from ¬φ we obtain a contradiction, then we are entitled to deduce φ: PBC. The rule for contradiction is called reductio ad absurdum, which means ‘reduc-tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. We will use this rule more than once in our derivation of the rules for the proof of natural deduction. As far as truth is concerned, they are all equivalent. We’ll be able to prove this later, when we have introduced the rules for negation. Contradictions are a very important notion in logic. Any formula can be derived from a contradiction. This can be seen in natural deduction. Natural deduction can be confusing when you ﬁrst encounter it; why should we endorse the argument that the moon is made of green cheese? It may seem absurd, but natural deduction does have this feature that any for-reprehensible-mula can be derive from a contradictions and therefore it makes this argu-                ment valid. It’s not just that contradictions can be. derived from contradic- If all the premises compute to ‘true’, then the conclusion must compute ‘ true’ as well. We summarise this reasoning into therule modus tollens, or MT for short. If Abraham Lincoln was Ethiopian, then he was African. If p holds, we may infer that p must be false. But this can only mean that ¬p is true. If q holds, then we can use →e to conclude that q holds. This has the advantage that we can match ⊢to checks based on semantic                intuitions which we formalise later by using truth tables. The reason it takes this stance is that it does not care whether such premises make any sense. In the following proof of the rule, we use several of the rules introduced so far. We will be able to derive this rule from other ones later on, but we introduce it here because it allows us already to do some pretty slick proofs. The rule is: ‘Lincoln was not African; therefore he was not Ethiopian.’ We will use this rule in the next section of the book The rule MT implies introduction of new premises. The order of applying double negation rules and MT is diﬀerentin these examples. Yet, so far we have no rule which builds implications that do not already occur as premises in our proofs. The rule MT made it possible for us to show that p →q, ¬q ⊢¬p is valid, but the validity of the sequent p →¬q, q ⋅p seems just as plausible. That sequent is, in a certain sense, saying the same thing. We call the rule MT a Natural deduction. It does not mention the lower-level rules upon which it depends. In the second rule it is just the other way around: the conclusion ψ has to match the second conjunct ψ and φ can be any formula. It is important to engage in this kind of pattern matching before the application of proof rules. The mechanics of such a rule                are more involved than what we have seen so far. So let us proceed with the next section of the paper. We start by writing down the premises; then we leave a gap and write the                1.2 Natural deduction: P, R, q, r, p, r. The task of constructing the proof is to ﬁll the gap between the premises                and the conclusion by applying a suitable sequence of rules. If we applied these proof rules literally, then the proof above would actu-ally be a tree with root q and leaves p and r. However, we ﬂattened this tree into a linear presentation which necessitates the use of pointers as seen in lines 3 and 4 above. These pointers allow us to recreate the actual proof tree. Throughout this text, we will use the  version of presenting proofs that we used in the previous section. We also usuallynumber all the lines, and write in the justiﬁcation for each line, producing this:1p  p    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11. If a sequent is valid, there may be many diﬀerent ways of proving it. So if you compare your solution to these exercises with those of others, they need not coincide. The important thing to realise, though, is that any putative.",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-2",
                            "title": "Derived Rules",
                            "content": "1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25",
                            "summary": "23 Finally, we return to the argument of Examples 1.1 and 1.2, which can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity we prove. We could now go back through the proofs in this chapter and replace applica-reprehensibletions of MT by this combination of →e, e and ¬i. We now prove that the proof rule modus tollens (MT) is not a primitive rule of natural deduction, but can be derived from some of the other rules. Here is the derivation ofMT: Propositional logic from →e to e,  e to  i. There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy. The two derived rules we now introduce are extremely useful. They crop up frequently when doing exercises in natural deduction, so it is worth giving them names as derived rules. In the case of the second one, its derivation from the primitive proof rules is not very obvious. The Latin name reductio ad absurdum. means ‘reduc-                tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. It is convenient to think of MT as a shorthand (or a macro). 25.2 Natural deduction. The rule says: if from ¬φ we obtain a contradiction, then we",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-3",
                            "title": "Natural Deduction in Summary",
                            "content": "1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nsumed or given as a premise some formula η1 ∨η2 in some line k′ with\nk′ < k, which was referred to via ∨e in the justiﬁcation of line k. Thus,\nwe have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within that\nproof, obtained by turning all assumptions of boxes that are open at\nline k′ into premises. In a similar way we obtain proofs of the sequents\nφ1, φ2, . . . , φn, η1 ⊢ψ and φ1, φ2, . . . , φn, η2 ⊢ψ from the case analysis of ∨e.\nBy our induction hypothesis, we conclude that the relations φ1, φ2, . . . , φn ⊨\nη1 ∨η2, φ1, φ2, . . . , φn, η1 ⊨ψ and φ1, φ2, . . . , φn, η2 ⊨ψ hold. But together\nthese three relations then force that φ1, φ2, . . . , φn ⊨ψ holds as well –\nwhy?\n3.\nYou can guess by now that the rest of the argument checks each possible proof\nrule in turn and ultimately boils down to verifying that our natural deduction\n1.4 Semantics of propositional logic\n49\nrules behave semantically in the same way as their corresponding truth tables\nevaluate. We leave the details as an exercise.\n2\nThe soundness of propositional logic is useful in ensuring the non-existence of\na proof for a given sequent. Let’s say you try to prove that φ1, φ2, . . . , φ2 ⊢ψ\nis valid, but that your best eﬀorts won’t succeed. How could you be sure that\nno such proof can be found? After all, it might just be that you can’t ﬁnd\na proof even though there is one. It suﬃces to ﬁnd a valuation in which φi\nevaluate to T whereas ψ evaluates to F. Then, by deﬁnition of ⊨, we don’t\nhave φ1, φ2, . . . , φ2 ⊨ψ. Using soundness, this means that φ1, φ2, . . . , φ2 ⊢ψ\ncannot be valid. Therefore, this sequent does not have a proof. You will\npractice this method in the exercises.\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nφ ∨ψ\n∨i1\nψ\nφ ∨ψ\n∨i2\nφ ∨ψ\nφ\n...\nχ\nψ\n...\nχ\nχ\n∨e\n→\nφ\n...\nψ\nφ →ψ\n→i\nφ\nφ →ψ\nψ\n→e\n¬\nφ\n...\n⊥\n¬φ\n¬i\nφ\n¬φ\n⊥\n¬e\n⊥\n(no introduction rule for ⊥)\n⊥\nφ\n⊥e\n¬¬\n¬¬φ\nφ\n¬¬e\nSome useful derived rules:\nφ →ψ\n¬ψ\n¬φ\nMT\nφ\n¬¬φ\n¬¬i\n¬φ\n...\n⊥\nφ\nPBC\nφ ∨¬φ\nLEM\nFigure 1.2. Natural deduction rules for propositional logic.\n28\n1 Propositional logic\nAt any stage of a proof, it is permitted to introduce any formula as as-\nsumption, by choosing a proof rule that opens a box. As we saw, natural\ndeduction employs boxes to control the scope of assumptions. When an as-\nsumption is introduced, a box is opened. Discharging assumptions is achieved\nby closing a box according to the pattern of its particular proof rule. It’s\nuseful to make assumptions by opening boxes. But don’t forget you have to\nclose them in the manner prescribed by their proof rule.\nOK, but how do we actually go about constructing a proof?\nGiven a sequent, you write its premises at the top of your page and\nits conclusion at the bottom. Now, you’re trying to ﬁll in the gap,\nwhich involves working simultaneously on the premises (to bring them to-\nwards the conclusion) and on the conclusion (to massage it towards the\npremises).\nLook ﬁrst at the conclusion. If it is of the form φ →ψ, then apply6 the\nrule →i. This means drawing a box with φ at the top and ψ at the bottom.\nSo your proof, which started out like this:\n...\npremises\n...\nφ →ψ\nnow looks like this:\n...\npremises\n...\nφ\nassumption\nψ\nφ →ψ\n→i\nYou still have to ﬁnd a way of ﬁlling in the gap between the φ and the ψ.\nBut you now have an extra formula to work with and you have simpliﬁed\nthe conclusion you are trying to reach.\n6 Except in situations such as p →(q →¬r), p ⊢q →¬r where →e produces a simpler proof.\n1.2 Natural deduction\n29\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.",
                            "summary": "The elimination rules break (p) up into its atomic constituents p, qand r. The introduction rules then built up the formula p ∨(q ∨r). 1.1 Humanitarian deduction. 1.2 Natural deduction. 2. Humanitarian theory. 3. Theory of natural deduction. 4. Natural deduction theory. 5. The Theory of Natural Deduction. 6. The theory of natural deduction. 7. Natural deduction theory. 8. Natural deductives. 9. Natural deductions. 10. Natural  deduction  theory. 11. A ﬁnal rule is required in order to allow us to conclude a box with a for-mula which has already appeared earlier in the proof. The rule ‘copy’ allows us to repeat something that we know already. We need to do this in this example, because the rule →i requires that we end the inner box with p. The copy rule entitles us to copy formulas that appeared before,unless they depend on temporary assumptions whose box has already been closed. The following proof is a proof of the validity of the ‘converse’ (p ∧q) and you are encouraged to show it yourself. The proof is based on the following: We have seen the rules for negation, but we haven’t seen any rules that introduce or eliminate single negations. This detour is to be expected since we’ve seen the summary of natural deduction rules in Figure 1.2 on page 27. Do you need to include derived rules? Show that the following sequents are not valid by ﬁnding a valuation in which. the truth values of the formulas to the left of ⊢are T and the truth value of the formula to the right of. F is F. The rule is a little inelegant, but it is a small price to pay for the freedom of being able to use premises, or any other ‘visible Find a formula of propositional logic which contains only the atoms p, q and r and which is true only when p and q are false. Prove the validity of the following sequents needed to secure the completeness of the formula. Use mathematical induction on n to prove the theorem. Use the following examples of natural language to test the correctness of the formulas. For each example, give examples of sentences such that the premises are true, but the conclusion is false. For example, given the premises p,q and r, give the sentences: p →q ⊢p ∨q(d) p →(q ∨r) ≢(p →q) (d) (p →r) An adequate set of connectives for propositional logic is a set such that for every formula there is an equivalent formula with only connectives from that set. For example, the set {¬, ∨} is adequate for propositionally logic,Summed or given as a premise some formula in some line k′ with k < k, which was referred to via ∨e in the justiﬁcation of line k. We have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within thatproof, obtained by turning all assumptions of boxes that are open atline k′ into premises. The soundness of propositional logic is useful in ensuring the non-existence of a proof for a given sequent. The rest of the argument checks each possible proof in turn and ultimately boils down to verifying that our natural deduction is true. The rules behave semantically in the same way as their corresponding truth tables. We leave the details as an exercise and will return to the argument in a few weeks. We hope that this article has helped you understand some of the concepts behind propositional logic and its application to your own life. Back to the page you came from. The post was originally published in the online edition of the book ‘The Logic of Propositional Logic’, published by Oxford University Press. In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. We will first prove that there exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ. Then, we will show how to use this method in the exercises.4.1. Completeness of the rules of logic. We claim that x ̸⊩p  is an instance of LEM which we proved in Chapter 1 with the full natural deduction calculus. We do not have x ⊩ p, for p is not in the set L(x) which is empty. Theory LEM simply does not hold, since there is a world y with R(x, y) such that y ⊩p holds, for p ⊨L(y). The availability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. One can now deﬁne semantic entailment in the same manner as for modal grotesquelogics. Then, one can prove soundness and completeness of the reduced nat-                ural deduction system with respect to this semantic entailsment. But thoseproofs are beyond the scope of this book. Natural deduction proofs are linear representations of proof trees. The proof boxes have formulas and/or other boxes insidethem. There are rules which dictate how to construct proofs. When a box is closed – in accordance with a rule – we say that its assumption is discharged. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. Every formula must have some justiﬁcation to its right: a justi ﬉cation can be the name of a rule, or the word ‘assumption,’ or an instance of the proof rule copy. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This intention is right-associative: expressions of the form p →q →r denote p →(q → r) In Examples 1.1 and 1.2, we show how this works by applying the rules to the premises and the conclusion. We denote the intention we denote by the formula φ1, φ2, . . .       . ..   We denote our intention by φn, which we will call premises, and another formula, �  Constructing such a proof is a creative exercise, a bit like programming. It is notnecessarily obvious which rules to apply, and in what order, to obtain the desired conclusion. For Examples 1.1 and 1.2, we use Greek letters. Lower-case letters are used to stand for formulas, and upper-case Letters are used for sets of formulas. For example, p ⊢q. , φn ⋅n ≅n is a set of three formulas. The Greek alphabet is used to write the Greek language. Here are some of the more commonly used Greek letters, together with their pronunciation. We hope to convince you that the natural deduction rules of propositional logic are complete. We will discuss the Completeness of the rules of logic in the next section. The next section will discuss how to use these rules in the application of the Greek alphabet to the English language. The final section will cover the use of the English alphabet to understand the Greek word for ‘gold’ and ‘silver’ in English. The last section will focus on how to apply the Greek letter ‘p’ to the word “gold” in the English word ‘ The ﬁrst method involves a proof search, upon which the logic program-ming paradigm is based. The second method typically forces you to com-pute a truth table which is exponential in the size of occurring proposi-                tional atoms. Often it is much easier to show one of these two relationships (al-though neither of the two is universally better, or easier, to establish). The remainder of this section is concerned with an argument saying that if φ1, φ2, . . . , φn ⊨ψ holds, then φ 1, χ2, and χ3 are valid. The argument proceeds in three steps: The first two steps are quite easy; all the real work is done in the third one. We repre-sent parse trees for φ1, φ2, . . . , φn as triangles. The only way this parse tree can evaluate to F. is to use the formula of propositional logic φ called a tautology. We call this formula the \"propositional logic\" formula. The formula evaluates to T under all its valuations, i.e. iﬀ⊨φ is valid. Natural deduction employs boxes to control the scope of assumptions. Discharging assumptions is achieved by closing a box according to the pattern of its particular proof rule. At any stage of a proof, it is permitted to introduce any formula as as-astonishingsumption, by choosing a proof rule that opens a box. Natural deduction rules for propositional logic. Propositional logic rules for logical induction. Natural deductions for theorems. Natural deductive reasoning. Natural logic for theory of propositions. Theory of propositional Logic. Theorems for natural deduction. Natural reasoning for the theory of logic. The theory of logical induction for the Theory of Propositions. The logic of natural deduction for the philosophy of propositions. Given a sequent, you write its premises at the top of your page and its conclusion at the bottom. Now, you’re trying to ﬁll in the gap, which involves working simultaneously on the premises (to bring them to the conclusion) and on the conclusion (to massage it towards thepremises). If it is of the form φ → ω, then apply6 the proof rule. This means drawing a box with φ at the top and ψ at the bottom. You still have to find a way of filling in the gap between the φ and the ψ. But you now have an extra formula to work with and you have simpliﬁed the conclusion you are trying to reach. Except in situations such as p →(q →¬r) where →e produces a simpler proof. The proof rules are: Propositional logic, natural deduction, and logical inference. For example, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q. We want to infer that ‘Gold is a metal For each of the connectives, there is one or more rules to introduce it and one or two rules to eliminate it. We present about ﬁfteen of them in total. We will go through them in turn and then summarise at the end of this section.1 Rules for natural deduction for conjunction.2. The rules for conjunction for conjunction, for conjunction with conjunction, and for conjunction without conjunction.3. The rule for conjunc-unc-tion for conjunction and-introduction.4. The Rules for Natural Deduction for Conjunctions for Conjunction, for Conjugation with Conjunction, and Conjuration with Conjunctivity. The rules for and-elimination are these two: one for proof and the other for elimination. The rules are based on pattern matching. The exact nature of the second conjunct of the proof is irrelevant. It is important not to engage in this kind of pattern matching before the application of proof rules. In the second rule it is just the other way around: the conclusion of a proof can be any formula. The conclusion of the elimination rule is the same, but it is based on a different rule. The result is that the proof of and-Elimination can be applied to any proof of φ.",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-4",
                            "title": "Provable Equivalence",
                            "content": "the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne",
                            "summary": "In the exercises, we apply this to show that a se-                quent does not have a proof. Completeness comprised a much more powerful state-                ment. No matter what (semantically) valid sequents there are, they all have syntactic proofs in the proof system of natural deduction. This tight cor-                respondence allows us to freely switch between working with the notion of Humeanproofs and that of semantic entailment. Using natural deduction to decide the validity of instances of ⊢is only one of many possibilities. In Exercise 1.6 we sketch a non-linear, tree-like, tree notion of proofs for sequents. We now investigate various alternatives for deciding whether an instance of Two formulas φ and ψ are said to be equivalent if they have the same ‘meaning’ This suggestion is vague and needs to be reﬁned. ’Coincidence of truth tables’ is not good enough for what we have in mind. We need to clarify what exactly we mean by ‘equivalent’ formulas. We can then settle the matter bypurely syntactic or algorithmic means.1.5.1 Semantic equivalence, satisfiability and validity2. ‘Satisfiability’ and ‘validity’ are terms that can be used to test the validity of a formula.3. “Suffiability” and “valid",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-5",
                            "title": "Proof by Contradiction",
                            "content": "of proof, which states rules for transforming valid sequents into valid sequents.\nFor example, if we have already a proof for the sequent Γ, φ ⊢ψ, then we ob-\ntain a proof of the sequent Γ ⊢φ →ψ by augmenting this very proof with one\napplication of the rule →i. The new approach expresses this as an inference rule\nbetween sequents:\nΓ, φ ⊢ψ\nΓ ⊢φ →ψ →i.\nThe rule ‘assumption’ is written as\nφ ⊢φ assumption\ni.e. the premise is empty. Such rules are called axioms.\n(a) Express all remaining proof rules of Figure 1.2 in such a form. (Hint: some\nof your rules may have more than one premise.)\n(b) Explain why proofs of Γ ⊢ψ in this new system have a tree-like structure\nwith Γ ⊢ψ as root.\n(c) Prove p ∨(p ∧q) ⊢p in your new proof system.\n1.7 Exercises\n81\n7. Show that\n√\n2 cannot be a rational number. Proceed by proof by contradiction:\nassume that\n√\n2 is a fraction k/l with integers k and l ̸= 0. On squaring both sides\nwe get 2 = k2/l2, or equivalently 2l2 = k2. We may assume that any common 2\nfactors of k and l have been cancelled. Can you now argue that 2l2 has a diﬀerent\nnumber of 2 factors from k2? Why would that be a contradiction and to what?\n8. There is an alternative approach to treating negation. One could simply ban the\noperator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally,\nsuch a logic cannot rely on the natural deduction rules for negation. Which of\nthe rules ¬i, ¬e, ¬¬e and ¬¬i can you simulate with the remaining proof rules\nby letting ¬φ be φ →⊥?\n9. Let us introduce a new connective φ ↔ψ which should abbreviate (φ →ψ) ∧\n(ψ →φ). Design introduction and elimination rules for ↔and show that they\nare derived rules if φ ↔ψ is interpreted as (φ →ψ) ∧(ψ →φ).\nExercises 1.3\nIn order to facilitate reading these exercises we assume below the usual\nconventions about binding priorities agreed upon in Convention 1.3.\n1. Given the following formulas, draw their corresponding parse tree:\n(a) p\n(b)\n*\np ∧q\n(c) p ∧¬q →¬p\n(d)\n*\np ∧(¬q →¬p)\n(e) p →(¬q ∨(q →p))\n(f)",
                            "summary": "The new approach expresses this as an inference rule between sequents. The rule ‘assumption’ is written as an assumption, i.e. the premise is empty. Such rules are called axioms. The new system has a tree-like structure with the root of the proof as a root. Prove that 2l2 cannot be a rational number with k/l and l ̸= 0. Show that p ∨(p ∧q) ⊢p in your new proof system is not a square root of p. Proving that p is not an irrational number by contradiction is also called proof by contradiction. For more details on the new system, see the appendix to this article. An alternative approach to treating negation. One could simply ban the operator ¬ from propositional logic. Such a logic cannot rely on the natural deduction rules for Negation. Let us introduce a new connective φ ↔ψ. Design introduction and elimination rules for φ. We assume below the usualconventions about binding priorities agreed upon in Convention 1.3.1. We show that they are derived rules if φ is interpreted as ( φ →ψ) ( ω → φ) (φ → ω) (2l2) 2l2 has a diﬀerentnumber of 2 factors from k2. Why would that be a contradiction and to what? Given the following formulas, draw the corresponding parse tree. For example, the tree looks like the following: p (a) p (",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-3",
                    "title": "Semantics of Propositional Logic",
                    "content": "reality (they are true), or they don’t (they are false).\nIf we combine declarative sentences p and q with a logical connective, say\n∧, then the truth value of p ∧q is determined by three things: the truth value\nof p, the truth value of q and the meaning of ∧. The meaning of ∧is captured\nby the observation that p ∧q is true iﬀp and q are both true; otherwise p ∧q\nis false. Thus, as far as ∧is concerned, it needs only to know whether p and\nq are true, it does not need to know what p and q are actually saying about\nthe world out there. This is also the case for all the other logical connectives\nand is the reason why we can compute the truth value of a formula just by\nknowing the truth values of the atomic propositions occurring in it.\nDeﬁnition 1.28 1.\nThe set of truth values contains two elements T and F, where\nT represents ‘true’ and F represents ‘false’.\n2.\nA valuation or model of a formula φ is an assignment of each propositional atom\nin φ to a truth value.\nExample 1.29 The map which assigns T to q and F to p is a valuation for\np ∨¬q. Please list the remaining three valuations for this formula.\nWe can think of the meaning of ∧as a function of two arguments; each\nargument is a truth value and the result is again such a truth value. We\nspecify this function in a table, called the truth table for conjunction, which\nyou can see in Figure 1.5. In the ﬁrst column, labelled φ, we list all possible\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nFigure 1.5. The truth table for conjunction, the logical connective ∧.\n38\n1 Propositional logic\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nφ\nψ\nφ ∨ψ\nT\nT\nT\nT\nF\nT\nF\nT\nT\nF\nF\nF\nφ\nψ\nφ →ψ\nT\nT\nT\nT\nF\nF\nF\nT\nT\nF\nF\nT\nφ\n¬φ\nT\nF\nF\nT\n⊤\nT\n⊥\nF\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nvalues in the ﬁrst two columns really exhaust all those possibilities (TT, TF,\nFT and FF). In the third column, we list the result of φ ∧ψ according to the\ntruth values of φ and ψ. So in the ﬁrst line, where φ and ψ have value T,\nthe result is T again. In all other lines, the result is F since at least one of\nthe propositions φ or ψ has value F.\nIn Figure 1.6 you ﬁnd the truth tables for all logical connectives of propo-\nsitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the\nmirror image of conjunction if we swap T and F, namely, a disjunction re-\nturns F iﬀboth arguments are equal to F, otherwise (= at least one of the\narguments equals T) it returns T. The behaviour of implication is not quite\nas intuitive. Think of the meaning of →as checking whether truth is being\npreserved. Clearly, this is not the case when we have T →F, since we infer\nsomething that is false from something that is true. So the second entry\nin the column φ →ψ equals F. On the other hand, T →T obviously pre-\nserves truth, but so do the cases F →T and F →F, because there is no truth\nto be preserved in the ﬁrst place as the assumption of the implication is\nfalse.\nIf you feel slightly uncomfortable with the semantics (= the meaning)\nof →, then it might be good to think of φ →ψ as an abbreviation of the\nformula ¬φ ∨ψ as far as meaning is concerned; these two formulas are very\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nany other variable y to l(y).\nFinally, we are able to give a semantics to formulas of predicate logic. For\npropositional logic, we did this by computing a truth value. Clearly, it suﬃces\nto know in which cases this value is T.\n128\n2 Predicate logic\nDeﬁnition 2.18 Given a model M for a pair (F, P) and given an environ-\nment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula\nφ over the pair (F, P) and look-up table l by structural induction on φ. If\nM ⊨l φ holds, we say that φ computes to T in the model M with respect to\nthe environment l.\nP:\nIf φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, t2, . . . , tn in\nour set A by replacing all variables with their values according to l. In this way\nwe compute concrete values a1, a2, . . . , an of A for each of these terms, where\nwe interpret any function symbol f ∈F by f M. Now M ⊨l P(t1, t2, . . . , tn)\nholds iﬀ(a1, a2, . . . , an) is in the set P M.\n∀x:\nThe relation M ⊨l ∀x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for all a ∈A.\n∃x:\nDually, M ⊨l ∃x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for some a ∈A.\n¬:\nThe relation M ⊨l ¬ψ holds iﬀit is not the case that M ⊨l ψ holds.\n∨:\nThe relation M ⊨l ψ1 ∨ψ2 holds iﬀM ⊨l ψ1 or M ⊨l ψ2 holds.\n∧:\nThe relation M ⊨l ψ1 ∧ψ2 holds iﬀM ⊨l ψ1 and M ⊨l ψ2 hold.\n→:\nThe relation M ⊨l ψ1 →ψ2 holds iﬀM ⊨l ψ2 holds whenever M ⊨l ψ1 holds.\nWe sometimes write M ̸⊨l φ to denote that M ⊨l φ does not hold.\nThere is a straightforward inductive argument on the height of the parse\ntree of a formula which says that M ⊨l φ holds iﬀM ⊨l′ φ holds, whenever\nl and l′ are two environments which are identical on the set of free variables\nof φ. In particular, if φ has no free variables at all, we then call φ a sentence;\nwe conclude that M ⊨l φ holds, or does not hold, regardless of the choice of\nl. Thus, for sentences φ we often elide l and write M ⊨φ since the choice of\nan environment l is then irrelevant.\nExample 2.19 Let us illustrate the deﬁnitions above by means of an-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\n(e) Cancer will not be cured unless its cause is determined and a new drug for\ncancer is found.\n(f) If interest rates go up, share prices go down.\n(g) If Smith has installed central heating, then he has sold his car or he has not\npaid his mortgage.\n(h)\n*\nToday it will rain or shine, but not both.\n(i)\n*\nIf Dick met Jane yesterday, they had a cup of coﬀee together, or they took\na walk in the park.\n(j) No shoes, no shirt, no service.\n(k) My sister wants a black and white cat.\n2. The formulas of propositional logic below implicitly assume the binding priorities\nof the logical connectives put forward in Convention 1.3. Make sure that you fully\nunderstand those conventions by reinserting as many brackets as possible. For\nexample, given p ∧q →r, change it to (p ∧q) →r since ∧binds more tightly\nthan →.\n(a)\n*\n¬p ∧q →r\n(b) (p →q) ∧¬(r ∨p →q)\n(c)\n*\n(p →q) →(r →s ∨t)\n(d) p ∨(¬q →p ∧r)\n(e)\n*\np ∨q →¬p ∧r\n(f) p ∨p →¬q\n(g)\n*\nWhy is the expression p ∨q ∧r problematic?\nExercises 1.2\n1. Prove the validity of the following sequents:\n(a) (p ∧q) ∧r, s ∧t ⊢q ∧s\n1.7 Exercises\n79\n(b) p ∧q ⊢q ∧p\n(c)\n*\n(p ∧q) ∧r ⊢p ∧(q ∧r)\n(d) p →(p →q), p ⊢q\n(e)\n*\nq →(p →r), ¬r, q ⊢¬p\n(f)\n*\n⊢(p ∧q) →p\n(g) p ⊢q →(p ∧q)\n(h)\n*\np ⊢(p →q) →q\n(i)\n*\n(p →r) ∧(q →r) ⊢p ∧q →r\n(j)\n*\nq →r ⊢(p →q) →(p →r)\n(k) p →(q →r), p →q ⊢p →r\n(l)\n*\np →q, r →s ⊢p ∨r →q ∨s\n(m) p ∨q ⊢r →(p ∨q) ∧r\n(n)\n*\n(p ∨(q →p)) ∧q ⊢p\n(o)\n*\np →q, r →s ⊢p ∧r →q ∧s\n(p) p →q ⊢((p ∧q) →p) ∧(p →(p ∧q))\n(q) ⊢q →(p →(p →(q →p)))\n(r)\n*\np →q ∧r ⊢(p →q) ∧(p →r)\n(s) (p →q) ∧(p →r) ⊢p →q ∧r\n(t) ⊢(p →q) →((r →s) →(p ∧r →q ∧s)); here you might be able to ‘recycle’\nand augment a proof from a previous exercise.\n(u) p →q ⊢¬q →¬p\n(v)\n*\np ∨(p ∧q) ⊢p\n(w) r, p →(r →q) ⊢p →(q ∧r)\n(x)\n*\np →(q ∨r), q →s, r →s ⊢p →s\n(y)\n*\n(p ∧q) ∨(p ∧r) ⊢p ∧(q ∨r).\n2. For the sequents below, show which ones are valid and which ones aren’t:\n(a)\n*\n¬p →¬q ⊢q →p\n(b)\n*\n¬p ∨¬q ⊢¬(p ∧q)\n(c)\n*\n¬p, p ∨q ⊢q\n(d)\n*\np ∨q, ¬q ∨r ⊢p ∨r\n(e)\n*\np →(q ∨r), ¬q, ¬r ⊢¬p without using the MT rule\n(f)\n*\nsuggesting that q is a logical consequence of p. We write p →q for that3. We\ncall p the assumption of p →q and q its conclusion.\nOf course, we are entitled to use these rules of constructing propositions\nrepeatedly. For example, we are now in a position to form the proposition\np ∧q →¬r ∨q\nwhich means that ‘if p and q then not r or q’. You might have noticed a\npotential ambiguity in this reading. One could have argued that this sentence\nhas the structure ‘p is the case and if q then . . . ’ A computer would require\nthe insertion of brackets, as in\n(p ∧q) →((¬r) ∨q)\n2 Its meaning should not be confused with the often implicit meaning of or in natural language\ndiscourse as either . . . or. In this text or always means at least one of them and should not be\nconfounded with exclusive or which states that exactly one of the two statements holds.\n3 The natural language meaning of ‘if . . . then . . . ’ often implicitly assumes a causal role of\nthe assumption somehow enabling its conclusion. The logical meaning of implication is a bit\ndiﬀerent, though, in the sense that it states the preservation of truth which might happen\nwithout any causal relationship. For example, ‘If all birds can ﬂy, then Bob Dole was never\npresident of the United States of America.’ is a true statement, but there is no known causal\nconnection between the ﬂying skills of penguins and eﬀective campaigning.\n1.2 Natural deduction\n5\nto disambiguate this assertion. However, we humans get annoyed by a pro-\nliferation of such brackets which is why we adopt certain conventions about\nthe binding priorities of these symbols.\nConvention 1.3 ¬ binds more tightly than ∨and ∧, and the latter two\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional done. Otherwise, we can use the inductive step, applied to n = 1, to infer\nthat 2 = 1 + 1 has property M(2). We can do that using →e, for we know\nthat 1 has the property in question. Now we use that same inductive step on\nn = 2 to infer that 3 has property M(3) and we repeat this until we reach\nn = k (see Figure 1.9). Therefore, we should have no objections about using\nthe principle of mathematical induction for natural numbers.\nReturning to Gauss’ example we claim that the sum 1 + 2 + 3 + 4 + · · · +\nn equals n · (n + 1)/2 for all natural numbers n.\nTheorem 1.31 The sum 1 + 2 + 3 + 4 + · · · + n equals n · (n + 1)/2 for all\nnatural numbers n.\n9 There is another way of ﬁnding the sum 1 + 2 + · · · + 100, which works like this: write the\nsum backwards, as 100 + 99 + · · · + 1. Now add the forwards and backwards versions, obtaining\n101 + 101 + · · · + 101 (100 times), which is 10100. Since we added the sum to itself, we now\ndivide by two to get the answer 5050. Gauss probably used this method; but the method of\nmathematical induction that we explore in this section is much more powerful and can be\napplied in a wide variety of situations.\n42\n1 Propositional logic\nWe prove M(1)\n...\n...\n1\n2\n3\n...\nn + 1\nn\nWe prove M(2) using M(1) and M(1) →M(2)\nWe prove M(3) using M(2) and M(2) →M(3)\nWe prove M(n) using M(n −1) and M(n −1) →M(n)\nWe prove M(n + 1) using M(n) and M(n) →M(n + 1)\nFigure 1.9. How the principle of mathematical induction works. By\nproving just two facts, M(1) and M(n) →M(n + 1) for a formal (and\nunconstrained) parameter n, we are able to deduce M(k) for each natural\nnumber k.\nProof: We use mathematical induction. In order to reveal the ﬁne structure\nof our proof we write LHSn for the expression 1 + 2 + 3 + 4 + · · · + n and\nRHSn for n · (n + 1)/2. Thus, we need to show LHSn = RHSn for all n ≥1.\nBase case: If n equals 1, then LHS1 is just 1 (there is only one summand),\nwhich happens to equal RHS1 = 1 · (1 + 1)/2.\nHere is a little anecdote about the German mathematician Gauss who, as a\npupil at age 8, did not pay attention in class (can you imagine?), with the\nresult that his teacher made him sum up all natural numbers from 1 to 100.\nThe story has it that Gauss came up with the correct answer 5050 within\nseconds, which infuriated his teacher. How did Gauss do it? Well, possibly\nhe knew that\n1 + 2 + 3 + 4 + · · · + n = n · (n + 1)\n2\n(1.5)\n1.4 Semantics of propositional logic\n41\nfor all natural numbers n.9 Thus, taking n = 100, Gauss could easily calcu-\nlate:\n1 + 2 + 3 + 4 + · · · + 100 = 100 · 101\n2\n= 5050.\nMathematical induction allows us to prove equations, such as the one\nin (1.5), for arbitrary n. More generally, it allows us to show that every\nnatural number satisﬁes a certain property. Suppose we have a property M\nwhich we think is true of all natural numbers. We write M(5) to say that\nthe property is true of 5, etc. Suppose that we know the following two things\nabout the property M:\n1.\nBase case: The natural number 1 has property M, i.e. we have a proof of\nM(1).\n2.\nInductive step: If n is a natural number which we assume to have property\nM(n), then we can show that n + 1 has property M(n + 1); i.e. we have a proof\nof M(n) →M(n + 1).\nDeﬁnition 1.30 The principle of mathematical induction says that, on the\ngrounds of these two pieces of information above, every natural number n\nhas property M(n). The assumption of M(n) in the inductive step is called\nthe induction hypothesis.\nWhy does this principle make sense? Well, take any natural number k.\nIf k equals 1, then k has property M(1) using the base case and so we are\ndone. Otherwise, we can use the inductive step, applied to n = 1, to infer\nthat 2 = 1 + 1 has property M(2). We can do that using →e, for we know\nthat 1 has the property in question. Now we use that same inductive step on\nn = 2 to infer that 3 has property M(3) and we repeat this until we reach 1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\nSo ¬p1, ¬p2 mean they (respectively) are wearing a white one. Informally\njustify each of the following premises in terms of the description of the\nproblem:\ni. K2K1 (p1 ∨p2)\nii. K2(¬p2 →K1 ¬p2)\niii. K2¬K1 p1.\n(c) Using natural deduction, prove from these premises that K2 p2.\n(d) Show that the third premise was essential, by exhibiting a model/world\nwhich satisﬁes the ﬁrst two, but not the conclusion.\n(e) Now is it easy to answer questions like ‘If man 2 were blind would he still be\nable to tell?’ and ‘if man 1 were blind, would man 2 still be able to tell?’?\n12. Recall our informal discussion on positive-knowledge formulas and negative-\nknowledge formulas. Give formal deﬁnitions of these notions.\n5.7 Bibliographic notes\nThe ﬁrst systematic approaches to modal logic were made by C. I. Lewis\nin the 1950s. The possible-worlds approach, which greatly simpliﬁed modal\nlogic and is now almost synonymous with it, was invented by S. Kripke.\nBooks devoted to modal logic include [Che80, Gol87, Pop94], where exten-\nsive references to the literature may be found. All these books discuss the\nsoundness and completeness of proof calculi for modal logics. They also in-\nvestigate which modal logics have the ﬁnite-model property: if a sequent\ndoes not have a proof, there is a ﬁnite model which demonstrates that. Not\nall modal logics enjoy this property, which is important for decidability.\nIntuitionistic propositional logic has the ﬁnite-model property; an anima-\ntion which generates such ﬁnite models (called PORGI) is available from\nA. Stoughton’s website2.\nThe idea of using modal logic to reason about knowledge is due to J.\nHintikka. A great deal of work on applying modal logic to multi-agent sys-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nsumed or given as a premise some formula η1 ∨η2 in some line k′ with\nk′ < k, which was referred to via ∨e in the justiﬁcation of line k. Thus,\nwe have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within that\nproof, obtained by turning all assumptions of boxes that are open at\nline k′ into premises. In a similar way we obtain proofs of the sequents\nφ1, φ2, . . . , φn, η1 ⊢ψ and φ1, φ2, . . . , φn, η2 ⊢ψ from the case analysis of ∨e.\nBy our induction hypothesis, we conclude that the relations φ1, φ2, . . . , φn ⊨\nη1 ∨η2, φ1, φ2, . . . , φn, η1 ⊨ψ and φ1, φ2, . . . , φn, η2 ⊨ψ hold. But together\nthese three relations then force that φ1, φ2, . . . , φn ⊨ψ holds as well –\nwhy?\n3.\nYou can guess by now that the rest of the argument checks each possible proof\nrule in turn and ultimately boils down to verifying that our natural deduction\n1.4 Semantics of propositional logic\n49\nrules behave semantically in the same way as their corresponding truth tables\nevaluate. We leave the details as an exercise.\n2\nThe soundness of propositional logic is useful in ensuring the non-existence of\na proof for a given sequent. Let’s say you try to prove that φ1, φ2, . . . , φ2 ⊢ψ\nis valid, but that your best eﬀorts won’t succeed. How could you be sure that\nno such proof can be found? After all, it might just be that you can’t ﬁnd\na proof even though there is one. It suﬃces to ﬁnd a valuation in which φi\nevaluate to T whereas ψ evaluates to F. Then, by deﬁnition of ⊨, we don’t\nhave φ1, φ2, . . . , φ2 ⊨ψ. Using soundness, this means that φ1, φ2, . . . , φ2 ⊢ψ\ncannot be valid. Therefore, this sequent does not have a proof. You will\npractice this method in the exercises.\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\nas instances of the axiom scheme K: 2(φ →ψ) →(2φ →2ψ) and of the\nschemes in (5.3). Many other formulas, such as\nr 2p →p\nr 2p →22p\nr ¬2p →2¬2p\nr 3⊤\nare not valid. For example, for each one of these, there is a world in the\nKripke model of Figure 5.3 which does not satisfy the formula. The world\nx1 satisﬁes 2p, but it does not satisfy p, so it does not satisfy 2p →p. If we\nadd R(x2, x1) to our model, then x1 still satisﬁes 2p but does not satisfy\n22p. Thus, x1 fails to satisfy 2p →22p. If we change L(x4) to {p, q}, then\nx4 does not satisfy ¬2p →2¬2p, because it satisﬁes ¬2p, but it does not\nsatisfy 2¬2p – the path R(x4, x5)R(x5, x4) serves as a counter example.\nFinally, x6 does not satisfy 3⊤, for this formula states that there is an\naccessible world satisfying ⊤, which is not the case.\nIf we are to build a logic capturing the concept of necessity, however, we\nmust surely have that 2p →p is valid; for anything which is necessarily true\nis also simply true. Similarly, we would expect 2p →p to be valid in the\ncase that 2p means ‘agent Q knows p,’ for anything which is known must\nalso be true. We cannot know something which is false. We can, however,\nbelieve falsehoods, so in the case of a logic of belief, we would not expect\n2p →p to be valid.\nPart of the job of logic engineering is to determine what formula schemes\nshould be valid and to craft the logic in such a way that precisely those ones\nare valid.\nTable 5.7 shows six interesting readings for 2 and eight formula schemes.\nFor each reading and each formula scheme, we decide whether we should\nexpect the scheme to be valid. Notice that we should only put a tick if the\n318\n5 Modal logics and agents\n2φ\n2φ →φ\n2φ →22φ\n3φ →23φ\n3⊤\n2φ →3φ\n2φ ∨2¬φ\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\nputational situations. If we disallow their usage in natural deduction proofs,\nwe obtain a logic, called intuitionistic propositional logic, together with its\nown proof theory. So far so good; but it is less clear what sort of semantics\none could have for such a logic – again with soundness and completeness in\nmind. This is where certain models of KT4 will do the job quite nicely. Recall\nthat correspondence theory implies that a model M = (W, R, L) of KT4 is\nsuch that R is reﬂexive and transitive. The only additional requirement we\nimpose on a model for intuitionistic propositional logic is that its labelling\nfunction L be monotone in R: R(x, y) implies that L(x) is a subset of L(y).\nThis models that the truth of atomic positive formulas persist throughout\nthe worlds that are reachable from a given world.\nDeﬁnition 5.19 A model of intuitionistic propositional logic is a model\nM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). Given\na propositional logic formula as in (1.3), we deﬁne x ⊩φ as in Deﬁnition 5.4\nexception for the clauses →and ¬. For φ1 →φ2 we deﬁne x ⊩φ1 →φ2 iﬀ\nfor all y with R(x, y) we have y ⊩φ2 whenever we have y ⊩φ1. For ¬φ we\ndeﬁne x ⊩¬φ iﬀfor all y with R(x, y) we have y ̸⊩φ.\nAs an example, consider the model W = {x, y} with accessibility relation\nR = {(x, x), (x, y), (y, y)}, which is indeed reﬂexive and transitive. For a la-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables 1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nseparate layers such that validity checks are easy. This is being done by\n1.\nusing the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of →from a\nformula and\n2.\nby specifying an algorithm that takes a formula without any →into a normal\nform (still without →) for which checking validity is easy.\nNaturally, we have to specify which forms of formulas we think of as being\n‘normal.’ Again, there are many such notions, but in this text we study only\ntwo important ones.\nDeﬁnition 1.42 A literal L is either an atom p or the negation of an atom\n¬p. A formula C is in conjunctive normal form (CNF) if it is a conjunction\nof clauses, where each clause D is a disjunction of literals:\nL ::= p | ¬p\nD ::= L | L ∨D\n(1.6)\nC ::= D | D ∧C.\n56\n1 Propositional logic\nExamples of formulas in conjunctive normal form are\n(i)\n(¬q ∨p ∨r) ∧(¬p ∨r) ∧q\n(ii)\n(p ∨r) ∧(¬p ∨r) ∧(p ∨¬r).\nIn the ﬁrst case, there are three clauses of type D: ¬q ∨p ∨r, ¬p ∨r, and q –\nwhich is a literal promoted to a clause by the ﬁrst rule of clauses in (1.6).\nNotice how we made implicit use of the associativity laws for ∧and ∨,\nsaying that φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η and φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η, since\nwe omitted some parentheses. The formula (¬(q ∨p) ∨r) ∧(q ∨r) is not in\nCNF since q ∨p is not a literal.\nWhy do we care at all about formulas φ in CNF? One of the reasons\nfor their usefulness is that they allow easy checks of validity which other-\nwise take times exponential in the number of atoms. For example, consider\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\nputational situations. If we disallow their usage in natural deduction proofs,\nwe obtain a logic, called intuitionistic propositional logic, together with its\nown proof theory. So far so good; but it is less clear what sort of semantics\none could have for such a logic – again with soundness and completeness in\nmind. This is where certain models of KT4 will do the job quite nicely. Recall\nthat correspondence theory implies that a model M = (W, R, L) of KT4 is\nsuch that R is reﬂexive and transitive. The only additional requirement we\nimpose on a model for intuitionistic propositional logic is that its labelling\nfunction L be monotone in R: R(x, y) implies that L(x) is a subset of L(y).\nThis models that the truth of atomic positive formulas persist throughout\nthe worlds that are reachable from a given world.\nDeﬁnition 5.19 A model of intuitionistic propositional logic is a model\nM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). Given\na propositional logic formula as in (1.3), we deﬁne x ⊩φ as in Deﬁnition 5.4\nexception for the clauses →and ¬. For φ1 →φ2 we deﬁne x ⊩φ1 →φ2 iﬀ\nfor all y with R(x, y) we have y ⊩φ2 whenever we have y ⊩φ1. For ¬φ we\ndeﬁne x ⊩¬φ iﬀfor all y with R(x, y) we have y ̸⊩φ.\nAs an example, consider the model W = {x, y} with accessibility relation\nR = {(x, x), (x, y), (y, y)}, which is indeed reﬂexive and transitive. For a la-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nthe truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nevaluate to F, then our induction hypothesis and the rule ∧i give us ˆp1, . . . , ˆpn ⊢\n¬φ1 ∧¬φ2 and we have to show ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2), which we leave as an\nexercise. Second, if φ1 and φ2 evaluate to T, then we obtain ˆp1, . . . , ˆpn ⊢φ1 ∧φ2,\nby our induction hypothesis, and we need a proof for φ1 ∧φ2 ⊢φ1 ∨φ2, which\nwe leave as an exercise. Third, if φ1 evaluates to F and φ2 to T, then we arrive\nat ˆp1, . . . , ˆpn ⊢¬φ1 ∧φ2, using our induction hypothesis, and need to establish\n¬φ1 ∧φ2 ⊢φ1 ∨φ2, which we leave as an exercise. Fourth, if φ1 evaluates to T\nand φ2 to F, then ˆp1, . . . , ˆpn ⊢φ1 ∧¬φ2 results from our induction hypothesis\nand all we need is a proof for φ1 ∧¬φ2 ⊢φ1 ∨φ2, which we leave as an\nexercise.\n2\nWe apply this technique to the formula ⊨φ1 →(φ2 →(φ3 →(. . . (φn →\nψ) . . . ))). Since it is a tautology it evaluates to T in all 2n lines of its truth\ntable; thus, the proposition above gives us 2n many proofs of ˆp1, ˆp2, . . . , ˆpn ⊢\nη, one for each of the cases that ˆpi is pi or ¬pi. Our job now is to assemble\nall these proofs into a single proof for η which does not use any premises.\nWe illustrate how to do this for an example, the tautology p ∧q →p.\nThe formula p ∧q →p has two propositional atoms p and q. By the propo-\nsition above, we are guaranteed to have a proof for each of the four sequents\np, q ⊢p ∧q →p\n¬p, q ⊢p ∧q →p\np, ¬q ⊢p ∧q →p\n¬p, ¬q ⊢p ∧q →p.\nUltimately, we want to prove p ∧q →p by appealing to the four proofs of\nthe sequents above. Thus, we somehow need to get rid of the premises on\n1.5 Normal forms\n53\nthe left-hand sides of these four sequents. This is the place where we rely on\nthe law of the excluded middle which states r ∨¬r, for any r. We use LEM\nfor all propositional atoms (here p and q) and then we separately assume all\nthe four cases, by using ∨e. That way we can invoke all four proofs of the\nsequents above and use the rule ∨e repeatedly until we have got rid of all our\nonly ﬁnitely many premises ∆from Γ. But then ∆⊢⊥is valid, too, and\nso ∆⊨⊥follows by soundness. But the latter contradicts the fact that all\nﬁnite subsets of Γ are consistent.\n2\nFrom this theorem one may derive a number of useful techniques. We men-\ntion a technique for ensuring the existence of models of inﬁnite size.\nTheorem 2.25 (L¨owenheim-Skolem Theorem) Let ψ be a sentence of\npredicate logic such for any natural number n ≥1 there is a model of ψ with\nat least n elements. Then ψ has a model with inﬁnitely many elements.\nPROOF:\nThe formula φn\ndef\n= ∃x1∃x2 . . . ∃xn\n\u0004\n1≤i<j≤n ¬(xi = xj) speciﬁes\nthat there are at least n elements. Consider the set of sentences Γ\ndef\n=\n{ψ} ∪{φn | n ≥1} and let ∆be any if its ﬁnite subsets. Let k ≥1 be such\nthat n ≤k for all n with φn ∈∆. Since the latter set is ﬁnite, such a k has to\nexist. By assumption, {ψ, φk} is satisﬁable; but φk →φn is valid for all n ≤k\n(why?). Therefore, ∆is satisﬁable as well. The compactness theorem then\nimplies that Γ is satisﬁable by some model M; in particular, M ⊨ψ holds.\nSince M satisﬁes φn for all n ≥1, it cannot have ﬁnitely many elements. 2\nWe can now show that reachability is not expressible in predicate logic.\nTheorem 2.26 Reachability is not expressible in predicate logic: there is\nno predicate-logic formula φ with u and v as its only free variables and R as\nits only predicate symbol (of arity 2) such that φ holds in directed graphs\niﬀthere is a path in that graph from the node associated to u to the node\nassociated to v.\nPROOF:\nSuppose there is a formula φ expressing the existence of a path\nfrom the node associated to u to the node associated to v. Let c and c′ be\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and",
                    "summary": "If we combine declarative sentences p and q with a logical connective, say                , the truth value of p is determined by three things. The meaning of  is captured by the observation that p is true iﬀp and q are both true; otherwise p is false. As far as  is concerned, it needs only to know whether p andQ are true, it does not need to know what p andq are actually saying about the world out there.  A valuation or model of a formula φ is an assignment of each propositional atom in φ to a truth value. The set of truth values contains two elements T and F, where T represents 'true' and F represents 'false' This is also the case for all the other logical connectives and is the reason why we can compute the truth value of a Formula just by knowing the truth values of the atomic propositions occurring in it. In the ﬁrst column, labelled φ, we list all possible valuations for a formula. We can think of the meaning of φ as a function of two arguments; each argument is a truthvalue. Wespecify this function in a table, called the truth The truth tables for all the logical connectives discussed so far. In the third column, we list the result of φ  according to the truth values of  φ and ψ. Notice that the possible number of combinations of. truthvalues for ω and ω equals 2 · 2 = 4. The truth table for conjunction, the logical connectedive, is shown in Figure 1.6.1 Propositional logic. The logical connective is called the ‘logical connective’ and it is defined by the following formula: ‘T’, ‘F,’ ‘C’,. ‘D’. ‘‘F’., ‘ In Figure 1.6 you can see the truth tables for all logical connectives of propo-sitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the mirror image of conjunction if we swap T and F. The behaviour of implication is not quite intuitive. Think of the meaning of →as checking whether truth is beingpreserved. It is not the case when we have T →F, since we infersomething that is false from something that is true. In all other lines, the result is F since at least one of the propositions φ or ψ has value F. So the second entry in the column φ →ψ equals F. If you feel slightly uncomfortable with the semantics of propositional logic, then it might be good to think of φ → ω as an abbreviation of the formula ¬φ ∨ ω. The two formulas are very similar syntactically and natural deduction treats them diﬀerently as well. Using the truth tables for ¬ and ∨you can check that φ · ω evaluates the truth table. This means that the formulas are semanticallyequivalent; more on that in Section 1.5. R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. The unary connectives (consisting of ¬ and the temporal connectives X, F and G) bind most tightly. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. We assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The parse tree of F p →G r is illustrated in Figure 3.2. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities. Others, however, are required to resolve ambiguisms. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. We are able to give a semantics to formulas of predicate logic. Forpositional logic, we did this by computing a truth value. Verification by model checking can be done by checking the formula’s subformula for a variable y to l(y). For example, with no brackets at all, the second formula would become F p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.1. The following are not well-formed formulas: U r – since U is binary, not unary Given a model M for a pair (F, P) and given an environ-                ment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula over the pair. If φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, T2, tn in the set A by replacing all variables with their values according to l. In this way, we compute concrete values a1, a2,. . ., an of A for each of these terms, where a1 is a function symbol. We say that φ computes to T in the model M with respect to the The relation M ⊨l ψ holds for all a ∈A. , an) is in the set P M. It is not the case that M ≹ holds. We sometimes write M  M    φ to denote that M    does not hold, regardless of the choice of φ. There is a straightforward inductive argument on the height of the parse tree of a formula which says that M M M φ holds, whenever l′ and l′ are two environments which are identical on the set of free variables M  M φ is called a sentence. The relation M  ≳ M  ω holds iﬀM � The deﬁnitions (¬, 2 and 3) bind most closely, followed by  and then followed by                by. This convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. For example, for sentences φ we often elide l and write M ⊨φ since the choice of                an environment l is then irrelevant. We cannot omit theremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse tree from the one in Figure 5.2. We may read modal logics to express various modes of truth, we may read them appropriately. For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. Model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W →P(Atoms) These models are often called Kripke models, in honour of S. Kripk who invented them. The parse tree for 23q ∧¬r →2p.3 is shown in the next section of the book. The book is published by Oxford University Press, priced £9.99, with a print run of 1,000 copies. For confidential support call the Samaritans on 08457 90 90 The formulas of propositional logic below implicitly assume the binding priorities of the logical connectives put forward in Convention 1.3. Make sure that you fullyunderstand those conventions by reinserting as many brackets as possible. For example, given p ∧q →r, change it to (p  q  r) since (p  q  r binds more tightly than p q. Here you might be able to ‘recycle’ and augment a proof from a previous exercise. Prove the validity of the following sequents: Prove that the ‘p’ in the word ‘prove’ is not the same as the “p” in “proving” the statement ‘I’m not sure I’ve got it right’. Proving that the p is not ‘the same thing’ as the p in ‘Proving that I think I know it’s the same thing is a lie’ can be done by using the following steps: 1.7 Exercises 1.79 Exercise We are entitled to use these rules of constructing propositions repeatedly. For the sequents below, show which ones are valid and which ones aren’t. For example, we are now in a position to form the proposition. ‘If p and q then not r or q’. You might have noticed a potential ambiguity in this reading. A computer would requirethe insertion of brackets, as in(p ∧q) → (¬r) (‘p’) ‘p is the case and if q then . . . ’ ‘P’ is the assumption of p →q and q its conclusion.’ “P” is the logical consequence of p. � In this text or always means at least one of them and should not beconfounded with exclusive or which states that exactly one of the two statements holds. The natural language meaning of ‘if . .. then . . . ’ often implicitly assumes a causal role of somehow enabling its conclusion. For example, ‘If all birds can ﬂy, then Bob Dole was never president of the United States of America’ is a true statement, but there is no known causal connection between penguins and eﬀective campaigning. We humans get annoyed by a pro-liferation of such brackets which is why we adopt certain conventions about the binding priorities of these symbols. Gentzen invented the idea of working with assumptions and treating all the connectives sepa- progressively. The linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the United States of America. For an introduction to algorithms and datastructures see e.g. the bibliographic remarks at the end of Chapter 2. The book is available in English, Swedish, Finnish, Danish, Norwegian, Finnish and Danish. The price for the book is £16.99, which includes the book and its bibliographical remarks. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samar In the ﬁrst chapter, we developed propositional logic by examining it from three angles. Propositional logic dealt quite satisfactorily with sentence components like not, and, or if. But the logical aspects of natural and artiﬁcial languages are much richer than that. What can we do with modi-glueers like there exists? And how can we use them to encode declarative sentences in a richer language? We begin this second chapter by pointing out the limitations of propo-sitional logic with respect to encoding declaratives sentences. We conclude this chapter by discussing the possibility of using predicate logic to encode statements about the world. In propositional logic, we could identify this assertion with a propositional done. We can do that using →e, for we know that 1 has the property in question. The desire to express more subtle declarative sentences led to the design of predicate logic, which is also called ﬁrst-order logic. We use that same inductive step on n = 2 to infer that 3 has property M(3) and we repeat this until we reach k (see Figure 1.9).  Here, propositional Logic shows clearlimitations. Theorem 1.31: The sum 1 + 2 + 3 + 4 + · · · + n equals n · (n + 1)/2 for all natural numbers n. 2.9: There is another way of writing the sum 1.3 + 2.4 + 3.5 + 4 as 100 + 99 + ·· · + 1. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 34. 35. 34, 35, 36, 37, 38, 39 The principle of mathematical induction works. By proving just two facts, M(1) and M(n) →M(n + 1) for a formal (andunconstrained) parameter n, we are able to deduce M(k) for each natural number k. In order to reveal the structure of our proof, we write LHSn for the expression 1 + 2 + 3 + 4 + · · · + n and RHSn  for n · ( n + 1)/2. The method of Mathematical induction is much more powerful and can be used in a wide variety of situations. We use mathematical induction to prove the following propositions. The proof is based on the theory of propositional logic. The story has it that Gauss came up with the correct answer 5050 within seconds, which infuriated his teacher. How did Gauss do it? Well, possibly he knew that n = n · (n + 1) + 2 + 3 + 4 + · · · + n. More generally, it allows us to show that everynatural number satisﬁes a certain property. For example, we need to show LHSn = RHSn for all n ≥1. If n equals 1, then LHS1 is just 1 (there is only one summand),                which happens to equal RHS1 = 1 · (1 + 1)/2. 30 The principle of mathematical induction says that, on the grounds of these two pieces of information above, every natural number nhas property M(n) The assumption of M( n) in the inductive step is called the induction hypothesis. If n is a natural number which we assume to have property M, then we can show that n + 1 has propertyM(n + 1); i.e. we have a proof of M('M' is a number that has property M('N' or 'N' is the same as 'M('N')). If n = 1, we can infer from the base case that 2 = 1 + 1 is also a number with property M ('N' + 1) In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. Whenever φ1, φ2, . . . , φn ⊨ψ holds, then there exists a natural deduction proof for the sequent. The logic program-centric paradigm is based on this idea of complete deduction rules. We hope that this will give you a better idea of how to use the logic program to solve problems in your program. We conclude with the conclusion that the logical program can be used to solve questions in a program that is more intuitive than the propositional one. The program can also be used as a tool to teach people how to solve propositional problems. The second method typically forces you to com-pute a truth table which is exponential in the size of occurring proposi-                tional atoms. Both methods are intractable in general but particular in-stances of formulas often respond diﬀerently to treatment under these two methods. The only way this parse tree can evaluate to F. is to repre-sent parse trees for φ1, φ2, . . .    Figure 1.11. Propositional logic: Theory of propositional logic and its application to propositional reasoning. Figure 1.10. The Theory of Propositions: Theory of Positional Logic and its Applications. A formula of propositional logic φ is called a tautology iﬀit evaluates to T under all its valuations, i.e. φ1, φ2, . . . , φn ⊨ψ holds. In this section we will prove that K2 p2 means that K1 p1 is wearing a white one. We will also show that the third premise was essential, by exhibiting a model/world which satisﬁes the ﬁrst two, but not the conclusion. In the next section, we will look at the problem of how to prove that a formula can be proved to be true. The idea of using modal logic to reason about knowledge is due to J.Hintikka. The possible-worlds approach, which greatly simpliﬁed modallogic and is now almost synonymous with it, was invented by S. Kripke. Not all modal logics enjoy the property that if a sequent does not have a proof, there is a model which demonstrates that. This property is important for decidability. The idea that propositional logic can be used to prove that a proposition is true is based on the fact that it can be shown to be true with a certain degree of certainty. The notion of a ‘world’ can be derived from the idea that the An adequate set of connectives for propositional logic is a set such that for every formula there is an equivalent formula with only connectives from that set. A great deal of work on applying modal logic to multi-agentsys-                tems has been done in [FHMV95] and [MvdH95] Many examples in this chapter are taken from this literature. Some examples are attributed to other people there, though our treatment of them is original. We show that the set {¬, ∨} is adequate for propositionally logic, because any occurrence of and can be removed by using the equivalences. We also show that, if C is adequate, then C or ⊥C Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that the relation ≡ is reﬂexive, symmetric, transitive, commutative, associative, distributive, and absorptive. Prove your answer to the question Is {↔, ¬} adequate? Proving your answer will help you understand the de Morgan rules. Proving the truth value of a formula φ, formed by using only the connectives in C, can be done by using the word \"proving\" in the form C = C + T.  construct a formula in CNF based on each of the following truth tables. Construct a formula based on the truth tables: (a) (b) (c) (d) (e) (f) (g) (h) (i) (j) (k) (l) (m) (n) (o) (t) (p) (r) (u) (w) (z) (s) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) The soundness of propositional logic is useful in ensuring the non-existence of a proof for a given sequent. It suﬃces to ﬁnd a valuation in which φievaluate to T whereas ψ evaluates to F. The rest of the argument checks each possible proof in turn and ultimately boils down to verifying that our natural deduction holds as well as the corresponding truth table. We leave the details as an exercise and will return to the argument in the next section of the book. We hope that this article has helped you understand some of the concepts behind propositional Logic and its use in the study of the theory of logic. The book is published by Oxford University Press and is available in English and In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. Whenever φ1, φ2, . . . , φn ⊨ψ holds, then there exists a natural deduction proof for the sequent. You will practice this method in the exercises. We see some valid formulas of basic modal logic, such as instances of the axiom scheme K: 2( φ → ω) and 2(2φ →2ω) The world in the Kripke model of Figure 5.3 does not satisfy the formula 2p →p. For example, for each one of these, there is a world which does not satisfies the formula If we add R(x2, x1) to our model, then x1 still satisﬁes 2p but does not satisfy 22p. If we change L(x4) to {p, q], then x4 does not satisfies 2¬2p. For anything which is necessarily true, it must also be simply true. We cannot know something which is false. We would expect 2p →p to be valid in the case that 2p means ‘agent Q knows p,’ for anything that is known mustalso be true. For this to be true, 2p must surely be valid, and we need to know 2p is valid. The job of logic engineering is to determine what formula schemesshould be valid and to craft the logic in such a way that precisely those ones are valid. Table 5.7 shows six interesting readings for 2 and eight formula schemes. For each reading and each formula scheme, we decide whether we should expect the scheme to be valid. Notice that we should only put a tick if the scheme is valid for both the reading and the formula scheme. We also pointed out that the proof rules PBC, LEM and ¬¬e are questionable in certain com-putational situations. In Chapter 1, we gave a natural de-duction system for propositional logic which was sound and complete with semantic entailment based on truth tables. A model of intuitionistic propositional logic is a model M = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). This models that the truth of atomic positive formulas persist throughout the worlds that are reachable from a given world. If we disallow their usage in natural deduction proofs, we obtain a logic, called intuitionistic logic, together with its own proof theory. So far so good; but it is less clear what sort of semantics one could have for such a logic – again with soundness and completeness in                mind. This is where certain models ofKT4 will do the job quite nicely. Given a propositional logic formula as in (1.3), we deﬁne x ⊩φ as in De ﬁnition 5.4. We claim that x  p is an instance of LEM which we proved in Chapter 1 with the full natural deduction calculus. We do not have x p, for p is not in the set L(x) which is empty. For all y with R(x, y) we have y ̸⊩ φ. For ¬φ we claim that y    φ1 is the same as y    ω1. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modalLogics with this property are called normal and all modallogics we study in this text are normal. The modal Logic KT45 is used to reason about knowledge; 2φ means that                the agent Q knows φ. The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience: the agent’s knowledge is closed under logical consequence. There are several attempts in the literature to deﬁne logics of knowledge that are more dystopianrealistic, but we will not consider them here. Even computer agents may not have all the properties of knowledge we think they do. We will discuss some of them in the next section. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 is valid if it is an equivalence relation. The relation ⊢par should be contained in Par, if our calculus is any good. If P is partially correct, then P can be proved to be partially-correct by our calculus. The second one means it is provably correct according to our calculus, while the first one means that it is actually correct. Theorem 5.17: KT45 has a sequence of equivalence relations that are valid if and only if they are provably true. We say that a calculus is complete if it is able to prove everything that is true. Formally, ⊢par is completeif it is valid whenever ⊨par is valid. We said that soundness is relatively easy to show, since typically typically the soundness of individual proof rules can be establishedindependently of the others. Thus, it is sound if it doesn’t tell us that false things can be proved. We write that the calculus that is sound is the one that is valid for all φ, ψ and P; and, similarly, similarly for  ‘tot’. We say that sounds is relativelyeasy to show since it’s easy to establish Establishing its soundness is simply a matter of considering each rule in turn. Completeness, on the other hand, is harder to show since it depends on the entire set of proof rules cooperating together. In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. This gives you a certain freedom regarding which method you prefer to use. In the next section, we will look at the program variables and logical variables in this chapter. We will then move on to the logical variables and program variables in the following sections. The final section of the book will focus on the program logic in the form of a set of logical variables. The book will be published in two parts: 1. The ﬁrst method involves a proof search, upon which the logic program-ming paradigm is based. The second method typically forces you to com-pute a truth table which is exponential in the size of occurring proposi-                tional atoms. Often it is much easier to show one of these two relationships (al-though neither of the two is universally better, or easier, to establish). The remainder of this section is concerned with an argument saying that if φ1, φ2, . . . , φn ⊨ψ holds, then φ 1, χ2, and χ3 are valid. The argument proceeds in three steps: The only way this parse tree can evaluate to F. is to repre-sent parse trees for φ1, φ2, . . . , φn as triangles. An adequate set of connectives for propositional logic is a set such that for every formula there is an equivalent formula with only connectives from that set. The first two steps are quite easy; all the real work is done in the third one. The third step is the most difficult, but it is the only way to prove that the formula is valid. The fourth and fifth steps are the most important, and they are the hardest to prove. The last step is to prove the existence of a formula that is valid under all val Prove that the set {¬,  ,   is adequate for propositional logic. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that, with respect to the relation  “Idempotent”, the terms  “idempotents” and “ idempotence” are idempotsent. Prove that a relation is symmetric if it holds for all φ and transitive if it’s symmetric for all ”“”. Proving the truth value of a formula  construct a formula in CNF based on each of the following truth tables. Construct a formula based on the de Morgan rules for double negation. Exercises in the CNF formula include the following:8.7 Exercise in the truth table: 8.7.1 Exercised in the truths table: 9.8 Exercising in the facts table: 10.9 Exercice in the Truth table: 11.9. Exercise in thetruth table: 12.9 The truth table is: 13. The truth tables are: 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27. We want to transform formulas into ones which don’t contain → at all. This is being done by using the equivalence φ → ω to remove all occurrences of → from a formula. We then specify an algorithm that takes a formula without any → into a normal form (still without →) for which checking validity is easy. We have to specify which forms of formulas we think of as being ‘normal.’ Again, there are many such notions, but in this text we study only two important ones: L and the negation of an atom p. A literal L is either an atoms p or the negations of atoms p and p. The negation is either a literal p or a literal L A formula C is in conjunctive normal form (CNF) if it is a conjunction of clauses. CNF is a disjunction of literals, where each clause D is a literal. The formula (¬(q ∨p) ∨r)  is not in CNF since q is not a literal, but it is in the rule of clauses in (1.6) CNF uses the associativity laws for  and  in the case of   and   in (i) and (ii) The formulas φ and φ are used because they allow easy checks of validity which other-wise take times exponential in the number of atoms. In the partial-correctness calculus we develop in this chapter, we say that the. subsequent ⊢par is valid. If our calculus is any good, then the relation should be contained inpar! More precisely, we will say that our calculus. is sound if, whenever it tells us something can be proved, that thing is indeed true. Thus, it is sound. if it doesn’t tell us that false things can be. proved. In the total-corrects calculus to be developed in the next chapter, the relation. ⊨par holds if P is partially correct, while the validity of. the relation of ‘P’ is valid if P can be proven to be partially-correct In Chapters 1 and 2, we said that soundness is relatively easy to show, typically typically the soundness of individual proof rules can be established independently of the others. We say that a calculus is complete if it is able to prove everything that is true. Formally, ⊢par is completeif it is valid for all φ, ψ and P; and, similarly,  tot is sound if it can be proved that all of the numbers in it are true. We also say that  “par’s” existence is valid whenever it is used in a calculus, and that “tot” can be proven to be true as well. In Chapter 1, we gave a natural de-duction system for propositional logic which was sound and complete with its own proof theory. We also pointed out that the proof rules PBC, LEM and ¬¬e are questionable in certain com-putational situations. The same situation holds for the program logic we introduce in this chapter. Establishing its soundness is simply a matter of considering each rule in turn – done in exercise 3 on page 303 – whereas establishing its (relative)completeness is harder and beyond the scope of this book. In Chapter 4, we show that the program verification depends on the entire set of proof rules cooperating together. We conclude that the logic, called intuitionistic propositional Logic A model of intuitionistic propositional logic is a modelM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y) This models that the truth of atomic positive formulas persist throughout the worlds that are reachable from a given world. So far so good; but it is less clear what sort of semantics one could have for such a logic – again with soundness and completeness in mind. This is where certain models ofKT4 will do the job quite nicely. Recall that correspondence theory implies that a model M = (w, r, l) is reﬂexive and transitive. For all y with R(x, y) we have y ̸⊩φ. We do not have x ⊩p, for p is not in the set L(x) which is empty. Deﬁnition 5.4 for the case of φ1, φ2, . . . , φ 2 does not have a proof. In the exercises, we apply this to show that a se-                quent does not has a proof: simply show that φ does not seman-                tically entail ψ. Then soundness implies that the sequent φ doesn't have aProof of truth-table semantics. In Exercise 1.2.6 we sketch a non-linear, tree-like,                notion of proofs for sequents. This tight cor-                respondence allows us to freely switch between working with the notion of                proofs and that of semantic entailment. We now investigate various alternatives for deciding whether two formulas are ‘equivalent’ by syntactic or algorithmic means. This requires that we clarify exactly what exactly we mean by equivalent formulas. We conclude by looking at the validity of two formulas, and their satisfiability and validity in terms of their semantic meaning and their syntactic and algorithmic counterparts. The results of this investigation will be published in the next issue of Theoretical Semantics. For example, all four combinations of T and F for p and q return the same result. This suggests that we deﬁnelyevaluate to F, then our induction hypothesis and the rule  i give us ˆp1, . . . , ˾pn ⊢                 ¬φ1   ¬ 2, which we leave as an exercise. Third, if φ1 and φ2 evaluate to T, then we arrive at ˼p1,. . ., ˉpn ≢ φ 1 ≵    “” and we need a proof for ”  If φ1 evaluates to T and φ2 to F, then ˆp1, . . . ,  ˆpn ⊢¬φ1  , using our induction hypothesis. Since it is a tautology, the proposition above gives us 2n many proofs. Our job now is to assemble all these proofs into a single proof for η which does not use any premises. We illustrate how to do this for an example, the tautological p ∧q →p. The formula p  has two propositional atoms p and q.  We apply this technique to the formula ⊨ ω1 →( ω2 → ( ω3 → By the propo-                sition above, we are guaranteed to have a proof for each of the four sequents. We use LEMfor all propositional atoms (here p and q) and then we separately assume all four cases. That way we can invoke all four proofs of the sequents above and use the rule ∨e repeatedly until we have got rid of all our premises. But then the latter contradicts the fact that all subsets of Γ are consistent. From this theorem one may derive a number of useful techniques. For example, we can use the LEM rule to prove that p  p q q is not a non-positional atom. Theorem 2.25 (L¨owenheim-Skolem Theorem) Let ψ be a sentence of predicate logic with at least n elements. Then ψ has a model with inﬁnitely many elements. We men-                tion a technique for ensuring the existence of models of in-nite size. For example, the formula φn                 is a model of ψ with n elements in it. The compactness theorem thenimplies that ψ is satisﬀable by some model M. Since M cannot have in-NINE elements, ψ cannot be a model for M. Theorem 2,25 (SkoleM Theorem), is based on the Theorem 2.26 Reachability is not expressible in predicate logic. There is no predicate-logic formula φ with u and v as its only free variables and R as the only predicate symbol (of arity 2) Such that φ holds in directed graphs such that there is a path in that graph from the node associated to u to the nodes associated to v. We can now show that reachability isn't expressible with a formula like this. The proof is given in the next section of the book. For more information on the book, visit: http://www.academyofmaths.org/faculty/facile/facility-of-mathematicians/mathematician-",
                    "children": [
                        {
                            "id": "chapter-1-section-3-subsection-1",
                            "title": "Meaning of Logical Connectives",
                            "content": "reality (they are true), or they don’t (they are false).\nIf we combine declarative sentences p and q with a logical connective, say\n∧, then the truth value of p ∧q is determined by three things: the truth value\nof p, the truth value of q and the meaning of ∧. The meaning of ∧is captured\nby the observation that p ∧q is true iﬀp and q are both true; otherwise p ∧q\nis false. Thus, as far as ∧is concerned, it needs only to know whether p and\nq are true, it does not need to know what p and q are actually saying about\nthe world out there. This is also the case for all the other logical connectives\nand is the reason why we can compute the truth value of a formula just by\nknowing the truth values of the atomic propositions occurring in it.\nDeﬁnition 1.28 1.\nThe set of truth values contains two elements T and F, where\nT represents ‘true’ and F represents ‘false’.\n2.\nA valuation or model of a formula φ is an assignment of each propositional atom\nin φ to a truth value.\nExample 1.29 The map which assigns T to q and F to p is a valuation for\np ∨¬q. Please list the remaining three valuations for this formula.\nWe can think of the meaning of ∧as a function of two arguments; each\nargument is a truth value and the result is again such a truth value. We\nspecify this function in a table, called the truth table for conjunction, which\nyou can see in Figure 1.5. In the ﬁrst column, labelled φ, we list all possible\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nFigure 1.5. The truth table for conjunction, the logical connective ∧.\n38\n1 Propositional logic\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nφ\nψ\nφ ∨ψ\nT\nT\nT\nT\nF\nT\nF\nT\nT\nF\nF\nF\nφ\nψ\nφ →ψ\nT\nT\nT\nT\nF\nF\nF\nT\nT\nF\nF\nT\nφ\n¬φ\nT\nF\nF\nT\n⊤\nT\n⊥\nF\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nvalues in the ﬁrst two columns really exhaust all those possibilities (TT, TF,\nFT and FF). In the third column, we list the result of φ ∧ψ according to the\ntruth values of φ and ψ. So in the ﬁrst line, where φ and ψ have value T,\nthe result is T again. In all other lines, the result is F since at least one of\nthe propositions φ or ψ has value F.\nIn Figure 1.6 you ﬁnd the truth tables for all logical connectives of propo-\nsitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the\nmirror image of conjunction if we swap T and F, namely, a disjunction re-\nturns F iﬀboth arguments are equal to F, otherwise (= at least one of the\narguments equals T) it returns T. The behaviour of implication is not quite\nas intuitive. Think of the meaning of →as checking whether truth is being\npreserved. Clearly, this is not the case when we have T →F, since we infer\nsomething that is false from something that is true. So the second entry\nin the column φ →ψ equals F. On the other hand, T →T obviously pre-\nserves truth, but so do the cases F →T and F →F, because there is no truth\nto be preserved in the ﬁrst place as the assumption of the implication is\nfalse.\nIf you feel slightly uncomfortable with the semantics (= the meaning)\nof →, then it might be good to think of φ →ψ as an abbreviation of the\nformula ¬φ ∨ψ as far as meaning is concerned; these two formulas are very\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nany other variable y to l(y).\nFinally, we are able to give a semantics to formulas of predicate logic. For\npropositional logic, we did this by computing a truth value. Clearly, it suﬃces\nto know in which cases this value is T.\n128\n2 Predicate logic\nDeﬁnition 2.18 Given a model M for a pair (F, P) and given an environ-\nment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula\nφ over the pair (F, P) and look-up table l by structural induction on φ. If\nM ⊨l φ holds, we say that φ computes to T in the model M with respect to\nthe environment l.\nP:\nIf φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, t2, . . . , tn in\nour set A by replacing all variables with their values according to l. In this way\nwe compute concrete values a1, a2, . . . , an of A for each of these terms, where\nwe interpret any function symbol f ∈F by f M. Now M ⊨l P(t1, t2, . . . , tn)\nholds iﬀ(a1, a2, . . . , an) is in the set P M.\n∀x:\nThe relation M ⊨l ∀x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for all a ∈A.\n∃x:\nDually, M ⊨l ∃x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for some a ∈A.\n¬:\nThe relation M ⊨l ¬ψ holds iﬀit is not the case that M ⊨l ψ holds.\n∨:\nThe relation M ⊨l ψ1 ∨ψ2 holds iﬀM ⊨l ψ1 or M ⊨l ψ2 holds.\n∧:\nThe relation M ⊨l ψ1 ∧ψ2 holds iﬀM ⊨l ψ1 and M ⊨l ψ2 hold.\n→:\nThe relation M ⊨l ψ1 →ψ2 holds iﬀM ⊨l ψ2 holds whenever M ⊨l ψ1 holds.\nWe sometimes write M ̸⊨l φ to denote that M ⊨l φ does not hold.\nThere is a straightforward inductive argument on the height of the parse\ntree of a formula which says that M ⊨l φ holds iﬀM ⊨l′ φ holds, whenever\nl and l′ are two environments which are identical on the set of free variables\nof φ. In particular, if φ has no free variables at all, we then call φ a sentence;\nwe conclude that M ⊨l φ holds, or does not hold, regardless of the choice of\nl. Thus, for sentences φ we often elide l and write M ⊨φ since the choice of\nan environment l is then irrelevant.\nExample 2.19 Let us illustrate the deﬁnitions above by means of an-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\n(e) Cancer will not be cured unless its cause is determined and a new drug for\ncancer is found.\n(f) If interest rates go up, share prices go down.\n(g) If Smith has installed central heating, then he has sold his car or he has not\npaid his mortgage.\n(h)\n*\nToday it will rain or shine, but not both.\n(i)\n*\nIf Dick met Jane yesterday, they had a cup of coﬀee together, or they took\na walk in the park.\n(j) No shoes, no shirt, no service.\n(k) My sister wants a black and white cat.\n2. The formulas of propositional logic below implicitly assume the binding priorities\nof the logical connectives put forward in Convention 1.3. Make sure that you fully\nunderstand those conventions by reinserting as many brackets as possible. For\nexample, given p ∧q →r, change it to (p ∧q) →r since ∧binds more tightly\nthan →.\n(a)\n*\n¬p ∧q →r\n(b) (p →q) ∧¬(r ∨p →q)\n(c)\n*\n(p →q) →(r →s ∨t)\n(d) p ∨(¬q →p ∧r)\n(e)\n*\np ∨q →¬p ∧r\n(f) p ∨p →¬q\n(g)\n*\nWhy is the expression p ∨q ∧r problematic?\nExercises 1.2\n1. Prove the validity of the following sequents:\n(a) (p ∧q) ∧r, s ∧t ⊢q ∧s\n1.7 Exercises\n79\n(b) p ∧q ⊢q ∧p\n(c)\n*\n(p ∧q) ∧r ⊢p ∧(q ∧r)\n(d) p →(p →q), p ⊢q\n(e)\n*\nq →(p →r), ¬r, q ⊢¬p\n(f)\n*\n⊢(p ∧q) →p\n(g) p ⊢q →(p ∧q)\n(h)\n*\np ⊢(p →q) →q\n(i)\n*\n(p →r) ∧(q →r) ⊢p ∧q →r\n(j)\n*\nq →r ⊢(p →q) →(p →r)\n(k) p →(q →r), p →q ⊢p →r\n(l)\n*\np →q, r →s ⊢p ∨r →q ∨s\n(m) p ∨q ⊢r →(p ∨q) ∧r\n(n)\n*\n(p ∨(q →p)) ∧q ⊢p\n(o)\n*\np →q, r →s ⊢p ∧r →q ∧s\n(p) p →q ⊢((p ∧q) →p) ∧(p →(p ∧q))\n(q) ⊢q →(p →(p →(q →p)))\n(r)\n*\np →q ∧r ⊢(p →q) ∧(p →r)\n(s) (p →q) ∧(p →r) ⊢p →q ∧r\n(t) ⊢(p →q) →((r →s) →(p ∧r →q ∧s)); here you might be able to ‘recycle’\nand augment a proof from a previous exercise.\n(u) p →q ⊢¬q →¬p\n(v)\n*\np ∨(p ∧q) ⊢p\n(w) r, p →(r →q) ⊢p →(q ∧r)\n(x)\n*\np →(q ∨r), q →s, r →s ⊢p →s\n(y)\n*\n(p ∧q) ∨(p ∧r) ⊢p ∧(q ∨r).\n2. For the sequents below, show which ones are valid and which ones aren’t:\n(a)\n*\n¬p →¬q ⊢q →p\n(b)\n*\n¬p ∨¬q ⊢¬(p ∧q)\n(c)\n*\n¬p, p ∨q ⊢q\n(d)\n*\np ∨q, ¬q ∨r ⊢p ∨r\n(e)\n*\np →(q ∨r), ¬q, ¬r ⊢¬p without using the MT rule\n(f)\n*\nsuggesting that q is a logical consequence of p. We write p →q for that3. We\ncall p the assumption of p →q and q its conclusion.\nOf course, we are entitled to use these rules of constructing propositions\nrepeatedly. For example, we are now in a position to form the proposition\np ∧q →¬r ∨q\nwhich means that ‘if p and q then not r or q’. You might have noticed a\npotential ambiguity in this reading. One could have argued that this sentence\nhas the structure ‘p is the case and if q then . . . ’ A computer would require\nthe insertion of brackets, as in\n(p ∧q) →((¬r) ∨q)\n2 Its meaning should not be confused with the often implicit meaning of or in natural language\ndiscourse as either . . . or. In this text or always means at least one of them and should not be\nconfounded with exclusive or which states that exactly one of the two statements holds.\n3 The natural language meaning of ‘if . . . then . . . ’ often implicitly assumes a causal role of\nthe assumption somehow enabling its conclusion. The logical meaning of implication is a bit\ndiﬀerent, though, in the sense that it states the preservation of truth which might happen\nwithout any causal relationship. For example, ‘If all birds can ﬂy, then Bob Dole was never\npresident of the United States of America.’ is a true statement, but there is no known causal\nconnection between the ﬂying skills of penguins and eﬀective campaigning.\n1.2 Natural deduction\n5\nto disambiguate this assertion. However, we humans get annoyed by a pro-\nliferation of such brackets which is why we adopt certain conventions about\nthe binding priorities of these symbols.\nConvention 1.3 ¬ binds more tightly than ∨and ∧, and the latter two\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional",
                            "summary": "If we combine declarative sentences p and q with a logical connective, say                , the truth value of p is determined by three things. The meaning of  is captured by the observation that p is true iﬀp and q are both true; otherwise p is false. As far as  is concerned, it needs only to know whether p andQ are true, it does not need to know what p andq are actually saying about the world out there.  A valuation or model of a formula φ is an assignment of each propositional atom in φ to a truth value. The set of truth values contains two elements T and F, where T represents 'true' and F represents 'false' This is also the case for all the other logical connectives and is the reason why we can compute the truth value of a Formula just by knowing the truth values of the atomic propositions occurring in it. In the ﬁrst column, labelled φ, we list all possible valuations for a formula. We can think of the meaning of φ as a function of two arguments; each argument is a truthvalue. Wespecify this function in a table, called the truth The truth tables for all the logical connectives discussed so far. In the third column, we list the result of φ  according to the truth values of  φ and ψ. Notice that the possible number of combinations of. truthvalues for ω and ω equals 2 · 2 = 4. The truth table for conjunction, the logical connectedive, is shown in Figure 1.6.1 Propositional logic. The logical connective is called the ‘logical connective’ and it is defined by the following formula: ‘T’, ‘F,’ ‘C’,. ‘D’. ‘‘F’., ‘ In Figure 1.6 you can see the truth tables for all logical connectives of propo-sitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the mirror image of conjunction if we swap T and F. The behaviour of implication is not quite intuitive. Think of the meaning of →as checking whether truth is beingpreserved. It is not the case when we have T →F, since we infersomething that is false from something that is true. In all other lines, the result is F since at least one of the propositions φ or ψ has value F. So the second entry in the column φ →ψ equals F. If you feel slightly uncomfortable with the semantics of propositional logic, then it might be good to think of φ → ω as an abbreviation of the formula ¬φ ∨ ω. The two formulas are very similar syntactically and natural deduction treats them diﬀerently as well. Using the truth tables for ¬ and ∨you can check that φ · ω evaluates the truth table. This means that the formulas are semanticallyequivalent; more on that in Section 1.5. R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. The unary connectives (consisting of ¬ and the temporal connectives X, F and G) bind most tightly. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. We assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The parse tree of F p →G r is illustrated in Figure 3.2. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities. Others, however, are required to resolve ambiguisms. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. We are able to give a semantics to formulas of predicate logic. Forpositional logic, we did this by computing a truth value. Verification by model checking can be done by checking the formula’s subformula for a variable y to l(y). For example, with no brackets at all, the second formula would become F p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.1. The following are not well-formed formulas: U r – since U is binary, not unary Given a model M for a pair (F, P) and given an environ-                ment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula over the pair. If φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, T2, tn in the set A by replacing all variables with their values according to l. In this way, we compute concrete values a1, a2,. . ., an of A for each of these terms, where a1 is a function symbol. We say that φ computes to T in the model M with respect to the The relation M ⊨l ψ holds for all a ∈A. , an) is in the set P M. It is not the case that M ≹ holds. We sometimes write M  M    φ to denote that M    does not hold, regardless of the choice of φ. There is a straightforward inductive argument on the height of the parse tree of a formula which says that M M M φ holds, whenever l′ and l′ are two environments which are identical on the set of free variables M  M φ is called a sentence. The relation M  ≳ M  ω holds iﬀM � The deﬁnitions (¬, 2 and 3) bind most closely, followed by  and then followed by                by. This convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. For example, for sentences φ we often elide l and write M ⊨φ since the choice of                an environment l is then irrelevant. We cannot omit theremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse tree from the one in Figure 5.2. We may read modal logics to express various modes of truth, we may read them appropriately. For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. Model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W →P(Atoms) These models are often called Kripke models, in honour of S. Kripk who invented them. The parse tree for 23q ∧¬r →2p.3 is shown in the next section of the book. The book is published by Oxford University Press, priced £9.99, with a print run of 1,000 copies. For confidential support call the Samaritans on 08457 90 90 The formulas of propositional logic below implicitly assume the binding priorities of the logical connectives put forward in Convention 1.3. Make sure that you fullyunderstand those conventions by reinserting as many brackets as possible. For example, given p ∧q →r, change it to (p  q  r) since (p  q  r binds more tightly than p q. Here you might be able to ‘recycle’ and augment a proof from a previous exercise. Prove the validity of the following sequents: Prove that the ‘p’ in the word ‘prove’ is not the same as the “p” in “proving” the statement ‘I’m not sure I’ve got it right’. Proving that the p is not ‘the same thing’ as the p in ‘Proving that I think I know it’s the same thing is a lie’ can be done by using the following steps: 1.7 Exercises 1.79 Exercise We are entitled to use these rules of constructing propositions repeatedly. For the sequents below, show which ones are valid and which ones aren’t. For example, we are now in a position to form the proposition. ‘If p and q then not r or q’. You might have noticed a potential ambiguity in this reading. A computer would requirethe insertion of brackets, as in(p ∧q) → (¬r) (‘p’) ‘p is the case and if q then . . . ’ ‘P’ is the assumption of p →q and q its conclusion.’ “P” is the logical consequence of p. � In this text or always means at least one of them and should not beconfounded with exclusive or which states that exactly one of the two statements holds. The natural language meaning of ‘if . .. then . . . ’ often implicitly assumes a causal role of somehow enabling its conclusion. For example, ‘If all birds can ﬂy, then Bob Dole was never president of the United States of America’ is a true statement, but there is no known causal connection between penguins and eﬀective campaigning. We humans get annoyed by a pro-liferation of such brackets which is why we adopt certain conventions about the binding priorities of these symbols. Gentzen invented the idea of working with assumptions and treating all the connectives sepa- progressively. The linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the United States of America. For an introduction to algorithms and datastructures see e.g. the bibliographic remarks at the end of Chapter 2. The book is available in English, Swedish, Finnish, Danish, Norwegian, Finnish and Danish. The price for the book is £16.99, which includes the book and its bibliographical remarks. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samar In the ﬁrst chapter, we developed propositional logic by examining it from three angles. Propositional logic dealt quite satisfactorily with sentence components like not, and, or if. But the logical aspects of natural and artiﬁcial languages are much richer than that. What can we do with modi-glueers like there exists? And how can we use them to encode declarative sentences in a richer language? We begin this second chapter by pointing out the limitations of propo-sitional logic with respect to encoding declaratives sentences. We conclude this chapter by discussing the possibility of using predicate logic to encode statements about the world. In propositional logic, we could identify this assertion with a propositional. The desire to express more subtle declarative sentences led to the design of predicate logic, which is also called ﬁrst-order logic.",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-2",
                            "title": "Mathematical Induction",
                            "content": "done. Otherwise, we can use the inductive step, applied to n = 1, to infer\nthat 2 = 1 + 1 has property M(2). We can do that using →e, for we know\nthat 1 has the property in question. Now we use that same inductive step on\nn = 2 to infer that 3 has property M(3) and we repeat this until we reach\nn = k (see Figure 1.9). Therefore, we should have no objections about using\nthe principle of mathematical induction for natural numbers.\nReturning to Gauss’ example we claim that the sum 1 + 2 + 3 + 4 + · · · +\nn equals n · (n + 1)/2 for all natural numbers n.\nTheorem 1.31 The sum 1 + 2 + 3 + 4 + · · · + n equals n · (n + 1)/2 for all\nnatural numbers n.\n9 There is another way of ﬁnding the sum 1 + 2 + · · · + 100, which works like this: write the\nsum backwards, as 100 + 99 + · · · + 1. Now add the forwards and backwards versions, obtaining\n101 + 101 + · · · + 101 (100 times), which is 10100. Since we added the sum to itself, we now\ndivide by two to get the answer 5050. Gauss probably used this method; but the method of\nmathematical induction that we explore in this section is much more powerful and can be\napplied in a wide variety of situations.\n42\n1 Propositional logic\nWe prove M(1)\n...\n...\n1\n2\n3\n...\nn + 1\nn\nWe prove M(2) using M(1) and M(1) →M(2)\nWe prove M(3) using M(2) and M(2) →M(3)\nWe prove M(n) using M(n −1) and M(n −1) →M(n)\nWe prove M(n + 1) using M(n) and M(n) →M(n + 1)\nFigure 1.9. How the principle of mathematical induction works. By\nproving just two facts, M(1) and M(n) →M(n + 1) for a formal (and\nunconstrained) parameter n, we are able to deduce M(k) for each natural\nnumber k.\nProof: We use mathematical induction. In order to reveal the ﬁne structure\nof our proof we write LHSn for the expression 1 + 2 + 3 + 4 + · · · + n and\nRHSn for n · (n + 1)/2. Thus, we need to show LHSn = RHSn for all n ≥1.\nBase case: If n equals 1, then LHS1 is just 1 (there is only one summand),\nwhich happens to equal RHS1 = 1 · (1 + 1)/2.\nHere is a little anecdote about the German mathematician Gauss who, as a\npupil at age 8, did not pay attention in class (can you imagine?), with the\nresult that his teacher made him sum up all natural numbers from 1 to 100.\nThe story has it that Gauss came up with the correct answer 5050 within\nseconds, which infuriated his teacher. How did Gauss do it? Well, possibly\nhe knew that\n1 + 2 + 3 + 4 + · · · + n = n · (n + 1)\n2\n(1.5)\n1.4 Semantics of propositional logic\n41\nfor all natural numbers n.9 Thus, taking n = 100, Gauss could easily calcu-\nlate:\n1 + 2 + 3 + 4 + · · · + 100 = 100 · 101\n2\n= 5050.\nMathematical induction allows us to prove equations, such as the one\nin (1.5), for arbitrary n. More generally, it allows us to show that every\nnatural number satisﬁes a certain property. Suppose we have a property M\nwhich we think is true of all natural numbers. We write M(5) to say that\nthe property is true of 5, etc. Suppose that we know the following two things\nabout the property M:\n1.\nBase case: The natural number 1 has property M, i.e. we have a proof of\nM(1).\n2.\nInductive step: If n is a natural number which we assume to have property\nM(n), then we can show that n + 1 has property M(n + 1); i.e. we have a proof\nof M(n) →M(n + 1).\nDeﬁnition 1.30 The principle of mathematical induction says that, on the\ngrounds of these two pieces of information above, every natural number n\nhas property M(n). The assumption of M(n) in the inductive step is called\nthe induction hypothesis.\nWhy does this principle make sense? Well, take any natural number k.\nIf k equals 1, then k has property M(1) using the base case and so we are\ndone. Otherwise, we can use the inductive step, applied to n = 1, to infer\nthat 2 = 1 + 1 has property M(2). We can do that using →e, for we know\nthat 1 has the property in question. Now we use that same inductive step on\nn = 2 to infer that 3 has property M(3) and we repeat this until we reach",
                            "summary": "Theorem 1.31: The sum 1 + 2 + 3 + 4 + · · · + n equals n · (n + 1)/2 for all                natural numbers n. The inductive step applied to n = 1 can be used to infer that 2 = 1 + 1 has property M(2). We can do that using →e, for we know                that 1 has the property in question. The same inductive steps can be applied on n = 2 and k, until we reach k = k (see Figure 1.9). Therefore, we should have no objections about using the principle of mathematical induction for natural numbers. We claim that the sum 1. + 2, 3, 4, 5, 6, The principle of mathematical induction works. By proving just two facts, M(1) and M(n) →M(n + 1) for a formal (andunconstrained) parameter n, we are able to deduce M(k) for each natural number k. In order to reveal the structure of our proof, we write LHSn for the expression 1 + 2 + 3 + 4 + · · · + n and RHSn  for n · ( n + 1)/2. The method of Mathematical induction is much more powerful and can be used in a wide variety of situations. We use mathematical induction to prove the following propositions. The proof is based on the theory of propositional logic. The story has it that Gauss came up with the correct answer 5050 within seconds, which infuriated his teacher. How did Gauss do it? Well, possibly he knew that n = n · (n + 1) + 2 + 3 + 4 + · · · + n. More generally, it allows us to show that everynatural number satisﬁes a certain property. For example, we need to show LHSn = RHSn for all n ≥1. If n equals 1, then LHS1 is just 1 (there is only one summand),                which happens to equal RHS1 = 1 · (1 + 1)/2. 30 The principle of mathematical induction says that, on the grounds of these two pieces of information above, every natural number nhas property M(n) The assumption of M( n) in the inductive step is called the induction hypothesis. If n is a natural number which we assume to have property M, then we can show that n + 1 has propertyM(n + 1); i.e. we have a proof of M('M' is a number that has property M('N' or 'N' is the same as 'M('N')). If n = 1, we can infer from the base case that 2 = 1 + 1 is also a number with property M ('N' + 1) Using the same inductive step onn = 2 to infer that 3 has property M(3) and we repeat this until we reach.e, for we knowthat 1 has the property",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-3",
                            "title": "Soundness of Propositional Logic",
                            "content": "1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\nSo ¬p1, ¬p2 mean they (respectively) are wearing a white one. Informally\njustify each of the following premises in terms of the description of the\nproblem:\ni. K2K1 (p1 ∨p2)\nii. K2(¬p2 →K1 ¬p2)\niii. K2¬K1 p1.\n(c) Using natural deduction, prove from these premises that K2 p2.\n(d) Show that the third premise was essential, by exhibiting a model/world\nwhich satisﬁes the ﬁrst two, but not the conclusion.\n(e) Now is it easy to answer questions like ‘If man 2 were blind would he still be\nable to tell?’ and ‘if man 1 were blind, would man 2 still be able to tell?’?\n12. Recall our informal discussion on positive-knowledge formulas and negative-\nknowledge formulas. Give formal deﬁnitions of these notions.\n5.7 Bibliographic notes\nThe ﬁrst systematic approaches to modal logic were made by C. I. Lewis\nin the 1950s. The possible-worlds approach, which greatly simpliﬁed modal\nlogic and is now almost synonymous with it, was invented by S. Kripke.\nBooks devoted to modal logic include [Che80, Gol87, Pop94], where exten-\nsive references to the literature may be found. All these books discuss the\nsoundness and completeness of proof calculi for modal logics. They also in-\nvestigate which modal logics have the ﬁnite-model property: if a sequent\ndoes not have a proof, there is a ﬁnite model which demonstrates that. Not\nall modal logics enjoy this property, which is important for decidability.\nIntuitionistic propositional logic has the ﬁnite-model property; an anima-\ntion which generates such ﬁnite models (called PORGI) is available from\nA. Stoughton’s website2.\nThe idea of using modal logic to reason about knowledge is due to J.\nHintikka. A great deal of work on applying modal logic to multi-agent sys-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nsumed or given as a premise some formula η1 ∨η2 in some line k′ with\nk′ < k, which was referred to via ∨e in the justiﬁcation of line k. Thus,\nwe have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within that\nproof, obtained by turning all assumptions of boxes that are open at\nline k′ into premises. In a similar way we obtain proofs of the sequents\nφ1, φ2, . . . , φn, η1 ⊢ψ and φ1, φ2, . . . , φn, η2 ⊢ψ from the case analysis of ∨e.\nBy our induction hypothesis, we conclude that the relations φ1, φ2, . . . , φn ⊨\nη1 ∨η2, φ1, φ2, . . . , φn, η1 ⊨ψ and φ1, φ2, . . . , φn, η2 ⊨ψ hold. But together\nthese three relations then force that φ1, φ2, . . . , φn ⊨ψ holds as well –\nwhy?\n3.\nYou can guess by now that the rest of the argument checks each possible proof\nrule in turn and ultimately boils down to verifying that our natural deduction\n1.4 Semantics of propositional logic\n49\nrules behave semantically in the same way as their corresponding truth tables\nevaluate. We leave the details as an exercise.\n2\nThe soundness of propositional logic is useful in ensuring the non-existence of\na proof for a given sequent. Let’s say you try to prove that φ1, φ2, . . . , φ2 ⊢ψ\nis valid, but that your best eﬀorts won’t succeed. How could you be sure that\nno such proof can be found? After all, it might just be that you can’t ﬁnd\na proof even though there is one. It suﬃces to ﬁnd a valuation in which φi\nevaluate to T whereas ψ evaluates to F. Then, by deﬁnition of ⊨, we don’t\nhave φ1, φ2, . . . , φ2 ⊨ψ. Using soundness, this means that φ1, φ2, . . . , φ2 ⊢ψ\ncannot be valid. Therefore, this sequent does not have a proof. You will\npractice this method in the exercises.\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\nas instances of the axiom scheme K: 2(φ →ψ) →(2φ →2ψ) and of the\nschemes in (5.3). Many other formulas, such as\nr 2p →p\nr 2p →22p\nr ¬2p →2¬2p\nr 3⊤\nare not valid. For example, for each one of these, there is a world in the\nKripke model of Figure 5.3 which does not satisfy the formula. The world\nx1 satisﬁes 2p, but it does not satisfy p, so it does not satisfy 2p →p. If we\nadd R(x2, x1) to our model, then x1 still satisﬁes 2p but does not satisfy\n22p. Thus, x1 fails to satisfy 2p →22p. If we change L(x4) to {p, q}, then\nx4 does not satisfy ¬2p →2¬2p, because it satisﬁes ¬2p, but it does not\nsatisfy 2¬2p – the path R(x4, x5)R(x5, x4) serves as a counter example.\nFinally, x6 does not satisfy 3⊤, for this formula states that there is an\naccessible world satisfying ⊤, which is not the case.\nIf we are to build a logic capturing the concept of necessity, however, we\nmust surely have that 2p →p is valid; for anything which is necessarily true\nis also simply true. Similarly, we would expect 2p →p to be valid in the\ncase that 2p means ‘agent Q knows p,’ for anything which is known must\nalso be true. We cannot know something which is false. We can, however,\nbelieve falsehoods, so in the case of a logic of belief, we would not expect\n2p →p to be valid.\nPart of the job of logic engineering is to determine what formula schemes\nshould be valid and to craft the logic in such a way that precisely those ones\nare valid.\nTable 5.7 shows six interesting readings for 2 and eight formula schemes.\nFor each reading and each formula scheme, we decide whether we should\nexpect the scheme to be valid. Notice that we should only put a tick if the\n318\n5 Modal logics and agents\n2φ\n2φ →φ\n2φ →22φ\n3φ →23φ\n3⊤\n2φ →3φ\n2φ ∨2¬φ\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\nputational situations. If we disallow their usage in natural deduction proofs,\nwe obtain a logic, called intuitionistic propositional logic, together with its\nown proof theory. So far so good; but it is less clear what sort of semantics\none could have for such a logic – again with soundness and completeness in\nmind. This is where certain models of KT4 will do the job quite nicely. Recall\nthat correspondence theory implies that a model M = (W, R, L) of KT4 is\nsuch that R is reﬂexive and transitive. The only additional requirement we\nimpose on a model for intuitionistic propositional logic is that its labelling\nfunction L be monotone in R: R(x, y) implies that L(x) is a subset of L(y).\nThis models that the truth of atomic positive formulas persist throughout\nthe worlds that are reachable from a given world.\nDeﬁnition 5.19 A model of intuitionistic propositional logic is a model\nM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). Given\na propositional logic formula as in (1.3), we deﬁne x ⊩φ as in Deﬁnition 5.4\nexception for the clauses →and ¬. For φ1 →φ2 we deﬁne x ⊩φ1 →φ2 iﬀ\nfor all y with R(x, y) we have y ⊩φ2 whenever we have y ⊩φ1. For ¬φ we\ndeﬁne x ⊩¬φ iﬀfor all y with R(x, y) we have y ̸⊩φ.\nAs an example, consider the model W = {x, y} with accessibility relation\nR = {(x, x), (x, y), (y, y)}, which is indeed reﬂexive and transitive. For a la-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables",
                            "summary": "In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. whenever φ1, φ2, . . . , φn ⊨ψ holds, then there exists a natural deduction proof for the sequent. This gives you a certain freedom regarding which method you prefer to use to prove a proposition. The second method typically forces you to com-                pute a truth table which is exponential in the size of occurring proposi-                tional atoms. The third method involves a proof search, upon which the logic program-inducing paradigm is based. 1.4.4 Completeness of propositionally logic is the result of the soundness of the rules. The argument proceeds in three steps. The only way this parse tree can evaluate to F. is to repre-sent parse trees for φ1, φ2, . . .    Figure 1.11. Propositional logic is a form of propositional logic. For example, the argument says that if φ 1, ω 2, and ω 3 are valid, then the argument is true. The argument can also be used to prove that ω 4 is valid, if it is not true that it is, or to prove it is true that φ 5 is valid. For instance, if ω 6 is not valid, it can be shown that the argument for ω 7 is A formula of propositional logic φ is called a tautology iﬀit evaluates to T under all its valuations, i.e. φ1, φ2, . . . , φn ⊨ψ holds. In this section we will prove that K2 p2 means that K1 p1 is wearing a white one. We will also show that the third premise was essential, by exhibiting a model/world which satisﬁes the ﬁrst two, but not the conclusion. In the next section, we will look at the problem of how to prove that a formula can be proved to be true. The idea of using modal logic to reason about knowledge is due to J.Hintikka. The possible-worlds approach, which greatly simpliﬁed modallogic and is now almost synonymous with it, was invented by S. Kripke. Not all modal logics enjoy the property that if a sequent does not have a proof, there is a model which demonstrates that. This property is important for decidability. The idea that propositional logic can be used to prove that a proposition is true is based on the fact that it can be shown to be true with a certain degree of certainty. The notion of a ‘world’ can be derived from the idea that the An adequate set of connectives for propositional logic is a set such that for every formula there is an equivalent formula with only connectives from that set. A great deal of work on applying modal logic to multi-agentsys-                tems has been done in [FHMV95] and [MvdH95] Many examples in this chapter are taken from this literature. Some examples are attributed to other people there, though our treatment of them is original. We show that the set {¬, ∨} is adequate for propositionally logic, because any occurrence of and can be removed by using the equivalences. We also show that, if C is adequate, then C or ⊥C Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that the relation ≡ is reﬂexive, symmetric, transitive, commutative, associative, distributive, and absorptive. Prove your answer to the question Is {↔, ¬} adequate? Proving your answer will help you understand the de Morgan rules. Proving the truth value of a formula φ, formed by using only the connectives in C, can be done by using the word \"proving\" in the form C = C + T.  construct a formula in CNF based on each of the following truth tables. Construct a formula based on the truth tables: (a) (b) (c) (d) (e) (f) (g) (h) (i) (j) (k) (l) (m) (n) (o) (t) (p) (r) (u) (w) (z) (s) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) The soundness of propositional logic is useful in ensuring the non-existence of a proof for a given sequent. It suﬃces to ﬁnd a valuation in which φievaluate to T whereas ψ evaluates to F. The rest of the argument checks each possible proof in turn and ultimately boils down to verifying that our natural deduction holds as well as the corresponding truth table. We leave the details as an exercise and will return to the argument in the next section of the book. We hope that this article has helped you understand some of the concepts behind propositional Logic and its use in the study of the theory of logic. The book is published by Oxford University Press and is available in English and In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. Whenever φ1, φ2, . . . , φn ⊨ψ holds, then there exists a natural deduction proof for the sequent. You will practice this method in the exercises. We see some valid formulas of basic modal logic, such as instances of the axiom scheme K: 2( φ → ω) and 2(2φ →2ω) The world in the Kripke model of Figure 5.3 does not satisfy the formula 2p →p. For example, for each one of these, there is a world which does not satisfies the formula If we add R(x2, x1) to our model, then x1 still satisﬁes 2p but does not satisfy 22p. If we change L(x4) to {p, q], then x4 does not satisfies 2¬2p. For anything which is necessarily true, it must also be simply true. We cannot know something which is false. We would expect 2p →p to be valid in the case that 2p means ‘agent Q knows p,’ for anything that is known mustalso be true. For this to be true, 2p must surely be valid, and we need to know 2p is valid. The job of logic engineering is to determine what formula schemesshould be valid and to craft the logic in such a way that precisely those ones are valid. Table 5.7 shows six interesting readings for 2 and eight formula schemes. For each reading and each formula scheme, we decide whether we should expect the scheme to be valid. Notice that we should only put a tick if the scheme is valid for both the reading and the formula scheme. We also pointed out that the proof rules PBC, LEM and ¬¬e are questionable in certain com-putational situations. In Chapter 1, we gave a natural de-duction system for propositional logic which was sound and complete with semantic entailment based on truth tables. A model of intuitionistic propositional logic is a model M = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). This models that the truth of atomic positive formulas persist throughout the worlds that are reachable from a given world. If we disallow their usage in natural deduction proofs, we obtain a logic, called intuitionistic logic, together with its own proof theory. So far so good; but it is less clear what sort of semantics one could have for such a logic – again with soundness and completeness in                mind. This is where certain models ofKT4 will do the job quite nicely. Given a propositional logic formula as in (1.3), we deﬁne x ⊩φ as in De ﬁnition 5.4. We claim that x  p is an instance of LEM which we proved in Chapter 1 with the full natural deduction calculus. We do not have x p, for p is not in the set L(x) which is empty. For all y with R(x, y) we have y ̸⊩ φ. For ¬φ we claim that y    φ1 is the same as y    ω1. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modalLogics with this property are called normal and all modallogics we study in this text are normal. The modal Logic KT45 is used to reason about knowledge; 2φ means that                the agent Q knows φ. The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience: the agent’s knowledge is closed under logical consequence. There are several attempts in the literature to deﬁne logics of knowledge that are more dystopianrealistic, but we will not consider them here. Even computer agents may not have all the properties of knowledge we think they do. We will discuss some of them in the next section. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 is valid if it is an equivalence relation. The relation ⊢par should be contained in Par, if our calculus is any good. If P is partially correct, then P can be proved to be partially-correct by our calculus. The second one means it is provably correct according to our calculus, while the first one means that it is actually correct. Theorem 5.17: KT45 has a sequence of equivalence relations that are valid if and only if they are provably true. We say that a calculus is complete if it is able to prove everything that is true. Formally, ⊢par is completeif it is valid whenever ⊨par is valid. We said that soundness is relatively easy to show, since typically typically the soundness of individual proof rules can be establishedindependently of the others. Thus, it is sound if it doesn’t tell us that false things can be proved. We write that the calculus that is sound is the one that is valid for all φ, ψ and P; and, similarly, similarly for  ‘tot’. We say that sounds is relativelyeasy to show since it’s easy to establish The same situation holds for the program logic we introduce in this chapter. Establishing its soundness is simply a matter of considering each rule in turn – done in exercise 3 on page 303. Completeness, on the other hand, is harder to show since it depends on the entire set of proof rules cooperating together. We introduce the program variables and logical variables.",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-4",
                            "title": "Completeness of Propositional Logic",
                            "content": "1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\nCombined with the soundness result of the previous subsection, we then\nobtain\nφ1, φ2, . . . , φn ⊢ψ is valid iﬀφ1, φ2, . . . , φn ⊨ψ holds.\nThis gives you a certain freedom regarding which method you prefer to\nuse. Often it is much easier to show one of these two relationships (al-\nthough neither of the two is universally better, or easier, to establish).\nThe ﬁrst method involves a proof search, upon which the logic program-\nming paradigm is based. The second method typically forces you to com-\npute a truth table which is exponential in the size of occurring proposi-\ntional atoms. Both methods are intractable in general but particular in-\nstances of formulas often respond diﬀerently to treatment under these two\nmethods.\nThe remainder of this section is concerned with an argument saying that\nif φ1, φ2, . . . , φn ⊨ψ holds, then φ1, φ2, . . . , φn ⊢ψ is valid. Assuming that\nφ1, φ2, . . . , φn ⊨ψ holds, the argument proceeds in three steps:\nStep 1: We show that ⊨φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) holds.\nStep 2: We show that ⊢φ1 →(φ2 →(φ3 →(. . . (φn →ψ) . . . ))) is valid.\nStep 3: Finally, we show that φ1, φ2, . . . , φn ⊢ψ is valid.\nThe ﬁrst and third steps are quite easy; all the real work is done in the\nsecond one.\n50\n1 Propositional logic\n→\n→\n→\n→\n→\nF\nF\nF\nF\nF\nψ\nF\nT\nT\nT\nT\nT\nφn\nφn−1\nφ3\nφ2\nφ1\nFigure 1.11. The only way this parse tree can evaluate to F. We repre-\nsent parse trees for φ1, φ2, . . . , φn as triangles as their internal structure\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nseparate layers such that validity checks are easy. This is being done by\n1.\nusing the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of →from a\nformula and\n2.\nby specifying an algorithm that takes a formula without any →into a normal\nform (still without →) for which checking validity is easy.\nNaturally, we have to specify which forms of formulas we think of as being\n‘normal.’ Again, there are many such notions, but in this text we study only\ntwo important ones.\nDeﬁnition 1.42 A literal L is either an atom p or the negation of an atom\n¬p. A formula C is in conjunctive normal form (CNF) if it is a conjunction\nof clauses, where each clause D is a disjunction of literals:\nL ::= p | ¬p\nD ::= L | L ∨D\n(1.6)\nC ::= D | D ∧C.\n56\n1 Propositional logic\nExamples of formulas in conjunctive normal form are\n(i)\n(¬q ∨p ∨r) ∧(¬p ∨r) ∧q\n(ii)\n(p ∨r) ∧(¬p ∨r) ∧(p ∨¬r).\nIn the ﬁrst case, there are three clauses of type D: ¬q ∨p ∨r, ¬p ∨r, and q –\nwhich is a literal promoted to a clause by the ﬁrst rule of clauses in (1.6).\nNotice how we made implicit use of the associativity laws for ∧and ∨,\nsaying that φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η and φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η, since\nwe omitted some parentheses. The formula (¬(q ∨p) ∨r) ∧(q ∨r) is not in\nCNF since q ∨p is not a literal.\nWhy do we care at all about formulas φ in CNF? One of the reasons\nfor their usefulness is that they allow easy checks of validity which other-\nwise take times exponential in the number of atoms. For example, consider\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\nputational situations. If we disallow their usage in natural deduction proofs,\nwe obtain a logic, called intuitionistic propositional logic, together with its\nown proof theory. So far so good; but it is less clear what sort of semantics\none could have for such a logic – again with soundness and completeness in\nmind. This is where certain models of KT4 will do the job quite nicely. Recall\nthat correspondence theory implies that a model M = (W, R, L) of KT4 is\nsuch that R is reﬂexive and transitive. The only additional requirement we\nimpose on a model for intuitionistic propositional logic is that its labelling\nfunction L be monotone in R: R(x, y) implies that L(x) is a subset of L(y).\nThis models that the truth of atomic positive formulas persist throughout\nthe worlds that are reachable from a given world.\nDeﬁnition 5.19 A model of intuitionistic propositional logic is a model\nM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y). Given\na propositional logic formula as in (1.3), we deﬁne x ⊩φ as in Deﬁnition 5.4\nexception for the clauses →and ¬. For φ1 →φ2 we deﬁne x ⊩φ1 →φ2 iﬀ\nfor all y with R(x, y) we have y ⊩φ2 whenever we have y ⊩φ1. For ¬φ we\ndeﬁne x ⊩¬φ iﬀfor all y with R(x, y) we have y ̸⊩φ.\nAs an example, consider the model W = {x, y} with accessibility relation\nR = {(x, x), (x, y), (y, y)}, which is indeed reﬂexive and transitive. For a la-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nthe truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nevaluate to F, then our induction hypothesis and the rule ∧i give us ˆp1, . . . , ˆpn ⊢\n¬φ1 ∧¬φ2 and we have to show ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2), which we leave as an\nexercise. Second, if φ1 and φ2 evaluate to T, then we obtain ˆp1, . . . , ˆpn ⊢φ1 ∧φ2,\nby our induction hypothesis, and we need a proof for φ1 ∧φ2 ⊢φ1 ∨φ2, which\nwe leave as an exercise. Third, if φ1 evaluates to F and φ2 to T, then we arrive\nat ˆp1, . . . , ˆpn ⊢¬φ1 ∧φ2, using our induction hypothesis, and need to establish\n¬φ1 ∧φ2 ⊢φ1 ∨φ2, which we leave as an exercise. Fourth, if φ1 evaluates to T\nand φ2 to F, then ˆp1, . . . , ˆpn ⊢φ1 ∧¬φ2 results from our induction hypothesis\nand all we need is a proof for φ1 ∧¬φ2 ⊢φ1 ∨φ2, which we leave as an\nexercise.\n2\nWe apply this technique to the formula ⊨φ1 →(φ2 →(φ3 →(. . . (φn →\nψ) . . . ))). Since it is a tautology it evaluates to T in all 2n lines of its truth\ntable; thus, the proposition above gives us 2n many proofs of ˆp1, ˆp2, . . . , ˆpn ⊢\nη, one for each of the cases that ˆpi is pi or ¬pi. Our job now is to assemble\nall these proofs into a single proof for η which does not use any premises.\nWe illustrate how to do this for an example, the tautology p ∧q →p.\nThe formula p ∧q →p has two propositional atoms p and q. By the propo-\nsition above, we are guaranteed to have a proof for each of the four sequents\np, q ⊢p ∧q →p\n¬p, q ⊢p ∧q →p\np, ¬q ⊢p ∧q →p\n¬p, ¬q ⊢p ∧q →p.\nUltimately, we want to prove p ∧q →p by appealing to the four proofs of\nthe sequents above. Thus, we somehow need to get rid of the premises on\n1.5 Normal forms\n53\nthe left-hand sides of these four sequents. This is the place where we rely on\nthe law of the excluded middle which states r ∨¬r, for any r. We use LEM\nfor all propositional atoms (here p and q) and then we separately assume all\nthe four cases, by using ∨e. That way we can invoke all four proofs of the\nsequents above and use the rule ∨e repeatedly until we have got rid of all our\nonly ﬁnitely many premises ∆from Γ. But then ∆⊢⊥is valid, too, and\nso ∆⊨⊥follows by soundness. But the latter contradicts the fact that all\nﬁnite subsets of Γ are consistent.\n2\nFrom this theorem one may derive a number of useful techniques. We men-\ntion a technique for ensuring the existence of models of inﬁnite size.\nTheorem 2.25 (L¨owenheim-Skolem Theorem) Let ψ be a sentence of\npredicate logic such for any natural number n ≥1 there is a model of ψ with\nat least n elements. Then ψ has a model with inﬁnitely many elements.\nPROOF:\nThe formula φn\ndef\n= ∃x1∃x2 . . . ∃xn\n\u0004\n1≤i<j≤n ¬(xi = xj) speciﬁes\nthat there are at least n elements. Consider the set of sentences Γ\ndef\n=\n{ψ} ∪{φn | n ≥1} and let ∆be any if its ﬁnite subsets. Let k ≥1 be such\nthat n ≤k for all n with φn ∈∆. Since the latter set is ﬁnite, such a k has to\nexist. By assumption, {ψ, φk} is satisﬁable; but φk →φn is valid for all n ≤k\n(why?). Therefore, ∆is satisﬁable as well. The compactness theorem then\nimplies that Γ is satisﬁable by some model M; in particular, M ⊨ψ holds.\nSince M satisﬁes φn for all n ≥1, it cannot have ﬁnitely many elements. 2\nWe can now show that reachability is not expressible in predicate logic.\nTheorem 2.26 Reachability is not expressible in predicate logic: there is\nno predicate-logic formula φ with u and v as its only free variables and R as\nits only predicate symbol (of arity 2) such that φ holds in directed graphs\niﬀthere is a path in that graph from the node associated to u to the node\nassociated to v.\nPROOF:\nSuppose there is a formula φ expressing the existence of a path\nfrom the node associated to u to the node associated to v. Let c and c′ be\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and",
                            "summary": "In this subsection, we hope to convince you that the natural deduction rules of propositional logic are complete. whenever φ1, φ2, . . . , φn ⊨ψ holds, then there exists a natural deduction proof for the sequent. This gives you a certain freedom regarding which method you prefer to use to prove a proposition. The second method typically forces you to com-                pute a truth table which is exponential in the size of occurring proposi-                tional atoms. The third method involves a proof search, upon which the logic program-inducing paradigm is based. 1.4.4 Completeness of propositionally logic is the result of the soundness of the rules. The argument proceeds in three steps. The only way this parse tree can evaluate to F. is to repre-sent parse trees for φ1, φ2, . . .    Figure 1.11. Propositional logic is a form of propositional logic. For example, the argument says that if φ 1, ω 2, and ω 3 are valid, then the argument is true. The argument can also be used to prove that ω 4 is valid, if it is not true that it is, or to prove it is true that φ 5 is valid. For instance, if ω 6 is not valid, it can be shown that the argument for ω 7 is An adequate set of connectives for propositional logic is a set such that for every formula of logic there is an equivalent formula with only connectives from that set. For example, the set {¬, ∨} is adequate because any occurrence of  can be removed by using the equivalences φ and φ. The definition of a tautology iﬀ evaluates to T under all its valuations, i.e. i ﬀ⊨φ. i ﬁnition 1.36 A formula of propositional. logic φ is called a Tautology. i.﬉nition 2. The structure of triangles as their internal structure does not concern us Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that the relation ≡ is reﬂexive, symmetric, transitive, commutative, associative, distributive, and absorptive. Prove your answer to the question Is {↔, ¬} adequate? Proving your answer will help you understand the de Morgan rules. Proving the truth value of a formula φ, formed by using only the connectives in C, can be done by using the word \"proving\" in the form C = C + T.  construct a formula in CNF based on each of the following truth tables. Construct a formula based on the truth tables:                (a)                (b)                 (c)                               “Exercises’”, ““”,. ‘’,  ’,.  ,  , ”“,” ‘‘,’ ‚’. “.”. ”,“;”;“:”:’;’:‘; : ;‚:  : “; ’ A literal L is either an atom p or the negation of an atom P. A normalform is a formula without any → into which checking validity is easy. This is being done by.using the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of. →from a formula. We study only two important ones, the first of which is the definition of ‘normal’ A formula C is in conjunctive normal form (CNF) if it is a conjunction of clauses. CNF is a disjunction of literals, where each clause D is a literal. The formula (¬(q ∨p) ∨r)  is not in CNF since q is not a literal, but it is in the rule of clauses in (1.6) CNF uses the associativity laws for  and  in the case of   and   in (i) and (ii) The formulas φ and φ are used because they allow easy checks of validity which other-wise take times exponential in the number of atoms. In the partial-correctness calculus we develop in this chapter, we say that the. subsequent ⊢par is valid. If our calculus is any good, then the relation should be contained inpar! More precisely, we will say that our calculus. is sound if, whenever it tells us something can be proved, that thing is indeed true. Thus, it is sound. if it doesn’t tell us that false things can be. proved. In the total-corrects calculus to be developed in the next chapter, the relation. ⊨par holds if P is partially correct, while the validity of. the relation of ‘P’ is valid if P can be proven to be partially-correct In Chapters 1 and 2, we said that soundness is relatively easy to show, typically typically the soundness of individual proof rules can be established independently of the others. We say that a calculus is complete if it is able to prove everything that is true. Formally, ⊢par is completeif it is valid for all φ, ψ and P; and, similarly,  tot is sound if it can be proved that all of the numbers in it are true. We also say that  “par’s” existence is valid whenever it is used in a calculus, and that “tot” can be proven to be true as well. In Chapter 1, we gave a natural de-duction system for propositional logic which was sound and complete with its own proof theory. We also pointed out that the proof rules PBC, LEM and ¬¬e are questionable in certain com-putational situations. The same situation holds for the program logic we introduce in this chapter. Establishing its soundness is simply a matter of considering each rule in turn – done in exercise 3 on page 303 – whereas establishing its (relative)completeness is harder and beyond the scope of this book. In Chapter 4, we show that the program verification depends on the entire set of proof rules cooperating together. We conclude that the logic, called intuitionistic propositional Logic A model of intuitionistic propositional logic is a modelM = (W, R, L) of KT4 such that R(x, y) always implies L(x) ⊆L(y) This models that the truth of atomic positive formulas persist throughout the worlds that are reachable from a given world. So far so good; but it is less clear what sort of semantics one could have for such a logic – again with soundness and completeness in mind. This is where certain models ofKT4 will do the job quite nicely. Recall that correspondence theory implies that a model M = (w, r, l) is reﬂexive and transitive. For all y with R(x, y) we have y ̸⊩φ. We do not have x ⊩p, for p is not in the set L(x) which is empty. Deﬁnition 5.4 for the case of φ1, φ2, . . . , φ 2 does not have a proof. In the exercises, we apply this to show that a se-                quent does not has a proof: simply show that φ does not seman-                tically entail ψ. Then soundness implies that the sequent φ doesn't have aProof of truth-table semantics. In Exercise 1.2.6 we sketch a non-linear, tree-like,                notion of proofs for sequents. This tight cor-                respondence allows us to freely switch between working with the notion of                proofs and that of semantic entailment. We now investigate various alternatives for deciding whether two formulas are ‘equivalent’ by syntactic or algorithmic means. This requires that we clarify exactly what exactly we mean by equivalent formulas. We conclude by looking at the validity of two formulas, and their satisfiability and validity in terms of their semantic meaning and their syntactic and algorithmic counterparts. The results of this investigation will be published in the next issue of Theoretical Semantics. For example, all four combinations of T and F for p and q return the same result. This suggests that we deﬁnelyevaluate to F, then our induction hypothesis and the rule  i give us ˆp1, . . . , ˾pn ⊢                 ¬φ1   ¬ 2, which we leave as an exercise. Third, if φ1 and φ2 evaluate to T, then we arrive at ˼p1,. . ., ˉpn ≢ φ 1 ≵    “” and we need a proof for ”  If φ1 evaluates to T and φ2 to F, then ˆp1, . . . ,  ˆpn ⊢¬φ1  , using our induction hypothesis. Since it is a tautology, the proposition above gives us 2n many proofs. Our job now is to assemble all these proofs into a single proof for η which does not use any premises. We illustrate how to do this for an example, the tautological p ∧q →p. The formula p  has two propositional atoms p and q.  We apply this technique to the formula ⊨ ω1 →( ω2 → ( ω3 → By the propo-                sition above, we are guaranteed to have a proof for each of the four sequents. We use LEMfor all propositional atoms (here p and q) and then we separately assume all four cases. That way we can invoke all four proofs of the sequents above and use the rule ∨e repeatedly until we have got rid of all our premises. But then the latter contradicts the fact that all subsets of Γ are consistent. From this theorem one may derive a number of useful techniques. For example, we can use the LEM rule to prove that p  p q q is not a non-positional atom. Theorem 2.25 (L¨owenheim-Skolem Theorem) Let ψ be a sentence of predicate logic with at least n elements. Then ψ has a model with inﬁnitely many elements. We men-                tion a technique for ensuring the existence of models of in-nite size. For example, the formula φn                 is a model of ψ with n elements in it. The compactness theorem thenimplies that ψ is satisﬀable by some model M. Since M cannot have in-NINE elements, ψ cannot be a model for M. Theorem 2,25 (SkoleM Theorem), is based on the Theorem 2.26 Reachability is not expressible in predicate logic. There is no predicate-logic formula φ with u and v as its only free variables and R as the only predicate symbol (of arity 2) Such that φ holds in directed graphs such that there is a path in that graph from the node associated to u to the nodes associated to v. We can now show that reachability isn't expressible with a formula like this. The proof is given in the next section of the book. For more information on the book, visit: http://www.academyofmaths.org/faculty/facile/facility-of-mathematicians/mathematician-",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-4",
                    "title": "Normal Forms",
                    "content": "the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\n9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\n29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\n(a) ∃x.(x′ ↔(y + y′ · x))\n(b) ∀x.(x′ ↔(y + y′ · x))\n(c) ∃x′.(x′ ↔(y + y′ · x))\n(d) ∀x′.(x′ ↔(y + y′ · x)).\n5. Let ρ be a valuation with ρ(x′\n1) = 1 and ρ(x′\n2) = 0. Determine whether ρ ⊨f\nholds for the following:\n(a) x1[ˆx := ˆx′]\n(b) (x1 + x2)[ˆx := ˆx′]\n(c) (x1 · x2)[ˆx := ˆx′].\n6. Evaluate ρ ⊨(∃x1.(x1 + x2))[ˆx := ˆx′] and explain how the valuation ρ changes\nin that process. In particular, [ˆx := ˆx′] replaces xi by x′\ni, but why does this not\ninterfere with the binding quantiﬁer ∃x1?\n410\n6 Binary decision diagrams\n7. (a) How would you deﬁne the notion of semantic entailment for the relational\nmu-calculus?\n(b) Deﬁne formally when two formulas of the relational mu-calculus are seman-\ntically equivalent.\nExercises 6.15\n1. Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)\nholds, where ρ is\n(a) (x1, x2) ⇒(1, 0)\n(b) (x1, x2) ⇒(0, 1)\n(c) (x1, x2) ⇒(0, 0).\n2. Let S be {s0, s1}, with s0 →s0, s0 →s1 and s1 →s0 as possible transitions\nand L(s0) = {x1} and L(s1) = ∅. Compute the boolean function f EX (EX ¬x1).\n3. Equations (6.17) (page 395), (6.19) and (6.20) deﬁne f EF φ, f AF φ and f EG φ.\nWrite down a similar equation to deﬁne f AG φ.\n4. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately.\n5. Mimic the example checks on page 396 for the connective AU: consider the\nmodel of Figure 6.24 (page 384). Since [[E[(x1 ∨x2) U (¬x1 ∧¬x2)]]] equals the\nentire state set {s0, s1, s2}, your coding of f E[x1∨x2U¬x1∧¬x2] is correct if it\ncomputes 1 for all bit vectors diﬀerent from (1, 1).\n(a) Verify that your coding is indeed correct.\n(b) Find a boolean formula without ﬁxed points which is semantically equiva-\nlent to f E[(x1∨x2)U(¬x1∧¬x2)].\n6. (a) Use (6.20) on page 395 to compute f EG ¬x1 for the model in Figure 6.24.\n(b) Show that f EG ¬x1 faithfully models the set of all states which satisfy\nEG ¬x1.\n7. In the grammar (6.10) for the relational mu-calculus on page 390, it was stated\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nthe equivalence of formulas φ and ψ via ⊨: if φ semantically entails ψ and\nvice versa, then these formulas should be the same as far as our truth-table\nsemantics is concerned.\nDeﬁnition 1.40 Let φ and ψ be formulas of propositional logic. We say\nthat φ and ψ are semantically equivalent iﬀφ ⊨ψ and ψ ⊨φ hold. In that\ncase we write φ ≡ψ. Further, we call φ valid if ⊨φ holds.\nNote that we could also have deﬁned φ ≡ψ to mean that ⊨(φ →ψ) ∧\n(ψ →φ) holds; it amounts to the same concept. Indeed, because of soundness\nand completeness, semantic equivalence is identical to provable equivalence\n1.5 Normal forms\n55\n(Deﬁnition 1.25). Examples of equivalent formulas are\np →q ≡¬q →¬p\np →q ≡¬p ∨q\np ∧q →p ≡r ∨¬r\np ∧q →r ≡p →(q →r).\nRecall that a formula η is called a tautology if ⊨η holds, so the tautologies\nare exactly the valid formulas. The following lemma says that any decision\nprocedure for tautologies is in fact a decision procedure for the validity of\nsequents as well.\nLemma 1.41 Given formulas φ1, φ2, . . . , φn and ψ of propositional logic,\nφ1, φ2, . . . , φn ⊨ψ holds iﬀ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nProof: First, suppose that ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nIf φ1, φ2, . . . , φn are all true under some valuation, then ψ has to be true\nas well for that same valuation. Otherwise,\n⊨φ1 →(φ2 →(φ3 →· · · →\n(φn →ψ))) would not hold (compare this with Figure 1.11). Second, if\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nto be {(a, a), (b, b), (c, c)}. Hence the semantics of equality is easy, for it is\nalways modelled extensionally.\n2.5 Undecidability of predicate logic\nWe continue our introduction to predicate logic with some negative results.\nGiven a formula φ in propositional logic we can, at least in principle, de-\ntermine whether ⊨φ holds: if φ has n propositional atoms, then the truth\ntable of φ contains 2n lines; and ⊨φ holds if, and only if, the column for φ\n(of length 2n) contains only T entries.\nThe bad news is that such a mechanical procedure, working for all for-\nmulas φ, cannot be provided in predicate logic. We will give a formal proof\nof this negative result, though we rely on an informal (yet intuitive) notion\nof computability.\nThe problem of determining whether a predicate logic formula is valid is\nknown as a decision problem. A solution to a decision problem is a program\n(written in Java, C, or any other common language) that takes problem\ninstances as input and always terminates, producing a correct ‘yes’ or ‘no’\noutput. In the case of the decision problem for predicate logic, the input to\nthe program is an arbitrary formula φ of predicate logic and the program\n132\n2 Predicate logic\nis correct if it produces ‘yes’ whenever the input formula is valid and ‘no’\nwhenever it is not. Note that the program which solves a decision problem\nmust terminate for all well-formed input: a program which goes on thinking\nabout it for ever is not allowed. The decision problem at hand is this:\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced (¬p ∨¬q ∨r) ∧(p ∨¬q ∨¬r) ∧(p ∨¬q ∨r) ∧(p ∨q ∨¬r).\nIf we don’t have a full truth table at our disposal, but do know the structure\nof φ, then we would like to compute a version of φ in CNF. It should be\nclear by now that a full truth table of φ and an equivalent formula in\nCNF are pretty much the same thing as far as questions about validity are\nconcerned – although the formula in CNF may be much more compact.\n1.5.2 Conjunctive normal forms and validity\nWe have already seen the beneﬁts of conjunctive normal forms in that they\nallow for a fast and easy syntactic test of validity. Therefore, one wonders\nwhether any formula can be transformed into an equivalent formula in CNF.\nWe now develop an algorithm achieving just that. Note that, by Deﬁni-\ntion 1.40, a formula is valid iﬀany of its equivalent formulas is valid. We\nreduce the problem of determining whether any φ is valid to the problem\nof computing an equivalent ψ ≡φ such that ψ is in CNF and checking, via\nLemma 1.43, whether ψ is valid.\n1.5 Normal forms\n59\nBefore we sketch such a procedure, we make some general remarks about\nits possibilities and its realisability constraints. First of all, there could be\nmore or less eﬃcient ways of computing such normal forms. But even more\nso, there could be many possible correct outputs, for ψ1 ≡φ and ψ2 ≡φ\ndo not generally imply that ψ1 is the same as ψ2, even if ψ1 and ψ2 are in\nCNF. For example, take φ\ndef\n= p, ψ1\ndef\n= p and ψ2\ndef\n= p ∧(p ∨q); then convince\nyourself that φ ≡ψ2 holds. Having this ambiguity of equivalent conjunctive\nnormal forms, the computation of a CNF for φ with minimal ‘cost’ (where\n‘cost’ could for example be the number of conjuncts, or the height of φ’s\nparse tree) becomes a very important practical problem, an issue persued in\nChapter 6. Right now, we are content with stating a deterministic algorithm\nwhich always computes the same output CNF for a given input φ.\nThis algorithm, called CNF, should satisfy the following requirements:\n(1)\nto the distributivity laws, which entitle us to translate any disjunction of\nconjunctions into a conjunction of disjunctions. However, for this to result in\na CNF, we need to make certain that those disjunctions generated contain\nonly literals. We apply a strategy for using distributivity based on matching\npatterns in φ1 ∨φ2. This results in an independent algorithm called DISTR\nwhich will do all that work for us. Thus, we simply call DISTR with the pair\n(η1, η2) as input and pass along its result.\nAssuming that we already have written code for IMPL FREE, NNF and\nDISTR, we may now write pseudo code for CNF:\nfunction CNF (φ):\n/* precondition: φ implication free and in NNF */\n/* postcondition: CNF (φ) computes an equivalent CNF for φ */\nbegin function\ncase\nφ is a literal: return φ\nφ is φ1 ∧φ2 : return CNF (φ1) ∧CNF (φ2)\nφ is φ1 ∨φ2 : return DISTR (CNF (φ1), CNF (φ2))\nend case\nend function\n1.5 Normal forms\n61\nNotice how the calling of DISTR is done with the computed conjunctive nor-\nmal forms of φ1 and φ2. The routine DISTR has η1 and η2 as input parameters\nand does a case analysis on whether these inputs are conjunctions. What\nshould DISTR do if none of its input formulas is such a conjunction? Well,\nsince we are calling DISTR for inputs η1 and η2 which are in CNF, this can\nonly mean that η1 and η2 are literals, or disjunctions of literals. Thus, η1 ∨η2\nis in CNF.\nOtherwise, at least one of the formulas η1 and η2 is a conjunction. Since\none conjunction suﬃces for simplifying the problem, we have to decide which\nconjunct we want to transform if both formulas are conjunctions. That way\nwe maintain that our algorithm CNF is deterministic. So let us suppose that\nη1 is of the form η11 ∧η12. Then the distributive law says that η1 ∨η2 ≡\n(η11 ∨η2) ∧(η12 ∨η2). Since all participating formulas η11, η12 and η2 are\nin CNF, we may call DISTR again for the pairs (η11, η2) and (η12, η2), and\nthen simply form their conjunction. This is the key insight for writing the\nfunction DISTR.\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nseparate layers such that validity checks are easy. This is being done by\n1.\nusing the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of →from a\nformula and\n2.\nby specifying an algorithm that takes a formula without any →into a normal\nform (still without →) for which checking validity is easy.\nNaturally, we have to specify which forms of formulas we think of as being\n‘normal.’ Again, there are many such notions, but in this text we study only\ntwo important ones.\nDeﬁnition 1.42 A literal L is either an atom p or the negation of an atom\n¬p. A formula C is in conjunctive normal form (CNF) if it is a conjunction\nof clauses, where each clause D is a disjunction of literals:\nL ::= p | ¬p\nD ::= L | L ∨D\n(1.6)\nC ::= D | D ∧C.\n56\n1 Propositional logic\nExamples of formulas in conjunctive normal form are\n(i)\n(¬q ∨p ∨r) ∧(¬p ∨r) ∧q\n(ii)\n(p ∨r) ∧(¬p ∨r) ∧(p ∨¬r).\nIn the ﬁrst case, there are three clauses of type D: ¬q ∨p ∨r, ¬p ∨r, and q –\nwhich is a literal promoted to a clause by the ﬁrst rule of clauses in (1.6).\nNotice how we made implicit use of the associativity laws for ∧and ∨,\nsaying that φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η and φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η, since\nwe omitted some parentheses. The formula (¬(q ∨p) ∨r) ∧(q ∨r) is not in\nCNF since q ∨p is not a literal.\nWhy do we care at all about formulas φ in CNF? One of the reasons\nfor their usefulness is that they allow easy checks of validity which other-\nwise take times exponential in the number of atoms. For example, consider\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nof literals, or literals, we can settle the matter as follows.\nLemma 1.43 A disjunction of literals L1 ∨L2 ∨· · · ∨Lm is valid iﬀthere\nare 1 ≤i, j ≤m such that Li is ¬Lj.\nProof: If Li equals ¬Lj, then L1 ∨L2 ∨· · · ∨Lm evaluates to T for all\nvaluations. For example, the disjunct p ∨q ∨r ∨¬q can never be made false.\nTo see that the converse holds as well, assume that no literal Lk has a\nmatching negation in L1 ∨L2 ∨· · · ∨Lm. Then, for each k with 1 ≤k ≤n,\nwe assign F to Lk, if Lk is an atom; or T, if Lk is the negation of an atom.\nFor example, the disjunct ¬q ∨p ∨r can be made false by assigning F to p\nand r and T to q.\n2\nHence, we have an easy and fast check for the validity of ⊨φ, provided\nthat φ is in CNF; inspect all conjuncts ψk of φ and search for atoms in ψk\nsuch that ψk also contains their negation. If such a match is found for all\nconjuncts, we have ⊨φ. Otherwise (= some conjunct contains no pair Li and\n¬Li), φ is not valid by the lemma above. Thus, the formula (¬q ∨p ∨r) ∧\n(¬p ∨r) ∧q above is not valid. Note that the matching literal has to be found\nin the same conjunct ψk. Since there is no free lunch in this universe, we can\nexpect that the computation of a formula φ′ in CNF, which is equivalent to\na given formula φ, is a costly worst-case operation.\nBefore we study how to compute equivalent conjunctive normal forms, we\nintroduce another semantic concept closely related to that of validity.\n1.5 Normal forms\n57\nDeﬁnition 1.44 Given a formula φ in propositional logic, we say that φ is\nsatisﬁable if it has a valuation in which is evaluates to T.\nFor example, the formula p ∨q →p is satisﬁable since it computes T if we\nassign T to p. Clearly, p ∨q →p is not valid. Thus, satisﬁability is a weaker\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\n(e) Cancer will not be cured unless its cause is determined and a new drug for\ncancer is found.\n(f) If interest rates go up, share prices go down.\n(g) If Smith has installed central heating, then he has sold his car or he has not\npaid his mortgage.\n(h)\n*\nToday it will rain or shine, but not both.\n(i)\n*\nIf Dick met Jane yesterday, they had a cup of coﬀee together, or they took\na walk in the park.\n(j) No shoes, no shirt, no service.\n(k) My sister wants a black and white cat.\n2. The formulas of propositional logic below implicitly assume the binding priorities\nof the logical connectives put forward in Convention 1.3. Make sure that you fully\nunderstand those conventions by reinserting as many brackets as possible. For\nexample, given p ∧q →r, change it to (p ∧q) →r since ∧binds more tightly\nthan →.\n(a)\n*\n¬p ∧q →r\n(b) (p →q) ∧¬(r ∨p →q)\n(c)\n*\n(p →q) →(r →s ∨t)\n(d) p ∨(¬q →p ∧r)\n(e)\n*\np ∨q →¬p ∧r\n(f) p ∨p →¬q\n(g)\n*\nWhy is the expression p ∨q ∧r problematic?\nExercises 1.2\n1. Prove the validity of the following sequents:\n(a) (p ∧q) ∧r, s ∧t ⊢q ∧s\n1.7 Exercises\n79\n(b) p ∧q ⊢q ∧p\n(c)\n*\n(p ∧q) ∧r ⊢p ∧(q ∧r)\n(d) p →(p →q), p ⊢q\n(e)\n*\nq →(p →r), ¬r, q ⊢¬p\n(f)\n*\n⊢(p ∧q) →p\n(g) p ⊢q →(p ∧q)\n(h)\n*\np ⊢(p →q) →q\n(i)\n*\n(p →r) ∧(q →r) ⊢p ∧q →r\n(j)\n*\nq →r ⊢(p →q) →(p →r)\n(k) p →(q →r), p →q ⊢p →r\n(l)\n*\np →q, r →s ⊢p ∨r →q ∨s\n(m) p ∨q ⊢r →(p ∨q) ∧r\n(n)\n*\n(p ∨(q →p)) ∧q ⊢p\n(o)\n*\np →q, r →s ⊢p ∧r →q ∧s\n(p) p →q ⊢((p ∧q) →p) ∧(p →(p ∧q))\n(q) ⊢q →(p →(p →(q →p)))\n(r)\n*\np →q ∧r ⊢(p →q) ∧(p →r)\n(s) (p →q) ∧(p →r) ⊢p →q ∧r\n(t) ⊢(p →q) →((r →s) →(p ∧r →q ∧s)); here you might be able to ‘recycle’\nand augment a proof from a previous exercise.\n(u) p →q ⊢¬q →¬p\n(v)\n*\np ∨(p ∧q) ⊢p\n(w) r, p →(r →q) ⊢p →(q ∧r)\n(x)\n*\np →(q ∨r), q →s, r →s ⊢p →s\n(y)\n*\n(p ∧q) ∨(p ∧r) ⊢p ∧(q ∨r).\n2. For the sequents below, show which ones are valid and which ones aren’t:\n(a)\n*\n¬p →¬q ⊢q →p\n(b)\n*\n¬p ∨¬q ⊢¬(p ∧q)\n(c)\n*\n¬p, p ∨q ⊢q\n(d)\n*\np ∨q, ¬q ∨r ⊢p ∨r\n(e)\n*\np →(q ∨r), ¬q, ¬r ⊢¬p without using the MT rule\n(f)\n* ciding their satisﬁability. One such example is the class of Horn formu-\nlas; the name ‘Horn’ is derived from the logician A. Horn’s last name.\nWe shortly deﬁne them and give an algorithm for checking their satisﬁ-\nability.\nRecall that the logical constants ⊥(‘bottom’) and ⊤(‘top’) denote an\nunsatisﬁable formula, respectively, a tautology.\nDeﬁnition 1.46 A Horn formula is a formula φ of propositional logic if it\ncan be generated as an instance of H in this grammar:\nP ::= ⊥| ⊤| p\nA ::= P | P ∧A\nC ::= A →P\nH ::= C | C ∧H.\n(1.7)\nWe call each instance of C a Horn clause.\n66\n1 Propositional logic\nHorn formulas are conjunctions of Horn clauses. A Horn clause is an impli-\ncation whose assumption A is a conjunction of propositions of type P and\nwhose conclusion is also of type P. Examples of Horn formulas are\n(p ∧q ∧s →p) ∧(q ∧r →p) ∧(p ∧s →s)\n(p ∧q ∧s →⊥) ∧(q ∧r →p) ∧(⊤→s)\n(p2 ∧p3 ∧p5 →p13) ∧(⊤→p5) ∧(p5 ∧p11 →⊥).\nExamples of formulas which are not Horn formulas are\n(p ∧q ∧s →¬p) ∧(q ∧r →p) ∧(p ∧s →s)\n(p ∧q ∧s →⊥) ∧(¬q ∧r →p) ∧(⊤→s)\n(p2 ∧p3 ∧p5 →p13 ∧p27) ∧(⊤→p5) ∧(p5 ∧p11 →⊥)\n(p2 ∧p3 ∧p5 →p13 ∧p27) ∧(⊤→p5) ∧(p5 ∧p11 ∨⊥).\nThe ﬁrst formula is not a Horn formula since ¬p, the conclusion of the\nimplication of the ﬁrst conjunct, is not of type P. The second formula does\nnot qualify since the premise of the implication of the second conjunct,\n¬q ∧r, is not a conjunction of atoms, ⊥, or ⊤. The third formula is not a\nHorn formula since the conclusion of the implication of the ﬁrst conjunct,\np13 ∧p27, is not of type P. The fourth formula clearly is not a Horn formula\nsince it is not a conjunction of implications.\nThe algorithm we propose for deciding the satisﬁability of a Horn for-\nmula φ maintains a list of all occurrences of type P in φ and proceeds like\nthis:\n1.\nIt marks ⊤if it occurs in that list.\n2.\nIf there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ such that all Pj with 1 ≤j ≤\nki are marked, mark P ′ as well and go to 2. Otherwise (= there is no conjunct\ncorrect replies. First, if ⊥is marked, then there has to be some conjunct\nP1 ∧P2 ∧· · · ∧Pki →⊥of φ such that all Pi are marked as well. By (1.8)\nthat conjunct of φ evaluates to T →F = F whenever φ is true. As this is\nimpossible the reply ‘unsatisﬁable’ is correct. Second, if ⊥is not marked, we\nsimply assign T to all marked atoms and F to all unmarked atoms and use\nproof by contradiction to show that φ has to be true with respect to that\nvaluation.\nIf φ is not true under that valuation, it must make one of its principal\nconjuncts P1 ∧P2 ∧· · · ∧Pki →P ′ false. By the semantics of implication\nthis can only mean that all Pj are true and P ′ is false. By the deﬁnition of our\nvaluation, we then infer that all Pj are marked, so P1 ∧P2 ∧· · · ∧Pki →P ′\nis a conjunct of φ that would have been dealt with in one of the cycles of\nthe while-statement and so P ′ is marked, too. Since ⊥is not marked, P ′ has\nto be ⊤or some atom q. In any event, the conjunct is then true by (1.8), a\ncontradiction\n2\nNote that the proof by contradiction employed in the last proof was not\nreally needed. It just made the argument seem more natural to us. The\nliterature is full of such examples where one uses proof by contradiction\nmore out of psychological than proof-theoretical necessity.\n1.6 SAT solvers\nThe marking algorithm for Horn formulas computes marks as constraints\non all valuations that can make a formule true. By (1.8), all marked atoms\nhave to be true for any such valuation. We can extend this idea to general\nformulas φ by computing constraints saying which subformulas of φ require\na certain truth value for all valuations that make φ true:\n‘All marked subformulas evaluate to their mark value\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\n(a)\n*\n(p ∧q ∧w →⊥) ∧(t →⊥) ∧(r →p) ∧(⊤→r) ∧(⊤→q) ∧(u →\ns) ∧(⊤→u)\n(b) (p ∧q ∧w →⊥) ∧(t →⊥) ∧(r →p) ∧(⊤→r) ∧(⊤→q) ∧(r ∧u →\nw) ∧(u →s) ∧(⊤→u)\n(c) (p ∧q ∧s →p) ∧(q ∧r →p) ∧(p ∧s →s)\n(d) (p ∧q ∧s →⊥) ∧(q ∧r →p) ∧(⊤→s)\n(e) (p5 →p11) ∧(p2 ∧p3 ∧p5 →p13) ∧(⊤→p5) ∧(p5 ∧p11 →⊥)\n(f) (⊤→q) ∧(⊤→s) ∧(w →⊥) ∧(p ∧q ∧s →⊥) ∧(v →s) ∧(⊤→\nr) ∧(r →p)\n90\n1 Propositional logic\n(g)\n*\n(⊤→q) ∧(⊤→s) ∧(w →⊥) ∧(p ∧q ∧s →v) ∧(v →s) ∧(⊤→\nr) ∧(r →p).\n16. Explain why the algorithm HORN fails to work correctly if we change the concept\nof Horn formulas by extending the clause for P on page 65 to P ::= ⊥| ⊤|\np | ¬p?\n17. What can you say about the CNF of Horn formulas. More precisely, can you\nspecify syntactic criteria for a CNF that ensure that there is an equivalent Horn\nformula? Can you describe informally programs which would translate from one\nform of representation into another?\nExercises 1.6\n1. Use mathematical induction to show that, for all φ of (1.3) on page 33,\n(a) T(φ) can be generated by (1.10) on page 69,\n(b) T(φ) has the same set of valuations as φ, and\n(c) the set of valuations in which φ is true equals the set of valuations in which\nT(φ) is true.\n2.\n*\nShow that all rules of Figure 1.14 (page 71) are sound: if all current marks\nsatisfy the invariant (1.9) from page 68, then this invariant still holds if the\nderived constraint of that rule becomes an additional mark.\n3. In Figure 1.16 on page 73 we detected a contradiction which secured the validity\nof the sequent p ∧q →r ⊢p →q →r. Use the same method with the linear SAT\nsolver to show that the sequent ⊢(p →q) ∨(r →p) is valid. (This is interest-\ning since we proved this validity in natural deduction with a judicious choice\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nlaws to it, and extract a witness to the DAG’s satisﬁability. Explain in what\nsense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is\nnot valid.\n5. Explain in what sense the SAT solving technique, as presented in this chapter,\ncan be used to check whether formulas are tautologies.\n6. For φ from (1.10), can one reverse engineer φ from the DAG of T(φ)?\n7. Consider a modiﬁcation of our method which initially tags a DAG’s root node\nwith ‘1: F.’ In that case,\n(a) are the forcing laws still sound? If so, state the invariant.\n(b) what can we say about the formula(s) a DAG represents if\ni. we detect contradictory constraints?\nii. we compute consistent forced constraints for each node?\n8. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied\nto T(φ) –\nto the marking algorithm – applied to φ. Discuss similarities and\ndiﬀerences of these approaches.\n1.8 Bibliographic notes\n91\n9. Consider Figure 1.20 on page 77. Verify that\n(a) its test produces contradictory constraints\n(b) its cubic analysis does not decide satisﬁability, regardless of whether the\ntwo optimizations we described are present.\n10. Verify that the DAG of Figure 1.17 (page 74) is indeed the one obtained for\nT(φ), where φ is the formula in (1.11) on page 73.\n11.\n*\nAn implementor may be concerned with the possibility that the answers to the\ncubic SAT solver may depend on a particular order in which we test unmarked\nnodes or use the rules in Figure 1.14. Give a semi-formal argument for why the\nanalysis results don’t depend on such an order.\n12. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability\nof T(φ).\n13. Advanced Project: Write a complete implementation of the cubic SAT solver\nmula φ maintains a list of all occurrences of type P in φ and proceeds like\nthis:\n1.\nIt marks ⊤if it occurs in that list.\n2.\nIf there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ such that all Pj with 1 ≤j ≤\nki are marked, mark P ′ as well and go to 2. Otherwise (= there is no conjunct\nP1 ∧P2 ∧· · · ∧Pki →P ′ such that all Pj are marked) go to 3.\n3.\nIf ⊥is marked, print out ‘The Horn formula φ is unsatisﬁable.’ and stop. Oth-\nerwise, go to 4.\n4.\nPrint out ‘The Horn formula φ is satisﬁable.’ and stop.\nIn these instructions, the markings of formulas are shared by all other oc-\ncurrences of these formulas in the Horn formula. For example, once we\nmark p2 because of one of the criteria above, then all other occurrences\nof p2 are marked as well. We use pseudo code to specify this algorithm\nformally:\n1.5 Normal forms\n67\nfunction HORN (φ):\n/* precondition: φ is a Horn formula */\n/* postcondition: HORN (φ) decides the satisﬁability for φ */\nbegin function\nmark all occurrences of ⊤in φ;\nwhile there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ\nsuch that all Pj are marked but P ′ isn’t do\nmark P ′\nend while\nif ⊥is marked then return ‘unsatisﬁable’ else return ‘satisﬁable’\nend function\nWe need to make sure that this algorithm terminates on all Horn formulas\nφ as input and that its output (= its decision) is always correct.\nTheorem 1.47 The algorithm HORN is correct for the satisﬁability decision\nproblem of Horn formulas and has no more than n + 1 cycles in its while-\nstatement if n is the number of atoms in φ. In particular, HORN always\nterminates on correct input.\nProof: Let us ﬁrst consider the question of program termination. Notice\nthat entering the body of the while-statement has the eﬀect of marking an\nunmarked P which is not ⊤. Since this marking applies to all occurrences\nof P in φ, the while-statement can have at most one more cycle than there\nare atoms in φ.\nSince we guaranteed termination, it suﬃces to show that the answers\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nWhen we applied our linear SAT solver, we saw two possible outcomes:\nwe either detected contradictory constraints, meaning that no formula rep-\nresented by the DAG is satisﬁable (e.g. Fig. 1.16); or we managed to force\nconsistent constraints on all nodes, in which case all formulas represented by\nthis DAG are satisﬁable with those constraints as a witness (e.g. Fig. 1.13).\nUnfortunately, there is a third possibility: all forced constraints are consis-\ntent with each other, but not all nodes are constrained! We already remarked\nthat this occurs for formulas of the form ¬(φ1 ∧φ2).\n1.6 SAT solvers\n73\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n1: T\n2: F\n3: T\n4: T\n4: T\n5: F\n6: T\n5: F\n7: T\n8: F\n9: T\n11: F\n10: T\n10: T\n7: T\nits conjunction parent\n– a contradiction\nand ∧frr force F\nits children and\n∧ti force T\nFigure 1.16. The forcing rules, applied to the DAG of Figure 1.15,\ndetect contradictory constraints at the indicated node – implying that\nthe initial constraint ‘1:T’ cannot be realized. Thus, formulas represented\nby this DAG are not satisfiable.\nRecall that checking validity of formulas in CNF is very easy. We already\nhinted at the fact that checking satisﬁability of formulas in CNF is hard. To\nillustrate, consider the formula\n((p ∨(q ∨r)) ∧((p ∨¬q) ∧((q ∨¬r) ∧((r ∨¬p) ∧(¬p ∨(¬q ∨¬r))))))\n(1.11)\nin CNF – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula\nshould not be satisﬁable. The ﬁrst and last clause in (1.11) ‘say’ that at least\none of p, q, and r are false and true (respectively). The remaining three\nclauses, in their conjunction, ‘say’ that p, q, and r all have the same truth\nvalue. This cannot be satisﬁable, and a good SAT solver should discover\nunmarked P which is not ⊤. Since this marking applies to all occurrences\nof P in φ, the while-statement can have at most one more cycle than there\nare atoms in φ.\nSince we guaranteed termination, it suﬃces to show that the answers\ngiven by the algorithm HORN are always correct. To that end, it helps to\nreveal the functional role of those markings. Essentially, marking a P means\nthat that P has got to be true if the formula φ is ever going to be satisﬁable.\nWe use mathematical induction to show that\n‘All marked P are true for all valuations in which φ evaluates to T.’ (1.8)\nholds after any number of executions of the body of the while-statement\nabove. The base case, zero executions, is when the while-statement has not\nyet been entered but we already and only marked all occurrences of ⊤. Since\n⊤must be true in all valuations, (1.8) follows.\nIn the inductive step, we assume that (1.8) holds after k cycles of the\nwhile-statement. Then we need to show that same assertion for all marked\nP after k + 1 cycles. If we enter the (k + 1)th cycle, the condition of the\nwhile-statement is certainly true. Thus, there exists a conjunct P1 ∧P2 ∧\n· · · ∧Pki →P ′ of φ such that all Pj are marked. Let v be any valuation\n68\n1 Propositional logic\nin which φ is true. By our induction hypothesis, we know that all Pj and\ntherefore P1 ∧P2 ∧· · · ∧Pki have to be true in v as well. The conjunct P1 ∧\nP2 ∧· · · ∧Pki →P ′ of φ has be to true in v, too, from which we infer that\nP ′ has to be true in v.\nBy mathematical induction, we therefore secured that (1.8) holds no mat-\nter how many cycles that while-statement went through.\nFinally, we need to make sure that the if-statement above always renders\ncorrect replies. First, if ⊥is marked, then there has to be some conjunct\nP1 ∧P2 ∧· · · ∧Pki →⊥of φ such that all Pi are marked as well. By (1.8)\nthat conjunct of φ evaluates to T →F = F whenever φ is true. As this is\nimpossible the reply ‘unsatisﬁable’ is correct. Second, if ⊥is not marked, we\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver",
                    "summary": "the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does no",
                    "children": [
                        {
                            "id": "chapter-1-section-4-subsection-1",
                            "title": "Semantic Equivalence, Satisfiability and Validity",
                            "content": "the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\n9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\n29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\n(a) ∃x.(x′ ↔(y + y′ · x))\n(b) ∀x.(x′ ↔(y + y′ · x))\n(c) ∃x′.(x′ ↔(y + y′ · x))\n(d) ∀x′.(x′ ↔(y + y′ · x)).\n5. Let ρ be a valuation with ρ(x′\n1) = 1 and ρ(x′\n2) = 0. Determine whether ρ ⊨f\nholds for the following:\n(a) x1[ˆx := ˆx′]\n(b) (x1 + x2)[ˆx := ˆx′]\n(c) (x1 · x2)[ˆx := ˆx′].\n6. Evaluate ρ ⊨(∃x1.(x1 + x2))[ˆx := ˆx′] and explain how the valuation ρ changes\nin that process. In particular, [ˆx := ˆx′] replaces xi by x′\ni, but why does this not\ninterfere with the binding quantiﬁer ∃x1?\n410\n6 Binary decision diagrams\n7. (a) How would you deﬁne the notion of semantic entailment for the relational\nmu-calculus?\n(b) Deﬁne formally when two formulas of the relational mu-calculus are seman-\ntically equivalent.\nExercises 6.15\n1. Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)\nholds, where ρ is\n(a) (x1, x2) ⇒(1, 0)\n(b) (x1, x2) ⇒(0, 1)\n(c) (x1, x2) ⇒(0, 0).\n2. Let S be {s0, s1}, with s0 →s0, s0 →s1 and s1 →s0 as possible transitions\nand L(s0) = {x1} and L(s1) = ∅. Compute the boolean function f EX (EX ¬x1).\n3. Equations (6.17) (page 395), (6.19) and (6.20) deﬁne f EF φ, f AF φ and f EG φ.\nWrite down a similar equation to deﬁne f AG φ.\n4. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately.\n5. Mimic the example checks on page 396 for the connective AU: consider the\nmodel of Figure 6.24 (page 384). Since [[E[(x1 ∨x2) U (¬x1 ∧¬x2)]]] equals the\nentire state set {s0, s1, s2}, your coding of f E[x1∨x2U¬x1∧¬x2] is correct if it\ncomputes 1 for all bit vectors diﬀerent from (1, 1).\n(a) Verify that your coding is indeed correct.\n(b) Find a boolean formula without ﬁxed points which is semantically equiva-\nlent to f E[(x1∨x2)U(¬x1∧¬x2)].\n6. (a) Use (6.20) on page 395 to compute f EG ¬x1 for the model in Figure 6.24.\n(b) Show that f EG ¬x1 faithfully models the set of all states which satisfy\nEG ¬x1.\n7. In the grammar (6.10) for the relational mu-calculus on page 390, it was stated\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nthe equivalence of formulas φ and ψ via ⊨: if φ semantically entails ψ and\nvice versa, then these formulas should be the same as far as our truth-table\nsemantics is concerned.\nDeﬁnition 1.40 Let φ and ψ be formulas of propositional logic. We say\nthat φ and ψ are semantically equivalent iﬀφ ⊨ψ and ψ ⊨φ hold. In that\ncase we write φ ≡ψ. Further, we call φ valid if ⊨φ holds.\nNote that we could also have deﬁned φ ≡ψ to mean that ⊨(φ →ψ) ∧\n(ψ →φ) holds; it amounts to the same concept. Indeed, because of soundness\nand completeness, semantic equivalence is identical to provable equivalence\n1.5 Normal forms\n55\n(Deﬁnition 1.25). Examples of equivalent formulas are\np →q ≡¬q →¬p\np →q ≡¬p ∨q\np ∧q →p ≡r ∨¬r\np ∧q →r ≡p →(q →r).\nRecall that a formula η is called a tautology if ⊨η holds, so the tautologies\nare exactly the valid formulas. The following lemma says that any decision\nprocedure for tautologies is in fact a decision procedure for the validity of\nsequents as well.\nLemma 1.41 Given formulas φ1, φ2, . . . , φn and ψ of propositional logic,\nφ1, φ2, . . . , φn ⊨ψ holds iﬀ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nProof: First, suppose that ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nIf φ1, φ2, . . . , φn are all true under some valuation, then ψ has to be true\nas well for that same valuation. Otherwise,\n⊨φ1 →(φ2 →(φ3 →· · · →\n(φn →ψ))) would not hold (compare this with Figure 1.11). Second, if\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nto be {(a, a), (b, b), (c, c)}. Hence the semantics of equality is easy, for it is\nalways modelled extensionally.\n2.5 Undecidability of predicate logic\nWe continue our introduction to predicate logic with some negative results.\nGiven a formula φ in propositional logic we can, at least in principle, de-\ntermine whether ⊨φ holds: if φ has n propositional atoms, then the truth\ntable of φ contains 2n lines; and ⊨φ holds if, and only if, the column for φ\n(of length 2n) contains only T entries.\nThe bad news is that such a mechanical procedure, working for all for-\nmulas φ, cannot be provided in predicate logic. We will give a formal proof\nof this negative result, though we rely on an informal (yet intuitive) notion\nof computability.\nThe problem of determining whether a predicate logic formula is valid is\nknown as a decision problem. A solution to a decision problem is a program\n(written in Java, C, or any other common language) that takes problem\ninstances as input and always terminates, producing a correct ‘yes’ or ‘no’\noutput. In the case of the decision problem for predicate logic, the input to\nthe program is an arbitrary formula φ of predicate logic and the program\n132\n2 Predicate logic\nis correct if it produces ‘yes’ whenever the input formula is valid and ‘no’\nwhenever it is not. Note that the program which solves a decision problem\nmust terminate for all well-formed input: a program which goes on thinking\nabout it for ever is not allowed. The decision problem at hand is this:\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced",
                            "summary": "the truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does no",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-2",
                            "title": "Conjunctive Normal Forms and Validity",
                            "content": "(¬p ∨¬q ∨r) ∧(p ∨¬q ∨¬r) ∧(p ∨¬q ∨r) ∧(p ∨q ∨¬r).\nIf we don’t have a full truth table at our disposal, but do know the structure\nof φ, then we would like to compute a version of φ in CNF. It should be\nclear by now that a full truth table of φ and an equivalent formula in\nCNF are pretty much the same thing as far as questions about validity are\nconcerned – although the formula in CNF may be much more compact.\n1.5.2 Conjunctive normal forms and validity\nWe have already seen the beneﬁts of conjunctive normal forms in that they\nallow for a fast and easy syntactic test of validity. Therefore, one wonders\nwhether any formula can be transformed into an equivalent formula in CNF.\nWe now develop an algorithm achieving just that. Note that, by Deﬁni-\ntion 1.40, a formula is valid iﬀany of its equivalent formulas is valid. We\nreduce the problem of determining whether any φ is valid to the problem\nof computing an equivalent ψ ≡φ such that ψ is in CNF and checking, via\nLemma 1.43, whether ψ is valid.\n1.5 Normal forms\n59\nBefore we sketch such a procedure, we make some general remarks about\nits possibilities and its realisability constraints. First of all, there could be\nmore or less eﬃcient ways of computing such normal forms. But even more\nso, there could be many possible correct outputs, for ψ1 ≡φ and ψ2 ≡φ\ndo not generally imply that ψ1 is the same as ψ2, even if ψ1 and ψ2 are in\nCNF. For example, take φ\ndef\n= p, ψ1\ndef\n= p and ψ2\ndef\n= p ∧(p ∨q); then convince\nyourself that φ ≡ψ2 holds. Having this ambiguity of equivalent conjunctive\nnormal forms, the computation of a CNF for φ with minimal ‘cost’ (where\n‘cost’ could for example be the number of conjuncts, or the height of φ’s\nparse tree) becomes a very important practical problem, an issue persued in\nChapter 6. Right now, we are content with stating a deterministic algorithm\nwhich always computes the same output CNF for a given input φ.\nThis algorithm, called CNF, should satisfy the following requirements:\n(1)\nto the distributivity laws, which entitle us to translate any disjunction of\nconjunctions into a conjunction of disjunctions. However, for this to result in\na CNF, we need to make certain that those disjunctions generated contain\nonly literals. We apply a strategy for using distributivity based on matching\npatterns in φ1 ∨φ2. This results in an independent algorithm called DISTR\nwhich will do all that work for us. Thus, we simply call DISTR with the pair\n(η1, η2) as input and pass along its result.\nAssuming that we already have written code for IMPL FREE, NNF and\nDISTR, we may now write pseudo code for CNF:\nfunction CNF (φ):\n/* precondition: φ implication free and in NNF */\n/* postcondition: CNF (φ) computes an equivalent CNF for φ */\nbegin function\ncase\nφ is a literal: return φ\nφ is φ1 ∧φ2 : return CNF (φ1) ∧CNF (φ2)\nφ is φ1 ∨φ2 : return DISTR (CNF (φ1), CNF (φ2))\nend case\nend function\n1.5 Normal forms\n61\nNotice how the calling of DISTR is done with the computed conjunctive nor-\nmal forms of φ1 and φ2. The routine DISTR has η1 and η2 as input parameters\nand does a case analysis on whether these inputs are conjunctions. What\nshould DISTR do if none of its input formulas is such a conjunction? Well,\nsince we are calling DISTR for inputs η1 and η2 which are in CNF, this can\nonly mean that η1 and η2 are literals, or disjunctions of literals. Thus, η1 ∨η2\nis in CNF.\nOtherwise, at least one of the formulas η1 and η2 is a conjunction. Since\none conjunction suﬃces for simplifying the problem, we have to decide which\nconjunct we want to transform if both formulas are conjunctions. That way\nwe maintain that our algorithm CNF is deterministic. So let us suppose that\nη1 is of the form η11 ∧η12. Then the distributive law says that η1 ∨η2 ≡\n(η11 ∨η2) ∧(η12 ∨η2). Since all participating formulas η11, η12 and η2 are\nin CNF, we may call DISTR again for the pairs (η11, η2) and (η12, η2), and\nthen simply form their conjunction. This is the key insight for writing the\nfunction DISTR.\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\nseparate layers such that validity checks are easy. This is being done by\n1.\nusing the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of →from a\nformula and\n2.\nby specifying an algorithm that takes a formula without any →into a normal\nform (still without →) for which checking validity is easy.\nNaturally, we have to specify which forms of formulas we think of as being\n‘normal.’ Again, there are many such notions, but in this text we study only\ntwo important ones.\nDeﬁnition 1.42 A literal L is either an atom p or the negation of an atom\n¬p. A formula C is in conjunctive normal form (CNF) if it is a conjunction\nof clauses, where each clause D is a disjunction of literals:\nL ::= p | ¬p\nD ::= L | L ∨D\n(1.6)\nC ::= D | D ∧C.\n56\n1 Propositional logic\nExamples of formulas in conjunctive normal form are\n(i)\n(¬q ∨p ∨r) ∧(¬p ∨r) ∧q\n(ii)\n(p ∨r) ∧(¬p ∨r) ∧(p ∨¬r).\nIn the ﬁrst case, there are three clauses of type D: ¬q ∨p ∨r, ¬p ∨r, and q –\nwhich is a literal promoted to a clause by the ﬁrst rule of clauses in (1.6).\nNotice how we made implicit use of the associativity laws for ∧and ∨,\nsaying that φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η and φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η, since\nwe omitted some parentheses. The formula (¬(q ∨p) ∨r) ∧(q ∨r) is not in\nCNF since q ∨p is not a literal.\nWhy do we care at all about formulas φ in CNF? One of the reasons\nfor their usefulness is that they allow easy checks of validity which other-\nwise take times exponential in the number of atoms. For example, consider\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nthe formula in CNF from above: (¬q ∨p ∨r) ∧(¬p ∨r) ∧q. The semantic\nentailment ⊨(¬q ∨p ∨r) ∧(¬p ∨r) ∧q holds iﬀall three relations\n⊨¬q ∨p ∨r\n⊨¬p ∨r\n⊨q\nhold, by the semantics of ∧. But since all of these formulas are disjunctions\nof literals, or literals, we can settle the matter as follows.\nLemma 1.43 A disjunction of literals L1 ∨L2 ∨· · · ∨Lm is valid iﬀthere\nare 1 ≤i, j ≤m such that Li is ¬Lj.\nProof: If Li equals ¬Lj, then L1 ∨L2 ∨· · · ∨Lm evaluates to T for all\nvaluations. For example, the disjunct p ∨q ∨r ∨¬q can never be made false.\nTo see that the converse holds as well, assume that no literal Lk has a\nmatching negation in L1 ∨L2 ∨· · · ∨Lm. Then, for each k with 1 ≤k ≤n,\nwe assign F to Lk, if Lk is an atom; or T, if Lk is the negation of an atom.\nFor example, the disjunct ¬q ∨p ∨r can be made false by assigning F to p\nand r and T to q.\n2\nHence, we have an easy and fast check for the validity of ⊨φ, provided\nthat φ is in CNF; inspect all conjuncts ψk of φ and search for atoms in ψk\nsuch that ψk also contains their negation. If such a match is found for all\nconjuncts, we have ⊨φ. Otherwise (= some conjunct contains no pair Li and\n¬Li), φ is not valid by the lemma above. Thus, the formula (¬q ∨p ∨r) ∧\n(¬p ∨r) ∧q above is not valid. Note that the matching literal has to be found\nin the same conjunct ψk. Since there is no free lunch in this universe, we can\nexpect that the computation of a formula φ′ in CNF, which is equivalent to\na given formula φ, is a costly worst-case operation.\nBefore we study how to compute equivalent conjunctive normal forms, we\nintroduce another semantic concept closely related to that of validity.\n1.5 Normal forms\n57\nDeﬁnition 1.44 Given a formula φ in propositional logic, we say that φ is\nsatisﬁable if it has a valuation in which is evaluates to T.\nFor example, the formula p ∨q →p is satisﬁable since it computes T if we\nassign T to p. Clearly, p ∨q →p is not valid. Thus, satisﬁability is a weaker\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\n(e) Cancer will not be cured unless its cause is determined and a new drug for\ncancer is found.\n(f) If interest rates go up, share prices go down.\n(g) If Smith has installed central heating, then he has sold his car or he has not\npaid his mortgage.\n(h)\n*\nToday it will rain or shine, but not both.\n(i)\n*\nIf Dick met Jane yesterday, they had a cup of coﬀee together, or they took\na walk in the park.\n(j) No shoes, no shirt, no service.\n(k) My sister wants a black and white cat.\n2. The formulas of propositional logic below implicitly assume the binding priorities\nof the logical connectives put forward in Convention 1.3. Make sure that you fully\nunderstand those conventions by reinserting as many brackets as possible. For\nexample, given p ∧q →r, change it to (p ∧q) →r since ∧binds more tightly\nthan →.\n(a)\n*\n¬p ∧q →r\n(b) (p →q) ∧¬(r ∨p →q)\n(c)\n*\n(p →q) →(r →s ∨t)\n(d) p ∨(¬q →p ∧r)\n(e)\n*\np ∨q →¬p ∧r\n(f) p ∨p →¬q\n(g)\n*\nWhy is the expression p ∨q ∧r problematic?\nExercises 1.2\n1. Prove the validity of the following sequents:\n(a) (p ∧q) ∧r, s ∧t ⊢q ∧s\n1.7 Exercises\n79\n(b) p ∧q ⊢q ∧p\n(c)\n*\n(p ∧q) ∧r ⊢p ∧(q ∧r)\n(d) p →(p →q), p ⊢q\n(e)\n*\nq →(p →r), ¬r, q ⊢¬p\n(f)\n*\n⊢(p ∧q) →p\n(g) p ⊢q →(p ∧q)\n(h)\n*\np ⊢(p →q) →q\n(i)\n*\n(p →r) ∧(q →r) ⊢p ∧q →r\n(j)\n*\nq →r ⊢(p →q) →(p →r)\n(k) p →(q →r), p →q ⊢p →r\n(l)\n*\np →q, r →s ⊢p ∨r →q ∨s\n(m) p ∨q ⊢r →(p ∨q) ∧r\n(n)\n*\n(p ∨(q →p)) ∧q ⊢p\n(o)\n*\np →q, r →s ⊢p ∧r →q ∧s\n(p) p →q ⊢((p ∧q) →p) ∧(p →(p ∧q))\n(q) ⊢q →(p →(p →(q →p)))\n(r)\n*\np →q ∧r ⊢(p →q) ∧(p →r)\n(s) (p →q) ∧(p →r) ⊢p →q ∧r\n(t) ⊢(p →q) →((r →s) →(p ∧r →q ∧s)); here you might be able to ‘recycle’\nand augment a proof from a previous exercise.\n(u) p →q ⊢¬q →¬p\n(v)\n*\np ∨(p ∧q) ⊢p\n(w) r, p →(r →q) ⊢p →(q ∧r)\n(x)\n*\np →(q ∨r), q →s, r →s ⊢p →s\n(y)\n*\n(p ∧q) ∨(p ∧r) ⊢p ∧(q ∨r).\n2. For the sequents below, show which ones are valid and which ones aren’t:\n(a)\n*\n¬p →¬q ⊢q →p\n(b)\n*\n¬p ∨¬q ⊢¬(p ∧q)\n(c)\n*\n¬p, p ∨q ⊢q\n(d)\n*\np ∨q, ¬q ∨r ⊢p ∨r\n(e)\n*\np →(q ∨r), ¬q, ¬r ⊢¬p without using the MT rule\n(f)\n*",
                            "summary": "If we don’t have a full truth table at our disposal, but do know the structure of φ, then we would like to compute a version of that in CNF. It should be clear by now that a fulltruth table and an equivalent formula inCNF are pretty much the same thing as far as questions about validity are concerned. Note that, by Deﬁni-                tion 1.40, a formula is valid iﬀany of its equivalent formulas is valid. We now develop an algorithm achieving just that.1.5.2 Conjunctive normal forms and validity. We have already seen the bene’s of conjunctive normal form in that they allow for a fast We reduce the problem of determining whether any φ is valid to computing an equivalent ψ such that ψ is in CNF and checking whether it is valid. There could be many possible correct outputs, for ψ1 and ψ2 do not generally imply that ω1 is the same as ω2. Having this ambiguity of equivalent conjunctivenormal forms, the computation of a CNF for φ with minimal ‘cost’ becomes a very important practical problem, an issue persued in Chapter 6.5 of the CNF textbook. The CNF book is published by Oxford University Press, London, UK, priced £16.99 (including p&p) This algorithm, called CNF, should satisfy the following requirements. It should translate any disjunction of                conjunctions into a conjunction of disjunctions. We apply a strategy for using distributivity based on matchingpatterns in φ1 and φ2. This results in an independent algorithm called DISTRwhich will do all that work for us. The algorithm is called DISTR and it is based on the following: DISTR1 DISTR2 DISTR3 DISTR4. The code for CNF is based on IMPL FREE, NNF and DISTR. CNF computes an equivalent CNF for φ. The routine DISTR has η1 and η2 as input parameters and does a case analysis on whether these inputs are conjunctions. We simply call DISTR with the pair.(η1,η2) as input and pass along its result. The code for DISTR is called DISTR (CNF ( φ1), CNF (φ2) and it returns a CNF with the same result. It can only do this if the inputs are literals, or disjunctions of literals. For example, we could call DISTR (DPR (C We want to transform formulas into ones which don’t contain →at all. This is the key insight for writing the function DISTR. We want to create layers such that validity checks are easy. We have already shown that ⊨φ1 →(φ2 →( φ3 →) follows in step 1 of our completeness proof. We may call DISTR again for the pairs (η11, η2), and simply form their conjunction. The function DISTR holds for φn, φ2, . . . , ωn, and ωr, as well as for ω2, ω3, and so on. A literal L is either an atom p or the negation of an atom P. A normalform is a formula without any → into which checking validity is easy. This is being done by.using the equivalence φ →ψ ≡¬φ ∨ψ to remove all occurrences of. →from a formula. We study only two important ones, the first of which is the definition of ‘normal’ A formula C is in conjunctive normal form (CNF) if it is a conjunction of clauses. CNF is a disjunction of literals, where each clause D is a literal. The formula (¬(q ∨p) ∨r)  is not in CNF since q is not a literal, but it is in the rule of clauses in (1.6) CNF uses the associativity laws for  and  in the case of   and   in (i) and (ii) The formulas φ and φ are used because they allow easy checks of validity which other-wise take times exponential in the number of atoms. Lemma 1.43: A disjunction of literals is valid if there are 1 ≤i, j ≤m such that Li is ¬Lj. For example, the disjunct p  can never be made false. We can settle the matter as follows: If Li equals Lj, then L1  L2  evaluates to T for all                valuations. If no literal Lk has a matching negation in L1, Lm, we can say that Lk is valid. We call the formula in CNF from above: (¬q  p  r)  (¬p   r) (‘P’   For each k with 1 ≤k ≤n, we assign F to Lk, if Lk is an atom; or T, if T is the negation of an atom. If such a match is found for all                conjuncts, we have ⊨φ. Otherwise (= some conjunct contains no pair Li and                ¬Li), φ is not valid by the lemma above. Note that the matching literal has to be found in the same conjunct ψk. Thus, the formula (¬q ∨p ∨r)  is not valid. For example, the disjunct ¬q  can be made false by assigning F to p Given a formula φ in propositional logic, we say that φ issatisﬁable if it has a valuation in which is evaluates to T. Since there is no free lunch in this universe, we can expect that the computation of a formula in CNF is a costly worst-case operation. For example, the formula p ∨q →p is satisﬃable since it computes T if we wrongly assign T to p. Clearly, p ∪q → p is not valid. The concept of validity is closely related to that of validity. We will use this to study how to compute equivalent conjunctive normal forms. We call these normal forms the \"normal forms\" of the CTL* expresses in terms of the order of occurrence of events p, s and t. The translation from CTL with boolean combinations of path formulas to plainCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for: E[G F p] and EG EF p. Find a transition system which distinguishes the following pairs of CTL* formu-                las, i.e., show that they are not equivalent: AF G p and AF AG p; A[(p U r) ∨(q U r)] and A[ (p ∨q) U r): A[Q U r] and Q U r: A[q Q r] The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. The following LTL formulas are valid (i.e. true in any state of any model):(i) ¬Q U (¬p  p)  (ii) G (p U q) (ii) P (p G p) (iii) G p (p W p)  (iv) P U (p Q p) p (v) P p (q U p) P Q (p F p) Q (q We can apply SAT solvers to checking whether sequents are valid. The DAG of T(φ) is depicted in Figure 1.15. Notice that such DAGsmay be constructed by applying the translation clauses for T to sub-formulas in a bottom-up manner. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T( φ)whose DAG equals that of this ﬁgure are not satisﬁable. For example, the sequent p ⊢p →q →r is valid iﬀ(p ∧q → r) is The SAT solver has a linear running time in the size of the DAG for T(φ) Since that size is a linear function of the length of the formula, T causes only a linear blow-up. This linearity came with a price: our linear solver fails for all formulas of the form ¬( φ1)1.6.2 A cubic solver binds most closely to the first two of the three levels of the solver: 1, 2 and 3. The third level is the third level: 4, 5 and 6. The fourth level is a series of four levels: 7, 8, 9 and 10. The fifth level is an extension of the fourth level. This convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. In basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when we apply modal logics to express various modes of truth, we may read them more appropriately. We cannot omit the remaining brackets, however, for 23q ∧¬r →2p has quite a For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. Model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W →P(Atoms) These models are often called Kripke models, in honour of S. Kripk who invented them. The parse tree for 23q ∧¬r →2p.3 is shown in the next section of the book. The book is published by Oxford University Press, priced £9.99, with a print run of 1,000 copies. For confidential support call the Samaritans on 08457 90 90 The formulas of propositional logic below implicitly assume the binding priorities of the logical connectives put forward in Convention 1.3. Make sure that you fullyunderstand those conventions by reinserting as many brackets as possible. For example, given p ∧q →r, change it to (p  q  r) since (p  q  r binds more tightly than p q. Here you might be able to ‘recycle’ and augment a proof from a previous exercise. For the sequents below, show which ones are valid and which ones aren’t. Prove the validity of the following sequents: (p  p) (a) (b) (c) (d) (e) (f) (g) (h) (i) (j) (k) (l) (m) (n) (r) (s) (t) (u) (v) (w) (x) (z) (xi) (3) (4) (5) (6) (7) (8)",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-3",
                            "title": "Horn Clauses and Satisfiability",
                            "content": "ciding their satisﬁability. One such example is the class of Horn formu-\nlas; the name ‘Horn’ is derived from the logician A. Horn’s last name.\nWe shortly deﬁne them and give an algorithm for checking their satisﬁ-\nability.\nRecall that the logical constants ⊥(‘bottom’) and ⊤(‘top’) denote an\nunsatisﬁable formula, respectively, a tautology.\nDeﬁnition 1.46 A Horn formula is a formula φ of propositional logic if it\ncan be generated as an instance of H in this grammar:\nP ::= ⊥| ⊤| p\nA ::= P | P ∧A\nC ::= A →P\nH ::= C | C ∧H.\n(1.7)\nWe call each instance of C a Horn clause.\n66\n1 Propositional logic\nHorn formulas are conjunctions of Horn clauses. A Horn clause is an impli-\ncation whose assumption A is a conjunction of propositions of type P and\nwhose conclusion is also of type P. Examples of Horn formulas are\n(p ∧q ∧s →p) ∧(q ∧r →p) ∧(p ∧s →s)\n(p ∧q ∧s →⊥) ∧(q ∧r →p) ∧(⊤→s)\n(p2 ∧p3 ∧p5 →p13) ∧(⊤→p5) ∧(p5 ∧p11 →⊥).\nExamples of formulas which are not Horn formulas are\n(p ∧q ∧s →¬p) ∧(q ∧r →p) ∧(p ∧s →s)\n(p ∧q ∧s →⊥) ∧(¬q ∧r →p) ∧(⊤→s)\n(p2 ∧p3 ∧p5 →p13 ∧p27) ∧(⊤→p5) ∧(p5 ∧p11 →⊥)\n(p2 ∧p3 ∧p5 →p13 ∧p27) ∧(⊤→p5) ∧(p5 ∧p11 ∨⊥).\nThe ﬁrst formula is not a Horn formula since ¬p, the conclusion of the\nimplication of the ﬁrst conjunct, is not of type P. The second formula does\nnot qualify since the premise of the implication of the second conjunct,\n¬q ∧r, is not a conjunction of atoms, ⊥, or ⊤. The third formula is not a\nHorn formula since the conclusion of the implication of the ﬁrst conjunct,\np13 ∧p27, is not of type P. The fourth formula clearly is not a Horn formula\nsince it is not a conjunction of implications.\nThe algorithm we propose for deciding the satisﬁability of a Horn for-\nmula φ maintains a list of all occurrences of type P in φ and proceeds like\nthis:\n1.\nIt marks ⊤if it occurs in that list.\n2.\nIf there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ such that all Pj with 1 ≤j ≤\nki are marked, mark P ′ as well and go to 2. Otherwise (= there is no conjunct\ncorrect replies. First, if ⊥is marked, then there has to be some conjunct\nP1 ∧P2 ∧· · · ∧Pki →⊥of φ such that all Pi are marked as well. By (1.8)\nthat conjunct of φ evaluates to T →F = F whenever φ is true. As this is\nimpossible the reply ‘unsatisﬁable’ is correct. Second, if ⊥is not marked, we\nsimply assign T to all marked atoms and F to all unmarked atoms and use\nproof by contradiction to show that φ has to be true with respect to that\nvaluation.\nIf φ is not true under that valuation, it must make one of its principal\nconjuncts P1 ∧P2 ∧· · · ∧Pki →P ′ false. By the semantics of implication\nthis can only mean that all Pj are true and P ′ is false. By the deﬁnition of our\nvaluation, we then infer that all Pj are marked, so P1 ∧P2 ∧· · · ∧Pki →P ′\nis a conjunct of φ that would have been dealt with in one of the cycles of\nthe while-statement and so P ′ is marked, too. Since ⊥is not marked, P ′ has\nto be ⊤or some atom q. In any event, the conjunct is then true by (1.8), a\ncontradiction\n2\nNote that the proof by contradiction employed in the last proof was not\nreally needed. It just made the argument seem more natural to us. The\nliterature is full of such examples where one uses proof by contradiction\nmore out of psychological than proof-theoretical necessity.\n1.6 SAT solvers\nThe marking algorithm for Horn formulas computes marks as constraints\non all valuations that can make a formule true. By (1.8), all marked atoms\nhave to be true for any such valuation. We can extend this idea to general\nformulas φ by computing constraints saying which subformulas of φ require\na certain truth value for all valuations that make φ true:\n‘All marked subformulas evaluate to their mark value\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\n(a)\n*\n(p ∧q ∧w →⊥) ∧(t →⊥) ∧(r →p) ∧(⊤→r) ∧(⊤→q) ∧(u →\ns) ∧(⊤→u)\n(b) (p ∧q ∧w →⊥) ∧(t →⊥) ∧(r →p) ∧(⊤→r) ∧(⊤→q) ∧(r ∧u →\nw) ∧(u →s) ∧(⊤→u)\n(c) (p ∧q ∧s →p) ∧(q ∧r →p) ∧(p ∧s →s)\n(d) (p ∧q ∧s →⊥) ∧(q ∧r →p) ∧(⊤→s)\n(e) (p5 →p11) ∧(p2 ∧p3 ∧p5 →p13) ∧(⊤→p5) ∧(p5 ∧p11 →⊥)\n(f) (⊤→q) ∧(⊤→s) ∧(w →⊥) ∧(p ∧q ∧s →⊥) ∧(v →s) ∧(⊤→\nr) ∧(r →p)\n90\n1 Propositional logic\n(g)\n*\n(⊤→q) ∧(⊤→s) ∧(w →⊥) ∧(p ∧q ∧s →v) ∧(v →s) ∧(⊤→\nr) ∧(r →p).\n16. Explain why the algorithm HORN fails to work correctly if we change the concept\nof Horn formulas by extending the clause for P on page 65 to P ::= ⊥| ⊤|\np | ¬p?\n17. What can you say about the CNF of Horn formulas. More precisely, can you\nspecify syntactic criteria for a CNF that ensure that there is an equivalent Horn\nformula? Can you describe informally programs which would translate from one\nform of representation into another?\nExercises 1.6\n1. Use mathematical induction to show that, for all φ of (1.3) on page 33,\n(a) T(φ) can be generated by (1.10) on page 69,\n(b) T(φ) has the same set of valuations as φ, and\n(c) the set of valuations in which φ is true equals the set of valuations in which\nT(φ) is true.\n2.\n*\nShow that all rules of Figure 1.14 (page 71) are sound: if all current marks\nsatisfy the invariant (1.9) from page 68, then this invariant still holds if the\nderived constraint of that rule becomes an additional mark.\n3. In Figure 1.16 on page 73 we detected a contradiction which secured the validity\nof the sequent p ∧q →r ⊢p →q →r. Use the same method with the linear SAT\nsolver to show that the sequent ⊢(p →q) ∨(r →p) is valid. (This is interest-\ning since we proved this validity in natural deduction with a judicious choice\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nlaws to it, and extract a witness to the DAG’s satisﬁability. Explain in what\nsense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is\nnot valid.\n5. Explain in what sense the SAT solving technique, as presented in this chapter,\ncan be used to check whether formulas are tautologies.\n6. For φ from (1.10), can one reverse engineer φ from the DAG of T(φ)?\n7. Consider a modiﬁcation of our method which initially tags a DAG’s root node\nwith ‘1: F.’ In that case,\n(a) are the forcing laws still sound? If so, state the invariant.\n(b) what can we say about the formula(s) a DAG represents if\ni. we detect contradictory constraints?\nii. we compute consistent forced constraints for each node?\n8. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied\nto T(φ) –\nto the marking algorithm – applied to φ. Discuss similarities and\ndiﬀerences of these approaches.\n1.8 Bibliographic notes\n91\n9. Consider Figure 1.20 on page 77. Verify that\n(a) its test produces contradictory constraints\n(b) its cubic analysis does not decide satisﬁability, regardless of whether the\ntwo optimizations we described are present.\n10. Verify that the DAG of Figure 1.17 (page 74) is indeed the one obtained for\nT(φ), where φ is the formula in (1.11) on page 73.\n11.\n*\nAn implementor may be concerned with the possibility that the answers to the\ncubic SAT solver may depend on a particular order in which we test unmarked\nnodes or use the rules in Figure 1.14. Give a semi-formal argument for why the\nanalysis results don’t depend on such an order.\n12. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability\nof T(φ).\n13. Advanced Project: Write a complete implementation of the cubic SAT solver\nmula φ maintains a list of all occurrences of type P in φ and proceeds like\nthis:\n1.\nIt marks ⊤if it occurs in that list.\n2.\nIf there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ such that all Pj with 1 ≤j ≤\nki are marked, mark P ′ as well and go to 2. Otherwise (= there is no conjunct\nP1 ∧P2 ∧· · · ∧Pki →P ′ such that all Pj are marked) go to 3.\n3.\nIf ⊥is marked, print out ‘The Horn formula φ is unsatisﬁable.’ and stop. Oth-\nerwise, go to 4.\n4.\nPrint out ‘The Horn formula φ is satisﬁable.’ and stop.\nIn these instructions, the markings of formulas are shared by all other oc-\ncurrences of these formulas in the Horn formula. For example, once we\nmark p2 because of one of the criteria above, then all other occurrences\nof p2 are marked as well. We use pseudo code to specify this algorithm\nformally:\n1.5 Normal forms\n67\nfunction HORN (φ):\n/* precondition: φ is a Horn formula */\n/* postcondition: HORN (φ) decides the satisﬁability for φ */\nbegin function\nmark all occurrences of ⊤in φ;\nwhile there is a conjunct P1 ∧P2 ∧· · · ∧Pki →P ′ of φ\nsuch that all Pj are marked but P ′ isn’t do\nmark P ′\nend while\nif ⊥is marked then return ‘unsatisﬁable’ else return ‘satisﬁable’\nend function\nWe need to make sure that this algorithm terminates on all Horn formulas\nφ as input and that its output (= its decision) is always correct.\nTheorem 1.47 The algorithm HORN is correct for the satisﬁability decision\nproblem of Horn formulas and has no more than n + 1 cycles in its while-\nstatement if n is the number of atoms in φ. In particular, HORN always\nterminates on correct input.\nProof: Let us ﬁrst consider the question of program termination. Notice\nthat entering the body of the while-statement has the eﬀect of marking an\nunmarked P which is not ⊤. Since this marking applies to all occurrences\nof P in φ, the while-statement can have at most one more cycle than there\nare atoms in φ.\nSince we guaranteed termination, it suﬃces to show that the answers\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nWhen we applied our linear SAT solver, we saw two possible outcomes:\nwe either detected contradictory constraints, meaning that no formula rep-\nresented by the DAG is satisﬁable (e.g. Fig. 1.16); or we managed to force\nconsistent constraints on all nodes, in which case all formulas represented by\nthis DAG are satisﬁable with those constraints as a witness (e.g. Fig. 1.13).\nUnfortunately, there is a third possibility: all forced constraints are consis-\ntent with each other, but not all nodes are constrained! We already remarked\nthat this occurs for formulas of the form ¬(φ1 ∧φ2).\n1.6 SAT solvers\n73\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n1: T\n2: F\n3: T\n4: T\n4: T\n5: F\n6: T\n5: F\n7: T\n8: F\n9: T\n11: F\n10: T\n10: T\n7: T\nits conjunction parent\n– a contradiction\nand ∧frr force F\nits children and\n∧ti force T\nFigure 1.16. The forcing rules, applied to the DAG of Figure 1.15,\ndetect contradictory constraints at the indicated node – implying that\nthe initial constraint ‘1:T’ cannot be realized. Thus, formulas represented\nby this DAG are not satisfiable.\nRecall that checking validity of formulas in CNF is very easy. We already\nhinted at the fact that checking satisﬁability of formulas in CNF is hard. To\nillustrate, consider the formula\n((p ∨(q ∨r)) ∧((p ∨¬q) ∧((q ∨¬r) ∧((r ∨¬p) ∧(¬p ∨(¬q ∨¬r))))))\n(1.11)\nin CNF – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula\nshould not be satisﬁable. The ﬁrst and last clause in (1.11) ‘say’ that at least\none of p, q, and r are false and true (respectively). The remaining three\nclauses, in their conjunction, ‘say’ that p, q, and r all have the same truth\nvalue. This cannot be satisﬁable, and a good SAT solver should discover\nunmarked P which is not ⊤. Since this marking applies to all occurrences\nof P in φ, the while-statement can have at most one more cycle than there\nare atoms in φ.\nSince we guaranteed termination, it suﬃces to show that the answers\ngiven by the algorithm HORN are always correct. To that end, it helps to\nreveal the functional role of those markings. Essentially, marking a P means\nthat that P has got to be true if the formula φ is ever going to be satisﬁable.\nWe use mathematical induction to show that\n‘All marked P are true for all valuations in which φ evaluates to T.’ (1.8)\nholds after any number of executions of the body of the while-statement\nabove. The base case, zero executions, is when the while-statement has not\nyet been entered but we already and only marked all occurrences of ⊤. Since\n⊤must be true in all valuations, (1.8) follows.\nIn the inductive step, we assume that (1.8) holds after k cycles of the\nwhile-statement. Then we need to show that same assertion for all marked\nP after k + 1 cycles. If we enter the (k + 1)th cycle, the condition of the\nwhile-statement is certainly true. Thus, there exists a conjunct P1 ∧P2 ∧\n· · · ∧Pki →P ′ of φ such that all Pj are marked. Let v be any valuation\n68\n1 Propositional logic\nin which φ is true. By our induction hypothesis, we know that all Pj and\ntherefore P1 ∧P2 ∧· · · ∧Pki have to be true in v as well. The conjunct P1 ∧\nP2 ∧· · · ∧Pki →P ′ of φ has be to true in v, too, from which we infer that\nP ′ has to be true in v.\nBy mathematical induction, we therefore secured that (1.8) holds no mat-\nter how many cycles that while-statement went through.\nFinally, we need to make sure that the if-statement above always renders\ncorrect replies. First, if ⊥is marked, then there has to be some conjunct\nP1 ∧P2 ∧· · · ∧Pki →⊥of φ such that all Pi are marked as well. By (1.8)\nthat conjunct of φ evaluates to T →F = F whenever φ is true. As this is\nimpossible the reply ‘unsatisﬁable’ is correct. Second, if ⊥is not marked, we\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver",
                            "summary": "Horn clauses are conjunctions of Horn clauses. The name ‘Horn’ is derived from the logician A. Horn’s last name. A Horn clause is an impli-                cation whose assumption A is a conjunction of propositions of type P and whose conclusion is also oftype P. We call each instance of C a Horn clause. We give an algorithm for checking their satisﬁ-                 ability. ciding their sati-cularity. The algorithm is called the Horn algorithm. It is based on the H-Algorithm for Algorithms in propositional logic. We use the algorithm to test the correctness of the Horn formula. Horn formulas include the following. Examples of Horn formulas are                (p  q  s →p) and                (q   r  p s  → p) The ﬁrst formula is not a Horn formula since ¬p is not of type P. The second formula does not qualify since the premise of the implication of the second conjunct, ¬q r, is not a conjunction of atoms, ⊥, or ⊤. The third formula is also not Horn, since the conclusion of the imply of the ﬅrst conjunct is not type P, but of type P. The algorithm we propose for deciding the satisﬁability of a Horn for-mula φ maintains a list of all occurrences of type P in φ. First, if ⊥is marked, then there has to be some conjunct of φ such that all Pi are marked as well. Second, wesimply assign T to all marked atoms and F to all unmarked atoms and use disproving by contradiction to show that φ is true with respect to that valuation. The fourth formula clearly is not a Horn formula since it is a conjunction of implications. It is not possible for a Horn to be both true and false at the same time, so it cannot be a Horn. The marking algorithm for Horn formulas computes marks as constraints on all valuations that can make a formule true. By (1.8), all marked atoms have to be true for any such valuation. By the semantics of implication, this can only mean that all Pj are true and P ′ is false. The proof by contradiction employed in the last proof was notreally needed. It just made the argument seem more natural to us. The literature is full of such examples where one uses proof by. contradiction more out of psychological than proof-theoretical necessity.1.6 SAT solvers for the Horn formula are available at: http://www.santasolvers.com/. We can extend this idea to general                formulas φ by computing constraints saying which subformulas of φ require a certain truth value for all valuations that make φ true. ‘True’ marks generalize into ‘true’ and ‘false’ Marks. At the same time, (1.9) serves as a guide for designing an algorithm and as an invariant (a) and (b) Propositional logic (g) and logic (h) (1) and 1.6 SAT solvers (2) (3) and 3) (4) and 4 (5) and 5 (6) and 6 (7) Exercises 1.6: Use mathematical induction to show that, for all φ of (1.3) on page 33, T(φ) can be generated by T(1.10) on pages 69 and 71. 1.7: Show that all rules of Figure 1.14 (page 71) are sound. 2. Explain why the algorithm HORN fails to work correctly if we change the concept                of Horn formulas by extending the clause for P on page 65 to P ::= ⊥| ⊤|                p | ¬p? 3. Describe informally programs which would translate from one form of representation into another. 4. In Figure 1.16 on page 73 we detected a contradiction which secured the validity of the DAG. Use the same method with the linear SATsolver to show that the sequent ⊢(p →q) ∨(r →p) is valid. (This is interest-phthaling since we proved this validity in natural deduction with a judicious choice of the proof rule LEM.) The linear SAT solver does not employ any case-reassuring analysis. Theorem: A DAG which is not satisﬁable                iﬀthis sequent is valid, and a witness to its satis ﬁability is extracted from it. The SAT solving technique, as presented in this chapter, can be used to check whether formulas are tautologies. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied to T(φ) – with the marking algorithm applied to φ. Discuss similarities and similarities of these approaches. For φ from (1.10), can one reverse engineer φ  from the DAG of T( φ)? For a DAG with a root node of ‘1: F’, is the forcing laws still sound? If so, state the invariant. If not, what can we say about the formula(s) a D AG represents if we detect contradictory constraints? An implementor may be concerned with the possibility that the answers to the                cubic SAT solver may depend on a particular order in which we test unmarkednodes or use the rules in Figure 1.14. Give a semi-formal argument for why the results don’t depend on such an order. Find a formula φ such that our cubic SATsolver cannot decide the satisﬁability of T(φ) Find a list of all occurrences of type P in φ and proceed like this: mark P if it occurs in that list. If there is no conjunct P1, mark P as well and go to 2. Otherwise, print out ‘The Horn formula χ Print out ‘The Horn formula φ is satisﬁable’ and stop. In these instructions, the markings of formulas are shared by all other oc-                currences of these formulas in the Horn formula. For example, once we mark p2 because We use pseudo code to specify this algorithm. We need to make sure that this algorithm terminates on all Horn formulas as input and that its output (= its decision) is always correct. The algorithm HORN is correct for the satisﬁability decision problem of Horn formulas and has no more than n + 1 cycles in its while-statement if n is the number of atoms in φ. In particular, HORN alwaysterminates on correct input. Theorem 1.47: HORN (φ) decides the satiﬀability for φ and terminates when it is wrong. We use the pseudo code: 1.5 Normal forms, 1.67 Normal forms and 1.7 Normal forms When we applied our linear SAT solver, we saw two possible outcomes. We either detected contradictory constraints, meaning that no formula rep-resented by the DAG is satisﬁable (e.g. Fig. 1.16) or we managed to force consistent constraints on all nodes. The linearity came with a price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).1.6.2 A cubic solver. The DAG can be used to solve the problem of how to solve a cubic equation. The solution can be found in the next section of this article. The forcing rules, applied to the DAG of Figure 1.15,detect contradictory constraints at the indicated node – implying that the initial constraint ‘1:T’ cannot be realized. Thus, formulas represented by this DAG are not satisfiable. We already remarked that this occurs for formulas of the form ¬(φ1 ∧φ2). 1.6 SAT solvers73p.p.qr: P.P.R: R. P. R: Q. R. T: T. T. F: T: F: F. A: T, T, F, T. A. B. C: F, F. F. We use mathematical induction to show that ‘All marked P are true for all valuations in which φ evaluates to T’ (1.8) The while-statement can have at most one more cycle than there are atoms in φ. Since we guaranteed termination, it suﬃces to show the answers given by the algorithm HORN are always correct. To that end, it helps to Reveal the functional role of those markings. Essentially, marking a P meansthat that P has got to be true if the formula φ is ever going to be satisﬁable. It helps to reveal the role of the ‘false’ and ‘true’ clauses in the while- In the inductive step, we assume that (1.8) holds after k cycles of the while-statement. If we enter the (k + 1)th cycle, the condition of thewhile-statement is certainly true. Let v be any valuation in which φ is true. By our induction hypothesis, we know that all Pj and Pki have to be true in v as well. The base case, zero executions, is when we already and only marked all occurrences of ⊤. Since P1 and P2 must betrue in all valuations, the proof of the induction hypothesis follows. The proof is that P1, P2, Pki and P By mathematical induction, we secured that (1.8) holds no mat-                ter how many cycles that while-statement went through. A post-processing phase takes the marks for all                atoms and re-computes marks of all other nodes in a bottom-up manner, as done in Section 1.4 on parse trees. Figure 1.14. Rules for flow of constraints in a formula’s DAG. Small                circles indicate arbitrary nodes (¬, ∧or atom). Note that the rules  require that the source constraints of both =⇒are present. The rules  for the sources of the constraints  are:  ‘P1’, We can apply SAT solvers to checking whether sequents are valid. The DAG of T(φ) is depicted in Figure 1.15. Notice that such DAGsmay be constructed by applying the translation clauses for T to sub-formulas in a bottom-up manner. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T( φ)whose DAG equals that of this ﬁgure are not satisﬁable. For example, the sequent p ⊢p →q →r is valid iﬀ(p ∧q → r) is The SAT solver has a linear running time in the size of the DAG for T(φ) Since that size is a linear function of the length of the formula, T causes only a linear blow-up. This linearity came with a price: our linear solver fails for all formulas of the form ¬( φ1)1.6.2 A cubic solver. In particular, all the formulas in Figure 1.15.72 are unsatisﬁable. The DAG. for the translation of ¬((p ∧q →r) →p →q →phthalr). Labels ‘1’’ etc indicate which nodes represent what subformulas are",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-5",
                    "title": "SAT Solvers",
                    "content": "",
                    "summary": "",
                    "children": [
                        {
                            "id": "chapter-1-section-5-subsection-1",
                            "title": "A Linear Solver",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-5-subsection-2",
                            "title": "A Cubic Solver",
                            "content": "",
                            "summary": null,
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-2",
            "title": "Predicate Logic",
            "content": "made concrete. There are two principal such occurrences:\n1.\nIn our example in Figure 2.1, we have three leaf nodes x. If we walk up the\ntree beginning at any one of these x leaves, we run into the quantiﬁer ∀x. This\nmeans that those occurrences of x are actually bound to ∀x so they represent,\nor stand for, any possible value of x.\n2.\nIn walking upwards, the only quantiﬁer that the leaf node y runs into is ∀x but\nthat x has nothing to do with y; x and y are diﬀerent place holders. So y is free\nin this formula. This means that its value has to be speciﬁed by some additional\ninformation, for example, the contents of a location in memory.\nDeﬁnition 2.6 Let φ be a formula in predicate logic. An occurrence of x\nin φ is free in φ if it is a leaf node in the parse tree of φ such that there\nis no path upwards from that node x to a node ∀x or ∃x. Otherwise, that\noccurrence of x is called bound. For ∀x φ, or ∃x φ, we say that φ – minus\nany of φ’s subformulas ∃x ψ, or ∀x ψ – is the scope of ∀x, respectively ∃x.\nThus, if x occurs in φ, then it is bound if, and only if, it is in the scope of\nsome ∃x or some ∀x; otherwise it is free. In terms of parse trees, the scope\nof a quantiﬁer is just its subtree, minus any subtrees which re-introduce a\n104\n2 Predicate logic\n→\n∀x\n∨\n∧\n¬\nQ\nP\nQ\nP\ny\nx\nx\nx\nfree\nfree\nbound\nbound\nFigure 2.2. A parse tree of a predicate logic formula illustrating free\nand bound occurrences of variables.\nquantiﬁer for x; e.g. the scope of ∀x in ∀x (P(x) →∃x Q(x)) is P(x). It is\nquite possible, and common, that a variable is bound and free in a formula.\nConsider the formula\n(∀x (P(x) ∧Q(x))) →(¬P(x) ∨Q(y))\nand its parse tree in Figure 2.2. The two x leaves in the subtree of ∀x are\nbound since they are in the scope of ∀x, but the leaf x in the right subtree of\n→is free since it is not in the scope of any quantiﬁer ∀x or ∃x. Note, however,\nthat a single leaf either is under the scope of a quantiﬁer, or it isn’t. Hence\nbound since they are in the scope of ∀x, but the leaf x in the right subtree of\n→is free since it is not in the scope of any quantiﬁer ∀x or ∃x. Note, however,\nthat a single leaf either is under the scope of a quantiﬁer, or it isn’t. Hence\nindividual occurrences of variables are either free or bound, never both at\nthe same time.\n2.2.4 Substitution\nVariables are place holders so we must have some means of replacing them\nwith more concrete information. On the syntactic side, we often need to\nreplace a leaf node x by the parse tree of an entire term t. Recall from the\ndeﬁnition of formulas that any replacement of x may only be a term; it\ncould not be a predicate expression, or a more complex formula, for x serves\nas a term to a predicate symbol one step higher up in the parse tree (see\nDeﬁnition 2.1 and the grammar in (2.2)). In substituting t for x we have to\n2.2 Predicate logic as a formal language\n105\nleave untouched the bound leaves x since they are in the scope of some ∃x\nor ∀x, i.e. they stand for some unspeciﬁed or all values respectively.\nDeﬁnition 2.7 Given a variable x, a term t and a formula φ we deﬁne φ[t/x]\nto be the formula obtained by replacing each free occurrence of variable x\nin φ with t.\nSubstitutions are easily understood by looking at some examples. Let f be a\nfunction symbol with two arguments and φ the formula with the parse tree\nin Figure 2.1. Then f(x, y) is a term and φ[f(x, y)/x] is just φ again. This\nis true because all occurrences of x are bound in φ, so none of them gets\nsubstituted.\nNow consider φ to be the formula with the parse tree in Figure 2.2. Here\nwe have one free occurrence of x in φ, so we substitute the parse tree of\nf(x, y) for that free leaf node x and obtain the parse tree in Figure 2.3.\nNote that the bound x leaves are unaﬀected by this operation. You can see\nthat the process of substitution is straightforward, but requires that it be\napplied only to the free occurrences of the variable to be substituted. 1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\n1.2.3 Natural deduction in summary\nThe proof rules for natural deduction are summarised in Figure 1.2. The\nexplanation of the rules we have given so far in this chapter is declarative;\nwe have presented each rule and justiﬁed it in terms of our intuition about\nthe logical connectives. However, when you try to use the rules yourself,\nyou’ll ﬁnd yourself looking for a more procedural interpretation; what does\na rule do and how do you use it? For example,\nr ∧i says: to prove φ ∧ψ, you must ﬁrst prove φ and ψ separately and then use\nthe rule ∧i.\nr ∧e1 says: to prove φ, try proving φ ∧ψ and then use the rule ∧e1. Actually,\nthis doesn’t sound like very good advice because probably proving φ ∧ψ will\nbe harder than proving φ alone. However, you might ﬁnd that you already have\nφ ∧ψ lying around, so that’s when this rule is useful. Compare this with the\nexample sequent in Example 1.15.\nr ∨i1 says: to prove φ ∨ψ, try proving φ. Again, in general it is harder to prove\nφ than it is to prove φ ∨ψ, so this will usually be useful only if you’ve already\nmanaged to prove φ. For example, if you want to prove q |−p ∨q, you certainly\nwon’t be able simply to use the rule ∨i1, but ∨i2 will work.\nr ∨e has an excellent procedural interpretation. It says: if you have φ ∨ψ, and you\nwant to prove some χ, then try to prove χ from φ and from ψ in turn. (In those\nsubproofs, of course you can use the other prevailing premises as well.)\nr Similarly, →i says, if you want to prove φ →ψ, try proving ψ from φ (and the\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nour reasoning is concerned about the inference, and therefore the preserva-\ntion, of truth. Hence, there cannot be a direct way of inferring ¬φ, given\nφ.\nDeﬁnition 1.19 Contradictions are expressions of the form φ ∧¬φ or ¬φ ∧\nφ, where φ is any formula.\nExamples of such contradictions are r ∧¬r, (p →q) ∧¬(p →q) and ¬(r ∨\ns →q) ∧(r ∨s →q). Contradictions are a very important notion in logic.\nAs far as truth is concerned, they are all equivalent; that means we should\nbe able to prove the validity of\n¬(r ∨s →q) ∧(r ∨s →q) ⊣⊢(p →q) ∧¬(p →q)\n(1.2)\nsince both sides are contradictions. We’ll be able to prove this later, when\nwe have introduced the rules for negation.\nIndeed, it’s not just that contradictions can be derived from contradic-\ntions; actually, any formula can be derived from a contradiction. This can be\n1.2 Natural deduction\n21\nconfusing when you ﬁrst encounter it; why should we endorse the argument\np ∧¬p ⊢q, where\np : The moon is made of green cheese.\nq : I like pepperoni on my pizza.\nconsidering that our taste in pizza doesn’t have anything to do with the\nconstitution of the moon? On the face of it, such an endorsement may seem\nabsurd. Nevertheless, natural deduction does have this feature that any for-\nmula can be derived from a contradiction and therefore it makes this argu-\nment valid. The reason it takes this stance is that ⊢tells us all the things\nwe may infer, provided that we can assume the formulas to the left of it.\nThis process does not care whether such premises make any sense. This has\nat least the advantage that we can match ⊢to checks based on semantic\nintuitions which we formalise later by using truth tables: if all the premises\ncompute to ‘true’, then the conclusion must compute ‘true’ as well. In partic-\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nan implication. Suppose that p →q and ¬q are the case. Then, if p holds\nwe can use →e to conclude that q holds. Thus, we then have that q and ¬q\nhold, which is impossible. Therefore, we may infer that p must be false. But\nthis can only mean that ¬p is true. We summarise this reasoning into the\nrule modus tollens, or MT for short:5\nφ →ψ\n¬ψ\n¬φ\nMT.\nAgain, let us see an example of this rule in the natural language setting:\n‘If Abraham Lincoln was Ethiopian, then he was African. Abraham\nLincoln was not African; therefore he was not Ethiopian.’\nExample 1.7 In the following proof of\np →(q →r), p, ¬r ⊢¬q\nwe use several of the rules introduced so far:\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq →r\n→e 1, 2\n5\n¬q\nMT 4, 3\n5 We will be able to derive this rule from other ones later on, but we introduce it here because it\nallows us already to do some pretty slick proofs. You may think of this rule as one on a higher\nlevel insofar as it does not mention the lower-level rules upon which it depends.\n1.2 Natural deduction\n11\nExamples 1.8 Here are two example proofs which combine the rule MT\nwith either ¬¬e or ¬¬i:\n1\n¬p →q\npremise\n2\n¬q\npremise\n3\n¬¬p\nMT 1, 2\n4\np\n¬¬e 3\nproves that the sequent ¬p →q, ¬q ⊢p is valid; and\n1\np →¬q\npremise\n2\nq\npremise\n3\n¬¬q\n¬¬i 2\n4\n¬p\nMT 1, 3\nshows the validity of the sequent p →¬q, q ⊢¬p.\nNote that the order of applying double negation rules and MT is diﬀerent\nin these examples; this order is driven by the structure of the particular\nsequent whose validity one is trying to show.\nThe rule implies introduction\nThe rule MT made it possible for us to\nshow that p →q, ¬q ⊢¬p is valid. But the validity of the sequent p →q ⊢\n¬q →¬p seems just as plausible. That sequent is, in a certain sense, saying\nthe same thing. Yet, so far we have no rule which builds implications that\ndo not already occur as premises in our proofs. The mechanics of such a rule\nare more involved than what we have seen so far. So let us proceed with quantiﬁcation. Now we want to provide formal proofs for some of the most\ncommonly used quantiﬁer equivalences. Quite a few of them involve several\nquantiﬁcations over more than just one variable. Thus, this topic is also\ngood practice for using the proof rules for quantiﬁers in a nested fashion.\nFor example, the formula ∀x ∀y φ should be equivalent to ∀y ∀x φ since\nboth say that φ should hold for all values of x and y. What about (∀x φ) ∧\n(∀x ψ) versus ∀x (φ ∧ψ)? A moment’s thought reveals that they should have\nthe same meaning as well. But what if the second conjunct does not start\nwith ∀x? So what if we are looking at (∀x φ) ∧ψ in general and want to\ncompare it with ∀x (φ ∧ψ)? Here we need to be careful, since x might be\nfree in ψ and would then become bound in the formula ∀x (φ ∧ψ).\nExample 2.12 We may specify ‘Not all birds can ﬂy.’ as ¬∀x (B(x) →\nF(x)) or as ∃x (B(x) ∧¬F(x)). The former formal speciﬁcation is closer\nto the structure of the English speciﬁcation, but the latter is logically equiv-\nalent to the former. Quantiﬁer equivalences help us in establishing that\nspeciﬁcations that ‘look’ diﬀerent are really saying the same thing.\nHere are some quantiﬁer equivalences which you should become familiar\nwith. As in Chapter 1, we write φ1 ⊣⊢φ2 as an abbreviation for the validity\nof φ1 ⊢φ2 and φ2 ⊢φ1.\nTheorem 2.13 Let φ and ψ be formulas of predicate logic. Then we have\nthe following equivalences:\n1.\n(a) ¬∀x φ ⊣⊢∃x ¬φ\n(b) ¬∃x φ ⊣⊢∀x ¬φ.\n2.\nAssuming that x is not free in ψ:\n118\n2 Predicate logic\n(a) ∀x φ ∧ψ ⊣⊢∀x (φ ∧ψ)3\n(b) ∀x φ ∨ψ ⊣⊢∀x (φ ∨ψ)\n(c) ∃x φ ∧ψ ⊣⊢∃x (φ ∧ψ)\n(d) ∃x φ ∨ψ ⊣⊢∃x (φ ∨ψ)\n(e) ∀x (ψ →φ) ⊣⊢ψ →∀x φ\n(f) ∃x (φ →ψ) ⊣⊢∀x φ →ψ\n(g) ∀x (φ →ψ) ⊣⊢∃x φ →ψ\n(h) ∃x (ψ →φ) ⊣⊢ψ →∃x φ.\n3.\n(a) ∀x φ ∧∀x ψ ⊣⊢∀x (φ ∧ψ)\n(b) ∃x φ ∨∃x ψ ⊣⊢∃x (φ ∨ψ).\n4.\n(a) ∀x ∀y φ ⊣⊢∀y ∀x φ\n(b) ∃x ∃y φ ⊣⊢∃y ∃x φ.\nPROOF: We will prove most of these sequents; the proofs for the remaining\nones are straightforward adaptations and are left as exercises. Recall that\nand necessary requirements for any sane concept of (extensional) equality.\nWe leave the topic of equality for now to move on to the proof rules for\nquantiﬁers.\nThe proof rules for universal quantification\nThe rule for eliminat-\ning ∀is the following:\n∀x φ\nφ[t/x]\n∀x e.\nIt says: If ∀x φ is true, then you could replace the x in φ by any term t\n(given, as usual, the side condition that t be free for x in φ) and conclude\nthat φ[t/x] is true as well. The intuitive soundness of this rule is self-evident.\nRecall that φ[t/x] is obtained by replacing all free occurrences of x in φ\nby t. You may think of the term t as a more concrete instance of x. Since φ\nis assumed to be true for all x, that should also be the case for any term t.\nExample 2.11 To see the necessity of the proviso that t be free for x in\nφ, consider the case that φ is ∃y (x < y) and the term to be substituted\nfor x is y. Let’s suppose we are reasoning about numbers with the usual\n‘smaller than’ relation. The statement ∀x φ then says that for all numbers\nn there is some bigger number m, which is indeed true of integers or real\nnumbers. However, φ[y/x] is the formula ∃y (y < y) saying that there is a\nnumber which is bigger than itself. This is wrong; and we must not allow a\nproof rule which derives semantically wrong things from semantically valid\n110\n2 Predicate logic\nones. Clearly, what went wrong was that y became bound in the process of\nsubstitution; y is not free for x in φ. Thus, in going from ∀x φ to φ[t/x],\nwe have to enforce the side condition that t be free for x in φ: use a fresh\nvariable for y to change φ to, say, ∃z (x < z) and then apply [y/x] to that\nformula, rendering ∃z (y < z).\nThe rule ∀x i is a bit more complicated. It employs a proof box similar\nto those we have already seen in natural deduction for propositional logic,\nbut this time the box is to stipulate the scope of the ‘dummy variable’ x0\nrather than the scope of an assumption. The rule ∀x i is written\nx0\n...\nφ[x0/x]\n∀x φ\n∀x i.\nVerify that these sequents express the argument above in a symbolic form.\nPredicate logic extends propositional logic not only with quantiﬁers but\nwith one more concept, that of function symbols. Consider the declarative\nsentence\nEvery child is younger than its mother.\n2.1 The need for a richer language\n97\nUsing predicates, we could express this sentence as\n∀x ∀y (C(x) ∧M(y, x) →Y (x, y))\nwhere C(x) means that x is a child, M(x, y) means that x is y’s mother\nand Y (x, y) means that x is younger than y. (Note that we actually used\nM(y, x) (y is x’s mother), not M(x, y).) As we have coded it, the sentence\nsays that, for all children x and any mother y of theirs, x is younger than y.\nIt is not very elegant to say ‘any of x’s mothers’, since we know that every\nindividual has one and only one mother1. The inelegance of coding ‘mother’\nas a predicate is even more apparent if we consider the sentence\nAndy and Paul have the same maternal grandmother.\nwhich, using ‘variables’ a and p for Andy and Paul and a binary predicate\nM for mother as before, becomes\n∀x ∀y ∀u ∀v (M(x, y) ∧M(y, a) ∧M(u, v) ∧M(v, p) →x = u).\nThis formula says that, if y and v are Andy’s and Paul’s mothers, respec-\ntively, and x and u are their mothers (i.e. Andy’s and Paul’s maternal grand-\nmothers, respectively), then x and u are the same person. Notice that we\nused a special predicate in predicate logic, equality; it is a binary predicate,\ni.e. it takes two arguments, and is written =. Unlike other predicates, it is\nusually written in between its arguments rather than before them; that is,\nwe write x = y instead of = (x, y) to say that x and y are equal.\nThe function symbols of predicate logic give us a way of avoiding this\nugly encoding, for they allow us to represent y’s mother in a more direct\nway. Instead of writing M(x, y) to mean that x is y’s mother, we simply\nwrite m(y) to mean y’s mother. The symbol m is a function symbol: it takes\n(a) ∃x.(x′ ↔(y + y′ · x))\n(b) ∀x.(x′ ↔(y + y′ · x))\n(c) ∃x′.(x′ ↔(y + y′ · x))\n(d) ∀x′.(x′ ↔(y + y′ · x)).\n5. Let ρ be a valuation with ρ(x′\n1) = 1 and ρ(x′\n2) = 0. Determine whether ρ ⊨f\nholds for the following:\n(a) x1[ˆx := ˆx′]\n(b) (x1 + x2)[ˆx := ˆx′]\n(c) (x1 · x2)[ˆx := ˆx′].\n6. Evaluate ρ ⊨(∃x1.(x1 + x2))[ˆx := ˆx′] and explain how the valuation ρ changes\nin that process. In particular, [ˆx := ˆx′] replaces xi by x′\ni, but why does this not\ninterfere with the binding quantiﬁer ∃x1?\n410\n6 Binary decision diagrams\n7. (a) How would you deﬁne the notion of semantic entailment for the relational\nmu-calculus?\n(b) Deﬁne formally when two formulas of the relational mu-calculus are seman-\ntically equivalent.\nExercises 6.15\n1. Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)\nholds, where ρ is\n(a) (x1, x2) ⇒(1, 0)\n(b) (x1, x2) ⇒(0, 1)\n(c) (x1, x2) ⇒(0, 0).\n2. Let S be {s0, s1}, with s0 →s0, s0 →s1 and s1 →s0 as possible transitions\nand L(s0) = {x1} and L(s1) = ∅. Compute the boolean function f EX (EX ¬x1).\n3. Equations (6.17) (page 395), (6.19) and (6.20) deﬁne f EF φ, f AF φ and f EG φ.\nWrite down a similar equation to deﬁne f AG φ.\n4. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately.\n5. Mimic the example checks on page 396 for the connective AU: consider the\nmodel of Figure 6.24 (page 384). Since [[E[(x1 ∨x2) U (¬x1 ∧¬x2)]]] equals the\nentire state set {s0, s1, s2}, your coding of f E[x1∨x2U¬x1∧¬x2] is correct if it\ncomputes 1 for all bit vectors diﬀerent from (1, 1).\n(a) Verify that your coding is indeed correct.\n(b) Find a boolean formula without ﬁxed points which is semantically equiva-\nlent to f E[(x1∨x2)U(¬x1∧¬x2)].\n6. (a) Use (6.20) on page 395 to compute f EG ¬x1 for the model in Figure 6.24.\n(b) Show that f EG ¬x1 faithfully models the set of all states which satisfy\nEG ¬x1.\n7. In the grammar (6.10) for the relational mu-calculus on page 390, it was stated\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nx\ny\nS\nQ\n∧\nFigure 2.4. A parse tree for which a substitution has dire consequences.\n2.3 Proof theory of predicate logic\n2.3.1 Natural deduction rules\nProofs in the natural deduction calculus for predicate logic are similar to\nthose for propositional logic in Chapter 1, except that we have new proof\nrules for dealing with the quantiﬁers and with the equality symbol. Strictly\nspeaking, we are overloading the previously established proof rules for the\npropositional connectives ∧, ∨etc. That simply means that any proof rule\nof Chapter 1 is still valid for logical formulas of predicate logic (we origi-\nnally deﬁned those rules for logical formulas of propositional logic). As in\nthe natural deduction calculus for propositional logic, the additional rules\nfor the quantiﬁers and equality will come in two ﬂavours: introduction and\nelimination rules.\nThe proof rules for equality\nFirst, let us state the proof rules for\nequality. Here equality does not mean syntactic, or intensional, equality,\nbut equality in terms of computation results. In either of these senses, any\nterm t has to be equal to itself. This is expressed by the introduction rule\nfor equality:\nt = t\n=i\n(2.5)\nwhich is an axiom (as it does not depend on any premises). Notice that it\n108\n2 Predicate logic\nmay be invoked only if t is a term, our language doesn’t permit us to talk\nabout equality between formulas.\nThis rule is quite evidently sound, but it is not very useful on its own.\nWhat we need is a principle that allows us to substitute equals for equals\nrepeatedly. For example, suppose that y ∗(w + 2) equals y ∗w + y ∗2; then\nit certainly must be the case that z ≥y ∗(w + 2) implies z ≥y ∗w + y ∗2\nand vice versa. We may now express this substitution principle as the rule\n=e:\nt1 = t2\nφ[t1/x]\nφ[t2/x]\n=e.\nNote that t1 and t2 have to be free for x in φ, whenever we want to apply\nthe rule =e; this is an example of a side condition of a proof rule.\nConvention 2.10 Throughout this section, when we write a substitution\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\n2(φ ∧ψ) ≡2φ ∧2ψ and 3(φ ∨ψ) ≡3φ ∨3ψ.\nThese equivalences correspond closely to the quantiﬁer equivalences dis-\ncussed in Section 2.3.2. It is also not surprising to ﬁnd that 2 does not\ndistribute over ∨and 3 does not distribute over ∧, i.e. we do not have equiv-\nalences between 2(φ ∨ψ) and 2φ ∨2ψ, or between 3(φ ∧ψ) and 3φ ∧3ψ.\nFor example, in the fourth item of Example 5.6 we had x5 ⊩2(p ∨q) and\nx5 ̸⊩2p ∨2q.\nNote that 2⊤is equivalent to ⊤, but not to 3⊤, as we saw earlier.\nSimilarly, 3⊥≡⊥but they are not equivalent to 2⊥.\nAnother equivalence is 3⊤≡2p →3p. For suppose x ⊩3⊤– i.e. x has\nan accessible world, say y – and suppose x ⊩2p; then y ⊩p, so x ⊩3p.\nConversely, suppose x ⊩2p →3p; we must show it satisﬁes 3⊤. Let us\ndistinguish between the cases x ⊩2p and x ̸⊩2p; in the former, we get\nx ⊩3p from x ⊩2p →3p and so x must have an accessible world; and in\nthe latter, x must again have an accessible world in order to avoid satisfying\n2p. Either way, x has an accessible world, i.e. satisﬁes 3⊤. Naturally, this\nargument works for any formula φ, not just an atom p.\nValid formulas\nDeﬁnition 5.8 A formula φ of basic modal logic is said to be valid if it is\ntrue in every world of every model, i.e. iﬀ⊨φ holds.\nAny propositional tautology is a valid formula and so is any substitution\ninstance of it. A substitution instance of a formula is the result of uniformly\nsubstituting the atoms of the formula by other formulas as done in (5.2).\nFor example, since p ∨¬p is a tautology, performing the substitution p \u000e→\n2p ∧(q →p) gives us a valid formula (2p ∧(q →p)) ∨¬(2p ∧(q →p)).\nAs we may expect from equivalences above, these formulas are valid:\n¬2φ ↔3¬φ\n2(φ ∧ψ) ↔2φ ∧2ψ\n(5.3)\n3(φ ∨ψ) ↔3φ ∨3ψ.\nTo prove that the ﬁrst of these is valid, we reason as follows. Suppose x is\na world in a model M = (W, R, L). We want to show x ⊩¬2φ ↔3¬φ, i.e.\nthat x ⊩¬2φ iﬀx ⊩3¬φ. Well, using Deﬁnition 5.4,\n5.2 Basic modal logic\n315\nb\nc\nd\na\ne\np, q\np, q\nq\np\nFigure 5.5. Another Kripke model.\nx ⊩¬2φ 9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nφ1, φ2, . . . , φn ⊨ψ.\nThe latter expresses that, given any such model in which all φ1, φ2, . . . , φn\nhold, it is the case that ψ holds in that model as well. In that case, one\nalso says that ψ is semantically entailed by φ1, φ2, . . . , φn. Although this\ndeﬁnition of semantic entailment closely matches the one for propositional\nlogic in Deﬁnition 1.34, the process of evaluating a predicate formula diﬀers\nfrom the computation of truth values for propositional logic in the treatment\nof predicates (and functions). We discuss it in detail in Section 2.4.\nIt is outside the scope of this book to show that the natural deduction\ncalculus for predicate logic is sound and complete with respect to semantic\nentailment; but it is indeed the case that\nφ1, φ2, . . . , φn ⊢ψ\niﬀ\nφ1, φ2, . . . , φn ⊨ψ\nfor formulas of the predicate calculus. The ﬁrst proof of this was done by\nthe mathematician K. G¨odel.\nWhat kind of reasoning must predicate logic be able to support? To get\na feel for that, let us consider the following argument:\nNo books are gaseous. Dictionaries are books. Therefore, no dictio-\nnary is gaseous.\nThe predicates we choose are\nB(x) :\nx is a book\nG(x) :\nx is gaseous\nD(x) :\nx is a dictionary.\nEvidently, we need to build a proof theory and semantics that allow us to\nderive the validity and semantic entailment, respectively, of\n¬∃x (B(x) ∧G(x)), ∀x (D(x) →B(x)) ⊢¬∃x (D(x) ∧G(x))\n¬∃x (B(x) ∧G(x)), ∀x (D(x) →B(x)) ⊨¬∃x (D(x) ∧G(x)).\nVerify that these sequents express the argument above in a symbolic form.\nPredicate logic extends propositional logic not only with quantiﬁers but\nwith one more concept, that of function symbols. Consider the declarative\nsentence\nEvery child is younger than its mother.\nHowever, we can sometimes reason that certain semantic entailments are\nvalid. We do this by providing an argument that does not depend on the\nactual model at hand. Of course, this works only for a very limited number\nof cases. The most prominent ones are the quantiﬁer equivalences which we\nalready encountered in the section on natural deduction. Let us look at a\ncouple of examples of semantic entailment.\nExample 2.21 The justiﬁcation of the semantic entailment\n∀x (P(x) →Q(x)) ⊨∀x P(x) →∀x Q(x)\nis as follows. Let M be a model satisfying ∀x (P(x) →Q(x)). We need to\nshow that M satisﬁes ∀x P(x) →∀x Q(x) as well. On inspecting the deﬁni-\ntion of M ⊨ψ1 →ψ2, we see that we are done if not every element of our\nmodel satisﬁes P. Otherwise, every element does satisfy P. But since M\nsatisﬁes ∀x (P(x) →Q(x)), the latter fact forces every element of our model\nto satisfy Q as well. By combining these two cases (i.e. either all elements of\nM satisfy P, or not) we have shown that M satisﬁes ∀x P(x) →∀x Q(x).\nWhat about the converse of the above? Is\n∀x P(x) →∀x Q(x) ⊨∀x (P(x) →Q(x))\nvalid as well? Hardly! Suppose that M′ is a model satisfying ∀x P(x) →\n∀x Q(x). If A′ is its underlying set and P M′ and QM′ are the corresponding\ninterpretations of P and Q, then M′ ⊨∀x P(x) →∀x Q(x) simply says that,\nif P M′ equals A′, then QM′ must equal A′ as well. However, if P M′ does not\nequal A′, then this implication is vacuously true (remember that F →· = T\nno matter what · actually is). In this case we do not get any additional\nconstraints on our model M′. After these observations, it is now easy to\nconstruct a counter-example model. Let A′ def\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\nthe truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nany other variable y to l(y).\nFinally, we are able to give a semantics to formulas of predicate logic. For\npropositional logic, we did this by computing a truth value. Clearly, it suﬃces\nto know in which cases this value is T.\n128\n2 Predicate logic\nDeﬁnition 2.18 Given a model M for a pair (F, P) and given an environ-\nment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula\nφ over the pair (F, P) and look-up table l by structural induction on φ. If\nM ⊨l φ holds, we say that φ computes to T in the model M with respect to\nthe environment l.\nP:\nIf φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, t2, . . . , tn in\nour set A by replacing all variables with their values according to l. In this way\nwe compute concrete values a1, a2, . . . , an of A for each of these terms, where\nwe interpret any function symbol f ∈F by f M. Now M ⊨l P(t1, t2, . . . , tn)\nholds iﬀ(a1, a2, . . . , an) is in the set P M.\n∀x:\nThe relation M ⊨l ∀x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for all a ∈A.\n∃x:\nDually, M ⊨l ∃x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for some a ∈A.\n¬:\nThe relation M ⊨l ¬ψ holds iﬀit is not the case that M ⊨l ψ holds.\n∨:\nThe relation M ⊨l ψ1 ∨ψ2 holds iﬀM ⊨l ψ1 or M ⊨l ψ2 holds.\n∧:\nThe relation M ⊨l ψ1 ∧ψ2 holds iﬀM ⊨l ψ1 and M ⊨l ψ2 hold.\n→:\nThe relation M ⊨l ψ1 →ψ2 holds iﬀM ⊨l ψ2 holds whenever M ⊨l ψ1 holds.\nWe sometimes write M ̸⊨l φ to denote that M ⊨l φ does not hold.\nThere is a straightforward inductive argument on the height of the parse\ntree of a formula which says that M ⊨l φ holds iﬀM ⊨l′ φ holds, whenever\nl and l′ are two environments which are identical on the set of free variables\nof φ. In particular, if φ has no free variables at all, we then call φ a sentence;\nwe conclude that M ⊨l φ holds, or does not hold, regardless of the choice of\nl. Thus, for sentences φ we often elide l and write M ⊨φ since the choice of\nan environment l is then irrelevant.\nExample 2.19 Let us illustrate the deﬁnitions above by means of an-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nsuggesting that q is a logical consequence of p. We write p →q for that3. We\ncall p the assumption of p →q and q its conclusion.\nOf course, we are entitled to use these rules of constructing propositions\nrepeatedly. For example, we are now in a position to form the proposition\np ∧q →¬r ∨q\nwhich means that ‘if p and q then not r or q’. You might have noticed a\npotential ambiguity in this reading. One could have argued that this sentence\nhas the structure ‘p is the case and if q then . . . ’ A computer would require\nthe insertion of brackets, as in\n(p ∧q) →((¬r) ∨q)\n2 Its meaning should not be confused with the often implicit meaning of or in natural language\ndiscourse as either . . . or. In this text or always means at least one of them and should not be\nconfounded with exclusive or which states that exactly one of the two statements holds.\n3 The natural language meaning of ‘if . . . then . . . ’ often implicitly assumes a causal role of\nthe assumption somehow enabling its conclusion. The logical meaning of implication is a bit\ndiﬀerent, though, in the sense that it states the preservation of truth which might happen\nwithout any causal relationship. For example, ‘If all birds can ﬂy, then Bob Dole was never\npresident of the United States of America.’ is a true statement, but there is no known causal\nconnection between the ﬂying skills of penguins and eﬀective campaigning.\n1.2 Natural deduction\n5\nto disambiguate this assertion. However, we humans get annoyed by a pro-\nliferation of such brackets which is why we adopt certain conventions about\nthe binding priorities of these symbols.\nConvention 1.3 ¬ binds more tightly than ∨and ∧, and the latter two\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly, an interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nto be {(a, a), (b, b), (c, c)}. Hence the semantics of equality is easy, for it is\nalways modelled extensionally.\n2.5 Undecidability of predicate logic\nWe continue our introduction to predicate logic with some negative results.\nGiven a formula φ in propositional logic we can, at least in principle, de-\ntermine whether ⊨φ holds: if φ has n propositional atoms, then the truth\ntable of φ contains 2n lines; and ⊨φ holds if, and only if, the column for φ\n(of length 2n) contains only T entries.\nThe bad news is that such a mechanical procedure, working for all for-\nmulas φ, cannot be provided in predicate logic. We will give a formal proof\nof this negative result, though we rely on an informal (yet intuitive) notion\nof computability.\nThe problem of determining whether a predicate logic formula is valid is\nknown as a decision problem. A solution to a decision problem is a program\n(written in Java, C, or any other common language) that takes problem\ninstances as input and always terminates, producing a correct ‘yes’ or ‘no’\noutput. In the case of the decision problem for predicate logic, the input to\nthe program is an arbitrary formula φ of predicate logic and the program\n132\n2 Predicate logic\nis correct if it produces ‘yes’ whenever the input formula is valid and ‘no’\nwhenever it is not. Note that the program which solves a decision problem\nmust terminate for all well-formed input: a program which goes on thinking\nabout it for ever is not allowed. The decision problem at hand is this:\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\nouter product, whereas the interleaving model has an outer sum. The latter,\nif used in ∃ˆx′.f (‘for some next state’), can be optimised since sums distribute\nover existential quantiﬁcation; in Chapter 2 this was the equivalence ∃x.(φ ∨\nψ) ≡∃x.φ ∨∃x.ψ. Thus, global states reachable in one step are the ‘union’\nof all the states reachable in one step in the local components; compare the\nformulas in (6.8) and (6.9) with (6.6).\n6.4 A relational mu-calculus\nWe saw in Section 3.7 that evaluating the set of states satisfying a CTL for-\nmula in a model may involve the computation of a ﬁxed point of an operator.\nFor example, [[EF φ]] is the least ﬁxed point of the operator F : P(S) →P(S)\ngiven by F(X) = [[φ]] ∪pre∃(X).\nIn this section, we introduce a syntax for referring to ﬁxed points in the\ncontext of boolean formulas. Fixed-point invariants frequently occur in all\nsorts of applications (for example, the common-knowledge operator CG in\nChapter 5), so it makes sense to have an intermediate language for express-\ning such invariants syntactically. This language also provides a formalism\nfor describing interactions and dependences of such invariants. We will see\nshortly that symbolic model checking in the presence of simple fairness con-\nstraints exhibits such more complex relationships between invariants.\n6.4.1 Syntax and semantics\nDeﬁnition 6.14 The formulas of the relational mu-calculus are given by\nthe grammar\nv ::= x | Z\nf ::= 0 | 1 | v | f | f1 + f2 | f1 · f2 | f1 ⊕f2 |\n∃x.f | ∀x.f | µZ.f | νZ.f | f[ˆx := ˆx′]\n(6.10)\nwhere x and Z are boolean variables, and ˆx is a tuple of variables. In the\nformulas µZ.f and νZ.f, any occurrence of Z in f is required to fall within an\neven number of complementation symbols ¯; such an f is said to be formally\nmonotone in Z. (In exercise 7 on page 410 we consider what happens if we\ndo not require formal monotonicity.)\n6.4 A relational mu-calculus\n391\nConvention 6.15 The binding priorities for the grammar in (6.10) are that\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nand necessary requirements for any sane concept of (extensional) equality.\nWe leave the topic of equality for now to move on to the proof rules for\nquantiﬁers.\nThe proof rules for universal quantification\nThe rule for eliminat-\ning ∀is the following:\n∀x φ\nφ[t/x]\n∀x e.\nIt says: If ∀x φ is true, then you could replace the x in φ by any term t\n(given, as usual, the side condition that t be free for x in φ) and conclude\nthat φ[t/x] is true as well. The intuitive soundness of this rule is self-evident.\nRecall that φ[t/x] is obtained by replacing all free occurrences of x in φ\nby t. You may think of the term t as a more concrete instance of x. Since φ\nis assumed to be true for all x, that should also be the case for any term t.\nExample 2.11 To see the necessity of the proviso that t be free for x in\nφ, consider the case that φ is ∃y (x < y) and the term to be substituted\nfor x is y. Let’s suppose we are reasoning about numbers with the usual\n‘smaller than’ relation. The statement ∀x φ then says that for all numbers\nn there is some bigger number m, which is indeed true of integers or real\nnumbers. However, φ[y/x] is the formula ∃y (y < y) saying that there is a\nnumber which is bigger than itself. This is wrong; and we must not allow a\nproof rule which derives semantically wrong things from semantically valid\n110\n2 Predicate logic\nones. Clearly, what went wrong was that y became bound in the process of\nsubstitution; y is not free for x in φ. Thus, in going from ∀x φ to φ[t/x],\nwe have to enforce the side condition that t be free for x in φ: use a fresh\nvariable for y to change φ to, say, ∃z (x < z) and then apply [y/x] to that\nformula, rendering ∃z (y < z).\nThe rule ∀x i is a bit more complicated. It employs a proof box similar\nto those we have already seen in natural deduction for propositional logic,\nbut this time the box is to stipulate the scope of the ‘dummy variable’ x0\nrather than the scope of an assumption. The rule ∀x i is written\nx0\n...\nφ[x0/x]\n∀x φ\n∀x i.\nx\ny\nS\nQ\n∧\nFigure 2.4. A parse tree for which a substitution has dire consequences.\n2.3 Proof theory of predicate logic\n2.3.1 Natural deduction rules\nProofs in the natural deduction calculus for predicate logic are similar to\nthose for propositional logic in Chapter 1, except that we have new proof\nrules for dealing with the quantiﬁers and with the equality symbol. Strictly\nspeaking, we are overloading the previously established proof rules for the\npropositional connectives ∧, ∨etc. That simply means that any proof rule\nof Chapter 1 is still valid for logical formulas of predicate logic (we origi-\nnally deﬁned those rules for logical formulas of propositional logic). As in\nthe natural deduction calculus for propositional logic, the additional rules\nfor the quantiﬁers and equality will come in two ﬂavours: introduction and\nelimination rules.\nThe proof rules for equality\nFirst, let us state the proof rules for\nequality. Here equality does not mean syntactic, or intensional, equality,\nbut equality in terms of computation results. In either of these senses, any\nterm t has to be equal to itself. This is expressed by the introduction rule\nfor equality:\nt = t\n=i\n(2.5)\nwhich is an axiom (as it does not depend on any premises). Notice that it\n108\n2 Predicate logic\nmay be invoked only if t is a term, our language doesn’t permit us to talk\nabout equality between formulas.\nThis rule is quite evidently sound, but it is not very useful on its own.\nWhat we need is a principle that allows us to substitute equals for equals\nrepeatedly. For example, suppose that y ∗(w + 2) equals y ∗w + y ∗2; then\nit certainly must be the case that z ≥y ∗(w + 2) implies z ≥y ∗w + y ∗2\nand vice versa. We may now express this substitution principle as the rule\n=e:\nt1 = t2\nφ[t1/x]\nφ[t2/x]\n=e.\nNote that t1 and t2 have to be free for x in φ, whenever we want to apply\nthe rule =e; this is an example of a side condition of a proof rule.\nConvention 2.10 Throughout this section, when we write a substitution\nhow SMV could use fairness assumptions which were not expressible entirely\n5 Since we have added the variable u, there are actually six states; they all satisfy the formula.\n6.4 A relational mu-calculus\n397\nwithin CTL and its semantics. The addition of fairness could be achieved\nby restricting the ordinary CTL semantics to fair computation paths, or fair\nstates. Formally, we were given a set C = {ψ1, ψ2, . . . , ψk} of CTL formulas,\ncalled the fairness constraints, and we wanted to check whether s ⊨φ holds\nfor a CTL formula φ and all initial states s, with the additional fairness\nconstraints in C. Since ⊥, ¬, ∧, EX, EU and EG form an adequate set of\nconnectives for CTL, we may restrict this discussion to only these operators.\nClearly, the propositional connectives won’t change their meaning with the\naddition of fairness constraints. Therefore, it suﬃces to provide symbolic\ncodings for the fair connectives ECX, ECU and ECG from Chapter 3. The\nkey is to represent the set of fair states symbolically as a boolean formula\nfair deﬁned as\nfair\ndef\n= fECG⊤\n(6.22)\nwhich uses the (yet to be deﬁned) function fECG φ with ⊤as an instance.\nAssuming that the coding of fECG φ is correct, we see that fair computes 1\nin a state s if, and only if, there is a fair path with respect to C that begins\nin s. We say that such an s is a fair state.\nAs for ECX, note that s ⊨ECXφ if, and only if, there is some next state s′\nwith s →s′ and s′ ⊨φ such that s′ is a fair state. This immediately renders\nfECXφ def\n= ∃ˆx′.(f→· (fφ · fair)[ˆx := ˆx′]).\n(6.23)\nSimilarly, we obtain\nfEC[φ1Uφ2] def\n= µZ. (fφ2 · fair + fφ1 · ∃ˆx′. (f→· Z[ˆx := ˆx′])).\n(6.24)\nThis leaves us with the task of coding fECG φ. It is this last connective\nwhich reveals the complexity of fairness checks at work. Because the coding\nof fECG φ is rather complex, we proceed in steps. It is convenient to have the\nEX and EU functionality also at the level of boolean formulas directly. For\nreplaced by every student’s name in turn. Similarly, when trying to codify\na sentence having to do with the execution of a program, it would be rather\nlaborious to have to write down every state of the computer. Therefore,\nwe employ the concept of a variable. Variables are written u, v, w, x, y, z, . . .\nor x1, y3, u5, . . . and can be thought of as place holders for concrete values\n(like a student, or a program state). Using variables, we can now specify the\nmeanings of S, I and Y more formally:\nS(x) :\nx is a student\nI(x) :\nx is an instructor\nY (x, y) :\nx is younger than y.\nNote that the names of the variables are not important, provided that we\nuse them consistently. We can state the intended meaning of I by writing\nI(y) :\ny is an instructor\nor, equivalently, by writing\nI(z) :\nz is an instructor.\nVariables are mere place holders for objects. The availability of variables is\nstill not suﬃcient for capturing the essence of the example sentence above.\nWe need to convey the meaning of ‘Every student x is younger than some\ninstructor y.’ This is where we need to introduce quantiﬁers ∀(read: ‘for\nall’) and ∃(read: ‘there exists’ or ‘for some’) which always come attached\nto a variable, as in ∀x (‘for all x’) or in ∃z (‘there exists z’, or ‘there is some\nz’). Now we can write the example sentence in an entirely symbolic way as\n∀x (S(x) →(∃y (I(y) ∧Y (x, y)))).\n2.1 The need for a richer language\n95\nActually, this encoding is rather a paraphrase of the original sentence. In\nour example, the re-translation results in\nFor every x, if x is a student, then there is some y which is an\ninstructor such that x is younger than y.\nDiﬀerent predicates can have a diﬀerent number of arguments. The predi-\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ.\nThe equivalence of φ and ψ means that φ and ψ are semantically inter-\nchangeable. If φ is a subformula of some bigger formula χ, and ψ ≡φ, then\nwe can make the substitution of ψ for φ in χ without changing the meaning\nof χ. In propositional logic, we saw that ∧and ∨are duals of each other,\nmeaning that if you push a ¬ past a ∧, it becomes a ∨, and vice versa:\n¬(φ ∧ψ) ≡¬φ ∨¬ψ\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n(Because ∧and ∨are binary, pushing a negation downwards in the parse\ntree past one of them also has the eﬀect of duplicating that negation.)\n3.2 Linear-time temporal logic\n185\nSimilarly, F and G are duals of each other, and X is dual with itself:\n¬G φ ≡F ¬φ\n¬F φ ≡G ¬φ\n¬X φ ≡X ¬φ.\nAlso U and R are duals of each other:\n¬(φ U ψ) ≡¬φ R ¬ψ\n¬(φ R ψ) ≡¬φ U ¬ψ.\nWe should give formal proofs of these equivalences. But they are easy, so we\nleave them as an exercise to the reader. ‘Morally’ there ought to be a dual\nfor W, and you can invent one if you like. Work out what it might mean,\nand then pick a symbol based on the ﬁrst letter of the meaning. However, it\nmight not be very useful.\nIt’s also the case that F distributes over ∨and G over ∧, i.e.,\nF (φ ∨ψ) ≡F φ ∨F ψ\nG (φ ∧ψ) ≡G φ ∧G ψ.\nCompare this with the quantiﬁer equivalences in Section 2.3.2. But F does\nnot distribute over ∧. What this means is that there is a model with a\npath which distinguishes F (φ ∧ψ) and F φ ∧F ψ, for some φ, ψ. Take the\npath s0 →s1 →s0 →s1 →. . . from the system of Figure 3.3, for example;\nit satisﬁes F p ∧F r but it doesn’t satisfy F (p ∧r).\nHere are two more equivalences in LTL:\nF φ ≡⊤U φ\nG φ ≡⊥R φ.\nThe ﬁrst one exploits the fact that the clause for Until states two things: bols in the same formula, we arrive at fully-ﬂedged second-order logic, e.g.\n∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))).\n(2.15)\nWe have ∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))) iﬀ\nthere is some T such that for all U we have (MT )U ⊨∀x∀y (Q(x, y) →\nQ(y, x)) →∀u∀v (Q(u, v) →P(u, v)), the latter being a model check in ﬁrst-\norder logic.\nIf one wants to quantify over relations of relations, one gets third-order\nlogic etc. Higher-order logics require great care in their design. Typical re-\nsults such as completeness and compactness may quickly fail to hold. Even\nworse, a naive higher-order logic may be inconsistent at the meta-level. Re-\nlated problems were discovered in naive set theory, e.g. in the attempt to\ndeﬁne the ‘set’ A that contains as elements those sets X that do not contain\nthemselves as an element:\nA\ndef\n= {X | X ̸∈X}.\n(2.16)\nWe won’t study higher-order logics in this text, but remark that many the-\norem provers or deductive frameworks rely on higher-order logical frame-\nworks.\n2.7 Micromodels of software\nTwo of the central concepts developed so far are\nr model checking: given a formula φ of predicate logic and a matching model M\ndetermine whether M ⊨φ holds; and\nr semantic entailment: given a set of formulas Γ of predicate logic, is Γ ⊨φ valid?\n142\n2 Predicate logic\nHow can we put these concepts to use in the modelling and reasoning about\nsoftware? In the case of semantic entailment, Γ should contain all the re-\nquirements we impose on a software design and φ may be a property we\nthink should hold in any implementation that meets the requirements Γ.\nSemantic entailment therefore matches well with software speciﬁcation and\nvalidation; alas, it is undecidable in general. Since model checking is de-\ncidable, why not put all the requirements into a model M and then check\nM ⊨φ? The diﬃculty with this approach is that, by comitting to a particu-\nlar model M, we are comitting to a lot of detail which doesn’t form part of\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and\n∆is unsatisﬁable, since the ‘conjunction’ of all sentences in ∆says that\nthere is no path of length 0, no path of length 1, etc. from the node denoted\nby c to the node denoted by c′, but there is a ﬁnite path from c to c′ as\nφ[c/u][c′/v] is true.\n2.6 Expressiveness of predicate logic\n139\nHowever, every ﬁnite subset of ∆is satisﬁable since there are paths of any\nﬁnite length. Therefore, by the Compactness Theorem, ∆itself is satisﬁable.\nThis is a contradiction. Therefore, there cannot be such a formula φ.\n2\n2.6.1 Existential second-order logic\nIf predicate logic cannot express reachability in graphs, then what can, and\nat what cost? We seek an extension of predicate logic that can specify such\nimportant properties, rather than inventing an entirely new syntax, seman-\ntics and proof theory from scratch. This can be realized by applying quan-\ntiﬁers not only to variables, but also to predicate symbols. For a predicate\nsymbol P with n ≥1 arguments, consider formulas of the form\n∃P φ\n(2.11)\nwhere φ is a formula of predicate logic in which P occurs. Formulas of that\nform are the ones of existential second-order logic. An example of arity 2 is\n∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4)\n(2.12)\nwhere each Ci is a Horn clause4\nC1\ndef\n= P(x, x)\nC2\ndef\n= P(x, y) ∧P(y, z) →P(x, z)\nC3\ndef\n= P(u, v) →⊥\nC4\ndef\n= R(x, y) →P(x, y).\nIf we think of R and P as two transition relations on a set of states, then\nC4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive, C2\nspeciﬁes that P is transitive, and C3 ensures that there is no P-path from\nthe node associated to u to the node associated to v.\nGiven a model M with interpretations for all function and predicate sym-\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\nWe conclude this case study by pointing out limitations of Alloy and its\nanalyzer. In order to be able to use a SAT solver for propositional logic\nas an analysis engine, we can only check or run formulas of existential or\nuniversal second-order logic in the bodies of assertions or in the bodies of\nfun-statements (if they are wrapped in existential quantiﬁers for all param-\neters). For example, we cannot even check whether there is an instance of\nAddComponent such that for the resulting PDS a certain scheduling policy is\nimpossible. For less explicit reasons it also seems unlikely that we can check\nin Alloy that every coherent set of components is realizable as P.components\nfor some PDS P. This deﬁciency is due to the inherent complexity of such\nproblems and theorem provers may have to be used if such properties need\nto be guaranteed. On the other hand, the expressiveness of Alloy allows for\nthe rapid prototyping of models and the exploration of simulations and pos-\nsible counterexamples which should enhance once understanding of a design\nand so improve that design’s reliability.\n2.8 Exercises\n157\n2.8 Exercises\nExercises 2.1\n1.\n*\nUse the predicates\nA(x, y) :\nx admires y\nB(x, y) :\nx attended y\nP(x) :\nx is a professor\nS(x) :\nx is a student\nL(x) :\nx is a lecture\nand the nullary function symbol (constant)\nm :\nMary\nto translate the following into predicate logic:\n(a) Mary admires every professor.\n(The answer is not ∀x A(m, P(x)).)\n(b) Some professor admires Mary.\n(c) Mary admires herself.\n(d) No student attended every lecture.\n(e) No lecture was attended by every student.\n(f) No lecture was attended by any student.\n2. Use the predicate speciﬁcations\nB(x, y) :\nx beats y\nF(x) :\nx is an (American) football team\nQ(x, y) :\nx is quarterback of y\nL(x, y) :\nx loses to y\nand the constant symbols\nc :\nWildcats\nj :\nJayhawks\nto translate the following into predicate logic.\n(a) Every football team has a quarterback.\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\n∀x (P(x) →R(x)), ∀x (Q(x) →R(x)) ⊢∃x (P(x) ∧Q(x))\n(c) (∀x P(x)) →L ⊢∀x (P(x) →L), where L has arity 0\n(d)\n*\n∀x ∃y S(x, y) ⊢∃y ∀x S(x, y)\n(e) ∃x P(x), ∃y Q(y) ⊢∃z (P(z) ∧Q(z)).\n(f)\n*\n∃x (¬P(x) ∧Q(x)) ⊢∀x (P(x) →Q(x))\n(g)\n*\n∃x (¬P(x) ∨¬Q(x)) ⊢∀x (P(x) ∨Q(x)).\n2. Assuming that ⊢is sound and complete for ⊨in ﬁrst-order logic, explain in detail\nwhy the undecidability of ⊨implies that satisﬁability, validity, and provability\nare all undecidable for that logic.\n3. To show the soundness of our natural deduction rules for predicate logic, it\nintuitively suﬃces to show that the conclusion of a proof rule is true provided\nthat all its premises are true. What additional complication arises due to the\npresence of variables and quantiﬁers? Can you precisely formalise the necessary\ninduction hypothesis for proving soundness?\nExercises 2.6\n1. In Example 2.23, page 136, does M ⊨l ∃P φ hold if l satisﬁes\n(a)\n*\nl(u) = s3 and l(v) = s1;\n(b) l(u) = s1 and l(v) = s3?\nJustify your answers.\n2. Prove that M ⊨l ∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4) holds iﬀstate l(v) is not reach-\nable from state l(u) in the model M, where the Ci are the ones of (2.12) on\npage 139.\n3. Does Theorem 2.26 from page 138 apply or remain valid if we allow φ to contain\nfunction symbols of any ﬁnite arity?\n4.\n*\nIn the directed graph of Figure 2.5 from page 137, how many paths are there\nthat witness the reachability of node s3 from s2?\n5. Let P and R be predicate symbols of arity 2. Write formulas of existential second-\norder logic of the form ∃P ψ that hold in all models of the form M = (A, RM)\niﬀ\n(a)\n*\nR contains a reﬂexive and symmetric relation;\n(b) R contains an equivalence relation\n(c) there is an R-path that visits each node of the graph exactly once – such a\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\norder logic of the form ∃P ψ that hold in all models of the form M = (A, RM)\niﬀ\n(a)\n*\nR contains a reﬂexive and symmetric relation;\n(b) R contains an equivalence relation\n(c) there is an R-path that visits each node of the graph exactly once – such a\npath is called Hamiltonian\n(d) R can be extended to an equivalence relation: there is some equivalence\nrelation T with RM ⊆T\n(e)\n*\nthe relation ‘there is an R-path of length 2’ is transitive.\n6.\n*\nShow informally that (2.16) on page 141 gives rise to Russell’s paradox: A has\nto be, and cannot be, an element of A.\n7. The second item in the proof of Theorem 2.28 (page 140) relies on the fact\nthat if a binary relation R is contained in a reﬂexive, transitive relation T of\n166\n2 Predicate logic\nthe same type, then T also contains the reﬂexive, transitive closure of R. Prove\nthis.\n8. For the model of Example 2.23 and Figure 2.5 (page 137), determine which model\nchecks hold and justify your answer:\n(a)\n*\n∃P (∀x∀y P(x, y) →¬P(y, x)) ∧(∀u∀v R(u, v) →P(v, u));\n(b) ∀P (∃x∃y∃z P(x, y) ∧P(y, z) ∧¬P(x, z)) →(∀u∀v R(u, v) →P(u, v)); and\n(c) ∀P (∀x ¬P(x, x)) ∨(∀u∀v R(u, v) →P(u, v)).\n9. Express the following statements about a binary relation R in predicate\nlogic, universal second-order logic, or existential second-order logic – if at all\npossible:\n(a) All symmetric, transitive relations either don’t contain R or are equivalence\nrelations.\n(b)\n*\nAll nodes are on at least one R-cycle.\n(c) There is a smallest relation containing R which is symmetric.\n(d) There is a smallest relation containing R which is reﬂexive.\n(e)\n*\nThe relation R is a maximal equivalence relation: R is an equivalence relation;\nand there is no relation contained in R that is an equivalence relation.\nExercises 2.7\n1. (a)\n*\nExplain why the model of Figure 2.11 (page 148) is a counterexample to\nOfLovers in the presence of the fact NoSelfLove.\n(b) Can you identify the set {a, b, c} from Example 2.19 (page 128) with the\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced bols in the same formula, we arrive at fully-ﬂedged second-order logic, e.g.\n∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))).\n(2.15)\nWe have ∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))) iﬀ\nthere is some T such that for all U we have (MT )U ⊨∀x∀y (Q(x, y) →\nQ(y, x)) →∀u∀v (Q(u, v) →P(u, v)), the latter being a model check in ﬁrst-\norder logic.\nIf one wants to quantify over relations of relations, one gets third-order\nlogic etc. Higher-order logics require great care in their design. Typical re-\nsults such as completeness and compactness may quickly fail to hold. Even\nworse, a naive higher-order logic may be inconsistent at the meta-level. Re-\nlated problems were discovered in naive set theory, e.g. in the attempt to\ndeﬁne the ‘set’ A that contains as elements those sets X that do not contain\nthemselves as an element:\nA\ndef\n= {X | X ̸∈X}.\n(2.16)\nWe won’t study higher-order logics in this text, but remark that many the-\norem provers or deductive frameworks rely on higher-order logical frame-\nworks.\n2.7 Micromodels of software\nTwo of the central concepts developed so far are\nr model checking: given a formula φ of predicate logic and a matching model M\ndetermine whether M ⊨φ holds; and\nr semantic entailment: given a set of formulas Γ of predicate logic, is Γ ⊨φ valid?\n142\n2 Predicate logic\nHow can we put these concepts to use in the modelling and reasoning about\nsoftware? In the case of semantic entailment, Γ should contain all the re-\nquirements we impose on a software design and φ may be a property we\nthink should hold in any implementation that meets the requirements Γ.\nSemantic entailment therefore matches well with software speciﬁcation and\nvalidation; alas, it is undecidable in general. Since model checking is de-\ncidable, why not put all the requirements into a model M and then check\nM ⊨φ? The diﬃculty with this approach is that, by comitting to a particu-\nlar model M, we are comitting to a lot of detail which doesn’t form part of\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\n5 In most object-oriented languages, e.g. Java, extends creates a new type. In Alloy 2.0 and 2.1, it\ncreates a subset of a type and not a new type as such, where the subset has additional structure\nand may need to satisfy additional constraints.\n170\n2 Predicate logic\ndetermine whether they can be expressed in ﬁrst-order logic, existential second-\norder logic or universal second-order logic.\n9. Recalling the comment on page 142 that Alloy combines model checking M ⊨φ\nand validity checking Γ ⊨φ, can you discuss to what extent this is so?\n2.9 Bibliographic notes\nMany design decisions have been taken in the development of predicate\nlogic in the form known today. The Greeks and the medievals had systems\nin which many of the examples and exercises in this book could be rep-\nresented, but nothing that we would recognise as predicate logic emerged\nuntil the work of Gottlob Frege in 1879, printed in [Fre03]. An account of\nthe contributions of the many other people involved in the development of\nlogic can be found in the ﬁrst few pages of W. Hodges’ chapter in [Hod83].\nThere are many books covering classical logic and its use in computer sci-\nence; we give a few incomplete pointers to the literature. The books [SA91],\n[vD89] and [Gal87] cover more theoretical applications than those in this\nbook, including type theory, logic programming, algebraic speciﬁcation and\nterm-rewriting systems. An approach focusing on automatic theorem prov-\ning is taken by [Fit96]. Books which study the mathematical aspects of\npredicate logic in greater detail, such as completeness of the proof systems\nand incompleteness of ﬁrst-order arithmetic, include [Ham78] and [Hod83].\nMost of these books present other proof systems besides natural deduction\nsuch as axiomatic systems and tableau systems. Although natural deduction\nhas the advantages of elegance and simplicity over axiomatic methods, there\nare few expositions of it in logic books aimed at a computer science audi-\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and\n∆is unsatisﬁable, since the ‘conjunction’ of all sentences in ∆says that\nthere is no path of length 0, no path of length 1, etc. from the node denoted\nby c to the node denoted by c′, but there is a ﬁnite path from c to c′ as\nφ[c/u][c′/v] is true.\n2.6 Expressiveness of predicate logic\n139\nHowever, every ﬁnite subset of ∆is satisﬁable since there are paths of any\nﬁnite length. Therefore, by the Compactness Theorem, ∆itself is satisﬁable.\nThis is a contradiction. Therefore, there cannot be such a formula φ.\n2\n2.6.1 Existential second-order logic\nIf predicate logic cannot express reachability in graphs, then what can, and\nat what cost? We seek an extension of predicate logic that can specify such\nimportant properties, rather than inventing an entirely new syntax, seman-\ntics and proof theory from scratch. This can be realized by applying quan-\ntiﬁers not only to variables, but also to predicate symbols. For a predicate\nsymbol P with n ≥1 arguments, consider formulas of the form\n∃P φ\n(2.11)\nwhere φ is a formula of predicate logic in which P occurs. Formulas of that\nform are the ones of existential second-order logic. An example of arity 2 is\n∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4)\n(2.12)\nwhere each Ci is a Horn clause4\nC1\ndef\n= P(x, x)\nC2\ndef\n= P(x, y) ∧P(y, z) →P(x, z)\nC3\ndef\n= P(u, v) →⊥\nC4\ndef\n= R(x, y) →P(x, y).\nIf we think of R and P as two transition relations on a set of states, then\nC4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive, C2\nspeciﬁes that P is transitive, and C3 ensures that there is no P-path from\nthe node associated to u to the node associated to v.\nGiven a model M with interpretations for all function and predicate sym-\nfunctional, 321\nlinear, 321\nreﬂexive, 140, 320, 324\nas formula, 109\nserial, 320, 353\nsymmetric, 320\nas formula, 109\ntotal, 321\ntransition, 178\ntransitive, 140, 320, 324\nas formula, 109\nrelational mu-calculus\nﬁxed-point operators, 392\nrequirement\ninformal, 258, 263, 288\nrequirements, 142\nrestriction, 374\nright-associative, 5\nroot of a parse tree, 135\nrule\nderived, 23\nhybrid, 10\nRussell’s paradox, 165\nsafety property, 187, 189, 207\nSAT solver\ncubic, 76\nforcing rules, 71\npermanent marks, 75\ntemporary marks, 74\nsatisfaction\nin a frame, 322\nin a frame for KT45n, 337\nsatisfaction relation\nfor relational mu-calculus, 391\nfor basic modal logic, 310\nfor KT45, 337\nfor LTL, 180\nfor partial correctness, 265\nfor predicate logic, 128\nfor relational mu-calculus, 391\nfor total correctness, 266\nsatisﬁability, 360\n3SAT, 406\ndeciding, 65\nof a propositional logic formula,\n85\nundecidability of predicate logic,\n135\nSCC\nfair, 232\nscheduler\nfair, 197\nscope\nof a dummy variable, 117\nof a variable, 103, 113\nof an assumption, 28, 113, 329\nsearch space, 113, 133\nsecond-order logic, 141\nsemantic entailment\nfor predicate logic, 141\nfor basic modal logic, 313\nfor KT4, 328\nfor normal modal logics, 326\nfor predicate logic, 96\nfor propositional logic, 46\nfor relational mu-calculus, 410\nsemantic equivalence, 39\nsemantics\nof µZ.f, 392\nof νZ.f, 393\nof basic modal logic, 310\nof boolean quantiﬁcation, 392\nof CTL, 211\nof EG, 239\nof equality, 131\nof predicate logic, 122\nof propositional logic, 38\nof relational mu-calculus, 391\nof Until, 181\nsentence\natomic, 4\ncomponents, 93\ndeclarative, 93\nin predicate logic, 128\nsequent, 5\ninvalid, 116\nShannon expansion, 374\nside condition, 108, 110\nSifakis, J., 254\nsmall scope hypothesis, 143\nSMV, 254\nmain program for ABP, 207\nmodule, 193\nreceiver, 205\nsender, 204\nfor channel, 206\ninstantiation, 193\nprocess, 389\nprogram\nexample, 192\nfor Mutex, 195\nspeciﬁcation, 192\nsoftware\nlife-cycle, 142\nmicromodel, 142\nreliability, 149\nrequirements, 142\nspeciﬁcation, 142\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nFloyd, R., 269\nfor-statement, 299\nforall-elimination, 109\nforall-introduction, 110\nformal\npath, 218\nformula\natomic, 175\nheight, 44, 86\nHorn, 65\nill-formed, 177\nimmediate subformula, 223\nof basic modal logic, 314\nof CTL, 208\natomic, 208\nill-formed, 209\nwell-formed, 209\nof LTL\nvalid, 251\nof predicate logic, 100\nof propositional logic, 33, 50\nwell-formed, 32, 33, 44\nof relational mu-calculus, 390\npositive, 328, 343, 348\nscheme, 312, 317\nK, 315\nin propositional logic, 312\ninstance, 312\nsubformula, 35\nframe, 322\nfree for x in φ, 106, 109\nFrege, G., 170\nfunction\nin predicate logic, 124\nmonotone, 240\na non-example, 240\nnullary, 99\nrecursive, 250\nSAT, 225, 227\ntermination, 253\nSATaf, 228\nSATag, 253\nSATeg, 252\nSATeu, 229\nSATex, 228\nsymbol, 96, 98, 157\nbinary, 98\ntranslate, 250\nfunction pre∀(X), 227\nfunction pre∃(X), 227, 385\nfunction pre∀(X), 385\nfunction SAT\ncorrectness, 240\nfuture\nexcludes the present, 249, 353\nincludes the present, 182, 249, 353\nwhether it includes the present, 318\nG-reachable, 338\nin k steps, 338\nG¨odel, K., 96\nGentzen, G., 91\nGlobal Assembly Cache, 149\ngrammar, 33\nclause, 269\nguided simulation, 155\nHalpern, J., 254\nhigher-order logic, 141\nHoare triple, 264\nHoare, C. A. R., 264, 269\nHodges, W., 170\nHorn clause, 65, 139\nhybrid rule, 343\nif-statement, 280\nimplementation\ncompliant, 143\nimplication, 4\nlogical, 278\nimplies-elimination, 9\nimplies-introduction, 12\nin-order representation, 35\ninconsistency, 259\nindex, 132\ninduction\ncourse-of-values, 43\nhypothesis, 41, 42\nin model checking, 229\nmathematical, 40\ninductive step, 41\n422\nIndex\ninﬁx notation, 125, 210\ninformation\nnegative, 343\ninput parameter, 61\ninteger\nexpression, 260\ninteger label, 372\ninteger multiplication, 381\ninterface between logics, 277\ninterleaving\nformulas with code, 275\ntransitions, 188, 194\nintroduction rules, 6, 107\nintrospection\nnegative, 319, 326\npositive, 319, 326\nintuitionistic logic, 30, 120, 327\ninvariants, 273\ndiscovering, 283\nSAT solver, 69\niterative squaring, 412\nJape, 170\nWe saw in the preceding section that there appeared to be a correspondence\nbetween the validity of 2φ →φ and the property that the accessibility re-\nlation R is reﬂexive. The connection between them is that both relied on\nthe intuition that anything which is known by an agent is true. Moreover,\nthere also seemed to be a correspondence between 2φ →22φ and R being\ntransitive; they both seem to assert the property of positive introspection,\ni.e. that which is known is known to be known.\nIn this section, we will see that there is a precise mathematical relation-\nship between these formulas and properties of R. Indeed, to every formula\nscheme there corresponds a property of R. From the point of view of logic\nengineering, it is important to see this relationship, because it helps one to\nunderstand the logic being studied. For example, if you believe that a cer-\ntain formula scheme should be accepted in the system of modal logic you are\nengineering, then it is well worth looking at the corresponding property of\nR and checking that this property makes sense for the application, too. Al-\nternatively, the meaning of some formulas may seem diﬃcult to understand,\nso looking at their corresponding properties of R can help.\nTo state the relationship between formula schemes and their correspond-\ning properties, we need the notion of a (modal) frame.\nDeﬁnition 5.10 A frame F = (W, R) is a set W of worlds and a binary\nrelation R on W.\nA frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-\nbelling function. From any model we can extract a frame, by just forgetting\nabout the labelling function; for example, Figure 5.9 shows the frame ex-\ntracted from the Kripke model of Figure 5.3. A frame is just a set of worlds\nand an accessibility relationship between them. It has no information about\nwhat atomic formulas are true at the various worlds. However, it is useful to\nsay sometimes that the frame, as a whole, satisﬁes a formula. This is deﬁned\nas follows. cepting) states, respectively. Model M is concrete since there is nothing left\nun-speciﬁed and all checks M ⊨φ have deﬁnite answers: they either hold or\nthey don’t.\nIn practice not all functional or other requirements of a software sys-\ntem are known in advance, and they are likely to change during its life-\ncycle. For example, we may not know how many states there will be; and\nsome transitions may be mandatory whereas others may be optional in an\nimplementation. Conceptually, we seek a description M of all compliant\n2.7 Micromodels of software\n143\nimplementations Mi (i ∈I) of some software system. Given some matching\nproperty ψ, we then want to know\nr (assertion checking) whether ψ holds in all implementations Mi ∈M; or\nr (consistency checking) whether ψ holds in some implementation Mi ∈M.\nFor example, let M be the set of all concrete models of state machines, as\nabove. A possible assertion check ψ is ‘Final states are never initial states.’\nAn example of a consistency check ψ is ‘There are state machines that\ncontain a non-ﬁnal but deadlocked state.’\nAs remarked earlier, if M were the set of all state machines, then checking\nproperties would risk being undecidable, and would at least be intractable.\nIf M consists of a single model, then checking properties would be decidable;\nbut a single model is not general enough. It would comit us to instantiating\nseveral parameters which are not part of the requirements of a state machine,\nsuch as its size and detailed construction. A better idea is to ﬁx a ﬁnite bound\non the size of models, and check whether all models of that size that satisfy\nthe requirements also satisfy the property under consideration.\nr If we get a positive answer, we are somewhat conﬁdent that the property holds\nin all models. In this case, the answer is not conclusive, because there could be\na larger model which fails the property, but nevertheless a positive answer gives\nus some conﬁdence.\nassert FinalNotInitial {\nall M : StateMachine | no M.i & M.F\n} check FinalNotIntial for 3 but 1 StateMachine\ndeclares an assertion named FinalNotInitial whose body speciﬁes that\nfor all models M of type StateMachine the property no M.i & M.F is true.\nRead & for set intersection and no S (‘there is no S’) for ‘set S is empty.’\nAlloy identiﬁes elements a with singleton sets {a}, so this set intersection\nis well typed. The relational dot operator . enables access to the internal\ncomponents of a state machine: M.i is the initial state of M and M.F is its set\nof ﬁnal states etc. Therefore, the expression no M.i & M.F states ‘No initial\nstate of M is also a ﬁnal state of M.’ Finally, the check directive informs the\nanalyzer of Alloy that it should try to ﬁnd a counterexample of the assertion\nFinalNotInitial with at most three elements for every signature, except\nfor StateMachine which should have at most one.\nThe results of Alloy’s assertion check are shown in Figure 2.7. This visual-\nization has been customized to decorate initial and ﬁnal states with respec-\ntive labels i and F. The transition relation is shown as a labeled graph and\nthere is only one transition (from State 0 back to State 0) in this exam-\nple. Please verify that this is a counterexample to the claim of the assertion\nFinalNotInitial within the speciﬁed scopes. Alloy’s GUI lets you search\nfor additional witnesses (here: counterexamples), if they exist.\nSimilarly, we can check a property of state machines for consistency with\nour model. Alloy uses the keyword fun for consistency checks. e.g.\nfun AGuidedSimulation(M : StateMachine, s : M.A) {\nno s.(M.R)\nnot s in M.F\n# M.A = 3\n} run AGiudedSimulation for 3 but 1 StateMachine\n2.7 Micromodels of software\n145\nmodule AboutStateMachines\nsig State {}\n-- simple states\nsig StateMachine { -- composite state machines\nA : set State,\n-- set of states of a state machine\ni : A,\n-- initial state of a state machine\nF : set A,\n-- set of final states of a state machine 1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,\ncepting) states, respectively. Model M is concrete since there is nothing left\nun-speciﬁed and all checks M ⊨φ have deﬁnite answers: they either hold or\nthey don’t.\nIn practice not all functional or other requirements of a software sys-\ntem are known in advance, and they are likely to change during its life-\ncycle. For example, we may not know how many states there will be; and\nsome transitions may be mandatory whereas others may be optional in an\nimplementation. Conceptually, we seek a description M of all compliant\n2.7 Micromodels of software\n143\nimplementations Mi (i ∈I) of some software system. Given some matching\nproperty ψ, we then want to know\nr (assertion checking) whether ψ holds in all implementations Mi ∈M; or\nr (consistency checking) whether ψ holds in some implementation Mi ∈M.\nFor example, let M be the set of all concrete models of state machines, as\nabove. A possible assertion check ψ is ‘Final states are never initial states.’\nAn example of a consistency check ψ is ‘There are state machines that\ncontain a non-ﬁnal but deadlocked state.’\nAs remarked earlier, if M were the set of all state machines, then checking\nproperties would risk being undecidable, and would at least be intractable.\nIf M consists of a single model, then checking properties would be decidable;\nbut a single model is not general enough. It would comit us to instantiating\nseveral parameters which are not part of the requirements of a state machine,\nsuch as its size and detailed construction. A better idea is to ﬁx a ﬁnite bound\non the size of models, and check whether all models of that size that satisfy\nthe requirements also satisfy the property under consideration.\nr If we get a positive answer, we are somewhat conﬁdent that the property holds\nin all models. In this case, the answer is not conclusive, because there could be\na larger model which fails the property, but nevertheless a positive answer gives\nus some conﬁdence.\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,\na service is a method (a modular piece of program code), a ﬁeld entry, or a\ntype – e.g. the type of a class in an object-oriented programming language.\nComponents typically require the import of services from other components.\nTechnically speaking, such import services resolve all un-resolved references\nwithin that component, making the component linkable. A component also\nhas a name and may have a special service, called ‘main.’\nWe model components as a signature in Alloy:\nsig Component {\nname: Name,\n-- name of the component\nmain: option Service, -- component may have a ‘main’ service\nexport: set Service,\n-- services the component exports\nimport: set Service,\n-- services the component imports\nversion: Number\n-- version number of the component\n}{ no import & export }\n150\n2 Predicate logic\nThe signatures Service and Name won’t require any composite structure for\nour modelling purposes. The signature Number will get an ordering later on.\nA component is an instance of Component and therefore has a name, a set of\nservices export it oﬀers to other components, and a set import of services\nit needs to import from other components. Last but not least, a component\nhas a version number. Observe the role of the modiﬁers set and option\nabove.\nA declaration i : set S means that i is a subset of set S; but a declara-\ntion i : option S means that i is a subset of S with at most one element.\nThus, option enables us to model an element that may (non-empty, sin-\ngleton set) or may not (empty set) be present; a very useful ability indeed.\nFinally, a declaration i : S states that i is a subset of S containing ex-\nactly one element; this really speciﬁes a scalar/element of type S since Alloy\nidentiﬁes elements a with sets {a}.\nSince\nService 2 is contained in Component 2.export, we have two struc-\nturally diﬀerent legitimate post states which are obtained by adding\nComponent 2 but which diﬀer in their scheduler. In P’ we have the same\nscheduling instances as in PDS 0. Yet P’’ schedules Component 2 to\nprovide service Service 2 for Component 0; and Component 0 still provides\nService 1 to Component 1. This analysis reveals that the addition of\ncomponents creates opportunities to reschedule services, for better (e.g.\noptimizations) or for worse (e.g. security breaches).\nThe utility of a micromodel of software resides perhaps more in the ability\nto explore it through guided simulations, as opposed to verifying some of\nits properties with absolute certainty. We demonstrate this by generating\na simulation that shows the removal and the addition of a component to a\nPDS such that the scheduler always schedules components with the highest\nversion number possible in all PDSs. Therefore we know that such a schedul-\ning policy is consistent for these two operations; it is by no means the only\nsuch policy and is not guaranteed to ensure that applications won’t break\nwhen using scheduled services. The fun-statement\nfun HighestVersionPolicy(P: PDS) {\nwith P {\nall s : Service, c : components, c’ : c.schedule[s],\nc’’ : components - c’ {\ns in c’’.export && c’’.name = c’.name =>\nc’’.version in c’.version.^(Ord[Number].prev)\n}\n}\n} run HighestVersionPolicy for 3 but 1 PDS\nspeciﬁes that, among those suppliers with identical name, the scheduler\nchooses one with the highest available version number. The expression\nc’.version.^(Ord[Number].prev)\nneeds explaining: c’.version is the version number of c’, an element of\ntype Number. The symbol ^ can be applied to a binary relation r : T -> T\nsuch that ^r has again type T -> T and denotes the transitive closure of r.\nIn this case, T equals Number and r equals Ord[Number].prev.\n156\n2 Predicate logic",
            "summary": "In our example in Figure 2.1, we have three leaf nodes x. If we walk up the tree beginning at any one of these x leaves, we run into the quantiﬁer ∀x. This means that those occurrences of x are actually bound to   so they represent, or stand for, any possible value of x. There are two principal such occurrences: 1. made concrete and 2. free in a formula in predicate logic. For example, in the example above, x has nothing to do with y; x and y are diﬀerent place holders. So y is free in this formula, but its value has to be speci ﬁed by some additional information. In terms of parse trees, the scopeof a quantiﬁer is just its subtree, minus any subtrees which re-introduce a variable. If x occurs in φ, then it is bound if, and only if, it is in the scope of some of φ’s subformulas. It isquite possible, and common, that a variable is bound and free in a formula. Figure 2.2.2 shows a parse tree of a predicate logic formula illustrating free and bound occurrences of variables. The two x leaves in the subtree of ∀x are bound since they are in thescope of the formula. The leaf x in the right subtree is free since it is A single leaf either is under the scope of a quantiﬁer, or it isn’t. Note, however, that individual occurrences of variables are either free or bound, never both at the same time.2.4 Substitution. Variables are place holders so we must have some means of replacing them with more concrete information. On the syntactic side, we often need to replace a leaf node x by the parse tree of an entire term t. Recall that any replacement of x may only be a term; it could not be a predicate expression, or a more complex formula, for x serves as a term to a predicate symbol one step higher up in the parsing tree. Deﬁnition 2.7 given a variable x, a term t and a formula φ. We replace each free occurrence of variable x in φ with t. In substituting t for x we have to leave untouched the bound leaves x. This is true because all occurrences of x are bound in the formula, so none of them getssubstituted. The bound x leaves are unaﬀected by this operation. The parse tree of f(x, y) for that free leaf node x and obtain the parse tree in Figure 2.3. For example, in Figure 1.1 we substitute f(y, x) for x and get f(Y,x) in Figure The substitution process is straightforward, but requires that it be applied only to the free occurrences of the variable to be substituted. The elimination rules break (p ∨q) ∨r up into its atomic constituents p, qand r, whereas the introduction rules then built up the formula p ∨(q  r) 1. We are now able to prove this in                natural deduction. 2. We can see that the process of substitution is straightforward. 3. You can see. that it is only necessary to apply the substitution process to free occurrences. 4. It is possible to prove that the substitution is not required to apply to all occurrences of a variable. 5. It can be shown that the elimination A ﬁnal rule is required in order to allow us to conclude a box with a for-mula which has already appeared earlier in the proof. The rule ‘copy’ allows us to repeat something that we know already. We need to do this in this example, because the rule →i requires that we end the inner box with p. The copy rule entitles us to copy formulas that appeared before,unless they depend on temporary assumptions whose box has already been closed. The following proof is a proof of the validity of the ‘converse’ (p ∧q) and you are encouraged to show it yourself. The proof is based on the following: The proof rules for natural deduction are summarised in Figure 1.2. The rules for negation involve the notion of contradiction. It can be diﬃcult to decide which instance of LEM would beneﬁt the progress of a proof. Can you re-do the example above with q ∨¬q as LEM? Can you do the same thing with q∨i? Can we use premises or any other ‘visible’ formulas, more than once? Can a proof be proved using a single negation or a series of negations? Can an argument be proved by using multiple negations or multiple premises? Can it be proven by using premises or other 'visible' formulas The rules have an excellent procedural interpretation. However, when you try to use the rules yourself, you’ll find yourself looking for a more procedural interpretation; what does                a rule do and how do you use it? For example, to prove φ, try proving φ and ψ separately and then use                the rule  in Example 1.15. The rules are written in the form of a list of rules, starting with the first one and ending with the last one. The first rule is called the ‘proving’ rule, the second is called ‘exercising’ the rules, and the third is ‘using the rules’. The basic rules of natural deduction:introduction, elimination, and derivation. Show that the following sequents are not valid by ﬁnding a valuation in which the truth values of the formulas to the left of ⊢are T and the truth value of the formula to the right of F is F. See Figure 1.2 on page 27 to see which cases are still missing, and to see how to use the rules in the rest of the book. See page 27 for the summary of the rules of deduction in the book, as well as a list of examples and examples of how to apply the rules to the real world. The book is published by Oxford University Press, London. Find a formula of propositional logic which contains only the atoms p, q and r and which is true only when p and q are false. Prove the validity of the following sequents needed to secure the completeness of the formula. Use mathematical induction on n to prove the theorem. Use the following examples of natural language to test the correctness of the formulas. For each example, give examples of sentences such that the premises are true, but the conclusion is false. For example, given the premises p,q and r, give the sentences: p →q ⊢p ∨q(d) p →(q ∨r) ≢(p →q) (d) (p →r) An adequate set of connectives for propositional logic is a set such that there is an equivalent formula with only connectives from that set. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an instance of LEM. Does ⊨φ hold for the φ below? Please justify your answer. Exercises 1.5 and 2.5 are based on the definition of the set {¬, ∨} and the set of propositional connectives. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This intention is right-associative: expressions of the form p →q →r denote p →(q → r) In Examples 1.1 and 1.2, we show how this works by applying the rules to the premises and the conclusion. We denote the intention we denote by the formula φ1, φ2, . . .       . ..   We denote our intention by φn, which we will call premises, and another formula, �  Constructing such a proof is a creative exercise, a bit like programming. It is notnecessarily obvious which rules to apply, and in what order, to obtain the desired conclusion. For Examples 1.1 and 1.2, we use Greek letters. Lower-case letters are used to stand for formulas, and upper-case Letters are used for sets of formulas. For example, p ⊢q. , φn ⋅n ≅n is a set of three formulas. Greek letters are used to express propositions. Propositional logic can be used to prove the existence of certain facts. The proof rule modus tollens (MT) can be derived from some of the other rules. The rules are: p, q ⊢p, r, ¬r, p |−q, p  ‘Gold is a metal’ and p  ‘Silver is a gold.’ The rules can be shown by the sequent p,q,r,p, ‘p’, “p” and ‘q’. The Greek word for ‘proof’ is ‘guideline’ or ‘propositional There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy;.and some purists would say that we should stick to a minimum set of rules, independent of each other. We don’t take such a purist view.Indeed, the two derived rules we now introduce are extremely useful. You will find that they crop up frequently when doing exercises in natural deduction, so it is worth giving them names as derived rules. For example, the rule ‘e, ¬e and ¬i’ can be derived from the rules “e” and “i”. The rules for negation involve the notion of contradiction. We have seen the rules ¬¬i and ¬E, but we haven’t seen any rules that introduce or eliminate single negations. The rules for contradiction are: If from ¬φ we obtain a contradiction, then we are entitled to deduce φ: PBC. The rule for contradiction is called reductio ad absurdum, which means ‘reduc-tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. We will use this rule more than once in our derivation of the rules for the proof of natural deduction. As far as truth is concerned, they are all equivalent. We’ll be able to prove this later, when we have introduced the rules for negation. Contradictions are a very important notion in logic. Any formula can be derived from a contradiction. This can be seen in natural deduction. Natural deduction can be confusing when you ﬁrst encounter it; why should we endorse the argument that the moon is made of green cheese? It may seem absurd, but natural deduction does have this feature that any for-reprehensible-mula can be derive from a contradictions and therefore it makes this argu-                ment valid. It’s not just that contradictions can be. derived from contradic- This process does not care whether such premises make any sense. The reason it takes this stance is that ⊢tells us all the things we may infer, provided that we can assume the formulas to the left of it. This has at least the advantage of matching checks based on semanticintuitions which we formalise later by using truth tables. If all the premises compute to ‘true’, then the conclusion must compute ‘ true’ as well. Let’s now look at our proof rules. First, we expect that we won’t be able to show the sequent p, q. Then, we look at the proof rules for the ‘propositional logic’ For each of the connectives, there is one or more rules to introduce it and one or two rules to eliminate it. We present about ﬁfteen of them in total. We will go through them in turn and then summarise at the end of this section.1 Rules for natural deduction for conjunction.2. The rules for conjunction for conjunction, for conjunction with conjunction, and for conjunction without conjunction.3. The rule for conjunc-unc-tion for conjunction and-introduction.4. The Rules for Natural Deduction for Conjunctions for Conjunction, for Conjugation with Conjunction, and Conjuration with Conjunctivity. The rules for and-elimination are these two: one for proof of φ and the other for elimination. In the first rule, the conclusion has to match the ﬁrst conjunct of the first conjunct, whereas the exact nature of the second conjunct is irrelevant. The second rule is just the other way around: the conclusion can be any formula. It is important not to engage in this kind of pattern matching before the application of proof rules. The rules for proof and elimination are these: one rule says: if you have a proof of. φ, then by applying this rule you can get a proof. of ω. The rule  says the same thing, but allows you to We summarise this reasoning into the rule modus tollens, or MT for short. We will be able to derive this rule from other ones later on, but we introduce it here because it enables us already to do some pretty slick proofs. In the following proof of the rule we use several of the rules introduced so far:. The rule can also be derived from other rules such as the rule that says ‘If Abraham Lincoln was Ethiopian, then he was African’ and ‘Abraham Lincoln was not African; therefore he was not Ethiopian’ The rule MT implies introduction of new premises. The order of applying double negation rules and MT is diﬀerentin these examples. Yet, so far we have no rule which builds implications that do not already occur as premises in our proofs. The rule MT made it possible for us to show that p →q, ¬q ⊢¬p is valid, but the validity of the sequent p →¬q, q ⋅p seems just as plausible. That sequent is, in a certain sense, saying the same thing. We call the rule MT a Natural deduction. It does not mention the lower-level rules upon which it depends. The mechanics of such a rule are more involved than what we have seen so far. So let us proceed with quantiﬁcation. Now we want to provide formal proofs for some of the most                commonly used quanti ﬁer equivalences. Quite a few of them involve several                quantiﬅcations over more than just one variable. Thus, this topic is also good practice for using the proof rules for quanti ﬉ers in a nested fashion. For example, we may specify ‘Not all birds can ﬂy.’ as ¬∀x (B(x) →                F(x)) or as  ‘not all birds The former formal speciﬁcation is closer to the structure of the English. The latter is logically equiv-alent to the former. Theorem 2.13 Let φ and ψ be formulas of predicate logic. As in Chapter 1, we write φ1 ⊣⊢φ2 as an abbreviation for the validityof φ2 � Assuming that x is not free in ψ, we have the following equivalences. We will prove most of these sequents; the proofs for the remaining ones are straightforward adaptations and are left as exercises. For example, we can say that the word φ is free if and only if it is free in x. We have the equivalences for the words φ, x, and x in this way. We can also use the equivalence for the word x, y, and y in the same way. For instance, we could say: φ (x) (y) (x), y (y), x (x, y), y, y (x The rule for eliminat-                ing is the following: If φ is true, then you could replace the x in φ by any term t. The intuitive soundness of this rule is self-evident. Recall that                and necessary requirements for any sane concept of (extensional) equality. We leave the topic of equality for now to move on to the proof rules for                quantiﬁers. The rules for universal quantification can be found in the next section of the book, ‘The Theory of Quantification’, which is published by Oxford University Press, priced £16.99 (US) and £19.99 ($24.99) The rule  is a bit more complicated. It employs a proof box similar to those we have already seen in natural deduction for propositional logic, but this time the box is to stipulate the scope of the ‘dummy variable’ x0. The rule is to enforce the side condition that t be free for x in φ. The statement  says that for all numbers                n there is some bigger number m, which is indeed true of integers or real                numbers. However, φ[y/x] is the formula  saying that there is a                number which is bigger than itself. This is wrong; and we must not allow a                proof rule which derives semantically wrong things from semantically Predicate logic extends propositional logic not only with quantiﬁers but also with function symbols. Consider the declarative sentence: Every child is younger than its mother. The rule  is written  referring to the argument above in a symbolic form. The need for a richer language needs to be addressed, too, we say. We need a language that is richer in terms of predicates, function symbols, and other concepts. We call this a new kind of language, the richer language of predicate logic, and it will be used in the next section of this article. We hope that this will help you understand the language of predicate logic a little better. The inelegance of coding ‘mother’ as a predicate is even more apparent if we consider the sentence:Andy and Paul have the same maternal grandmother. The function symbols of predicate logic give us a way of avoiding this grotesqueugly encoding, for they allow us to represent y’s mother in a more direct way. We write x = y instead of = (x, y) to say that x and y are equal. We use a special predicate in predicate logic, equality, which is a binary predicate, and is written =. Unlike other predicates, it is usually written in between its arguments rather than before them; that is, we write x + v instead of x + y. The symbol m is a function symbol. Instead of writing M(x, y) to mean that x is y’s mother, we simply.write m(y) to means y's mother. Let ρ be a valuation with ρ(x′ worrisome1) = 1 and ρ (x′ horrifying2) = 0. Determine whether ρ ⊨frulyholds for the following: x1[ˆx]  (x1 + x2), x2[˄x] (x2 + x3), x3 (x4 + x4), x5 (x5 + x6), x6 (x6 + x7), x7 (x Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)holds. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately. Mimic the example checks on page 396 for the connective AU. Find a boolean formula without ﬁxed points which is semantically equiva-                lent to f E[(x1 ∼U(¬ x1∧¬X2)]. For example, f E [x1â€™s U (¬ x1î€’s ‘x2’] is correct if In the grammar (6.10) for the relational mu-calculus, S and I have just one (they are called unary predicates), but predicate Y requires two arguments (it is called a binary predicate) Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’ or ‘There is some x which is a bird and cannot’. This is closer to the linguistic structure of the sentence above. We use f EG ¬x1 for the model in Figure 6.24. In Section 2.3, we extend our natural deduction calculus of propositional progressivelylogic so that it covers logical formulas of predicate logic as well. In this way we are able to prove the validity of sequents φ1, φ2, . . .    .      in the language we use. We will also explain whyhematicallyformulas like the two above are indeed equivalent semantically. The purpose of this section is to explain how such formulas can be given their meaning in general, and why they should be used in software design and in safety-critical systems. The goal is to reason symbolically orsemantically about the information expressed in those formulas. For example, penguins are birds In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicateLogic can be true or false. We are overloading the previously established proof rules for the previous chapter with rules for propositional connectives. We also introduce new proofrules for dealing with the quanti ﬁers and with the equality symbol in the natural deduction calculus for predicate logic. This allows us to deﬀn semantic entailment in a similar way to that in the first chapter of the book. We call this the ‘synthetic entailment’ of predicatelogic. Equality does not mean syntactic, or intensional, equality, but equality in terms of computation results. In either of these senses, any term t has to be equal to itself. As in the natural deduction calculus for propositional logic, the additional rules                for the quantiﬁers and equality will come in two ﬂavours: introduction and                elimination rules. The proof rules for equality are:t = t autoimmune=i autoimmune(2.5) which is an axiom (as it does not depend on any premises). Notice that it encompasses the rule that equality may be invoked only if t is a term, our language doesn’t permit us to talk about equality between formulas We have already pointed out the open-ended nature of the semantics of predicate logic. We may now express this substitution principle as the rule=e. The rule is an example of a side condition of a proof rule. The semantics of equality can be expanded to include the rule =e. For example, we can express the rule as follows:t1 = t2                 φ[t1/x]                 ω[t2/x], which is the rule of equality. Given a predicate logic over a set of function symbols F and predicates P, we need only a non-empty set A equipped with concrete functions or elements fM and P M. The right arities are agreed upon in our speciﬁcation. Of course, we also stressed that most models have natural interpretations of of of the symbols.2.5 Undecidability of predicate logic: How do we know when a model makes sense and when it doesn’t? The answer is that there is no way out of this peculiarity, and that it is impossible to choose a model that makes sense or one that doesn't. The answer to this question is that the answer is ‘no’ There are a lot of good reasons for maintaining a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. We discussed itsproof rule in natural deduction already in Section 2.3.1. We now move on to the next section of the book. The next section is on the subject of equality in the form of a function =M. The third section is about equality in terms of the quantiﬁer equivalences dis-                cussed in 2.2.2 and 2.4.1 respectively. The fourth and final section is the section on equality in propositional logic. 2 and 3 are not equivalent to 2 and 3, as we saw earlier. We do not have equiv-                alences between 2 and 2, or between 3 and 3. For example, in the fourth item of Example 5.6 we had x5 ⊩2(p ∨q) and x5 ̸⊩ 2p (p  2q) But we must show that x has an accessible world, i.e. satisﬁes 3⊤. We can also show that 2 is equivalent to 3, but not to 3. It is also not surprising to ﬁnd that 2 does not distribute over ∨ and 3 does not distribution over A formula φ of basic modal logic is said to be valid if it is true in every world of every model, i.e. iﬀ⊨φ holds. A substitution instance of a formula is the result of uniformlysubstituting the atoms of the formula by other formulas as done in (5.2). For example, since p ∨¬p is a tautology, performing the substitution p   2p ∧(q →p) gives us a valid formula (2p  2p (q    ) 2p   2p  2p 2p 1 p 1 p 2p1 p 1p1p 1p 1 Let φ and ψ and η be sentences of predicate logic. If ψ is semantically entailed by φ, is it necessarily the case that ω is not? Explain why ω iﬀφ is valid. Justify your answer. For each set of formulas below, show that they are consistent. If you disagree with one of these answers, you should change the answer to the other. If the answer is the same, then the original answer is correct. If it is not, then you should ask for a new answer. If there is no answer, you must accept that the previous answer was correct. The answer is that the first one is correct and the second one is not. For each of the formulas of predicate logic below, either ﬁnd a model which does not satisfy it, or prove it is valid. For each formula, either the model which doesn't satisfy it is not valid, or it can be proved to be valid. Exercises 2.5 and 2.6 are given in the section \"Exercises 1.5\" and \"2.5,\" respectively. For the rest of the section, see \"Exercise 1.6\" and \"Exercise 2.1\" for details. For more information on the exercises, see the expert guideline. In Section 2.4, we generalize the valuations of Chapter 1 to a proper                notion of models, real or artiﬁcial worlds in which formulas of predicate logic can be true or false. The latter expresses that, given any such model in which all φ1, φ2, . . . , φn. hold, it is the case that ψ holds in that model as well. In that case, one says that ω is semantically entailed by ω1,  ω2,   . ., ωn. In the next section, we show that the validity of the following sequents cannot be proved by a proof calculus. It is outside the scope of this book to show that the natural deduction for predicate logic is sound and complete with respect to semantic entailment. The process of evaluating a predicate formula diﬀersfrom the computation of truth values for propositional logic in the treatment of predicates (and functions) We discuss it in detail in Section 2.4. The proof of this was done by the mathematician K. G¨odel. To get a feel for that, let us consider the following argument: “No books are gaseous. Dictionaries are books.” The argument is based on the fact that “no book is a book”. Predicate logic extends propositional logic not only with quantiﬁers but also with function symbols. We can sometimes reason that certain semantic entailments arevalid. We do this by providing an argument that does not depend on the model at hand. The most prominent ones are the quanti ﬁer equivalences which we already encountered in the section on natural deduction. The predicates we choose are B(x) and G(x), which express the argument above in a symbolic form. For example, no dictio-                nary is gaseous, but a book is a book and a dictionary is a dictionary. For more information on the theory of predicates, see the Wikipedia article on predicates. The justiﬁcation of the semantic entailment is as follows. Let M be a model satisfying  P(x) →Q(x). We need to show that M satisﬃes  ‘P’ and ‘Q’ satisfy each other as well. The converse of the above is that M′ must also satisfy Q. Let us look at a couple of examples of this kind of entailment. For example, suppose M′ is a model with A′ as its underlying set. If P M′ equals A′, then QM′ must equal A′. If A′ is the underlying set, then M′ simply says that, if A′ equals We have already pointed out the open-ended nature of the semantics of predicate logic. In this article, we show that a se-quent does not have a proof. We also show that soundness implies that the sequent φ1, φ2, . . . , ω does not seman-                tically entail ω. We conclude that the truth-table semantics of a predicate logic over a set of function symbols F and T is the same as that of a truth- table semantics of the same logic over the same set of symbols F, T and F. We then show how to construct a counter-example model of the truth table semantics for the logic of equality. Using natural deduction to decide the validity of instances of ⊢is only one of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,                notion of proofs for sequents. We now investigate various alternatives for deciding these formulas which are based on transforming these formulas syntac-uroustically into ‘equivalent’ ones upon which we can then settle the matter by purely syntactic or algorithmic means. The results of the study are published in the book ‘Theoretical Foundations of Natural Deduction’, which is published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. Two formulas are said to be equivalent if they have the same ‘meaning’ This suggestion is vague and needs to be reﬁned. The truth table for p and q is four lines long, whereas the one for r is only two lines long. However, both formulas are always true. This suggests that we have just one unary predicates, but predicate Y requires two arguments (it is called a binary predicate). The idea is to have a single unary predicate, but two binary ones, such as S and I, as well as a binary one. The idea of a binary predicates is called ‘symbolic predicates’ and it is used in the theory of propositional logic. Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’. We address how such logical formulas can be given their meaning in general. We will also explain why they are indeed equivalent semantically and why they should be used in sentences like ‘Penguins are birds which cannot �ac’ and ‘There are no penguins in the world’, for example. We conclude with a discussion of the meaning of the ‘penguin’ part of the word ‘bird’ in English. In Section 2.3, we extend our natural deduction calculus of propositional logic so that it covers logical formulas of predicate logic as well. In Section. 4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of. predicate logic can be true or false. We are able to give a semantics to formulas ofpredicate logic. in software design with UML or in the creation of safety-critical systems – and much more care must be taken than in the case of propositionally logic. In section 2.4, we allow us to de ﬁne semantic entailment with any other variable y to l(y) Given a model M for a pair (F, P) and given an environ-                ment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula over the pair. If φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, T2, tn in the set A by replacing all variables with their values according to l. In this way, we compute concrete values a1, a2,. . ., an of A for each of these terms, where a1 is a function symbol. We say that φ computes to T in the model M with respect to the The relation M ⊨l ψ holds for all a ∈A. , an) is in the set P M. It is not the case that M ≹ holds. We sometimes write M  M    φ to denote that M    does not hold, regardless of the choice of φ. There is a straightforward inductive argument on the height of the parse tree of a formula which says that M M M φ holds, whenever l′ and l′ are two environments which are identical on the set of free variables M  M φ is called a sentence. The relation M  ≳ M  ω holds iﬀM � Deﬁnition 5.4 for the case  can hold only if x ⊩¬p holds. But x does not hold, since there is a world y with R(x, y) such that y ⊉p holds, for p ∈L(y) Theavailability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. Theorems can now be used to prove semantic entailment in the same manner as for modallogics. For sentences φ we often elide l and write M ⊨φ since the choice of an Verifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly would be rather diﬃcult. Fortunately, we have a much more usable approach, which is an extension, respectively adaptation, of the systems of natural deduction met in Chapters 1 and 2. Recall that we presented natural deduction proofs as linear representations of proof trees. The proof boxes have formulas and/or other boxes inside them. There are rules which dictate how to construct proofs. Boxes open with an assumption; when a box is closed – in accordance with a rule – we say that its assumption is discharged. We would have to consider every Kripke model to prove soundness and completeness of the Every formula must have some justiﬁcation to its right. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. We are entitled to use these rules of constructing propositionsrepeatedly. For example, we are now in a position to form the propositionp ∧q →¬r ∨q. This means that ‘if p and q then not r or q’ But the meaning should not be confused with the often implicit meaning of or in natural language as either . . . or.    ‘p is the case and if q then . .. ’ A computer would require the insertion of brackets, as in p (p) ( In this text or always means at least one of them and should not beconfounded with exclusive or which states that exactly one of the two statements holds. The natural language meaning of ‘if . .. then . . . ’ often implicitly assumes a causal role of somehow enabling its conclusion. For example, ‘If all birds can ﬂy, then Bob Dole was never president of the United States of America’ is a true statement, but there is no known causal connection between penguins and eﬀective campaigning. We humans get annoyed by a pro-liferation of such brackets which is why we adopt certain conventions about the binding priorities of these symbols. 1. Implication →is right-associative: expressions of the form p →q denote p →(q →r). 1.2 Natural deduction is the construction of a calculus for reasoning about proposi-tions, so that we can establish the validity of Examples 1.1 and 1. 2. For example, given a set A, the interpretation =M of equality is forced to be {(a, a), (b, b), (c, c The semantics of equality is easy, for it is always modelled extensionally. The problem of determining whether a predicate logic formula is valid is known as a decision problem. We will give a formal proof of this negative result, though we rely on an informal (yet intuitive) notion of computability. We conclude our introduction to predicate logic with some negative results. Back to Mail Online home. back to the page you came from. The next page will contain the rest of the article. The third and final page will be the introduction to propositional logic. The fourth and fifth pages will contain a discussion of the negative results of the previous section. The last page will include a discussion on the negative result of the first section. The decision problem at hand is this: given a logical formula φ, does it hold, yes or no? We now show that this problem is not solvable; we cannot write a correct Java program that works for all φ. It is important to be clear about the difference between the interleaving model and the outer sum. The latter, if used in ∃ˆx′f (‘for some next state’), can be optimised since sums distribute over existential quantiﬁcation; in Chapter 2 this was the equivalence. The outer sum is the sum of the sums of the previous two models, and can be used to optimise the inner sum. In this section, we introduce a syntax for referring to ﬁxed points in the context of boolean formulas. Fixed-point invariants frequently occur in all kinds of applications, so it makes sense to have an intermediate language for express- purposefullying such invariants syntactically. This language also provides a formalism for describing interactions and dependences of such. invariants.    The relational mu-calculus provides a language for expressing these invariants and for describing their interactions with each other and with other states in a model. The language is based on the CTL for-                mula in Section 3.7 of the previous section. We call this the ‘union’ of global states reachable 6.4.1 Syntax and semantics of the relational mu-calculus. We will see that symbolic model checking exhibits such more complex relationships between invariants. We consider what happens if we do not require formal monotonicity in the formulas of the mu-Calculus. In exercise 7 on page 410 we consider what happened if we did not need formal monotone. We conclude with the definition of the semantics of a relational Mu-Calculator. We call this a \"syntactic model\" and call it a \"semantics\" model. The semantics of this model is the \"semantic model\" of the relationship between the variables x and Z. It is the same as that of a binary variable and a We have already pointed out the open-ended nature of the semantics of predicate logic. We need only a non-empty set A equipped with concrete functions or elements fM and concrete predicates P M in A which have the right arities agreed upon in our speciﬁcation. But central notions like that of semantic entailment really depend on all possible models, even the ones that don’t seem to make any sense.Apparently there is no way out of this peculiarity.   We also stressed that most models have natural interpretations of                2.2.4. The semantics of equality is discussed in more detail in the section on equality and its consequences. Where would you draw the line between a model that makes sense and one that doesn’t? And would any such choice, or set of criteria, not be subjective? Such constraints could also forbid a modiﬁcation of your model if this alteration were caused by a slight adjustment of the problem domain you intended to model. You see that there are a lot of good reasons for maintaining such a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. Equality is the special role of equality in the theory of quantification. The proof rules for universal quantification follow from Section 2.3. The rule for eliminatat-                ing is the following: If φ is true, then you could replace the x in φ by any term t and conclude that φ[t/x] is true as well. The intuitive soundness of this rule is self-evident. We discuss itsproof rule in natural deduction already in Sections 2.1 and 2.2. We leave the topic of equality for now to move on to the proofrules for universalquantification. We will discuss the rules for quantification for the first time in this article. Since φ is assumed to be true for all x, that should also be the case for any term t. Clearly, what went wrong was that y became bound in the process ofsubstitution; y is not free for x in φ. This is wrong; and we must not allow aproof rule which derives semantically wrong things from semantically valid. Predicate logic is not a form of logic, it is a way of thinking about the world. We need to be able to think about numbers in a different way, not just in terms of the usual ‘smaller than’ relation, but also about the ‘bigger’ and ‘lesser’ ones. The rules for the natural deduction calculus for predicate logic are similar to those for propositional logic in Chapter 1. We have new proof rules for dealing with quantiﬁers and with the equality symbol. We are overloading the previously established proofrules for the propositional connectives  ,    , ‘’, “”,  ” and ’’. We also have a new rule for the ‘dummy variable’ x0, which is used to enforce the side condition that t be free for x in φ[t/x] Figure 2.4. A parse tree for which a substitution has dire consequences. Any proof rule of Chapter 1 is still valid for logical formulas of predicate logic. As in the natural deduction calculus for propositional logic, the additional rules for quantiﬁers and equality will come in two ﬂavours: introduction andelimination rules. The proof rules for equality are outlined in the next section of the book. The introduction rule for equality is an axiom (as it does not depend on any premises) and the elimination rule is for equality in terms of computation results. In either of these senses, any term t has to be equal to itself. In CTL, equality between formulas is not enough. We need a principle that allows us to substitute equals for equalsrepeatedly. We may now express this substitution principle as the ruleulent=e:t1 = t2. Since we have added the variable u, there are actually six states; they all satisfy the formula. Since t1 and t2 have to be free for x in φ, whenever we want to apply the rule =e, this is an example of a side condition of a proof rule. In the next section, we will look at how SMV could use fairness assumptions which were not expressible entirely in CTL. We will also look at a relational mu-calculus and its semantics. The addition of fairness could be achieved by restricting the ordinary CTL semantics to fair computation paths, or fairstates. The propositional connectives won’t change their meaning with the addition of the fairness constraints. It suﬃces to provide symboliccodings for the fair connectives ECX, ECU and ECG from Chapter 3 of the CTL textbook. The book is published by Oxford University Press and is available for download from the Google Play store and the Amazon Kindle store. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or The set of fair states symbolically is represented as a boolean formula. We say that there is a fair path with respect to C that begins with s and ends with s. The coding of fECG φ is rather complex, we proceed in steps. It is convenient to have the functionality of ECX and EU functionality also at the level of boolean formulas directly. For ECX, note that s ⊨ECXφ if, and only if, there is some next state s′with s →s′ and s′ ≳ such that s′ is aFair state. For EU, we obtainfEC[φ1Uφ2] def= µZ. This immediately rendersfEC The concept of a variable is used to codify sentences. Variables can be thought of as place holders for concrete values. Using variables, we can now specify themeanings of S, I and Y more formally: S(x) : S is a student, I (x) is an instructor. Y (x, y) : Y is younger than y. The names of the variables are not important, provided that we consistentlyuse them. We can state the intended meaning of I by writing I(y) : I am an instructor, or I(z) : Z is a program state, or z is a state. For example, we could write: I(X) : X is younger, I( We need to convey the meaning of ‘Every student x is younger than some                instructor y’ This is where we need to introduce quantiﬁers. The availability of variables is still not suﬃcient for capturing the essence of the example sentence above. Now we can write the example in an entirely symbolic way as. (S(x) → (∃y (I(y) ∧Y (x, y)). 2.1 The need for a richer language. 2.2 The need to create a new type of language called the ‘symbolic language’. 3. A new kind of language known as ‘non-symmetric’ 2.4 Important equivalences between LTL formulas                Deﬁnition 3.9 We say that two LTL. formulas φ and ψ are semantically.equivalent, or simply equivalent, writing φ ≡ ψ. Predicates with                any ﬅnite number of arguments are possible in predicate logic. Another example is the sentence                Not all birds can ﬂy.operators for quantifying over paths, and can express these properties.3.9 The equivalence of φ. and ω means that φ Pushing a negation downwards in the parse tree past one of them also has the eﬀect of duplicating that negation. ‘Morally’ there ought to be a dualfor W, and you can invent one if you like. However, it might not be very useful. We should give formal proofs of these equivalences. But they are easy, so we purposefullyleave them as an exercise to the reader. We see that F and G are duals of each other, and X is dual with itself. We also show that F distributes over  and G over  , i.e., F   over  and G over ’’. There are two more equivalences in LTL: F φ and G φ. One exploits the fact that the clause for Until states two things: bols in the same formula, we arrive at fully-ﬂedged second-order logic. If one wants to quantify over relations of relations, one gets third-orderlogic etc. Higher-order logics require great care in their design. Typical re-insuredsults such as completeness and compactness may quickly fail to hold. The second equivalence is a more general version of the first one. It is called F (F φ) and F (G φ), and it is used in the definition of LTL. A naive higher-order logic may be inconsistent at the meta-level. Re-lated problems We won’t study higher-order logics in this text, but remark that many the-                orem provers or deductive frameworks rely on higher- order logical frame-works. Two of the central concepts developed so far are model checking and semantic entailment. Given a formula φ of predicate logic and a matching model Mdetermine whether M ⊨φ holds; and given a set of formulas Γ, is the formula valid? In the case ofsemantic entailment, φ may be a property we                think should hold in any implementation that meets the requirements of Γ.Semantic entailsment matches well with software speciﬁcation and validateation; alas, it is Since model checking is de-                cidable, why not put all the requirements into a model M and then check it? The diﬃculty with this approach is that we are comitting to a lot of detail which doesn’t form part of the model’sconstants. Let φn be the formula expressing that there is a path of length nfrom c to c′. We deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1, for c = 1, we say R( c, x1, x2)  ‘Conjunction’ of all sentences in We seek an extension of predicate logic that can specify suchimportant properties. This can be realized by applying quan-                tiﬁers not only to variables, but also to predicate symbols. For a predicatesymbol P with n ≥1 arguments, consider formulas of the form P φ(2.11) where φ is a formula of logic in which P occurs. Formulas of thatforming are the ones of existential second-order logic. We show that such aform cannot be found in a graph. An example of arity 2 is P (C1, C2, C3, C4) where each Ci is a Horn clause. C4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive. C3 ensures that there is no P-path from u to the node associated to v. Given a model M with interpretations for all function and predicate sym-phthalon logic for computer science, this is what the model should look like. For example, we could think of R and P as two transition relations on a set This foreword is re-printed in the second edition with its author’s permis-                sion. We developed this theme for propositional, temporal, modal, and program logics. At the heart of this set-up is that one can often specify and implement algorithms for computing. I recommend it to the reader                with greatest enthusiasm and predict that the book will be an enormous                success. The book is published by Oxford University Press, London, priced £16.99. For more information on the book, visit the publisher's website or visit the book's website at: http://www.oxford-uk.com/books/computer-science- The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. We conclude this case study by pointing out limitations of Alloy and itsanalyzer. In order to be able to use a SAT solver for propositional logic                as an analysis engine, we can only check or run formulas of existential oruniversal second-order logic. For example, we cannot even check whether there is an instance of a PDS such that for the resulting PDS a certain scheduling policy is                impossible. For less explicit reasons it also seems unlikely that we can check in Alloy that every coherent set of components is realizable as P.components for some PDS. This deﬁciency is due to the inherent complexity of such problems and theorem provers may have to be used. The expressiveness of Alloy allows for rapid prototyping of models and the exploration of simulations. It should enhance once understanding of a design and so improve that design’s reliability. Use the predicates A(x, y) and L(x) to translate the following into predicate logic: Mary admires every professor. Some professor admires Mary. No student attended every lecture. No lecture was attended by any student. The answer is not A(m, P(x).) But it is the answer to the question ‘What is the number of people in the world who attended the most recent lecture?’ And the answer is ‘Mary’. Every football team has a quarterback. Use the predicate speciﬁcations B(x, y) and F(x) to translate the following into predicate logic. For each sequent a model such that all formulas to the left of T and the sole formula to the right of F (explain why this ensures the non-existence of a proof) is the same for T and F. Use these exercises to prove that the logic is sound and complete for ⊨in ﬁrst-order logic. The undecidability of ⊢implies that validity, and provability, and validity are all undecidable for that logic. Use this logic to explain in detail why the und Exercises 2.5 and 2.6: Prove the soundness of our natural deduction rules for predicate logic. Prove that the conclusion of a proof rule is true provided that all its premises are true. Can you precisely formalise the necessary inductive hypothesis for proving soundness? Can you prove that theorem 2.26 from page 138 applies or remains valid if we allow φ to containfunction symbols of any ﬁnite arity? Can we prove that node s3 is reachable from node s2 in Figure 2. 5 from page 137? How many paths are there that witness the reachability of nodes s3 and s2 from each other? Predicates with any number of arguments are possible in predicate logic. Write formulas of existential second-order logic of the form ∃P ψ that hold in all models. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can can’. The first version is closer to the linguistic structure of the sentence above. For the second version, we could code the sentence as: ‘There is some x which is a bird and cannot ﬁy.’ and the third version as follows: “Not all x can be a bird”. In Section 2.3, we extend our natural deduction calculus of propositional progressivelylogic so that it covers logical formulas of predicate logic as well. In this way we are able to prove the validity of sequents φ1, φ2, . . .    .      in the language we use. We will also explain whyhematicallyformulas like the two above are indeed equivalent semantically. The purpose of this section is to explain how such formulas can be given their meaning in general, and why they should be used in software design and in safety-critical systems. The goal is to reason symbolically orsemantically about the information expressed in those formulas. For example, penguins are birds In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicateLogic can be true or false. We also show that Russell’s paradox gives rise to the idea that A has not to be, and cannot be, an element of A. We conclude the book with a list of some of the things we have learned about the theory of predicatelogic in the last few years. We hope that this will provide a useful starting point for the next section of the book, which will focus on the notion of ‘order’ and ‘theory’ of logic. Theorem 2.28 (page 140) relies on the fact that if a binary relation R is contained in a reﬂexive, transitive relation T of the same type, then T also contains the re-transitive closure of R. For the model of Example 2.23 and Figure 2.5 (page 137), determine which model will hold and justify your answer. Prove this by solving the following equations: P(x, y), P(y, z), P (x, z) The relation R is a maximal equivalence relation. All nodes are on at least one R-cycle. There is a smallest relation containing R which is symmetric. Can you identify the set {a, b, c} from Example 2.19 (page 128) with the defs P M′ and QM′? The answer is “Yes’”. The model of Figure 2.11 (page 148) is a counterexample to NoSelfLove in the presence of the fact NoSelf love. is not a relation. The relation R has the identity “R is an equivalence relations;” and there is no relation contained in R that is a relation that is not an equival We have already pointed out the open-ended nature of the semantics of predicate logic. We need only a non-empty set A equipped with concrete functions or elements fM and concrete predicates P M in A which have the right arities agreed upon in our speciﬁcation. But central notions like that of semantic entailment really depend on all possible models, even the ones that don’t seem to make any sense.Apparently there is no way out of this peculiarity.   We also stressed that most models have natural interpretations of                2.2.4. The semantics of equality is discussed in more detail in the section on equality and its consequences. Where would you draw the line between a model that makes sense and one that doesn’t? And would any such choice, or set of criteria, not be subjective? Such constraints could also forbid a modiﬁcation of your model if this alteration were caused by a slight adjustment of the problem domain you intended to model. You see that there are a lot of good reasons for maintaining such a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. Equality is the special role of equality in second-order logic. We discussed itsuctiveproof rule in natural deduction already in Section 2.3.1. The interpretation =M of equality is forced bols in the same formula, we arrive at fully-ﬂedged second- order logic. If one wants to quantify over relations of relations, one gets third-orderLogic etc. Higher-order logics require great care in their design. Typical re-                sults such as completeness and compactness may quickly fail to hold. For example, given A                def= {a, b, c}, the interpretation of equality  is forced  in the formula. A naive higher-order logic may be inconsistent at the meta-level. Re-lated problems We won’t study higher-order logics in this text, but remark that many the-                orem provers or deductive frameworks rely on higher- order logical frame-works. Two of the central concepts developed so far are model checking and semantic entailment. Given a formula φ of predicate logic and a matching model Mdetermine whether M ⊨φ holds; and given a set of formulas Γ, is the formula valid? In the case ofsemantic entailment, φ may be a property we                think should hold in any implementation that meets the requirements of Γ.Semantic entailsment matches well with software speciﬁcation and validateation; alas, it is This foreword is re-printed in the second edition with its author’s permis- purposefullysion. I recommend it to the reader with greatest enthusiasm and predict that the book will be an enormous success. The book is written in the style of a book on computer science. It is published by Oxford University Press, London, priced £16.99. For more information, visit www.oxfordpub.co.uk or visit the book's website at http://www.ox-pub.com/Computer-Science-Logic-for-Computer-science-2.html. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.sam At the heart of this set-up is that one can often specify and implementgorithms for computing. We developed this theme for propos The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. In most object-oriented languages, e.g. Java, extends creates a new type. In Alloy 2.0 and 2.1, it creates a subset of a type. The Greeks and the medievals had systems that could be rep-resented. But nothing that we would recognise as predicate logic emerged until the work of Gottlob Frege in 1879, printed in Frege [Fre03] The book begins with a discus-                5. It now begins with an example of a predicate logic exercise. The book ends with a discussion of the use of predicate logic in the modern computer science field of computer science. The final chapter is a review of the book's bibliographic notes. There are many books covering classical logic and its use in computer sci-                ence. The books [SA91],[vD89] and [Gal87] cover more theoretical applications than those in this book. An account of the contributions of the many other people involved in the development of                logic can be found in the ﬁrst few pages of W. Hodges’ chapter in [Hod83]. The books which study the mathematical aspects of                predicate logic in greater detail, include [Ham78] and  [HOD83]. Most of these books present other proof systems besides natural deduction. Natural deduction has the advantages of elegance and simplicity over axiomatic methods. There are few expositions of it in logic books aimed at a computer science audi-                constants. All formulas in ∆are sentences and are unsatisﬁable, since the ‘conjunction’ of all sentences in   is a contradiction. However, every subset of    is satisﬄable since there are paths of any length. By the Compactness Theorem,  ‘self’ is satis ﬉able, so   ‘n’ can be any number of n, “n”    � We seek an extension of predicate logic that can specify suchimportant properties. This can be realized by applying quan-                tiﬁers not only to variables, but also to predicate symbols. For a predicatesymbol P with n ≥1 arguments, consider formulas of the form P φ(2.11) where φ is a formula of logic in which P occurs. Formulas of thatforming are the ones of existential second-order logic. We show that such aform cannot be found in a graph. An example of arity 2 is P (C1, C2, C3, C4) where each Ci is a Horn clause. C1 states that P is reﬂexive. C2speciﬁes P is transitive. C3 ensures that there is no P-path from u to the node associated to v. C4 says that any R-edge is also a P-edge. We do not have an instance of L(p) which we proved with the full natural calculus. We claim that we claim that L(y) is not in the set L(x) which is not empty. We also claim that p(x, y) is an instance Deﬁnition 5.4 for the case ∨implies that X can hold only if Y holds. But x ⊩¬p simply does not hold, since there is a world y with R(x, y) such that y holds. Theavailability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. We would have to consider every Kripke model with respect to the semantic entailment of LEM. We can prove soundness and completeness of the reduced nat-                ural deduction system. But thoseproofs are beyond the scope of this book. Natural deduction is an extension, respectively adaptation, of the systems of natural deduction met in Chapters 1 and 2. Recall that we presented natural deduction proofs as linear representations of prooftrees which may involve proof boxes. The proof boxes have formulas and/or other boxes inside them. There are rules which dictate how to construct proofs. Boxes open with an assumption; when a box is closed – in accordance with a rule – we say that its assumption is discharged. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. Every formula must have some justiﬁcation to its right. Every rule can be the name of a rule, or the word �                 Floyd, R., 269for-statement, 299                forall-elimination, 109                for all-introduction, 110                formal path, 218                formulaatomic, 175                height, 44, 86                Horn, 65                ill-formed, 177                immediate subformula, 223                of basic modal logic, 314                of CTL, 209                atomic, 208                well-formed. page 13. page 14. page 15. page 16. page 17. page 18. page 19. page 20. page 21. page 22. page 23. page 24. page 25. page 26. page 27. page 28. page 29. page 30. We saw in the preceding section that there appeared to be a correspondence between the validity of 2 φ and the property that the accessibility re-                lation R is reﬂexive. A. R., 264, 269                Hodges, W., 170                Horn clause, 65, 139                hybrid rule, 343if-statement, 280implementationCompliant, 143                implication, 4logical, 278                implies-elimination, 9                implie-introduction, 12                in-order representation, 35                inconsistency, 259                index, 132                course-of-values, 43                hypothesis. There is a precise mathematical relation-ship between these formulas and properties of R. The connection between them is that both relied on the intuition that anything which is known by an agent is true. From the point of view of logicengineering, it is important to see this relationship, because it helps one to understand the logic being studied. For example, if you believe that a formula scheme should be accepted in the system of modal logic, then it is well worth looking at the corresponding property of R and checking that this property makes sense for the application, too. The relationship between R and the formula scheme is called the R-scheme relation, and can be seen in the next section of the book. A frame F = (W, R) is a set W of worlds and a binaryrelation R on W. A frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-                belling function. From any model we can extract a frame, by just forgetting about the labelling function. Figure 5.9 shows the frame ex-                tracted from the K Ripke model of Figure 5,3. It has no information about what atomic formulas are true at the various worlds. However, it is useful to say sometimes that the frame, as a whole, satis ﬁes a formula. This is deﬀned as follows. In practice not all functional or other requirements of a software system are known in advance. For example, we may not know how many states there will be; and some transitions may be mandatory whereas others may be optional in an implementation. Conceptually, we seek a description M of all compliant2.7 Micromodels of software systems. Given some matchingproperty ψ, we then want to know whether ψ holds in all implementations Mi (i) of some software system. We call this model M. Model M is concrete since there is nothing left left that is un-speciﬁed and all checks M ⊨φ have de-species answers. If M consists of a single model, then checking properties would be decidable. A single model is not general enough. It would instantiate parameters which are not part of the requirements of a state machine. A better idea is to check whether all models of that size that satisfy the requirements also satisfy the property under consideration. If we get a positive answer, we are somewhat conﬁdent that the property holds in all models. We conclude that M is the set of all state machines, and that checking properties on M would be undecidable, and would at least be intractable. If M is a set of models, we conclude that it is not a model at all. Alloy identiﬁes elements a with singleton sets {a), so this set intersection is well typed. The relational dot operator . enables access to the internal components of a state machine: M.i is the initial state of M and M.F is its set. In this case, the answer is not conclusive, because there could be a larger model which fails the property, but nevertheless a positive answer gives                us some con ﬁdence. For all models M of type StateMachine the property no M. i & M. F is true. For example, there is no S for ‘set S is empty� Alloy’s GUI lets you search for additional witnesses (here: counterexamples), if they exist. We can check a property of state machines for consistency with our model. The transition relation is shown as a labeled graph and there is only one transition (from State 0 back to State 0) in this exam-                ple. Please verify that this is a countereXample to the claim of the assertion emphaticallyFinalNotInitial within the speciﬁed scopes. The results of Alloy's assertion check are shown in Figure 2.7. The check directive informs theanalyzer of Alloy that it should try to ﬁnd a countrexample of the assertions with at most three elements for The software captures formally static and dynamic system structure and behaviour. It can verify consistency of the constrained design space. It is executable, so it allows guided simulations through a potentially very com-plex design space; and. it can boost our conﬁdence into the correctness of claims about static andynamic aspects of all its compliant implementations. e.g. run AGiudedSimulation for 3 but 1 StateMachine on a 3 but one StateMachine. The software can be seen as a contract between software developers and the users of the software. It promises that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬃed therein. We model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to seeif prerequisites in the form of libraries or other packages are present. Software package dependency systems are used in several computer sys- grotesquetems, such as Red Hat Linux, .NET’s Global Assembly Cache and others. For more information on the model, or to download a copy of the code, visit: http://www.researchers.com/software-package-dependency-systems-models/v2.0/v3.0-v3/Software-Package-Dependency System. In our model, applications are built out of components. A service can be a number of things. To the best of our knowledge, there is no publicly available model of any particular dependency system to which programmers could turn if they had such non-trivial technicalquestions about its inner workings. Conceptually, we seek a description M of all compliant compliant 2.7 Micromodels of software systems Mi (i ∈I) of some software system. In practice not all functional or other requirements of a software system are known in advance. For example, we may not know how many states there will be; and some transitions may be mandatory whereas others may be optional in an implementation. If M is the set of all concrete models of state machines, then checking properties would be decidable. But a single model is not general enough. It would instantiate parameters which are not part of the requirements of a state machine, such as its size and detailed construction. For example, a possible assertion check ψ is ‘Final states are never initial states’ or ‘There are state machines that contain a non-ﬁnal but deadlocked state’. If M is a single set of models, then the properties would risk being undecidable, and would at least be intractable. But if it is a set of multiple models, the properties are decidable and would be general. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things. Typically, a service is a method (a modular piece of program code), a ﬁeld entry, or a type – e.g. ‘ruby’ or ‘synthesized’. We can test this by checking whether all models of that size that satisfy the requirements also satisfy the property under consideration. If we get a positive answer, we are somewhat conﬁdent that the property holds                in all models. A component is. the type of a class in an object-oriented programming language. It also has a name and may have a special service, called ‘main.’ We model components as a signature in Alloy. The signatures Service and Name won’t require any composite structure for modelling purposes. The signature of a component is the name of the component, and the version number of that component. It is not possible to import or export a component without creating a new component. The component signature is: component.name: Name, component.main: option Service, -- component may. have a � A component is an instance of Component and therefore has a name, a set of services export it oﬀers to other components, and a set import of services it needs to import from other components. A component also has a version number. A declaration i : set S means that i is a subset of set S with at most one element. An option enables us to model an element that may (non-empty, sin-gleton set) or may not (empty set) be present. In P’ we have the same Scheduler instances as in PDS 0. Yet P�’’ schedules Component 2 to provide service Service 2 for Component 0; and Component 0 still provides service Service 1 to Component 1. Since Service 2 is contained in Component 2.export, we have two legitimate post states which are obtained by addingComponent 2 but which diﬀer in their scheduler. This is a very useful ability indeed. The utility of a micromodel of software resides perhaps more in the ability to explore it through guided simulations. We demonstrate this by generating a simulation that shows the removal and the addition of a component to a PDS. The addition ofcomponents creates opportunities to reschedule services, for better (e.g.optimizations) or for worse (e.,g. security breaches). We know that such a schedul-ing policy is consistent for these two operations. It is by no means the only such policy and is not guaranteed to ensure that applications won’t break using scheduled services. The fun-statement                fun HighestVersionPolicy(P: PDS) {.with P {all s : Service, c : components, c’ : c.schedule[s],                c’’: components - c' {. exporting && c�’.name = c‘.name;. importing && c'.version.^(Ord[Number].prev) }. run Highest version policy for 3 but not 1 PDS. The expression                c'.versions is the version number of c', an element of the type Number.",
            "children": [
                {
                    "id": "chapter-2-section-1",
                    "title": "The Need for a Richer Language",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-2-section-2",
                    "title": "Predicate Logic as a Formal Language",
                    "content": "made concrete. There are two principal such occurrences:\n1.\nIn our example in Figure 2.1, we have three leaf nodes x. If we walk up the\ntree beginning at any one of these x leaves, we run into the quantiﬁer ∀x. This\nmeans that those occurrences of x are actually bound to ∀x so they represent,\nor stand for, any possible value of x.\n2.\nIn walking upwards, the only quantiﬁer that the leaf node y runs into is ∀x but\nthat x has nothing to do with y; x and y are diﬀerent place holders. So y is free\nin this formula. This means that its value has to be speciﬁed by some additional\ninformation, for example, the contents of a location in memory.\nDeﬁnition 2.6 Let φ be a formula in predicate logic. An occurrence of x\nin φ is free in φ if it is a leaf node in the parse tree of φ such that there\nis no path upwards from that node x to a node ∀x or ∃x. Otherwise, that\noccurrence of x is called bound. For ∀x φ, or ∃x φ, we say that φ – minus\nany of φ’s subformulas ∃x ψ, or ∀x ψ – is the scope of ∀x, respectively ∃x.\nThus, if x occurs in φ, then it is bound if, and only if, it is in the scope of\nsome ∃x or some ∀x; otherwise it is free. In terms of parse trees, the scope\nof a quantiﬁer is just its subtree, minus any subtrees which re-introduce a\n104\n2 Predicate logic\n→\n∀x\n∨\n∧\n¬\nQ\nP\nQ\nP\ny\nx\nx\nx\nfree\nfree\nbound\nbound\nFigure 2.2. A parse tree of a predicate logic formula illustrating free\nand bound occurrences of variables.\nquantiﬁer for x; e.g. the scope of ∀x in ∀x (P(x) →∃x Q(x)) is P(x). It is\nquite possible, and common, that a variable is bound and free in a formula.\nConsider the formula\n(∀x (P(x) ∧Q(x))) →(¬P(x) ∨Q(y))\nand its parse tree in Figure 2.2. The two x leaves in the subtree of ∀x are\nbound since they are in the scope of ∀x, but the leaf x in the right subtree of\n→is free since it is not in the scope of any quantiﬁer ∀x or ∃x. Note, however,\nthat a single leaf either is under the scope of a quantiﬁer, or it isn’t. Hence\nbound since they are in the scope of ∀x, but the leaf x in the right subtree of\n→is free since it is not in the scope of any quantiﬁer ∀x or ∃x. Note, however,\nthat a single leaf either is under the scope of a quantiﬁer, or it isn’t. Hence\nindividual occurrences of variables are either free or bound, never both at\nthe same time.\n2.2.4 Substitution\nVariables are place holders so we must have some means of replacing them\nwith more concrete information. On the syntactic side, we often need to\nreplace a leaf node x by the parse tree of an entire term t. Recall from the\ndeﬁnition of formulas that any replacement of x may only be a term; it\ncould not be a predicate expression, or a more complex formula, for x serves\nas a term to a predicate symbol one step higher up in the parse tree (see\nDeﬁnition 2.1 and the grammar in (2.2)). In substituting t for x we have to\n2.2 Predicate logic as a formal language\n105\nleave untouched the bound leaves x since they are in the scope of some ∃x\nor ∀x, i.e. they stand for some unspeciﬁed or all values respectively.\nDeﬁnition 2.7 Given a variable x, a term t and a formula φ we deﬁne φ[t/x]\nto be the formula obtained by replacing each free occurrence of variable x\nin φ with t.\nSubstitutions are easily understood by looking at some examples. Let f be a\nfunction symbol with two arguments and φ the formula with the parse tree\nin Figure 2.1. Then f(x, y) is a term and φ[f(x, y)/x] is just φ again. This\nis true because all occurrences of x are bound in φ, so none of them gets\nsubstituted.\nNow consider φ to be the formula with the parse tree in Figure 2.2. Here\nwe have one free occurrence of x in φ, so we substitute the parse tree of\nf(x, y) for that free leaf node x and obtain the parse tree in Figure 2.3.\nNote that the bound x leaves are unaﬀected by this operation. You can see\nthat the process of substitution is straightforward, but requires that it be\napplied only to the free occurrences of the variable to be substituted.",
                    "summary": "In our example in Figure 2.1, we have three leaf nodes x. If we walk up the tree beginning at any one of these x leaves, we run into the quantiﬁer ∀x. This means that those occurrences of x are actually bound to   so they represent, or stand for, any possible value of x. There are two principal such occurrences: 1. made concrete and 2. free in a formula in predicate logic. For example, in the example above, x has nothing to do with y; x and y are diﬀerent place holders. So y is free in this formula, but its value has to be speci ﬁed by some additional information. In terms of parse trees, the scopeof a quantiﬁer is just its subtree, minus any subtrees which re-introduce a variable. If x occurs in φ, then it is bound if, and only if, it is in the scope of some of φ’s subformulas. It isquite possible, and common, that a variable is bound and free in a formula. Figure 2.2.2 shows a parse tree of a predicate logic formula illustrating free and bound occurrences of variables. The two x leaves in the subtree of ∀x are bound since they are in thescope of the formula. The leaf x in the right subtree is free since it is A single leaf either is under the scope of a quantiﬁer, or it isn’t. Note, however, that individual occurrences of variables are either free or bound, never both at the same time.2.4 Substitution. Variables are place holders so we must have some means of replacing them with more concrete information. On the syntactic side, we often need to replace a leaf node x by the parse tree of an entire term t. Recall that any replacement of x may only be a term; it could not be a predicate expression, or a more complex formula, for x serves as a term to a predicate symbol one step higher up in the parsing tree. Deﬁnition 2.7 given a variable x, a term t and a formula φ. We replace each free occurrence of variable x in φ with t. In substituting t for x we have to leave untouched the bound leaves x. This is true because all occurrences of x are bound in the formula, so none of them getssubstituted. The bound x leaves are unaﬀected by this operation. The parse tree of f(x, y) for that free leaf node x and obtain the parse tree in Figure 2.3. For example, in Figure 1.1 we substitute f(y, x) for x and get f(Y,x) in Figure The process of substitution is straightforward, but requires that it be applied only to the free occurrences of the variable to be substituted",
                    "children": [
                        {
                            "id": "chapter-2-section-2-subsection-1",
                            "title": "Terms",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-2-subsection-2",
                            "title": "Formulas",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-2-subsection-3",
                            "title": "Free and Bound Variables",
                            "content": "made concrete. There are two principal such occurrences:\n1.\nIn our example in Figure 2.1, we have three leaf nodes x. If we walk up the\ntree beginning at any one of these x leaves, we run into the quantiﬁer ∀x. This\nmeans that those occurrences of x are actually bound to ∀x so they represent,\nor stand for, any possible value of x.\n2.\nIn walking upwards, the only quantiﬁer that the leaf node y runs into is ∀x but\nthat x has nothing to do with y; x and y are diﬀerent place holders. So y is free\nin this formula. This means that its value has to be speciﬁed by some additional\ninformation, for example, the contents of a location in memory.\nDeﬁnition 2.6 Let φ be a formula in predicate logic. An occurrence of x\nin φ is free in φ if it is a leaf node in the parse tree of φ such that there\nis no path upwards from that node x to a node ∀x or ∃x. Otherwise, that\noccurrence of x is called bound. For ∀x φ, or ∃x φ, we say that φ – minus\nany of φ’s subformulas ∃x ψ, or ∀x ψ – is the scope of ∀x, respectively ∃x.\nThus, if x occurs in φ, then it is bound if, and only if, it is in the scope of\nsome ∃x or some ∀x; otherwise it is free. In terms of parse trees, the scope\nof a quantiﬁer is just its subtree, minus any subtrees which re-introduce a\n104\n2 Predicate logic\n→\n∀x\n∨\n∧\n¬\nQ\nP\nQ\nP\ny\nx\nx\nx\nfree\nfree\nbound\nbound\nFigure 2.2. A parse tree of a predicate logic formula illustrating free\nand bound occurrences of variables.\nquantiﬁer for x; e.g. the scope of ∀x in ∀x (P(x) →∃x Q(x)) is P(x). It is\nquite possible, and common, that a variable is bound and free in a formula.\nConsider the formula\n(∀x (P(x) ∧Q(x))) →(¬P(x) ∨Q(y))\nand its parse tree in Figure 2.2. The two x leaves in the subtree of ∀x are\nbound since they are in the scope of ∀x, but the leaf x in the right subtree of\n→is free since it is not in the scope of any quantiﬁer ∀x or ∃x. Note, however,\nthat a single leaf either is under the scope of a quantiﬁer, or it isn’t. Hence\nbound since they are in the scope of ∀x, but the leaf x in the right subtree of\n→is free since it is not in the scope of any quantiﬁer ∀x or ∃x. Note, however,\nthat a single leaf either is under the scope of a quantiﬁer, or it isn’t. Hence\nindividual occurrences of variables are either free or bound, never both at\nthe same time.\n2.2.4 Substitution\nVariables are place holders so we must have some means of replacing them\nwith more concrete information. On the syntactic side, we often need to\nreplace a leaf node x by the parse tree of an entire term t. Recall from the\ndeﬁnition of formulas that any replacement of x may only be a term; it\ncould not be a predicate expression, or a more complex formula, for x serves\nas a term to a predicate symbol one step higher up in the parse tree (see\nDeﬁnition 2.1 and the grammar in (2.2)). In substituting t for x we have to\n2.2 Predicate logic as a formal language\n105\nleave untouched the bound leaves x since they are in the scope of some ∃x\nor ∀x, i.e. they stand for some unspeciﬁed or all values respectively.\nDeﬁnition 2.7 Given a variable x, a term t and a formula φ we deﬁne φ[t/x]\nto be the formula obtained by replacing each free occurrence of variable x\nin φ with t.\nSubstitutions are easily understood by looking at some examples. Let f be a\nfunction symbol with two arguments and φ the formula with the parse tree\nin Figure 2.1. Then f(x, y) is a term and φ[f(x, y)/x] is just φ again. This\nis true because all occurrences of x are bound in φ, so none of them gets\nsubstituted.\nNow consider φ to be the formula with the parse tree in Figure 2.2. Here\nwe have one free occurrence of x in φ, so we substitute the parse tree of\nf(x, y) for that free leaf node x and obtain the parse tree in Figure 2.3.\nNote that the bound x leaves are unaﬀected by this operation. You can see\nthat the process of substitution is straightforward, but requires that it be\napplied only to the free occurrences of the variable to be substituted.",
                            "summary": "In our example in Figure 2.1, we have three leaf nodes x. If we walk up the tree beginning at any one of these x leaves, we run into the quantiﬁer ∀x. This means that those occurrences of x are actually bound to   so they represent, or stand for, any possible value of x. There are two principal such occurrences: 1. made concrete and 2. free in a formula in predicate logic. For example, in the example above, x has nothing to do with y; x and y are diﬀerent place holders. So y is free in this formula, but its value has to be speci ﬁed by some additional information. In terms of parse trees, the scopeof a quantiﬁer is just its subtree, minus any subtrees which re-introduce a variable. If x occurs in φ, then it is bound if, and only if, it is in the scope of some of φ’s subformulas. It isquite possible, and common, that a variable is bound and free in a formula. Figure 2.2.2 shows a parse tree of a predicate logic formula illustrating free and bound occurrences of variables. The two x leaves in the subtree of ∀x are bound since they are in thescope of the formula. The leaf x in the right subtree is free since it is A single leaf either is under the scope of a quantiﬁer, or it isn’t. Note, however, that individual occurrences of variables are either free or bound, never both at the same time.2.4 Substitution. Variables are place holders so we must have some means of replacing them with more concrete information. On the syntactic side, we often need to replace a leaf node x by the parse tree of an entire term t. Recall that any replacement of x may only be a term; it could not be a predicate expression, or a more complex formula, for x serves as a term to a predicate symbol one step higher up in the parsing tree. Deﬁnition 2.7 given a variable x, a term t and a formula φ. We replace each free occurrence of variable x in φ with t. In substituting t for x we have to leave untouched the bound leaves x. This is true because all occurrences of x are bound in the formula, so none of them getssubstituted. The bound x leaves are unaﬀected by this operation. The parse tree of f(x, y) for that free leaf node x and obtain the parse tree in Figure 2.3. For example, in Figure 1.1 we substitute f(y, x) for x and get f(Y,x) in Figure The process of substitution is straightforward, but requires that it be applied only to the free occurrences of the variable to be substituted",
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-2-subsection-4",
                            "title": "Substitution",
                            "content": "",
                            "summary": null,
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-2-section-3",
                    "title": "Proof Theory of Predicate Logic",
                    "content": "1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\n1.2.3 Natural deduction in summary\nThe proof rules for natural deduction are summarised in Figure 1.2. The\nexplanation of the rules we have given so far in this chapter is declarative;\nwe have presented each rule and justiﬁed it in terms of our intuition about\nthe logical connectives. However, when you try to use the rules yourself,\nyou’ll ﬁnd yourself looking for a more procedural interpretation; what does\na rule do and how do you use it? For example,\nr ∧i says: to prove φ ∧ψ, you must ﬁrst prove φ and ψ separately and then use\nthe rule ∧i.\nr ∧e1 says: to prove φ, try proving φ ∧ψ and then use the rule ∧e1. Actually,\nthis doesn’t sound like very good advice because probably proving φ ∧ψ will\nbe harder than proving φ alone. However, you might ﬁnd that you already have\nφ ∧ψ lying around, so that’s when this rule is useful. Compare this with the\nexample sequent in Example 1.15.\nr ∨i1 says: to prove φ ∨ψ, try proving φ. Again, in general it is harder to prove\nφ than it is to prove φ ∨ψ, so this will usually be useful only if you’ve already\nmanaged to prove φ. For example, if you want to prove q |−p ∨q, you certainly\nwon’t be able simply to use the rule ∨i1, but ∨i2 will work.\nr ∨e has an excellent procedural interpretation. It says: if you have φ ∨ψ, and you\nwant to prove some χ, then try to prove χ from φ and from ψ in turn. (In those\nsubproofs, of course you can use the other prevailing premises as well.)\nr Similarly, →i says, if you want to prove φ →ψ, try proving ψ from φ (and the\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nour reasoning is concerned about the inference, and therefore the preserva-\ntion, of truth. Hence, there cannot be a direct way of inferring ¬φ, given\nφ.\nDeﬁnition 1.19 Contradictions are expressions of the form φ ∧¬φ or ¬φ ∧\nφ, where φ is any formula.\nExamples of such contradictions are r ∧¬r, (p →q) ∧¬(p →q) and ¬(r ∨\ns →q) ∧(r ∨s →q). Contradictions are a very important notion in logic.\nAs far as truth is concerned, they are all equivalent; that means we should\nbe able to prove the validity of\n¬(r ∨s →q) ∧(r ∨s →q) ⊣⊢(p →q) ∧¬(p →q)\n(1.2)\nsince both sides are contradictions. We’ll be able to prove this later, when\nwe have introduced the rules for negation.\nIndeed, it’s not just that contradictions can be derived from contradic-\ntions; actually, any formula can be derived from a contradiction. This can be\n1.2 Natural deduction\n21\nconfusing when you ﬁrst encounter it; why should we endorse the argument\np ∧¬p ⊢q, where\np : The moon is made of green cheese.\nq : I like pepperoni on my pizza.\nconsidering that our taste in pizza doesn’t have anything to do with the\nconstitution of the moon? On the face of it, such an endorsement may seem\nabsurd. Nevertheless, natural deduction does have this feature that any for-\nmula can be derived from a contradiction and therefore it makes this argu-\nment valid. The reason it takes this stance is that ⊢tells us all the things\nwe may infer, provided that we can assume the formulas to the left of it.\nThis process does not care whether such premises make any sense. This has\nat least the advantage that we can match ⊢to checks based on semantic\nintuitions which we formalise later by using truth tables: if all the premises\ncompute to ‘true’, then the conclusion must compute ‘true’ as well. In partic-\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nan implication. Suppose that p →q and ¬q are the case. Then, if p holds\nwe can use →e to conclude that q holds. Thus, we then have that q and ¬q\nhold, which is impossible. Therefore, we may infer that p must be false. But\nthis can only mean that ¬p is true. We summarise this reasoning into the\nrule modus tollens, or MT for short:5\nφ →ψ\n¬ψ\n¬φ\nMT.\nAgain, let us see an example of this rule in the natural language setting:\n‘If Abraham Lincoln was Ethiopian, then he was African. Abraham\nLincoln was not African; therefore he was not Ethiopian.’\nExample 1.7 In the following proof of\np →(q →r), p, ¬r ⊢¬q\nwe use several of the rules introduced so far:\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq →r\n→e 1, 2\n5\n¬q\nMT 4, 3\n5 We will be able to derive this rule from other ones later on, but we introduce it here because it\nallows us already to do some pretty slick proofs. You may think of this rule as one on a higher\nlevel insofar as it does not mention the lower-level rules upon which it depends.\n1.2 Natural deduction\n11\nExamples 1.8 Here are two example proofs which combine the rule MT\nwith either ¬¬e or ¬¬i:\n1\n¬p →q\npremise\n2\n¬q\npremise\n3\n¬¬p\nMT 1, 2\n4\np\n¬¬e 3\nproves that the sequent ¬p →q, ¬q ⊢p is valid; and\n1\np →¬q\npremise\n2\nq\npremise\n3\n¬¬q\n¬¬i 2\n4\n¬p\nMT 1, 3\nshows the validity of the sequent p →¬q, q ⊢¬p.\nNote that the order of applying double negation rules and MT is diﬀerent\nin these examples; this order is driven by the structure of the particular\nsequent whose validity one is trying to show.\nThe rule implies introduction\nThe rule MT made it possible for us to\nshow that p →q, ¬q ⊢¬p is valid. But the validity of the sequent p →q ⊢\n¬q →¬p seems just as plausible. That sequent is, in a certain sense, saying\nthe same thing. Yet, so far we have no rule which builds implications that\ndo not already occur as premises in our proofs. The mechanics of such a rule\nare more involved than what we have seen so far. So let us proceed with quantiﬁcation. Now we want to provide formal proofs for some of the most\ncommonly used quantiﬁer equivalences. Quite a few of them involve several\nquantiﬁcations over more than just one variable. Thus, this topic is also\ngood practice for using the proof rules for quantiﬁers in a nested fashion.\nFor example, the formula ∀x ∀y φ should be equivalent to ∀y ∀x φ since\nboth say that φ should hold for all values of x and y. What about (∀x φ) ∧\n(∀x ψ) versus ∀x (φ ∧ψ)? A moment’s thought reveals that they should have\nthe same meaning as well. But what if the second conjunct does not start\nwith ∀x? So what if we are looking at (∀x φ) ∧ψ in general and want to\ncompare it with ∀x (φ ∧ψ)? Here we need to be careful, since x might be\nfree in ψ and would then become bound in the formula ∀x (φ ∧ψ).\nExample 2.12 We may specify ‘Not all birds can ﬂy.’ as ¬∀x (B(x) →\nF(x)) or as ∃x (B(x) ∧¬F(x)). The former formal speciﬁcation is closer\nto the structure of the English speciﬁcation, but the latter is logically equiv-\nalent to the former. Quantiﬁer equivalences help us in establishing that\nspeciﬁcations that ‘look’ diﬀerent are really saying the same thing.\nHere are some quantiﬁer equivalences which you should become familiar\nwith. As in Chapter 1, we write φ1 ⊣⊢φ2 as an abbreviation for the validity\nof φ1 ⊢φ2 and φ2 ⊢φ1.\nTheorem 2.13 Let φ and ψ be formulas of predicate logic. Then we have\nthe following equivalences:\n1.\n(a) ¬∀x φ ⊣⊢∃x ¬φ\n(b) ¬∃x φ ⊣⊢∀x ¬φ.\n2.\nAssuming that x is not free in ψ:\n118\n2 Predicate logic\n(a) ∀x φ ∧ψ ⊣⊢∀x (φ ∧ψ)3\n(b) ∀x φ ∨ψ ⊣⊢∀x (φ ∨ψ)\n(c) ∃x φ ∧ψ ⊣⊢∃x (φ ∧ψ)\n(d) ∃x φ ∨ψ ⊣⊢∃x (φ ∨ψ)\n(e) ∀x (ψ →φ) ⊣⊢ψ →∀x φ\n(f) ∃x (φ →ψ) ⊣⊢∀x φ →ψ\n(g) ∀x (φ →ψ) ⊣⊢∃x φ →ψ\n(h) ∃x (ψ →φ) ⊣⊢ψ →∃x φ.\n3.\n(a) ∀x φ ∧∀x ψ ⊣⊢∀x (φ ∧ψ)\n(b) ∃x φ ∨∃x ψ ⊣⊢∃x (φ ∨ψ).\n4.\n(a) ∀x ∀y φ ⊣⊢∀y ∀x φ\n(b) ∃x ∃y φ ⊣⊢∃y ∃x φ.\nPROOF: We will prove most of these sequents; the proofs for the remaining\nones are straightforward adaptations and are left as exercises. Recall that\nand necessary requirements for any sane concept of (extensional) equality.\nWe leave the topic of equality for now to move on to the proof rules for\nquantiﬁers.\nThe proof rules for universal quantification\nThe rule for eliminat-\ning ∀is the following:\n∀x φ\nφ[t/x]\n∀x e.\nIt says: If ∀x φ is true, then you could replace the x in φ by any term t\n(given, as usual, the side condition that t be free for x in φ) and conclude\nthat φ[t/x] is true as well. The intuitive soundness of this rule is self-evident.\nRecall that φ[t/x] is obtained by replacing all free occurrences of x in φ\nby t. You may think of the term t as a more concrete instance of x. Since φ\nis assumed to be true for all x, that should also be the case for any term t.\nExample 2.11 To see the necessity of the proviso that t be free for x in\nφ, consider the case that φ is ∃y (x < y) and the term to be substituted\nfor x is y. Let’s suppose we are reasoning about numbers with the usual\n‘smaller than’ relation. The statement ∀x φ then says that for all numbers\nn there is some bigger number m, which is indeed true of integers or real\nnumbers. However, φ[y/x] is the formula ∃y (y < y) saying that there is a\nnumber which is bigger than itself. This is wrong; and we must not allow a\nproof rule which derives semantically wrong things from semantically valid\n110\n2 Predicate logic\nones. Clearly, what went wrong was that y became bound in the process of\nsubstitution; y is not free for x in φ. Thus, in going from ∀x φ to φ[t/x],\nwe have to enforce the side condition that t be free for x in φ: use a fresh\nvariable for y to change φ to, say, ∃z (x < z) and then apply [y/x] to that\nformula, rendering ∃z (y < z).\nThe rule ∀x i is a bit more complicated. It employs a proof box similar\nto those we have already seen in natural deduction for propositional logic,\nbut this time the box is to stipulate the scope of the ‘dummy variable’ x0\nrather than the scope of an assumption. The rule ∀x i is written\nx0\n...\nφ[x0/x]\n∀x φ\n∀x i.\nVerify that these sequents express the argument above in a symbolic form.\nPredicate logic extends propositional logic not only with quantiﬁers but\nwith one more concept, that of function symbols. Consider the declarative\nsentence\nEvery child is younger than its mother.\n2.1 The need for a richer language\n97\nUsing predicates, we could express this sentence as\n∀x ∀y (C(x) ∧M(y, x) →Y (x, y))\nwhere C(x) means that x is a child, M(x, y) means that x is y’s mother\nand Y (x, y) means that x is younger than y. (Note that we actually used\nM(y, x) (y is x’s mother), not M(x, y).) As we have coded it, the sentence\nsays that, for all children x and any mother y of theirs, x is younger than y.\nIt is not very elegant to say ‘any of x’s mothers’, since we know that every\nindividual has one and only one mother1. The inelegance of coding ‘mother’\nas a predicate is even more apparent if we consider the sentence\nAndy and Paul have the same maternal grandmother.\nwhich, using ‘variables’ a and p for Andy and Paul and a binary predicate\nM for mother as before, becomes\n∀x ∀y ∀u ∀v (M(x, y) ∧M(y, a) ∧M(u, v) ∧M(v, p) →x = u).\nThis formula says that, if y and v are Andy’s and Paul’s mothers, respec-\ntively, and x and u are their mothers (i.e. Andy’s and Paul’s maternal grand-\nmothers, respectively), then x and u are the same person. Notice that we\nused a special predicate in predicate logic, equality; it is a binary predicate,\ni.e. it takes two arguments, and is written =. Unlike other predicates, it is\nusually written in between its arguments rather than before them; that is,\nwe write x = y instead of = (x, y) to say that x and y are equal.\nThe function symbols of predicate logic give us a way of avoiding this\nugly encoding, for they allow us to represent y’s mother in a more direct\nway. Instead of writing M(x, y) to mean that x is y’s mother, we simply\nwrite m(y) to mean y’s mother. The symbol m is a function symbol: it takes\n(a) ∃x.(x′ ↔(y + y′ · x))\n(b) ∀x.(x′ ↔(y + y′ · x))\n(c) ∃x′.(x′ ↔(y + y′ · x))\n(d) ∀x′.(x′ ↔(y + y′ · x)).\n5. Let ρ be a valuation with ρ(x′\n1) = 1 and ρ(x′\n2) = 0. Determine whether ρ ⊨f\nholds for the following:\n(a) x1[ˆx := ˆx′]\n(b) (x1 + x2)[ˆx := ˆx′]\n(c) (x1 · x2)[ˆx := ˆx′].\n6. Evaluate ρ ⊨(∃x1.(x1 + x2))[ˆx := ˆx′] and explain how the valuation ρ changes\nin that process. In particular, [ˆx := ˆx′] replaces xi by x′\ni, but why does this not\ninterfere with the binding quantiﬁer ∃x1?\n410\n6 Binary decision diagrams\n7. (a) How would you deﬁne the notion of semantic entailment for the relational\nmu-calculus?\n(b) Deﬁne formally when two formulas of the relational mu-calculus are seman-\ntically equivalent.\nExercises 6.15\n1. Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)\nholds, where ρ is\n(a) (x1, x2) ⇒(1, 0)\n(b) (x1, x2) ⇒(0, 1)\n(c) (x1, x2) ⇒(0, 0).\n2. Let S be {s0, s1}, with s0 →s0, s0 →s1 and s1 →s0 as possible transitions\nand L(s0) = {x1} and L(s1) = ∅. Compute the boolean function f EX (EX ¬x1).\n3. Equations (6.17) (page 395), (6.19) and (6.20) deﬁne f EF φ, f AF φ and f EG φ.\nWrite down a similar equation to deﬁne f AG φ.\n4. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately.\n5. Mimic the example checks on page 396 for the connective AU: consider the\nmodel of Figure 6.24 (page 384). Since [[E[(x1 ∨x2) U (¬x1 ∧¬x2)]]] equals the\nentire state set {s0, s1, s2}, your coding of f E[x1∨x2U¬x1∧¬x2] is correct if it\ncomputes 1 for all bit vectors diﬀerent from (1, 1).\n(a) Verify that your coding is indeed correct.\n(b) Find a boolean formula without ﬁxed points which is semantically equiva-\nlent to f E[(x1∨x2)U(¬x1∧¬x2)].\n6. (a) Use (6.20) on page 395 to compute f EG ¬x1 for the model in Figure 6.24.\n(b) Show that f EG ¬x1 faithfully models the set of all states which satisfy\nEG ¬x1.\n7. In the grammar (6.10) for the relational mu-calculus on page 390, it was stated\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nx\ny\nS\nQ\n∧\nFigure 2.4. A parse tree for which a substitution has dire consequences.\n2.3 Proof theory of predicate logic\n2.3.1 Natural deduction rules\nProofs in the natural deduction calculus for predicate logic are similar to\nthose for propositional logic in Chapter 1, except that we have new proof\nrules for dealing with the quantiﬁers and with the equality symbol. Strictly\nspeaking, we are overloading the previously established proof rules for the\npropositional connectives ∧, ∨etc. That simply means that any proof rule\nof Chapter 1 is still valid for logical formulas of predicate logic (we origi-\nnally deﬁned those rules for logical formulas of propositional logic). As in\nthe natural deduction calculus for propositional logic, the additional rules\nfor the quantiﬁers and equality will come in two ﬂavours: introduction and\nelimination rules.\nThe proof rules for equality\nFirst, let us state the proof rules for\nequality. Here equality does not mean syntactic, or intensional, equality,\nbut equality in terms of computation results. In either of these senses, any\nterm t has to be equal to itself. This is expressed by the introduction rule\nfor equality:\nt = t\n=i\n(2.5)\nwhich is an axiom (as it does not depend on any premises). Notice that it\n108\n2 Predicate logic\nmay be invoked only if t is a term, our language doesn’t permit us to talk\nabout equality between formulas.\nThis rule is quite evidently sound, but it is not very useful on its own.\nWhat we need is a principle that allows us to substitute equals for equals\nrepeatedly. For example, suppose that y ∗(w + 2) equals y ∗w + y ∗2; then\nit certainly must be the case that z ≥y ∗(w + 2) implies z ≥y ∗w + y ∗2\nand vice versa. We may now express this substitution principle as the rule\n=e:\nt1 = t2\nφ[t1/x]\nφ[t2/x]\n=e.\nNote that t1 and t2 have to be free for x in φ, whenever we want to apply\nthe rule =e; this is an example of a side condition of a proof rule.\nConvention 2.10 Throughout this section, when we write a substitution\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\n2(φ ∧ψ) ≡2φ ∧2ψ and 3(φ ∨ψ) ≡3φ ∨3ψ.\nThese equivalences correspond closely to the quantiﬁer equivalences dis-\ncussed in Section 2.3.2. It is also not surprising to ﬁnd that 2 does not\ndistribute over ∨and 3 does not distribute over ∧, i.e. we do not have equiv-\nalences between 2(φ ∨ψ) and 2φ ∨2ψ, or between 3(φ ∧ψ) and 3φ ∧3ψ.\nFor example, in the fourth item of Example 5.6 we had x5 ⊩2(p ∨q) and\nx5 ̸⊩2p ∨2q.\nNote that 2⊤is equivalent to ⊤, but not to 3⊤, as we saw earlier.\nSimilarly, 3⊥≡⊥but they are not equivalent to 2⊥.\nAnother equivalence is 3⊤≡2p →3p. For suppose x ⊩3⊤– i.e. x has\nan accessible world, say y – and suppose x ⊩2p; then y ⊩p, so x ⊩3p.\nConversely, suppose x ⊩2p →3p; we must show it satisﬁes 3⊤. Let us\ndistinguish between the cases x ⊩2p and x ̸⊩2p; in the former, we get\nx ⊩3p from x ⊩2p →3p and so x must have an accessible world; and in\nthe latter, x must again have an accessible world in order to avoid satisfying\n2p. Either way, x has an accessible world, i.e. satisﬁes 3⊤. Naturally, this\nargument works for any formula φ, not just an atom p.\nValid formulas\nDeﬁnition 5.8 A formula φ of basic modal logic is said to be valid if it is\ntrue in every world of every model, i.e. iﬀ⊨φ holds.\nAny propositional tautology is a valid formula and so is any substitution\ninstance of it. A substitution instance of a formula is the result of uniformly\nsubstituting the atoms of the formula by other formulas as done in (5.2).\nFor example, since p ∨¬p is a tautology, performing the substitution p \u000e→\n2p ∧(q →p) gives us a valid formula (2p ∧(q →p)) ∨¬(2p ∧(q →p)).\nAs we may expect from equivalences above, these formulas are valid:\n¬2φ ↔3¬φ\n2(φ ∧ψ) ↔2φ ∧2ψ\n(5.3)\n3(φ ∨ψ) ↔3φ ∨3ψ.\nTo prove that the ﬁrst of these is valid, we reason as follows. Suppose x is\na world in a model M = (W, R, L). We want to show x ⊩¬2φ ↔3¬φ, i.e.\nthat x ⊩¬2φ iﬀx ⊩3¬φ. Well, using Deﬁnition 5.4,\n5.2 Basic modal logic\n315\nb\nc\nd\na\ne\np, q\np, q\nq\np\nFigure 5.5. Another Kripke model.\nx ⊩¬2φ",
                    "summary": "The elimination rules break (p) up into its atomic constituents p, qand r. The introduction rules then built up the formula p ∨(q ∨r). 1.1 Humanitarian deduction. 1.2 Natural deduction. 2. Humanitarian theory. 3. Theory of natural deduction. 4. Natural deduction theory. 5. The Theory of Natural Deduction. 6. The theory of natural deduction. 7. Natural deduction theory. 8. Natural deductives. 9. Natural deductions. 10. Natural  deduction  theory. 11. A ﬁnal rule is required in order to allow us to conclude a box with a for-mula which has already appeared earlier in the proof. The rule ‘copy’ allows us to repeat something that we know already. We need to do this in this example, because the rule →i requires that we end the inner box with p. The copy rule entitles us to copy formulas that appeared before,unless they depend on temporary assumptions whose box has already been closed. The following proof is a proof of the validity of the ‘converse’ (p ∧q) and you are encouraged to show it yourself. The proof is based on the following: The proof rules for natural deduction are summarised in Figure 1.2. The rules for negation involve the notion of contradiction. It can be diﬃcult to decide which instance of LEM would beneﬁt the progress of a proof. Can you re-do the example above with q ∨¬q as LEM? Can you do the same thing with q∨i? Can we use premises or any other ‘visible’ formulas, more than once? Can a proof be proved using a single negation or a series of negations? Can an argument be proved by using multiple negations or multiple premises? Can it be proven by using premises or other 'visible' formulas The rules have an excellent procedural interpretation. However, when you try to use the rules yourself, you’ll find yourself looking for a more procedural interpretation; what does                a rule do and how do you use it? For example, to prove φ, try proving φ and ψ separately and then use                the rule  in Example 1.15. The rules are written in the form of a list of rules, starting with the first one and ending with the last one. The first rule is called the ‘proving’ rule, the second is called ‘exercising’ the rules, and the third is ‘using the rules’. The basic rules of natural deduction:introduction, elimination, and derivation. Show that the following sequents are not valid by ﬁnding a valuation in which the truth values of the formulas to the left of ⊢are T and the truth value of the formula to the right of F is F. See Figure 1.2 on page 27 to see which cases are still missing, and to see how to use the rules in the rest of the book. See page 27 for the summary of the rules of deduction in the book, as well as a list of examples and examples of how to apply the rules to the real world. The book is published by Oxford University Press, London. Find a formula of propositional logic which contains only the atoms p, q and r and which is true only when p and q are false. Prove the validity of the following sequents needed to secure the completeness of the formula. Use mathematical induction on n to prove the theorem. Use the following examples of natural language to test the correctness of the formulas. For each example, give examples of sentences such that the premises are true, but the conclusion is false. For example, given the premises p,q and r, give the sentences: p →q ⊢p ∨q(d) p →(q ∨r) ≢(p →q) (d) (p →r) An adequate set of connectives for propositional logic is a set such that there is an equivalent formula with only connectives from that set. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an instance of LEM. Does ⊨φ hold for the φ below? Please justify your answer. Exercises 1.5 and 2.5 are based on the definition of the set {¬, ∨} and the set of propositional connectives. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This intention is right-associative: expressions of the form p →q →r denote p →(q → r) In Examples 1.1 and 1.2, we show how this works by applying the rules to the premises and the conclusion. We denote the intention we denote by the formula φ1, φ2, . . .       . ..   We denote our intention by φn, which we will call premises, and another formula, �  Constructing such a proof is a creative exercise, a bit like programming. It is notnecessarily obvious which rules to apply, and in what order, to obtain the desired conclusion. For Examples 1.1 and 1.2, we use Greek letters. Lower-case letters are used to stand for formulas, and upper-case Letters are used for sets of formulas. For example, p ⊢q. , φn ⋅n ≅n is a set of three formulas. Greek letters are used to express propositions. Propositional logic can be used to prove the existence of certain facts. The proof rule modus tollens (MT) can be derived from some of the other rules. The rules are: p, q ⊢p, r, ¬r, p |−q, p  ‘Gold is a metal’ and p  ‘Silver is a gold.’ The rules can be shown by the sequent p,q,r,p, ‘p’, “p” and ‘q’. The Greek word for ‘proof’ is ‘guideline’ or ‘propositional There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy;.and some purists would say that we should stick to a minimum set of rules, independent of each other. We don’t take such a purist view.Indeed, the two derived rules we now introduce are extremely useful. You will find that they crop up frequently when doing exercises in natural deduction, so it is worth giving them names as derived rules. For example, the rule ‘e, ¬e and ¬i’ can be derived from the rules “e” and “i”. The rules for negation involve the notion of contradiction. We have seen the rules ¬¬i and ¬E, but we haven’t seen any rules that introduce or eliminate single negations. The rules for contradiction are: If from ¬φ we obtain a contradiction, then we are entitled to deduce φ: PBC. The rule for contradiction is called reductio ad absurdum, which means ‘reduc-tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. We will use this rule more than once in our derivation of the rules for the proof of natural deduction. As far as truth is concerned, they are all equivalent. We’ll be able to prove this later, when we have introduced the rules for negation. Contradictions are a very important notion in logic. Any formula can be derived from a contradiction. This can be seen in natural deduction. Natural deduction can be confusing when you ﬁrst encounter it; why should we endorse the argument that the moon is made of green cheese? It may seem absurd, but natural deduction does have this feature that any for-reprehensible-mula can be derive from a contradictions and therefore it makes this argu-                ment valid. It’s not just that contradictions can be. derived from contradic- This process does not care whether such premises make any sense. The reason it takes this stance is that ⊢tells us all the things we may infer, provided that we can assume the formulas to the left of it. This has at least the advantage of matching checks based on semanticintuitions which we formalise later by using truth tables. If all the premises compute to ‘true’, then the conclusion must compute ‘ true’ as well. Let’s now look at our proof rules. First, we expect that we won’t be able to show the sequent p, q. Then, we look at the proof rules for the ‘propositional logic’ For each of the connectives, there is one or more rules to introduce it and one or two rules to eliminate it. We present about ﬁfteen of them in total. We will go through them in turn and then summarise at the end of this section.1 Rules for natural deduction for conjunction.2. The rules for conjunction for conjunction, for conjunction with conjunction, and for conjunction without conjunction.3. The rule for conjunc-unc-tion for conjunction and-introduction.4. The Rules for Natural Deduction for Conjunctions for Conjunction, for Conjugation with Conjunction, and Conjuration with Conjunctivity. The rules for and-elimination are these two: one for proof of φ and the other for elimination. In the first rule, the conclusion has to match the ﬁrst conjunct of the first conjunct, whereas the exact nature of the second conjunct is irrelevant. The second rule is just the other way around: the conclusion can be any formula. It is important not to engage in this kind of pattern matching before the application of proof rules. The rules for proof and elimination are these: one rule says: if you have a proof of. φ, then by applying this rule you can get a proof. of ω. The rule  says the same thing, but allows you to We summarise this reasoning into the rule modus tollens, or MT for short. We will be able to derive this rule from other ones later on, but we introduce it here because it enables us already to do some pretty slick proofs. In the following proof of the rule we use several of the rules introduced so far:. The rule can also be derived from other rules such as the rule that says ‘If Abraham Lincoln was Ethiopian, then he was African’ and ‘Abraham Lincoln was not African; therefore he was not Ethiopian’ The rule MT implies introduction of new premises. The order of applying double negation rules and MT is diﬀerentin these examples. Yet, so far we have no rule which builds implications that do not already occur as premises in our proofs. The rule MT made it possible for us to show that p →q, ¬q ⊢¬p is valid, but the validity of the sequent p →¬q, q ⋅p seems just as plausible. That sequent is, in a certain sense, saying the same thing. We call the rule MT a Natural deduction. It does not mention the lower-level rules upon which it depends. The mechanics of such a rule are more involved than what we have seen so far. So let us proceed with quantiﬁcation. Now we want to provide formal proofs for some of the most                commonly used quanti ﬁer equivalences. Quite a few of them involve several                quantiﬅcations over more than just one variable. Thus, this topic is also good practice for using the proof rules for quanti ﬉ers in a nested fashion. For example, we may specify ‘Not all birds can ﬂy.’ as ¬∀x (B(x) →                F(x)) or as  ‘not all birds The former formal speciﬁcation is closer to the structure of the English. The latter is logically equiv-alent to the former. Theorem 2.13 Let φ and ψ be formulas of predicate logic. As in Chapter 1, we write φ1 ⊣⊢φ2 as an abbreviation for the validityof φ2 � Assuming that x is not free in ψ, we have the following equivalences. We will prove most of these sequents; the proofs for the remaining ones are straightforward adaptations and are left as exercises. For example, we can say that the word φ is free if and only if it is free in x. We have the equivalences for the words φ, x, and x in this way. We can also use the equivalence for the word x, y, and y in the same way. For instance, we could say: φ (x) (y) (x), y (y), x (x, y), y, y (x The rule for eliminat-                ing is the following: If φ is true, then you could replace the x in φ by any term t. The intuitive soundness of this rule is self-evident. Recall that                and necessary requirements for any sane concept of (extensional) equality. We leave the topic of equality for now to move on to the proof rules for                quantiﬁers. The rules for universal quantification can be found in the next section of the book, ‘The Theory of Quantification’, which is published by Oxford University Press, priced £16.99 (US) and £19.99 ($24.99) The rule  is a bit more complicated. It employs a proof box similar to those we have already seen in natural deduction for propositional logic, but this time the box is to stipulate the scope of the ‘dummy variable’ x0. The rule is to enforce the side condition that t be free for x in φ. The statement  says that for all numbers                n there is some bigger number m, which is indeed true of integers or real                numbers. However, φ[y/x] is the formula  saying that there is a                number which is bigger than itself. This is wrong; and we must not allow a                proof rule which derives semantically wrong things from semantically Predicate logic extends propositional logic not only with quantiﬁers but also with function symbols. Consider the declarative sentence: Every child is younger than its mother. The rule  is written  referring to the argument above in a symbolic form. The need for a richer language needs to be addressed, too, we say. We need a language that is richer in terms of predicates, function symbols, and other concepts. We call this a new kind of language, the richer language of predicate logic, and it will be used in the next section of this article. We hope that this will help you understand the language of predicate logic a little better. The inelegance of coding ‘mother’ as a predicate is even more apparent if we consider the sentence:Andy and Paul have the same maternal grandmother. The function symbols of predicate logic give us a way of avoiding this grotesqueugly encoding, for they allow us to represent y’s mother in a more direct way. We write x = y instead of = (x, y) to say that x and y are equal. We use a special predicate in predicate logic, equality, which is a binary predicate, and is written =. Unlike other predicates, it is usually written in between its arguments rather than before them; that is, we write x + v instead of x + y. The symbol m is a function symbol. Instead of writing M(x, y) to mean that x is y’s mother, we simply.write m(y) to means y's mother. Let ρ be a valuation with ρ(x′ worrisome1) = 1 and ρ (x′ horrifying2) = 0. Determine whether ρ ⊨frulyholds for the following: x1[ˆx]  (x1 + x2), x2[˄x] (x2 + x3), x3 (x4 + x4), x5 (x5 + x6), x6 (x6 + x7), x7 (x Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)holds. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately. Mimic the example checks on page 396 for the connective AU. Find a boolean formula without ﬁxed points which is semantically equiva-                lent to f E[(x1 ∼U(¬ x1∧¬X2)]. For example, f E [x1â€™s U (¬ x1î€’s ‘x2’] is correct if In the grammar (6.10) for the relational mu-calculus, S and I have just one (they are called unary predicates), but predicate Y requires two arguments (it is called a binary predicate) Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’ or ‘There is some x which is a bird and cannot’. This is closer to the linguistic structure of the sentence above. We use f EG ¬x1 for the model in Figure 6.24. In Section 2.3, we extend our natural deduction calculus of propositional progressivelylogic so that it covers logical formulas of predicate logic as well. In this way we are able to prove the validity of sequents φ1, φ2, . . .    .      in the language we use. We will also explain whyhematicallyformulas like the two above are indeed equivalent semantically. The purpose of this section is to explain how such formulas can be given their meaning in general, and why they should be used in software design and in safety-critical systems. The goal is to reason symbolically orsemantically about the information expressed in those formulas. For example, penguins are birds In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicateLogic can be true or false. We are overloading the previously established proof rules for the previous chapter with rules for propositional connectives. We also introduce new proofrules for dealing with the quanti ﬁers and with the equality symbol in the natural deduction calculus for predicate logic. This allows us to deﬀn semantic entailment in a similar way to that in the first chapter of the book. We call this the ‘synthetic entailment’ of predicatelogic. Equality does not mean syntactic, or intensional, equality, but equality in terms of computation results. In either of these senses, any term t has to be equal to itself. As in the natural deduction calculus for propositional logic, the additional rules                for the quantiﬁers and equality will come in two ﬂavours: introduction and                elimination rules. The proof rules for equality are:t = t autoimmune=i autoimmune(2.5) which is an axiom (as it does not depend on any premises). Notice that it encompasses the rule that equality may be invoked only if t is a term, our language doesn’t permit us to talk about equality between formulas We have already pointed out the open-ended nature of the semantics of predicate logic. We may now express this substitution principle as the rule=e. The rule is an example of a side condition of a proof rule. The semantics of equality can be expanded to include the rule =e. For example, we can express the rule as follows:t1 = t2                 φ[t1/x]                 ω[t2/x], which is the rule of equality. Given a predicate logic over a set of function symbols F and predicates P, we need only a non-empty set A equipped with concrete functions or elements fM and P M. The right arities are agreed upon in our speciﬁcation. Of course, we also stressed that most models have natural interpretations of of of the symbols.2.5 Undecidability of predicate logic: How do we know when a model makes sense and when it doesn’t? The answer is that there is no way out of this peculiarity, and that it is impossible to choose a model that makes sense or one that doesn't. The answer to this question is that the answer is ‘no’ There are a lot of good reasons for maintaining a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. We discussed itsproof rule in natural deduction already in Section 2.3.1. We now move on to the next section of the book. The next section is on the subject of equality in the form of a function =M. The third section is about equality in terms of the quantiﬁer equivalences dis-                cussed in 2.2.2 and 2.4.1 respectively. The fourth and final section is the section on equality in propositional logic. 2 and 3 are not equivalent to 2 and 3, as we saw earlier. We do not have equiv-                alences between 2 and 2, or between 3 and 3. For example, in the fourth item of Example 5.6 we had x5 ⊩2(p ∨q) and x5 ̸⊩ 2p (p  2q) But we must show that x has an accessible world, i.e. satisﬁes 3⊤. We can also show that 2 is equivalent to 3, but not to 3. It is also not surprising to ﬁnd that 2 does not distribute over ∨ and 3 does not distribution over A formula φ of basic modal logic is said to be valid if it is true in every world of every model, i.e. iﬀ⊨φ holds. A substitution instance of a formula is the result of uniformlysubstituting the atoms of the formula by other formulas as done in (5.2). For example, since p ∨¬p is a tautology, performing the substitution p                 →2p ∧(q →p) gives us a valid formula (2p                 (q) → 2p (q) (2P                  (q), 2P (q, p), 2 P (p, p, p) (",
                    "children": [
                        {
                            "id": "chapter-2-section-3-subsection-1",
                            "title": "Natural Deduction Rules",
                            "content": "1.2 Natural deduction\n19\nthe elimination rules break (p ∨q) ∨r up into its atomic constituents p, q\nand r, whereas the introduction rules then built up the formula p ∨(q ∨r).\n1\n(p ∨q) ∨r\npremise\n2\n(p ∨q)\nassumption\n3\np\nassumption\n4\np ∨(q ∨r)\n∨i1 3\n5\nq\nassumption\n6\nq ∨r\n∨i1 5\n7\np ∨(q ∨r)\n∨i2 6\n8\np ∨(q ∨r)\n∨e 2, 3−4, 5−7\n9\nr\nassumption\n10\nq ∨r\n∨i2 9\n11\np ∨(q ∨r)\n∨i2 10\n12\np ∨(q ∨r)\n∨e 1, 2−8, 9−11\nExample 1.18 From boolean algebra, or circuit theory, you may know that\ndisjunctions distribute over conjunctions. We are now able to prove this in\nnatural deduction. The following proof:\n1\np ∧(q ∨r)\npremise\n2\np\n∧e1 1\n3\nq ∨r\n∧e2 1\n4\nq\nassumption\n5\np ∧q\n∧i 2, 4\n6\n(p ∧q) ∨(p ∧r)\n∨i1 5\n7\nr\nassumption\n8\np ∧r\n∧i 2, 7\n9\n(p ∧q) ∨(p ∧r)\n∨i2 8\n10\n(p ∧q) ∨(p ∧r)\n∨e 3, 4−6, 7−9\nveriﬁes the validity of the sequent p ∧(q ∨r) ⊢(p ∧q) ∨(p ∧r) and you\nare encouraged to show the validity of the ‘converse’ (p ∧q) ∨(p ∧r) ⊢p ∧\n(q ∨r) yourself.\n20\n1 Propositional logic\nA ﬁnal rule is required in order to allow us to conclude a box with a for-\nmula which has already appeared earlier in the proof. Consider the sequent\n⊢p →(q →p), whose validity may be proved as follows:\n1\np\nassumption\n2\nq\nassumption\n3\np\ncopy 1\n4\nq →p\n→i 2−3\n5\np →(q →p)\n→i 1−4\nThe rule ‘copy’ allows us to repeat something that we know already. We need\nto do this in this example, because the rule →i requires that we end the inner\nbox with p. The copy rule entitles us to copy formulas that appeared before,\nunless they depend on temporary assumptions whose box has already been\nclosed. Though a little inelegant, this additional rule is a small price to pay\nfor the freedom of being able to use premises, or any other ‘visible’ formulas,\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\n1.2.3 Natural deduction in summary\nThe proof rules for natural deduction are summarised in Figure 1.2. The\nexplanation of the rules we have given so far in this chapter is declarative;\nwe have presented each rule and justiﬁed it in terms of our intuition about\nthe logical connectives. However, when you try to use the rules yourself,\nyou’ll ﬁnd yourself looking for a more procedural interpretation; what does\na rule do and how do you use it? For example,\nr ∧i says: to prove φ ∧ψ, you must ﬁrst prove φ and ψ separately and then use\nthe rule ∧i.\nr ∧e1 says: to prove φ, try proving φ ∧ψ and then use the rule ∧e1. Actually,\nthis doesn’t sound like very good advice because probably proving φ ∧ψ will\nbe harder than proving φ alone. However, you might ﬁnd that you already have\nφ ∧ψ lying around, so that’s when this rule is useful. Compare this with the\nexample sequent in Example 1.15.\nr ∨i1 says: to prove φ ∨ψ, try proving φ. Again, in general it is harder to prove\nφ than it is to prove φ ∨ψ, so this will usually be useful only if you’ve already\nmanaged to prove φ. For example, if you want to prove q |−p ∨q, you certainly\nwon’t be able simply to use the rule ∨i1, but ∨i2 will work.\nr ∨e has an excellent procedural interpretation. It says: if you have φ ∨ψ, and you\nwant to prove some χ, then try to prove χ from φ and from ψ in turn. (In those\nsubproofs, of course you can use the other prevailing premises as well.)\nr Similarly, →i says, if you want to prove φ →ψ, try proving ψ from φ (and the\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nmore than once.\nThe rules for negation\nWe have seen the rules ¬¬i and ¬¬e, but we\nhaven’t seen any rules that introduce or eliminate single negations. These\nrules involve the notion of contradiction. This detour is to be expected since\nour reasoning is concerned about the inference, and therefore the preserva-\ntion, of truth. Hence, there cannot be a direct way of inferring ¬φ, given\nφ.\nDeﬁnition 1.19 Contradictions are expressions of the form φ ∧¬φ or ¬φ ∧\nφ, where φ is any formula.\nExamples of such contradictions are r ∧¬r, (p →q) ∧¬(p →q) and ¬(r ∨\ns →q) ∧(r ∨s →q). Contradictions are a very important notion in logic.\nAs far as truth is concerned, they are all equivalent; that means we should\nbe able to prove the validity of\n¬(r ∨s →q) ∧(r ∨s →q) ⊣⊢(p →q) ∧¬(p →q)\n(1.2)\nsince both sides are contradictions. We’ll be able to prove this later, when\nwe have introduced the rules for negation.\nIndeed, it’s not just that contradictions can be derived from contradic-\ntions; actually, any formula can be derived from a contradiction. This can be\n1.2 Natural deduction\n21\nconfusing when you ﬁrst encounter it; why should we endorse the argument\np ∧¬p ⊢q, where\np : The moon is made of green cheese.\nq : I like pepperoni on my pizza.\nconsidering that our taste in pizza doesn’t have anything to do with the\nconstitution of the moon? On the face of it, such an endorsement may seem\nabsurd. Nevertheless, natural deduction does have this feature that any for-\nmula can be derived from a contradiction and therefore it makes this argu-\nment valid. The reason it takes this stance is that ⊢tells us all the things\nwe may infer, provided that we can assume the formulas to the left of it.\nThis process does not care whether such premises make any sense. This has\nat least the advantage that we can match ⊢to checks based on semantic\nintuitions which we formalise later by using truth tables: if all the premises\ncompute to ‘true’, then the conclusion must compute ‘true’ as well. In partic-\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nan implication. Suppose that p →q and ¬q are the case. Then, if p holds\nwe can use →e to conclude that q holds. Thus, we then have that q and ¬q\nhold, which is impossible. Therefore, we may infer that p must be false. But\nthis can only mean that ¬p is true. We summarise this reasoning into the\nrule modus tollens, or MT for short:5\nφ →ψ\n¬ψ\n¬φ\nMT.\nAgain, let us see an example of this rule in the natural language setting:\n‘If Abraham Lincoln was Ethiopian, then he was African. Abraham\nLincoln was not African; therefore he was not Ethiopian.’\nExample 1.7 In the following proof of\np →(q →r), p, ¬r ⊢¬q\nwe use several of the rules introduced so far:\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq →r\n→e 1, 2\n5\n¬q\nMT 4, 3\n5 We will be able to derive this rule from other ones later on, but we introduce it here because it\nallows us already to do some pretty slick proofs. You may think of this rule as one on a higher\nlevel insofar as it does not mention the lower-level rules upon which it depends.\n1.2 Natural deduction\n11\nExamples 1.8 Here are two example proofs which combine the rule MT\nwith either ¬¬e or ¬¬i:\n1\n¬p →q\npremise\n2\n¬q\npremise\n3\n¬¬p\nMT 1, 2\n4\np\n¬¬e 3\nproves that the sequent ¬p →q, ¬q ⊢p is valid; and\n1\np →¬q\npremise\n2\nq\npremise\n3\n¬¬q\n¬¬i 2\n4\n¬p\nMT 1, 3\nshows the validity of the sequent p →¬q, q ⊢¬p.\nNote that the order of applying double negation rules and MT is diﬀerent\nin these examples; this order is driven by the structure of the particular\nsequent whose validity one is trying to show.\nThe rule implies introduction\nThe rule MT made it possible for us to\nshow that p →q, ¬q ⊢¬p is valid. But the validity of the sequent p →q ⊢\n¬q →¬p seems just as plausible. That sequent is, in a certain sense, saying\nthe same thing. Yet, so far we have no rule which builds implications that\ndo not already occur as premises in our proofs. The mechanics of such a rule\nare more involved than what we have seen so far. So let us proceed with",
                            "summary": "The elimination rules break (p) up into its atomic constituents p, qand r. The introduction rules then built up the formula p ∨(q ∨r). 1.1 Humanitarian deduction. 1.2 Natural deduction. 2. Humanitarian theory. 3. Theory of natural deduction. 4. Natural deduction theory. 5. The Theory of Natural Deduction. 6. The theory of natural deduction. 7. Natural deduction theory. 8. Natural deductives. 9. Natural deductions. 10. Natural  deduction  theory. 11. A ﬁnal rule is required in order to allow us to conclude a box with a for-mula which has already appeared earlier in the proof. The rule ‘copy’ allows us to repeat something that we know already. We need to do this in this example, because the rule →i requires that we end the inner box with p. The copy rule entitles us to copy formulas that appeared before,unless they depend on temporary assumptions whose box has already been closed. The following proof is a proof of the validity of the ‘converse’ (p ∧q) and you are encouraged to show it yourself. The proof is based on the following: The proof rules for natural deduction are summarised in Figure 1.2. The rules for negation involve the notion of contradiction. It can be diﬃcult to decide which instance of LEM would beneﬁt the progress of a proof. Can you re-do the example above with q ∨¬q as LEM? Can you do the same thing with q∨i? Can we use premises or any other ‘visible’ formulas, more than once? Can a proof be proved using a single negation or a series of negations? Can an argument be proved by using multiple negations or multiple premises? Can it be proven by using premises or other 'visible' formulas The rules have an excellent procedural interpretation. However, when you try to use the rules yourself, you’ll find yourself looking for a more procedural interpretation; what does                a rule do and how do you use it? For example, to prove φ, try proving φ and ψ separately and then use                the rule  in Example 1.15. The rules are written in the form of a list of rules, starting with the first one and ending with the last one. The first rule is called the ‘proving’ rule, the second is called ‘exercising’ the rules, and the third is ‘using the rules’. The basic rules of natural deduction:introduction, elimination, and derivation. Show that the following sequents are not valid by ﬁnding a valuation in which the truth values of the formulas to the left of ⊢are T and the truth value of the formula to the right of F is F. See Figure 1.2 on page 27 to see which cases are still missing, and to see how to use the rules in the rest of the book. See page 27 for the summary of the rules of deduction in the book, as well as a list of examples and examples of how to apply the rules to the real world. The book is published by Oxford University Press, London. Find a formula of propositional logic which contains only the atoms p, q and r and which is true only when p and q are false. Prove the validity of the following sequents needed to secure the completeness of the formula. Use mathematical induction on n to prove the theorem. Use the following examples of natural language to test the correctness of the formulas. For each example, give examples of sentences such that the premises are true, but the conclusion is false. For example, given the premises p,q and r, give the sentences: p →q ⊢p ∨q(d) p →(q ∨r) ≢(p →q) (d) (p →r) An adequate set of connectives for propositional logic is a set such that there is an equivalent formula with only connectives from that set. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an instance of LEM. Does ⊨φ hold for the φ below? Please justify your answer. Exercises 1.5 and 2.5 are based on the definition of the set {¬, ∨} and the set of propositional connectives. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This intention is right-associative: expressions of the form p →q →r denote p →(q → r) In Examples 1.1 and 1.2, we show how this works by applying the rules to the premises and the conclusion. We denote the intention we denote by the formula φ1, φ2, . . .       . ..   We denote our intention by φn, which we will call premises, and another formula, �  Constructing such a proof is a creative exercise, a bit like programming. It is notnecessarily obvious which rules to apply, and in what order, to obtain the desired conclusion. For Examples 1.1 and 1.2, we use Greek letters. Lower-case letters are used to stand for formulas, and upper-case Letters are used for sets of formulas. For example, p ⊢q. , φn ⋅n ≅n is a set of three formulas. Greek letters are used to express propositions. Propositional logic can be used to prove the existence of certain facts. The proof rule modus tollens (MT) can be derived from some of the other rules. The rules are: p, q ⊢p, r, ¬r, p |−q, p  ‘Gold is a metal’ and p  ‘Silver is a gold.’ The rules can be shown by the sequent p,q,r,p, ‘p’, “p” and ‘q’. The Greek word for ‘proof’ is ‘guideline’ or ‘propositional There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy;.and some purists would say that we should stick to a minimum set of rules, independent of each other. We don’t take such a purist view.Indeed, the two derived rules we now introduce are extremely useful. You will find that they crop up frequently when doing exercises in natural deduction, so it is worth giving them names as derived rules. For example, the rule ‘e, ¬e and ¬i’ can be derived from the rules “e” and “i”. The rules for negation involve the notion of contradiction. We have seen the rules ¬¬i and ¬E, but we haven’t seen any rules that introduce or eliminate single negations. The rules for contradiction are: If from ¬φ we obtain a contradiction, then we are entitled to deduce φ: PBC. The rule for contradiction is called reductio ad absurdum, which means ‘reduc-tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. We will use this rule more than once in our derivation of the rules for the proof of natural deduction. As far as truth is concerned, they are all equivalent. We’ll be able to prove this later, when we have introduced the rules for negation. Contradictions are a very important notion in logic. Any formula can be derived from a contradiction. This can be seen in natural deduction. Natural deduction can be confusing when you ﬁrst encounter it; why should we endorse the argument that the moon is made of green cheese? It may seem absurd, but natural deduction does have this feature that any for-reprehensible-mula can be derive from a contradictions and therefore it makes this argu-                ment valid. It’s not just that contradictions can be. derived from contradic- This process does not care whether such premises make any sense. The reason it takes this stance is that ⊢tells us all the things we may infer, provided that we can assume the formulas to the left of it. This has at least the advantage of matching checks based on semanticintuitions which we formalise later by using truth tables. If all the premises compute to ‘true’, then the conclusion must compute ‘ true’ as well. Let’s now look at our proof rules. First, we expect that we won’t be able to show the sequent p, q. Then, we look at the proof rules for the ‘propositional logic’ For each of the connectives, there is one or more rules to introduce it and one or two rules to eliminate it. We present about ﬁfteen of them in total. We will go through them in turn and then summarise at the end of this section.1 Rules for natural deduction for conjunction.2. The rules for conjunction for conjunction, for conjunction with conjunction, and for conjunction without conjunction.3. The rule for conjunc-unc-tion for conjunction and-introduction.4. The Rules for Natural Deduction for Conjunctions for Conjunction, for Conjugation with Conjunction, and Conjuration with Conjunctivity. The rules for and-elimination are these two: one for proof of φ and the other for elimination. In the first rule, the conclusion has to match the ﬁrst conjunct of the first conjunct, whereas the exact nature of the second conjunct is irrelevant. The second rule is just the other way around: the conclusion can be any formula. It is important not to engage in this kind of pattern matching before the application of proof rules. The rules for proof and elimination are these: one rule says: if you have a proof of. φ, then by applying this rule you can get a proof. of ω. The rule  says the same thing, but allows you to We summarise this reasoning into the rule modus tollens, or MT for short. We will be able to derive this rule from other ones later on, but we introduce it here because it enables us already to do some pretty slick proofs. In the following proof of the rule we use several of the rules introduced so far:. The rule can also be derived from other rules such as the rule that says ‘If Abraham Lincoln was Ethiopian, then he was African’ and ‘Abraham Lincoln was not African; therefore he was not Ethiopian’ The rule MT implies introduction of new premises. The order of applying double negation rules and MT is diﬀerentin these examples. Yet, so far we have no rule which builds implications that do not already occur as premises in our proofs. The rule MT made it possible for us to show that p →q, ¬q ⊢¬p is valid, but the validity of the sequent p →¬q, q ⋅p seems just as plausible. That sequent is, in a certain sense, saying the same thing. We call the rule MT a Natural deduction. It does not mention the lower-level rules upon which it depends. The mechanics of such a ruleare more involved than what we have seen so far. So",
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-3-subsection-2",
                            "title": "Quantifier Equivalences",
                            "content": "quantiﬁcation. Now we want to provide formal proofs for some of the most\ncommonly used quantiﬁer equivalences. Quite a few of them involve several\nquantiﬁcations over more than just one variable. Thus, this topic is also\ngood practice for using the proof rules for quantiﬁers in a nested fashion.\nFor example, the formula ∀x ∀y φ should be equivalent to ∀y ∀x φ since\nboth say that φ should hold for all values of x and y. What about (∀x φ) ∧\n(∀x ψ) versus ∀x (φ ∧ψ)? A moment’s thought reveals that they should have\nthe same meaning as well. But what if the second conjunct does not start\nwith ∀x? So what if we are looking at (∀x φ) ∧ψ in general and want to\ncompare it with ∀x (φ ∧ψ)? Here we need to be careful, since x might be\nfree in ψ and would then become bound in the formula ∀x (φ ∧ψ).\nExample 2.12 We may specify ‘Not all birds can ﬂy.’ as ¬∀x (B(x) →\nF(x)) or as ∃x (B(x) ∧¬F(x)). The former formal speciﬁcation is closer\nto the structure of the English speciﬁcation, but the latter is logically equiv-\nalent to the former. Quantiﬁer equivalences help us in establishing that\nspeciﬁcations that ‘look’ diﬀerent are really saying the same thing.\nHere are some quantiﬁer equivalences which you should become familiar\nwith. As in Chapter 1, we write φ1 ⊣⊢φ2 as an abbreviation for the validity\nof φ1 ⊢φ2 and φ2 ⊢φ1.\nTheorem 2.13 Let φ and ψ be formulas of predicate logic. Then we have\nthe following equivalences:\n1.\n(a) ¬∀x φ ⊣⊢∃x ¬φ\n(b) ¬∃x φ ⊣⊢∀x ¬φ.\n2.\nAssuming that x is not free in ψ:\n118\n2 Predicate logic\n(a) ∀x φ ∧ψ ⊣⊢∀x (φ ∧ψ)3\n(b) ∀x φ ∨ψ ⊣⊢∀x (φ ∨ψ)\n(c) ∃x φ ∧ψ ⊣⊢∃x (φ ∧ψ)\n(d) ∃x φ ∨ψ ⊣⊢∃x (φ ∨ψ)\n(e) ∀x (ψ →φ) ⊣⊢ψ →∀x φ\n(f) ∃x (φ →ψ) ⊣⊢∀x φ →ψ\n(g) ∀x (φ →ψ) ⊣⊢∃x φ →ψ\n(h) ∃x (ψ →φ) ⊣⊢ψ →∃x φ.\n3.\n(a) ∀x φ ∧∀x ψ ⊣⊢∀x (φ ∧ψ)\n(b) ∃x φ ∨∃x ψ ⊣⊢∃x (φ ∨ψ).\n4.\n(a) ∀x ∀y φ ⊣⊢∀y ∀x φ\n(b) ∃x ∃y φ ⊣⊢∃y ∃x φ.\nPROOF: We will prove most of these sequents; the proofs for the remaining\nones are straightforward adaptations and are left as exercises. Recall that\nand necessary requirements for any sane concept of (extensional) equality.\nWe leave the topic of equality for now to move on to the proof rules for\nquantiﬁers.\nThe proof rules for universal quantification\nThe rule for eliminat-\ning ∀is the following:\n∀x φ\nφ[t/x]\n∀x e.\nIt says: If ∀x φ is true, then you could replace the x in φ by any term t\n(given, as usual, the side condition that t be free for x in φ) and conclude\nthat φ[t/x] is true as well. The intuitive soundness of this rule is self-evident.\nRecall that φ[t/x] is obtained by replacing all free occurrences of x in φ\nby t. You may think of the term t as a more concrete instance of x. Since φ\nis assumed to be true for all x, that should also be the case for any term t.\nExample 2.11 To see the necessity of the proviso that t be free for x in\nφ, consider the case that φ is ∃y (x < y) and the term to be substituted\nfor x is y. Let’s suppose we are reasoning about numbers with the usual\n‘smaller than’ relation. The statement ∀x φ then says that for all numbers\nn there is some bigger number m, which is indeed true of integers or real\nnumbers. However, φ[y/x] is the formula ∃y (y < y) saying that there is a\nnumber which is bigger than itself. This is wrong; and we must not allow a\nproof rule which derives semantically wrong things from semantically valid\n110\n2 Predicate logic\nones. Clearly, what went wrong was that y became bound in the process of\nsubstitution; y is not free for x in φ. Thus, in going from ∀x φ to φ[t/x],\nwe have to enforce the side condition that t be free for x in φ: use a fresh\nvariable for y to change φ to, say, ∃z (x < z) and then apply [y/x] to that\nformula, rendering ∃z (y < z).\nThe rule ∀x i is a bit more complicated. It employs a proof box similar\nto those we have already seen in natural deduction for propositional logic,\nbut this time the box is to stipulate the scope of the ‘dummy variable’ x0\nrather than the scope of an assumption. The rule ∀x i is written\nx0\n...\nφ[x0/x]\n∀x φ\n∀x i.\nVerify that these sequents express the argument above in a symbolic form.\nPredicate logic extends propositional logic not only with quantiﬁers but\nwith one more concept, that of function symbols. Consider the declarative\nsentence\nEvery child is younger than its mother.\n2.1 The need for a richer language\n97\nUsing predicates, we could express this sentence as\n∀x ∀y (C(x) ∧M(y, x) →Y (x, y))\nwhere C(x) means that x is a child, M(x, y) means that x is y’s mother\nand Y (x, y) means that x is younger than y. (Note that we actually used\nM(y, x) (y is x’s mother), not M(x, y).) As we have coded it, the sentence\nsays that, for all children x and any mother y of theirs, x is younger than y.\nIt is not very elegant to say ‘any of x’s mothers’, since we know that every\nindividual has one and only one mother1. The inelegance of coding ‘mother’\nas a predicate is even more apparent if we consider the sentence\nAndy and Paul have the same maternal grandmother.\nwhich, using ‘variables’ a and p for Andy and Paul and a binary predicate\nM for mother as before, becomes\n∀x ∀y ∀u ∀v (M(x, y) ∧M(y, a) ∧M(u, v) ∧M(v, p) →x = u).\nThis formula says that, if y and v are Andy’s and Paul’s mothers, respec-\ntively, and x and u are their mothers (i.e. Andy’s and Paul’s maternal grand-\nmothers, respectively), then x and u are the same person. Notice that we\nused a special predicate in predicate logic, equality; it is a binary predicate,\ni.e. it takes two arguments, and is written =. Unlike other predicates, it is\nusually written in between its arguments rather than before them; that is,\nwe write x = y instead of = (x, y) to say that x and y are equal.\nThe function symbols of predicate logic give us a way of avoiding this\nugly encoding, for they allow us to represent y’s mother in a more direct\nway. Instead of writing M(x, y) to mean that x is y’s mother, we simply\nwrite m(y) to mean y’s mother. The symbol m is a function symbol: it takes\n(a) ∃x.(x′ ↔(y + y′ · x))\n(b) ∀x.(x′ ↔(y + y′ · x))\n(c) ∃x′.(x′ ↔(y + y′ · x))\n(d) ∀x′.(x′ ↔(y + y′ · x)).\n5. Let ρ be a valuation with ρ(x′\n1) = 1 and ρ(x′\n2) = 0. Determine whether ρ ⊨f\nholds for the following:\n(a) x1[ˆx := ˆx′]\n(b) (x1 + x2)[ˆx := ˆx′]\n(c) (x1 · x2)[ˆx := ˆx′].\n6. Evaluate ρ ⊨(∃x1.(x1 + x2))[ˆx := ˆx′] and explain how the valuation ρ changes\nin that process. In particular, [ˆx := ˆx′] replaces xi by x′\ni, but why does this not\ninterfere with the binding quantiﬁer ∃x1?\n410\n6 Binary decision diagrams\n7. (a) How would you deﬁne the notion of semantic entailment for the relational\nmu-calculus?\n(b) Deﬁne formally when two formulas of the relational mu-calculus are seman-\ntically equivalent.\nExercises 6.15\n1. Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)\nholds, where ρ is\n(a) (x1, x2) ⇒(1, 0)\n(b) (x1, x2) ⇒(0, 1)\n(c) (x1, x2) ⇒(0, 0).\n2. Let S be {s0, s1}, with s0 →s0, s0 →s1 and s1 →s0 as possible transitions\nand L(s0) = {x1} and L(s1) = ∅. Compute the boolean function f EX (EX ¬x1).\n3. Equations (6.17) (page 395), (6.19) and (6.20) deﬁne f EF φ, f AF φ and f EG φ.\nWrite down a similar equation to deﬁne f AG φ.\n4. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately.\n5. Mimic the example checks on page 396 for the connective AU: consider the\nmodel of Figure 6.24 (page 384). Since [[E[(x1 ∨x2) U (¬x1 ∧¬x2)]]] equals the\nentire state set {s0, s1, s2}, your coding of f E[x1∨x2U¬x1∧¬x2] is correct if it\ncomputes 1 for all bit vectors diﬀerent from (1, 1).\n(a) Verify that your coding is indeed correct.\n(b) Find a boolean formula without ﬁxed points which is semantically equiva-\nlent to f E[(x1∨x2)U(¬x1∧¬x2)].\n6. (a) Use (6.20) on page 395 to compute f EG ¬x1 for the model in Figure 6.24.\n(b) Show that f EG ¬x1 faithfully models the set of all states which satisfy\nEG ¬x1.\n7. In the grammar (6.10) for the relational mu-calculus on page 390, it was stated\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nx\ny\nS\nQ\n∧\nFigure 2.4. A parse tree for which a substitution has dire consequences.\n2.3 Proof theory of predicate logic\n2.3.1 Natural deduction rules\nProofs in the natural deduction calculus for predicate logic are similar to\nthose for propositional logic in Chapter 1, except that we have new proof\nrules for dealing with the quantiﬁers and with the equality symbol. Strictly\nspeaking, we are overloading the previously established proof rules for the\npropositional connectives ∧, ∨etc. That simply means that any proof rule\nof Chapter 1 is still valid for logical formulas of predicate logic (we origi-\nnally deﬁned those rules for logical formulas of propositional logic). As in\nthe natural deduction calculus for propositional logic, the additional rules\nfor the quantiﬁers and equality will come in two ﬂavours: introduction and\nelimination rules.\nThe proof rules for equality\nFirst, let us state the proof rules for\nequality. Here equality does not mean syntactic, or intensional, equality,\nbut equality in terms of computation results. In either of these senses, any\nterm t has to be equal to itself. This is expressed by the introduction rule\nfor equality:\nt = t\n=i\n(2.5)\nwhich is an axiom (as it does not depend on any premises). Notice that it\n108\n2 Predicate logic\nmay be invoked only if t is a term, our language doesn’t permit us to talk\nabout equality between formulas.\nThis rule is quite evidently sound, but it is not very useful on its own.\nWhat we need is a principle that allows us to substitute equals for equals\nrepeatedly. For example, suppose that y ∗(w + 2) equals y ∗w + y ∗2; then\nit certainly must be the case that z ≥y ∗(w + 2) implies z ≥y ∗w + y ∗2\nand vice versa. We may now express this substitution principle as the rule\n=e:\nt1 = t2\nφ[t1/x]\nφ[t2/x]\n=e.\nNote that t1 and t2 have to be free for x in φ, whenever we want to apply\nthe rule =e; this is an example of a side condition of a proof rule.\nConvention 2.10 Throughout this section, when we write a substitution\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\n2(φ ∧ψ) ≡2φ ∧2ψ and 3(φ ∨ψ) ≡3φ ∨3ψ.\nThese equivalences correspond closely to the quantiﬁer equivalences dis-\ncussed in Section 2.3.2. It is also not surprising to ﬁnd that 2 does not\ndistribute over ∨and 3 does not distribute over ∧, i.e. we do not have equiv-\nalences between 2(φ ∨ψ) and 2φ ∨2ψ, or between 3(φ ∧ψ) and 3φ ∧3ψ.\nFor example, in the fourth item of Example 5.6 we had x5 ⊩2(p ∨q) and\nx5 ̸⊩2p ∨2q.\nNote that 2⊤is equivalent to ⊤, but not to 3⊤, as we saw earlier.\nSimilarly, 3⊥≡⊥but they are not equivalent to 2⊥.\nAnother equivalence is 3⊤≡2p →3p. For suppose x ⊩3⊤– i.e. x has\nan accessible world, say y – and suppose x ⊩2p; then y ⊩p, so x ⊩3p.\nConversely, suppose x ⊩2p →3p; we must show it satisﬁes 3⊤. Let us\ndistinguish between the cases x ⊩2p and x ̸⊩2p; in the former, we get\nx ⊩3p from x ⊩2p →3p and so x must have an accessible world; and in\nthe latter, x must again have an accessible world in order to avoid satisfying\n2p. Either way, x has an accessible world, i.e. satisﬁes 3⊤. Naturally, this\nargument works for any formula φ, not just an atom p.\nValid formulas\nDeﬁnition 5.8 A formula φ of basic modal logic is said to be valid if it is\ntrue in every world of every model, i.e. iﬀ⊨φ holds.\nAny propositional tautology is a valid formula and so is any substitution\ninstance of it. A substitution instance of a formula is the result of uniformly\nsubstituting the atoms of the formula by other formulas as done in (5.2).\nFor example, since p ∨¬p is a tautology, performing the substitution p \u000e→\n2p ∧(q →p) gives us a valid formula (2p ∧(q →p)) ∨¬(2p ∧(q →p)).\nAs we may expect from equivalences above, these formulas are valid:\n¬2φ ↔3¬φ\n2(φ ∧ψ) ↔2φ ∧2ψ\n(5.3)\n3(φ ∨ψ) ↔3φ ∨3ψ.\nTo prove that the ﬁrst of these is valid, we reason as follows. Suppose x is\na world in a model M = (W, R, L). We want to show x ⊩¬2φ ↔3¬φ, i.e.\nthat x ⊩¬2φ iﬀx ⊩3¬φ. Well, using Deﬁnition 5.4,\n5.2 Basic modal logic\n315\nb\nc\nd\na\ne\np, q\np, q\nq\np\nFigure 5.5. Another Kripke model.\nx ⊩¬2φ",
                            "summary": "We want to provide formal proofs for some of the most                commonly used quantiﬁer equivalences. Quite a few of them involve several                quantiﬅcations over more than just one variable. This topic is also good practice for using the proof rules for quanti ﬁers in a nested fashion. For example, we may specify ‘Not all birds can ﬂy.’ as ¬∀x (B(x) →                F(x), or as  ‘B’ (B) (B (x) (F (x), F (x, x, x), x, y, y)’. The former formal speciﬁcation is closer to the structure of the English. The latter is logically equiv-alent to the former. Theorem 2.13 Let φ and ψ be formulas of predicate logic. As in Chapter 1, we write φ1 ⊣⊢φ2 as an abbreviation for the validityof φ2 � Assuming that x is not free in ψ, we have the following equivalences. We will prove most of these sequents; the proofs for the remaining ones are straightforward adaptations and are left as exercises. For example, we can say that the word φ is free if and only if it is free in x. We have the equivalences for the words φ, x, and x in this way. We can also use the equivalence for the word x, y, and y in the same way. For instance, we could say: φ (x) (y) (x), y (y), x (x, y), y, y (x The rule for eliminat-                ing is the following: If φ is true, then you could replace the x in φ by any term t. The intuitive soundness of this rule is self-evident. Recall that                and necessary requirements for any sane concept of (extensional) equality. We leave the topic of equality for now to move on to the proof rules for                quantiﬁers. The rules for universal quantification can be found in the next section of the book, ‘The Theory of Quantification’, which is published by Oxford University Press, priced £16.99 (US) and £19.99 ($24.99) The rule  is a bit more complicated. It employs a proof box similar to those we have already seen in natural deduction for propositional logic, but this time the box is to stipulate the scope of the ‘dummy variable’ x0. The rule is to enforce the side condition that t be free for x in φ. The statement  says that for all numbers                n there is some bigger number m, which is indeed true of integers or real                numbers. However, φ[y/x] is the formula  saying that there is a                number which is bigger than itself. This is wrong; and we must not allow a                proof rule which derives semantically wrong things from semantically Predicate logic extends propositional logic not only with quantiﬁers but also with function symbols. Consider the declarative sentence: Every child is younger than its mother. The rule  is written  referring to the argument above in a symbolic form. The need for a richer language needs to be addressed, too, we say. We need a language that is richer in terms of predicates, function symbols, and other concepts. We call this a new kind of language, the richer language of predicate logic, and it will be used in the next section of this article. We hope that this will help you understand the language of predicate logic a little better. The inelegance of coding ‘mother’ as a predicate is even more apparent if we consider the sentence:Andy and Paul have the same maternal grandmother. The function symbols of predicate logic give us a way of avoiding this grotesqueugly encoding, for they allow us to represent y’s mother in a more direct way. We write x = y instead of = (x, y) to say that x and y are equal. We use a special predicate in predicate logic, equality, which is a binary predicate, and is written =. Unlike other predicates, it is usually written in between its arguments rather than before them; that is, we write x + v instead of x + y. The symbol m is a function symbol. Instead of writing M(x, y) to mean that x is y’s mother, we simply.write m(y) to means y's mother. Let ρ be a valuation with ρ(x′ worrisome1) = 1 and ρ (x′ horrifying2) = 0. Determine whether ρ ⊨frulyholds for the following: x1[ˆx]  (x1 + x2), x2[˄x] (x2 + x3), x3 (x4 + x4), x5 (x5 + x6), x6 (x6 + x7), x7 (x Using the model of Figure 6.24 (page 384), determine whether ρ ⊨f EX (x1∨¬x2)holds. Deﬁne a direct coding f AU φ by modifying (6.18) appropriately. Mimic the example checks on page 396 for the connective AU. Find a boolean formula without ﬁxed points which is semantically equiva-                lent to f E[(x1 ∼U(¬ x1∧¬X2)]. For example, f E [x1â€™s U (¬ x1î€’s ‘x2’] is correct if In the grammar (6.10) for the relational mu-calculus, S and I have just one (they are called unary predicates), but predicate Y requires two arguments (it is called a binary predicate) Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’ or ‘There is some x which is a bird and cannot’. This is closer to the linguistic structure of the sentence above. We use f EG ¬x1 for the model in Figure 6.24. In Section 2.3, we extend our natural deduction calculus of propositional progressivelylogic so that it covers logical formulas of predicate logic as well. In this way we are able to prove the validity of sequents φ1, φ2, . . .    .      in the language we use. We will also explain whyhematicallyformulas like the two above are indeed equivalent semantically. The purpose of this section is to explain how such formulas can be given their meaning in general, and why they should be used in software design and in safety-critical systems. The goal is to reason symbolically orsemantically about the information expressed in those formulas. For example, penguins are birds In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicateLogic can be true or false. We are overloading the previously established proof rules for the previous chapter with rules for propositional connectives. We also introduce new proofrules for dealing with the quanti ﬁers and with the equality symbol in the natural deduction calculus for predicate logic. This allows us to deﬀn semantic entailment in a similar way to that in the first chapter of the book. We call this the ‘synthetic entailment’ of predicatelogic. Equality does not mean syntactic, or intensional, equality, but equality in terms of computation results. In either of these senses, any term t has to be equal to itself. As in the natural deduction calculus for propositional logic, the additional rules                for the quantiﬁers and equality will come in two ﬂavours: introduction and                elimination rules. The proof rules for equality are:t = t autoimmune=i autoimmune(2.5) which is an axiom (as it does not depend on any premises). Notice that it encompasses the rule that equality may be invoked only if t is a term, our language doesn’t permit us to talk about equality between formulas We have already pointed out the open-ended nature of the semantics of predicate logic. We may now express this substitution principle as the rule=e. The rule is an example of a side condition of a proof rule. The semantics of equality can be expanded to include the rule =e. For example, we can express the rule as follows:t1 = t2                 φ[t1/x]                 ω[t2/x], which is the rule of equality. Given a predicate logic over a set of function symbols F and predicates P, we need only a non-empty set A equipped with concrete functions or elements fM and P M. The right arities are agreed upon in our speciﬁcation. Of course, we also stressed that most models have natural interpretations of of of the symbols.2.5 Undecidability of predicate logic: How do we know when a model makes sense and when it doesn’t? The answer is that there is no way out of this peculiarity, and that it is impossible to choose a model that makes sense or one that doesn't. The answer to this question is that the answer is ‘no’ There are a lot of good reasons for maintaining a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. We discussed itsproof rule in natural deduction already in Section 2.3.1. We now move on to the next section of the book. The next section is on the subject of equality in the form of a function =M. The third section is about equality in terms of the quantiﬁer equivalences dis-                cussed in 2.2.2 and 2.4.1 respectively. The fourth and final section is the section on equality in propositional logic. 2 and 3 are not equivalent to 2 and 3, as we saw earlier. We do not have equiv-                alences between 2 and 2, or between 3 and 3. For example, in the fourth item of Example 5.6 we had x5 ⊩2(p ∨q) and x5 ̸⊩ 2p (p  2q) But we must show that x has an accessible world, i.e. satisﬁes 3⊤. We can also show that 2 is equivalent to 3, but not to 3. It is also not surprising to ﬁnd that 2 does not distribute over ∨ and 3 does not distribution over A formula φ of basic modal logic is said to be valid if it is true in every world of every model, i.e. iﬀ⊨φ holds. A substitution instance of a formula is the result of uniformlysubstituting the atoms of the formula by other formulas as done in (5.2). For example, since p ∨¬p is a tautology, performing the substitution p                 →2p ∧(q →p) gives us a valid formula (2p                 (q) → 2p (q) (2P                  (q), 2P (q, p), 2 P (p, p, p) (",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-2-section-4",
                    "title": "Semantics of Predicate Logic",
                    "content": "9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nφ1, φ2, . . . , φn ⊨ψ.\nThe latter expresses that, given any such model in which all φ1, φ2, . . . , φn\nhold, it is the case that ψ holds in that model as well. In that case, one\nalso says that ψ is semantically entailed by φ1, φ2, . . . , φn. Although this\ndeﬁnition of semantic entailment closely matches the one for propositional\nlogic in Deﬁnition 1.34, the process of evaluating a predicate formula diﬀers\nfrom the computation of truth values for propositional logic in the treatment\nof predicates (and functions). We discuss it in detail in Section 2.4.\nIt is outside the scope of this book to show that the natural deduction\ncalculus for predicate logic is sound and complete with respect to semantic\nentailment; but it is indeed the case that\nφ1, φ2, . . . , φn ⊢ψ\niﬀ\nφ1, φ2, . . . , φn ⊨ψ\nfor formulas of the predicate calculus. The ﬁrst proof of this was done by\nthe mathematician K. G¨odel.\nWhat kind of reasoning must predicate logic be able to support? To get\na feel for that, let us consider the following argument:\nNo books are gaseous. Dictionaries are books. Therefore, no dictio-\nnary is gaseous.\nThe predicates we choose are\nB(x) :\nx is a book\nG(x) :\nx is gaseous\nD(x) :\nx is a dictionary.\nEvidently, we need to build a proof theory and semantics that allow us to\nderive the validity and semantic entailment, respectively, of\n¬∃x (B(x) ∧G(x)), ∀x (D(x) →B(x)) ⊢¬∃x (D(x) ∧G(x))\n¬∃x (B(x) ∧G(x)), ∀x (D(x) →B(x)) ⊨¬∃x (D(x) ∧G(x)).\nVerify that these sequents express the argument above in a symbolic form.\nPredicate logic extends propositional logic not only with quantiﬁers but\nwith one more concept, that of function symbols. Consider the declarative\nsentence\nEvery child is younger than its mother.\nHowever, we can sometimes reason that certain semantic entailments are\nvalid. We do this by providing an argument that does not depend on the\nactual model at hand. Of course, this works only for a very limited number\nof cases. The most prominent ones are the quantiﬁer equivalences which we\nalready encountered in the section on natural deduction. Let us look at a\ncouple of examples of semantic entailment.\nExample 2.21 The justiﬁcation of the semantic entailment\n∀x (P(x) →Q(x)) ⊨∀x P(x) →∀x Q(x)\nis as follows. Let M be a model satisfying ∀x (P(x) →Q(x)). We need to\nshow that M satisﬁes ∀x P(x) →∀x Q(x) as well. On inspecting the deﬁni-\ntion of M ⊨ψ1 →ψ2, we see that we are done if not every element of our\nmodel satisﬁes P. Otherwise, every element does satisfy P. But since M\nsatisﬁes ∀x (P(x) →Q(x)), the latter fact forces every element of our model\nto satisfy Q as well. By combining these two cases (i.e. either all elements of\nM satisfy P, or not) we have shown that M satisﬁes ∀x P(x) →∀x Q(x).\nWhat about the converse of the above? Is\n∀x P(x) →∀x Q(x) ⊨∀x (P(x) →Q(x))\nvalid as well? Hardly! Suppose that M′ is a model satisfying ∀x P(x) →\n∀x Q(x). If A′ is its underlying set and P M′ and QM′ are the corresponding\ninterpretations of P and Q, then M′ ⊨∀x P(x) →∀x Q(x) simply says that,\nif P M′ equals A′, then QM′ must equal A′ as well. However, if P M′ does not\nequal A′, then this implication is vacuously true (remember that F →· = T\nno matter what · actually is). In this case we do not get any additional\nconstraints on our model M′. After these observations, it is now easy to\nconstruct a counter-example model. Let A′ def\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\nthe truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nany other variable y to l(y).\nFinally, we are able to give a semantics to formulas of predicate logic. For\npropositional logic, we did this by computing a truth value. Clearly, it suﬃces\nto know in which cases this value is T.\n128\n2 Predicate logic\nDeﬁnition 2.18 Given a model M for a pair (F, P) and given an environ-\nment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula\nφ over the pair (F, P) and look-up table l by structural induction on φ. If\nM ⊨l φ holds, we say that φ computes to T in the model M with respect to\nthe environment l.\nP:\nIf φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, t2, . . . , tn in\nour set A by replacing all variables with their values according to l. In this way\nwe compute concrete values a1, a2, . . . , an of A for each of these terms, where\nwe interpret any function symbol f ∈F by f M. Now M ⊨l P(t1, t2, . . . , tn)\nholds iﬀ(a1, a2, . . . , an) is in the set P M.\n∀x:\nThe relation M ⊨l ∀x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for all a ∈A.\n∃x:\nDually, M ⊨l ∃x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for some a ∈A.\n¬:\nThe relation M ⊨l ¬ψ holds iﬀit is not the case that M ⊨l ψ holds.\n∨:\nThe relation M ⊨l ψ1 ∨ψ2 holds iﬀM ⊨l ψ1 or M ⊨l ψ2 holds.\n∧:\nThe relation M ⊨l ψ1 ∧ψ2 holds iﬀM ⊨l ψ1 and M ⊨l ψ2 hold.\n→:\nThe relation M ⊨l ψ1 →ψ2 holds iﬀM ⊨l ψ2 holds whenever M ⊨l ψ1 holds.\nWe sometimes write M ̸⊨l φ to denote that M ⊨l φ does not hold.\nThere is a straightforward inductive argument on the height of the parse\ntree of a formula which says that M ⊨l φ holds iﬀM ⊨l′ φ holds, whenever\nl and l′ are two environments which are identical on the set of free variables\nof φ. In particular, if φ has no free variables at all, we then call φ a sentence;\nwe conclude that M ⊨l φ holds, or does not hold, regardless of the choice of\nl. Thus, for sentences φ we often elide l and write M ⊨φ since the choice of\nan environment l is then irrelevant.\nExample 2.19 Let us illustrate the deﬁnitions above by means of an-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nsuggesting that q is a logical consequence of p. We write p →q for that3. We\ncall p the assumption of p →q and q its conclusion.\nOf course, we are entitled to use these rules of constructing propositions\nrepeatedly. For example, we are now in a position to form the proposition\np ∧q →¬r ∨q\nwhich means that ‘if p and q then not r or q’. You might have noticed a\npotential ambiguity in this reading. One could have argued that this sentence\nhas the structure ‘p is the case and if q then . . . ’ A computer would require\nthe insertion of brackets, as in\n(p ∧q) →((¬r) ∨q)\n2 Its meaning should not be confused with the often implicit meaning of or in natural language\ndiscourse as either . . . or. In this text or always means at least one of them and should not be\nconfounded with exclusive or which states that exactly one of the two statements holds.\n3 The natural language meaning of ‘if . . . then . . . ’ often implicitly assumes a causal role of\nthe assumption somehow enabling its conclusion. The logical meaning of implication is a bit\ndiﬀerent, though, in the sense that it states the preservation of truth which might happen\nwithout any causal relationship. For example, ‘If all birds can ﬂy, then Bob Dole was never\npresident of the United States of America.’ is a true statement, but there is no known causal\nconnection between the ﬂying skills of penguins and eﬀective campaigning.\n1.2 Natural deduction\n5\nto disambiguate this assertion. However, we humans get annoyed by a pro-\nliferation of such brackets which is why we adopt certain conventions about\nthe binding priorities of these symbols.\nConvention 1.3 ¬ binds more tightly than ∨and ∧, and the latter two\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly, an interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nto be {(a, a), (b, b), (c, c)}. Hence the semantics of equality is easy, for it is\nalways modelled extensionally.\n2.5 Undecidability of predicate logic\nWe continue our introduction to predicate logic with some negative results.\nGiven a formula φ in propositional logic we can, at least in principle, de-\ntermine whether ⊨φ holds: if φ has n propositional atoms, then the truth\ntable of φ contains 2n lines; and ⊨φ holds if, and only if, the column for φ\n(of length 2n) contains only T entries.\nThe bad news is that such a mechanical procedure, working for all for-\nmulas φ, cannot be provided in predicate logic. We will give a formal proof\nof this negative result, though we rely on an informal (yet intuitive) notion\nof computability.\nThe problem of determining whether a predicate logic formula is valid is\nknown as a decision problem. A solution to a decision problem is a program\n(written in Java, C, or any other common language) that takes problem\ninstances as input and always terminates, producing a correct ‘yes’ or ‘no’\noutput. In the case of the decision problem for predicate logic, the input to\nthe program is an arbitrary formula φ of predicate logic and the program\n132\n2 Predicate logic\nis correct if it produces ‘yes’ whenever the input formula is valid and ‘no’\nwhenever it is not. Note that the program which solves a decision problem\nmust terminate for all well-formed input: a program which goes on thinking\nabout it for ever is not allowed. The decision problem at hand is this:\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\nouter product, whereas the interleaving model has an outer sum. The latter,\nif used in ∃ˆx′.f (‘for some next state’), can be optimised since sums distribute\nover existential quantiﬁcation; in Chapter 2 this was the equivalence ∃x.(φ ∨\nψ) ≡∃x.φ ∨∃x.ψ. Thus, global states reachable in one step are the ‘union’\nof all the states reachable in one step in the local components; compare the\nformulas in (6.8) and (6.9) with (6.6).\n6.4 A relational mu-calculus\nWe saw in Section 3.7 that evaluating the set of states satisfying a CTL for-\nmula in a model may involve the computation of a ﬁxed point of an operator.\nFor example, [[EF φ]] is the least ﬁxed point of the operator F : P(S) →P(S)\ngiven by F(X) = [[φ]] ∪pre∃(X).\nIn this section, we introduce a syntax for referring to ﬁxed points in the\ncontext of boolean formulas. Fixed-point invariants frequently occur in all\nsorts of applications (for example, the common-knowledge operator CG in\nChapter 5), so it makes sense to have an intermediate language for express-\ning such invariants syntactically. This language also provides a formalism\nfor describing interactions and dependences of such invariants. We will see\nshortly that symbolic model checking in the presence of simple fairness con-\nstraints exhibits such more complex relationships between invariants.\n6.4.1 Syntax and semantics\nDeﬁnition 6.14 The formulas of the relational mu-calculus are given by\nthe grammar\nv ::= x | Z\nf ::= 0 | 1 | v | f | f1 + f2 | f1 · f2 | f1 ⊕f2 |\n∃x.f | ∀x.f | µZ.f | νZ.f | f[ˆx := ˆx′]\n(6.10)\nwhere x and Z are boolean variables, and ˆx is a tuple of variables. In the\nformulas µZ.f and νZ.f, any occurrence of Z in f is required to fall within an\neven number of complementation symbols ¯; such an f is said to be formally\nmonotone in Z. (In exercise 7 on page 410 we consider what happens if we\ndo not require formal monotonicity.)\n6.4 A relational mu-calculus\n391\nConvention 6.15 The binding priorities for the grammar in (6.10) are that\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nand necessary requirements for any sane concept of (extensional) equality.\nWe leave the topic of equality for now to move on to the proof rules for\nquantiﬁers.\nThe proof rules for universal quantification\nThe rule for eliminat-\ning ∀is the following:\n∀x φ\nφ[t/x]\n∀x e.\nIt says: If ∀x φ is true, then you could replace the x in φ by any term t\n(given, as usual, the side condition that t be free for x in φ) and conclude\nthat φ[t/x] is true as well. The intuitive soundness of this rule is self-evident.\nRecall that φ[t/x] is obtained by replacing all free occurrences of x in φ\nby t. You may think of the term t as a more concrete instance of x. Since φ\nis assumed to be true for all x, that should also be the case for any term t.\nExample 2.11 To see the necessity of the proviso that t be free for x in\nφ, consider the case that φ is ∃y (x < y) and the term to be substituted\nfor x is y. Let’s suppose we are reasoning about numbers with the usual\n‘smaller than’ relation. The statement ∀x φ then says that for all numbers\nn there is some bigger number m, which is indeed true of integers or real\nnumbers. However, φ[y/x] is the formula ∃y (y < y) saying that there is a\nnumber which is bigger than itself. This is wrong; and we must not allow a\nproof rule which derives semantically wrong things from semantically valid\n110\n2 Predicate logic\nones. Clearly, what went wrong was that y became bound in the process of\nsubstitution; y is not free for x in φ. Thus, in going from ∀x φ to φ[t/x],\nwe have to enforce the side condition that t be free for x in φ: use a fresh\nvariable for y to change φ to, say, ∃z (x < z) and then apply [y/x] to that\nformula, rendering ∃z (y < z).\nThe rule ∀x i is a bit more complicated. It employs a proof box similar\nto those we have already seen in natural deduction for propositional logic,\nbut this time the box is to stipulate the scope of the ‘dummy variable’ x0\nrather than the scope of an assumption. The rule ∀x i is written\nx0\n...\nφ[x0/x]\n∀x φ\n∀x i.\nx\ny\nS\nQ\n∧\nFigure 2.4. A parse tree for which a substitution has dire consequences.\n2.3 Proof theory of predicate logic\n2.3.1 Natural deduction rules\nProofs in the natural deduction calculus for predicate logic are similar to\nthose for propositional logic in Chapter 1, except that we have new proof\nrules for dealing with the quantiﬁers and with the equality symbol. Strictly\nspeaking, we are overloading the previously established proof rules for the\npropositional connectives ∧, ∨etc. That simply means that any proof rule\nof Chapter 1 is still valid for logical formulas of predicate logic (we origi-\nnally deﬁned those rules for logical formulas of propositional logic). As in\nthe natural deduction calculus for propositional logic, the additional rules\nfor the quantiﬁers and equality will come in two ﬂavours: introduction and\nelimination rules.\nThe proof rules for equality\nFirst, let us state the proof rules for\nequality. Here equality does not mean syntactic, or intensional, equality,\nbut equality in terms of computation results. In either of these senses, any\nterm t has to be equal to itself. This is expressed by the introduction rule\nfor equality:\nt = t\n=i\n(2.5)\nwhich is an axiom (as it does not depend on any premises). Notice that it\n108\n2 Predicate logic\nmay be invoked only if t is a term, our language doesn’t permit us to talk\nabout equality between formulas.\nThis rule is quite evidently sound, but it is not very useful on its own.\nWhat we need is a principle that allows us to substitute equals for equals\nrepeatedly. For example, suppose that y ∗(w + 2) equals y ∗w + y ∗2; then\nit certainly must be the case that z ≥y ∗(w + 2) implies z ≥y ∗w + y ∗2\nand vice versa. We may now express this substitution principle as the rule\n=e:\nt1 = t2\nφ[t1/x]\nφ[t2/x]\n=e.\nNote that t1 and t2 have to be free for x in φ, whenever we want to apply\nthe rule =e; this is an example of a side condition of a proof rule.\nConvention 2.10 Throughout this section, when we write a substitution\nhow SMV could use fairness assumptions which were not expressible entirely\n5 Since we have added the variable u, there are actually six states; they all satisfy the formula.\n6.4 A relational mu-calculus\n397\nwithin CTL and its semantics. The addition of fairness could be achieved\nby restricting the ordinary CTL semantics to fair computation paths, or fair\nstates. Formally, we were given a set C = {ψ1, ψ2, . . . , ψk} of CTL formulas,\ncalled the fairness constraints, and we wanted to check whether s ⊨φ holds\nfor a CTL formula φ and all initial states s, with the additional fairness\nconstraints in C. Since ⊥, ¬, ∧, EX, EU and EG form an adequate set of\nconnectives for CTL, we may restrict this discussion to only these operators.\nClearly, the propositional connectives won’t change their meaning with the\naddition of fairness constraints. Therefore, it suﬃces to provide symbolic\ncodings for the fair connectives ECX, ECU and ECG from Chapter 3. The\nkey is to represent the set of fair states symbolically as a boolean formula\nfair deﬁned as\nfair\ndef\n= fECG⊤\n(6.22)\nwhich uses the (yet to be deﬁned) function fECG φ with ⊤as an instance.\nAssuming that the coding of fECG φ is correct, we see that fair computes 1\nin a state s if, and only if, there is a fair path with respect to C that begins\nin s. We say that such an s is a fair state.\nAs for ECX, note that s ⊨ECXφ if, and only if, there is some next state s′\nwith s →s′ and s′ ⊨φ such that s′ is a fair state. This immediately renders\nfECXφ def\n= ∃ˆx′.(f→· (fφ · fair)[ˆx := ˆx′]).\n(6.23)\nSimilarly, we obtain\nfEC[φ1Uφ2] def\n= µZ. (fφ2 · fair + fφ1 · ∃ˆx′. (f→· Z[ˆx := ˆx′])).\n(6.24)\nThis leaves us with the task of coding fECG φ. It is this last connective\nwhich reveals the complexity of fairness checks at work. Because the coding\nof fECG φ is rather complex, we proceed in steps. It is convenient to have the\nEX and EU functionality also at the level of boolean formulas directly. For\nreplaced by every student’s name in turn. Similarly, when trying to codify\na sentence having to do with the execution of a program, it would be rather\nlaborious to have to write down every state of the computer. Therefore,\nwe employ the concept of a variable. Variables are written u, v, w, x, y, z, . . .\nor x1, y3, u5, . . . and can be thought of as place holders for concrete values\n(like a student, or a program state). Using variables, we can now specify the\nmeanings of S, I and Y more formally:\nS(x) :\nx is a student\nI(x) :\nx is an instructor\nY (x, y) :\nx is younger than y.\nNote that the names of the variables are not important, provided that we\nuse them consistently. We can state the intended meaning of I by writing\nI(y) :\ny is an instructor\nor, equivalently, by writing\nI(z) :\nz is an instructor.\nVariables are mere place holders for objects. The availability of variables is\nstill not suﬃcient for capturing the essence of the example sentence above.\nWe need to convey the meaning of ‘Every student x is younger than some\ninstructor y.’ This is where we need to introduce quantiﬁers ∀(read: ‘for\nall’) and ∃(read: ‘there exists’ or ‘for some’) which always come attached\nto a variable, as in ∀x (‘for all x’) or in ∃z (‘there exists z’, or ‘there is some\nz’). Now we can write the example sentence in an entirely symbolic way as\n∀x (S(x) →(∃y (I(y) ∧Y (x, y)))).\n2.1 The need for a richer language\n95\nActually, this encoding is rather a paraphrase of the original sentence. In\nour example, the re-translation results in\nFor every x, if x is a student, then there is some y which is an\ninstructor such that x is younger than y.\nDiﬀerent predicates can have a diﬀerent number of arguments. The predi-\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ.\nThe equivalence of φ and ψ means that φ and ψ are semantically inter-\nchangeable. If φ is a subformula of some bigger formula χ, and ψ ≡φ, then\nwe can make the substitution of ψ for φ in χ without changing the meaning\nof χ. In propositional logic, we saw that ∧and ∨are duals of each other,\nmeaning that if you push a ¬ past a ∧, it becomes a ∨, and vice versa:\n¬(φ ∧ψ) ≡¬φ ∨¬ψ\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n(Because ∧and ∨are binary, pushing a negation downwards in the parse\ntree past one of them also has the eﬀect of duplicating that negation.)\n3.2 Linear-time temporal logic\n185\nSimilarly, F and G are duals of each other, and X is dual with itself:\n¬G φ ≡F ¬φ\n¬F φ ≡G ¬φ\n¬X φ ≡X ¬φ.\nAlso U and R are duals of each other:\n¬(φ U ψ) ≡¬φ R ¬ψ\n¬(φ R ψ) ≡¬φ U ¬ψ.\nWe should give formal proofs of these equivalences. But they are easy, so we\nleave them as an exercise to the reader. ‘Morally’ there ought to be a dual\nfor W, and you can invent one if you like. Work out what it might mean,\nand then pick a symbol based on the ﬁrst letter of the meaning. However, it\nmight not be very useful.\nIt’s also the case that F distributes over ∨and G over ∧, i.e.,\nF (φ ∨ψ) ≡F φ ∨F ψ\nG (φ ∧ψ) ≡G φ ∧G ψ.\nCompare this with the quantiﬁer equivalences in Section 2.3.2. But F does\nnot distribute over ∧. What this means is that there is a model with a\npath which distinguishes F (φ ∧ψ) and F φ ∧F ψ, for some φ, ψ. Take the\npath s0 →s1 →s0 →s1 →. . . from the system of Figure 3.3, for example;\nit satisﬁes F p ∧F r but it doesn’t satisfy F (p ∧r).\nHere are two more equivalences in LTL:\nF φ ≡⊤U φ\nG φ ≡⊥R φ.\nThe ﬁrst one exploits the fact that the clause for Until states two things:",
                    "summary": "Let φ and ψ and η be sentences of predicate logic. If ψ is semantically entailed by φ, is it necessarily the case that ω is not? The answer is that it is not. For each set of formulas below show that they are consistent, the answer is the same. The answer to the first question is that the first formula is consistent. The second and third formulas show that the second and the third formulas are consistent as well. The fourth and final formula shows that the fourth and fifth formulas are also consistent, and the sixth and seventh formulas are not. The answers are the same as the first and fourth formulas. The final formula is the fifth and sixth. For each of the formulas of predicate logic below, either ﬁnd a model which does not satisfy it, or prove it is valid. For each formula, either the model which doesn't satisfy it is not valid, or it can be proved to be valid. Exercises 2.5 and 2.6 are given in the section \"Exercises 1.5\" and \"2.5,\" respectively. For the rest of the section, see \"Exercise 1.6\" and \"Exercise 2.1\" for details. For more information on the exercises, see the expert guideline. In Section 2.4, we generalize the valuations of Chapter 1 to a proper                notion of models, real or artiﬁcial worlds in which formulas of predicate logic can be true or false. The latter expresses that, given any such model in which all φ1, φ2, . . . , φn. hold, it is the case that ψ holds in that model as well. In that case, one says that ω is semantically entailed by ω1,  ω2,   . ., ωn. In the next section, we show that the validity of the following sequents cannot be proved by a proof calculus. It is outside the scope of this book to show that the natural deduction for predicate logic is sound and complete with respect to semantic entailment. The process of evaluating a predicate formula diﬀersfrom the computation of truth values for propositional logic in the treatment of predicates (and functions) We discuss it in detail in Section 2.4. The proof of this was done by the mathematician K. G¨odel. To get a feel for that, let us consider the following argument: “No books are gaseous. Dictionaries are books.” The argument is based on the fact that “no book is a book”. Predicate logic extends propositional logic not only with quantiﬁers but also with function symbols. We can sometimes reason that certain semantic entailments arevalid. We do this by providing an argument that does not depend on the model at hand. The most prominent ones are the quanti ﬁer equivalences which we already encountered in the section on natural deduction. The predicates we choose are B(x) and G(x), which express the argument above in a symbolic form. For example, no dictio-                nary is gaseous, but a book is a book and a dictionary is a dictionary. For more information on the theory of predicates, see the Wikipedia article on predicates. The justiﬁcation of the semantic entailment is as follows. Let M be a model satisfying  P(x) →Q(x). We need to show that M satisﬃes  ‘P’ and ‘Q’ satisfy each other as well. The converse of the above is that M′ must also satisfy Q. Let us look at a couple of examples of this kind of entailment. For example, suppose M′ is a model with A′ as its underlying set. If P M′ equals A′, then QM′ must equal A′. If A′ is the underlying set, then M′ simply says that, if A′ equals We have already pointed out the open-ended nature of the semantics of predicate logic. In this article, we show that a se-quent does not have a proof. We also show that soundness implies that the sequent φ1, φ2, . . . , ω does not seman-                tically entail ω. We conclude that the truth-table semantics of a predicate logic over a set of function symbols F and T is the same as that of a truth- table semantics of the same logic over the same set of symbols F, T and F. We then show how to construct a counter-example model of the truth table semantics for the logic of equality. Using natural deduction to decide the validity of instances of ⊢is only one of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,                notion of proofs for sequents. We now investigate various alternatives for deciding these formulas which are based on transforming these formulas syntac-uroustically into ‘equivalent’ ones upon which we can then settle the matter by purely syntactic or algorithmic means. The results of the study are published in the book ‘Theoretical Foundations of Natural Deduction’, which is published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. Two formulas are said to be equivalent if they have the same ‘meaning’ This suggestion is vague and needs to be reﬁned. The truth table for p and q is four lines long, whereas the one for r is only two lines long. However, both formulas are always true. This suggests that we have just one unary predicates, but predicate Y requires two arguments (it is called a binary predicate). The idea is to have a single unary predicate, but two binary ones, such as S and I, as well as a binary one. The idea of a binary predicates is called ‘symbolic predicates’ and it is used in the theory of propositional logic. Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’. We address how such logical formulas can be given their meaning in general. We will also explain why they are indeed equivalent semantically and why they should be used in sentences like ‘Penguins are birds which cannot �ac’ and ‘There are no penguins in the world’, for example. We conclude with a discussion of the meaning of the ‘penguin’ part of the word ‘bird’ in English. In Section 2.3, we extend our natural deduction calculus of propositional logic so that it covers logical formulas of predicate logic as well. In Section. 4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of. predicate logic can be true or false. We are able to give a semantics to formulas ofpredicate logic. in software design with UML or in the creation of safety-critical systems – and much more care must be taken than in the case of propositionally logic. In section 2.4, we allow us to de ﬁne semantic entailment with any other variable y to l(y) Given a model M for a pair (F, P) and given an environ-                ment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula over the pair. If φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, T2, tn in the set A by replacing all variables with their values according to l. In this way, we compute concrete values a1, a2,. . ., an of A for each of these terms, where a1 is a function symbol. We say that φ computes to T in the model M with respect to the The relation M ⊨l ψ holds for all a ∈A. , an) is in the set P M. It is not the case that M ≹ holds. We sometimes write M  M    φ to denote that M    does not hold, regardless of the choice of φ. There is a straightforward inductive argument on the height of the parse tree of a formula which says that M M M φ holds, whenever l′ and l′ are two environments which are identical on the set of free variables M  M φ is called a sentence. The relation M  ≳ M  ω holds iﬀM � Deﬁnition 5.4 for the case  can hold only if x ⊩¬p holds. But x does not hold, since there is a world y with R(x, y) such that y ⊉p holds, for p ∈L(y) Theavailability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. Theorems can now be used to prove semantic entailment in the same manner as for modallogics. For sentences φ we often elide l and write M ⊨φ since the choice of an Verifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly would be rather diﬃcult. Fortunately, we have a much more usable approach, which is an extension, respectively adaptation, of the systems of natural deduction met in Chapters 1 and 2. Recall that we presented natural deduction proofs as linear representations of proof trees. The proof boxes have formulas and/or other boxes inside them. There are rules which dictate how to construct proofs. Boxes open with an assumption; when a box is closed – in accordance with a rule – we say that its assumption is discharged. We would have to consider every Kripke model to prove soundness and completeness of the Every formula must have some justiﬁcation to its right. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. We are entitled to use these rules of constructing propositionsrepeatedly. For example, we are now in a position to form the propositionp ∧q →¬r ∨q. This means that ‘if p and q then not r or q’ But the meaning should not be confused with the often implicit meaning of or in natural language as either . . . or.    ‘p is the case and if q then . .. ’ A computer would require the insertion of brackets, as in p (p) ( In this text or always means at least one of them and should not beconfounded with exclusive or which states that exactly one of the two statements holds. The natural language meaning of ‘if . .. then . . . ’ often implicitly assumes a causal role of somehow enabling its conclusion. For example, ‘If all birds can ﬂy, then Bob Dole was never president of the United States of America’ is a true statement, but there is no known causal connection between penguins and eﬀective campaigning. We humans get annoyed by a pro-liferation of such brackets which is why we adopt certain conventions about the binding priorities of these symbols. 1. Implication →is right-associative: expressions of the form p →q denote p →(q →r). 1.2 Natural deduction is the construction of a calculus for reasoning about proposi-tions, so that we can establish the validity of Examples 1.1 and 1. 2. For example, given a set A, the interpretation =M of equality is forced to be {(a, a), (b, b), (c, c The semantics of equality is easy, for it is always modelled extensionally. The problem of determining whether a predicate logic formula is valid is known as a decision problem. We will give a formal proof of this negative result, though we rely on an informal (yet intuitive) notion of computability. We conclude our introduction to predicate logic with some negative results. Back to Mail Online home. back to the page you came from. The next page will contain the rest of the article. The third and final page will be the introduction to propositional logic. The fourth and fifth pages will contain a discussion of the negative results of the previous section. The last page will include a discussion on the negative result of the first section. The decision problem at hand is this: given a logical formula φ, does it hold, yes or no? We now show that this problem is not solvable; we cannot write a correct Java program that works for all φ. It is important to be clear about the difference between the interleaving model and the outer sum. The latter, if used in ∃ˆx′f (‘for some next state’), can be optimised since sums distribute over existential quantiﬁcation; in Chapter 2 this was the equivalence. The outer sum is the sum of the sums of the previous two models, and can be used to optimise the inner sum. In this section, we introduce a syntax for referring to ﬁxed points in the context of boolean formulas. Fixed-point invariants frequently occur in all kinds of applications, so it makes sense to have an intermediate language for express- purposefullying such invariants syntactically. This language also provides a formalism for describing interactions and dependences of such. invariants.    The relational mu-calculus provides a language for expressing these invariants and for describing their interactions with each other and with other states in a model. The language is based on the CTL for-                mula in Section 3.7 of the previous section. We call this the ‘union’ of global states reachable 6.4.1 Syntax and semantics of the relational mu-calculus. We will see that symbolic model checking exhibits such more complex relationships between invariants. We consider what happens if we do not require formal monotonicity in the formulas of the mu-Calculus. In exercise 7 on page 410 we consider what happened if we did not need formal monotone. We conclude with the definition of the semantics of a relational Mu-Calculator. We call this a \"syntactic model\" and call it a \"semantics\" model. The semantics of this model is the \"semantic model\" of the relationship between the variables x and Z. It is the same as that of a binary variable and a We have already pointed out the open-ended nature of the semantics of predicate logic. We need only a non-empty set A equipped with concrete functions or elements fM and concrete predicates P M in A which have the right arities agreed upon in our speciﬁcation. But central notions like that of semantic entailment really depend on all possible models, even the ones that don’t seem to make any sense.Apparently there is no way out of this peculiarity.   We also stressed that most models have natural interpretations of                2.2.4. The semantics of equality is discussed in more detail in the section on equality and its consequences. Where would you draw the line between a model that makes sense and one that doesn’t? And would any such choice, or set of criteria, not be subjective? Such constraints could also forbid a modiﬁcation of your model if this alteration were caused by a slight adjustment of the problem domain you intended to model. You see that there are a lot of good reasons for maintaining such a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. Equality is the special role of equality in the theory of quantification. The proof rules for universal quantification follow from Section 2.3. The rule for eliminatat-                ing is the following: If φ is true, then you could replace the x in φ by any term t and conclude that φ[t/x] is true as well. The intuitive soundness of this rule is self-evident. We discuss itsproof rule in natural deduction already in Sections 2.1 and 2.2. We leave the topic of equality for now to move on to the proofrules for universalquantification. We will discuss the rules for quantification for the first time in this article. Since φ is assumed to be true for all x, that should also be the case for any term t. Clearly, what went wrong was that y became bound in the process ofsubstitution; y is not free for x in φ. This is wrong; and we must not allow aproof rule which derives semantically wrong things from semantically valid. Predicate logic is not a form of logic, it is a way of thinking about the world. We need to be able to think about numbers in a different way, not just in terms of the usual ‘smaller than’ relation, but also about the ‘bigger’ and ‘lesser’ ones. The rules for the natural deduction calculus for predicate logic are similar to those for propositional logic in Chapter 1. We have new proof rules for dealing with quantiﬁers and with the equality symbol. We are overloading the previously established proofrules for the propositional connectives  ,    , ‘’, “”,  ” and ’’. We also have a new rule for the ‘dummy variable’ x0, which is used to enforce the side condition that t be free for x in φ[t/x] Figure 2.4. A parse tree for which a substitution has dire consequences. Any proof rule of Chapter 1 is still valid for logical formulas of predicate logic. As in the natural deduction calculus for propositional logic, the additional rules for quantiﬁers and equality will come in two ﬂavours: introduction andelimination rules. The proof rules for equality are outlined in the next section of the book. The introduction rule for equality is an axiom (as it does not depend on any premises) and the elimination rule is for equality in terms of computation results. In either of these senses, any term t has to be equal to itself. In CTL, equality between formulas is not enough. We need a principle that allows us to substitute equals for equalsrepeatedly. We may now express this substitution principle as the ruleulent=e:t1 = t2. Since we have added the variable u, there are actually six states; they all satisfy the formula. Since t1 and t2 have to be free for x in φ, whenever we want to apply the rule =e, this is an example of a side condition of a proof rule. In the next section, we will look at how SMV could use fairness assumptions which were not expressible entirely in CTL. We will also look at a relational mu-calculus and its semantics. The addition of fairness could be achieved by restricting the ordinary CTL semantics to fair computation paths, or fairstates. The propositional connectives won’t change their meaning with the addition of the fairness constraints. It suﬃces to provide symboliccodings for the fair connectives ECX, ECU and ECG from Chapter 3 of the CTL textbook. The book is published by Oxford University Press and is available for download from the Google Play store and the Amazon Kindle store. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or The set of fair states symbolically is represented as a boolean formula. We say that there is a fair path with respect to C that begins with s and ends with s. The coding of fECG φ is rather complex, we proceed in steps. It is convenient to have the functionality of ECX and EU functionality also at the level of boolean formulas directly. For ECX, note that s ⊨ECXφ if, and only if, there is some next state s′with s →s′ and s′ ≳ such that s′ is aFair state. For EU, we obtainfEC[φ1Uφ2] def= µZ. This immediately rendersfEC The concept of a variable is used to codify sentences. Variables can be thought of as place holders for concrete values. Using variables, we can now specify themeanings of S, I and Y more formally: S(x) : S is a student, I (x) is an instructor. Y (x, y) : Y is younger than y. The names of the variables are not important, provided that we consistentlyuse them. We can state the intended meaning of I by writing I(y) : I am an instructor, or I(z) : Z is a program state, or z is a state. For example, we could write: I(X) : X is younger, I( We need to convey the meaning of ‘Every student x is younger than some                instructor y’ This is where we need to introduce quantiﬁers. The availability of variables is still not suﬃcient for capturing the essence of the example sentence above. Now we can write the example in an entirely symbolic way as. (S(x) → (∃y (I(y) ∧Y (x, y)). 2.1 The need for a richer language. 2.2 The need to create a new type of language called the ‘symbolic language’. 3. A new kind of language known as ‘non-symmetric’ 2.4 Important equivalences between LTL formulas                Deﬁnition 3.9 We say that two LTL. formulas φ and ψ are semantically.equivalent, or simply equivalent, writing φ ≡ ψ. Predicates with                any ﬅnite number of arguments are possible in predicate logic. Another example is the sentence                Not all birds can ﬂy.operators for quantifying over paths, and can express these properties.3.9 The equivalence of φ. and ω means that φ Pushing a negation downwards in the parse tree past one of them also has the eﬀect of duplicating that negation. ‘Morally’ there ought to be a dualfor W, and you can invent one if you like. However, it might not be very useful. We should give formal proofs of these equivalences. But they are easy, so we purposefullyleave them as an exercise to the reader. We see that F and G are duals of each other, and X is dual with itself. We also show that F distributes over  and G over  , i.e., F   over  and G over ’’. There are two more equivalences in LTL. The first one exploits the fact that the clause for Until states two things:. The second is that F does not distribute over  “f’s” in the system of Figure 3.3, for example; it doesn’t satisfy F (p ”f”) There is a model with a path which distinguishes F ( φ) and F (",
                    "children": [
                        {
                            "id": "chapter-2-section-4-subsection-1",
                            "title": "Models",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-4-subsection-2",
                            "title": "Semantic Entailment",
                            "content": "9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nφ1, φ2, . . . , φn ⊨ψ.\nThe latter expresses that, given any such model in which all φ1, φ2, . . . , φn\nhold, it is the case that ψ holds in that model as well. In that case, one\nalso says that ψ is semantically entailed by φ1, φ2, . . . , φn. Although this\ndeﬁnition of semantic entailment closely matches the one for propositional\nlogic in Deﬁnition 1.34, the process of evaluating a predicate formula diﬀers\nfrom the computation of truth values for propositional logic in the treatment\nof predicates (and functions). We discuss it in detail in Section 2.4.\nIt is outside the scope of this book to show that the natural deduction\ncalculus for predicate logic is sound and complete with respect to semantic\nentailment; but it is indeed the case that\nφ1, φ2, . . . , φn ⊢ψ\niﬀ\nφ1, φ2, . . . , φn ⊨ψ\nfor formulas of the predicate calculus. The ﬁrst proof of this was done by\nthe mathematician K. G¨odel.\nWhat kind of reasoning must predicate logic be able to support? To get\na feel for that, let us consider the following argument:\nNo books are gaseous. Dictionaries are books. Therefore, no dictio-\nnary is gaseous.\nThe predicates we choose are\nB(x) :\nx is a book\nG(x) :\nx is gaseous\nD(x) :\nx is a dictionary.\nEvidently, we need to build a proof theory and semantics that allow us to\nderive the validity and semantic entailment, respectively, of\n¬∃x (B(x) ∧G(x)), ∀x (D(x) →B(x)) ⊢¬∃x (D(x) ∧G(x))\n¬∃x (B(x) ∧G(x)), ∀x (D(x) →B(x)) ⊨¬∃x (D(x) ∧G(x)).\nVerify that these sequents express the argument above in a symbolic form.\nPredicate logic extends propositional logic not only with quantiﬁers but\nwith one more concept, that of function symbols. Consider the declarative\nsentence\nEvery child is younger than its mother.\nHowever, we can sometimes reason that certain semantic entailments are\nvalid. We do this by providing an argument that does not depend on the\nactual model at hand. Of course, this works only for a very limited number\nof cases. The most prominent ones are the quantiﬁer equivalences which we\nalready encountered in the section on natural deduction. Let us look at a\ncouple of examples of semantic entailment.\nExample 2.21 The justiﬁcation of the semantic entailment\n∀x (P(x) →Q(x)) ⊨∀x P(x) →∀x Q(x)\nis as follows. Let M be a model satisfying ∀x (P(x) →Q(x)). We need to\nshow that M satisﬁes ∀x P(x) →∀x Q(x) as well. On inspecting the deﬁni-\ntion of M ⊨ψ1 →ψ2, we see that we are done if not every element of our\nmodel satisﬁes P. Otherwise, every element does satisfy P. But since M\nsatisﬁes ∀x (P(x) →Q(x)), the latter fact forces every element of our model\nto satisfy Q as well. By combining these two cases (i.e. either all elements of\nM satisfy P, or not) we have shown that M satisﬁes ∀x P(x) →∀x Q(x).\nWhat about the converse of the above? Is\n∀x P(x) →∀x Q(x) ⊨∀x (P(x) →Q(x))\nvalid as well? Hardly! Suppose that M′ is a model satisfying ∀x P(x) →\n∀x Q(x). If A′ is its underlying set and P M′ and QM′ are the corresponding\ninterpretations of P and Q, then M′ ⊨∀x P(x) →∀x Q(x) simply says that,\nif P M′ equals A′, then QM′ must equal A′ as well. However, if P M′ does not\nequal A′, then this implication is vacuously true (remember that F →· = T\nno matter what · actually is). In this case we do not get any additional\nconstraints on our model M′. After these observations, it is now easy to\nconstruct a counter-example model. Let A′ def\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\nthe truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nany other variable y to l(y).\nFinally, we are able to give a semantics to formulas of predicate logic. For\npropositional logic, we did this by computing a truth value. Clearly, it suﬃces\nto know in which cases this value is T.\n128\n2 Predicate logic\nDeﬁnition 2.18 Given a model M for a pair (F, P) and given an environ-\nment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula\nφ over the pair (F, P) and look-up table l by structural induction on φ. If\nM ⊨l φ holds, we say that φ computes to T in the model M with respect to\nthe environment l.\nP:\nIf φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, t2, . . . , tn in\nour set A by replacing all variables with their values according to l. In this way\nwe compute concrete values a1, a2, . . . , an of A for each of these terms, where\nwe interpret any function symbol f ∈F by f M. Now M ⊨l P(t1, t2, . . . , tn)\nholds iﬀ(a1, a2, . . . , an) is in the set P M.\n∀x:\nThe relation M ⊨l ∀x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for all a ∈A.\n∃x:\nDually, M ⊨l ∃x ψ holds iﬀM ⊨l[x\u0005→a] ψ holds for some a ∈A.\n¬:\nThe relation M ⊨l ¬ψ holds iﬀit is not the case that M ⊨l ψ holds.\n∨:\nThe relation M ⊨l ψ1 ∨ψ2 holds iﬀM ⊨l ψ1 or M ⊨l ψ2 holds.\n∧:\nThe relation M ⊨l ψ1 ∧ψ2 holds iﬀM ⊨l ψ1 and M ⊨l ψ2 hold.\n→:\nThe relation M ⊨l ψ1 →ψ2 holds iﬀM ⊨l ψ2 holds whenever M ⊨l ψ1 holds.\nWe sometimes write M ̸⊨l φ to denote that M ⊨l φ does not hold.\nThere is a straightforward inductive argument on the height of the parse\ntree of a formula which says that M ⊨l φ holds iﬀM ⊨l′ φ holds, whenever\nl and l′ are two environments which are identical on the set of free variables\nof φ. In particular, if φ has no free variables at all, we then call φ a sentence;\nwe conclude that M ⊨l φ holds, or does not hold, regardless of the choice of\nl. Thus, for sentences φ we often elide l and write M ⊨φ since the choice of\nan environment l is then irrelevant.\nExample 2.19 Let us illustrate the deﬁnitions above by means of an-\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nsuggesting that q is a logical consequence of p. We write p →q for that3. We\ncall p the assumption of p →q and q its conclusion.\nOf course, we are entitled to use these rules of constructing propositions\nrepeatedly. For example, we are now in a position to form the proposition\np ∧q →¬r ∨q\nwhich means that ‘if p and q then not r or q’. You might have noticed a\npotential ambiguity in this reading. One could have argued that this sentence\nhas the structure ‘p is the case and if q then . . . ’ A computer would require\nthe insertion of brackets, as in\n(p ∧q) →((¬r) ∨q)\n2 Its meaning should not be confused with the often implicit meaning of or in natural language\ndiscourse as either . . . or. In this text or always means at least one of them and should not be\nconfounded with exclusive or which states that exactly one of the two statements holds.\n3 The natural language meaning of ‘if . . . then . . . ’ often implicitly assumes a causal role of\nthe assumption somehow enabling its conclusion. The logical meaning of implication is a bit\ndiﬀerent, though, in the sense that it states the preservation of truth which might happen\nwithout any causal relationship. For example, ‘If all birds can ﬂy, then Bob Dole was never\npresident of the United States of America.’ is a true statement, but there is no known causal\nconnection between the ﬂying skills of penguins and eﬀective campaigning.\n1.2 Natural deduction\n5\nto disambiguate this assertion. However, we humans get annoyed by a pro-\nliferation of such brackets which is why we adopt certain conventions about\nthe binding priorities of these symbols.\nConvention 1.3 ¬ binds more tightly than ∨and ∧, and the latter two\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,",
                            "summary": "Let φ and ψ and η be sentences of predicate logic. If ψ is semantically entailed by φ, is it necessarily the case that ω is not? The answer is that it is not. For each set of formulas below show that they are consistent, the answer is the same. The answer to the first question is that the first formula is consistent. The second and third formulas show that the second and the third formulas are consistent as well. The fourth and final formula shows that the fourth and fifth formulas are also consistent, and the sixth and seventh formulas are not. The answers are the same as the first and fourth formulas. The final formula is the fifth and sixth. For each of the formulas of predicate logic below, either ﬁnd a model which does not satisfy it, or prove it is valid. For each formula, either the model which doesn't satisfy it is not valid, or it can be proved to be valid. Exercises 2.5 and 2.6 are given in the section \"Exercises 1.5\" and \"2.5,\" respectively. For the rest of the section, see \"Exercise 1.6\" and \"Exercise 2.1\" for details. For more information on the exercises, see the expert guideline. In Section 2.4, we generalize the valuations of Chapter 1 to a proper                notion of models, real or artiﬁcial worlds in which formulas of predicate logic can be true or false. The latter expresses that, given any such model in which all φ1, φ2, . . . , φn. hold, it is the case that ψ holds in that model as well. In that case, one says that ω is semantically entailed by ω1,  ω2,   . ., ωn. In the next section, we show that the validity of the following sequents cannot be proved by a proof calculus. It is outside the scope of this book to show that the natural deduction for predicate logic is sound and complete with respect to semantic entailment. The process of evaluating a predicate formula diﬀersfrom the computation of truth values for propositional logic in the treatment of predicates (and functions) We discuss it in detail in Section 2.4. The proof of this was done by the mathematician K. G¨odel. To get a feel for that, let us consider the following argument: “No books are gaseous. Dictionaries are books.” The argument is based on the fact that “no book is a book”. Predicate logic extends propositional logic not only with quantiﬁers but also with function symbols. We can sometimes reason that certain semantic entailments arevalid. We do this by providing an argument that does not depend on the model at hand. The most prominent ones are the quanti ﬁer equivalences which we already encountered in the section on natural deduction. The predicates we choose are B(x) and G(x), which express the argument above in a symbolic form. For example, no dictio-                nary is gaseous, but a book is a book and a dictionary is a dictionary. For more information on the theory of predicates, see the Wikipedia article on predicates. The justiﬁcation of the semantic entailment is as follows. Let M be a model satisfying  P(x) →Q(x). We need to show that M satisﬃes  ‘P’ and ‘Q’ satisfy each other as well. The converse of the above is that M′ must also satisfy Q. Let us look at a couple of examples of this kind of entailment. For example, suppose M′ is a model with A′ as its underlying set. If P M′ equals A′, then QM′ must equal A′. If A′ is the underlying set, then M′ simply says that, if A′ equals We have already pointed out the open-ended nature of the semantics of predicate logic. In this article, we show that a se-quent does not have a proof. We also show that soundness implies that the sequent φ1, φ2, . . . , ω does not seman-                tically entail ω. We conclude that the truth-table semantics of a predicate logic over a set of function symbols F and T is the same as that of a truth- table semantics of the same logic over the same set of symbols F, T and F. We then show how to construct a counter-example model of the truth table semantics for the logic of equality. Using natural deduction to decide the validity of instances of ⊢is only one of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,                notion of proofs for sequents. We now investigate various alternatives for deciding these formulas which are based on transforming these formulas syntac-uroustically into ‘equivalent’ ones upon which we can then settle the matter by purely syntactic or algorithmic means. The results of the study are published in the book ‘Theoretical Foundations of Natural Deduction’, which is published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. Two formulas are said to be equivalent if they have the same ‘meaning’ This suggestion is vague and needs to be reﬁned. The truth table for p and q is four lines long, whereas the one for r is only two lines long. However, both formulas are always true. This suggests that we have just one unary predicates, but predicate Y requires two arguments (it is called a binary predicate). The idea is to have a single unary predicate, but two binary ones, such as S and I, as well as a binary one. The idea of a binary predicates is called ‘symbolic predicates’ and it is used in the theory of propositional logic. Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’. We address how such logical formulas can be given their meaning in general. We will also explain why they are indeed equivalent semantically and why they should be used in sentences like ‘Penguins are birds which cannot �ac’ and ‘There are no penguins in the world’, for example. We conclude with a discussion of the meaning of the ‘penguin’ part of the word ‘bird’ in English. In Section 2.3, we extend our natural deduction calculus of propositional logic so that it covers logical formulas of predicate logic as well. In Section. 4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of. predicate logic can be true or false. We are able to give a semantics to formulas ofpredicate logic. in software design with UML or in the creation of safety-critical systems – and much more care must be taken than in the case of propositionally logic. In section 2.4, we allow us to de ﬁne semantic entailment with any other variable y to l(y) Given a model M for a pair (F, P) and given an environ-                ment l, we deﬁne the satisfaction relation M ⊨l φ for each logical formula over the pair. If φ is of the form P(t1, t2, . . . , tn), then we interpret the terms t1, T2, tn in the set A by replacing all variables with their values according to l. In this way, we compute concrete values a1, a2,. . ., an of A for each of these terms, where a1 is a function symbol. We say that φ computes to T in the model M with respect to the The relation M ⊨l ψ holds for all a ∈A. , an) is in the set P M. It is not the case that M ≹ holds. We sometimes write M  M    φ to denote that M    does not hold, regardless of the choice of φ. There is a straightforward inductive argument on the height of the parse tree of a formula which says that M M M φ holds, whenever l′ and l′ are two environments which are identical on the set of free variables M  M φ is called a sentence. The relation M  ≳ M  ω holds iﬀM � Deﬁnition 5.4 for the case  can hold only if x ⊩¬p holds. But x does not hold, since there is a world y with R(x, y) such that y ⊉p holds, for p ∈L(y) Theavailability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. Theorems can now be used to prove semantic entailment in the same manner as for modallogics. For sentences φ we often elide l and write M ⊨φ since the choice of an Verifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly would be rather diﬃcult. Fortunately, we have a much more usable approach, which is an extension, respectively adaptation, of the systems of natural deduction met in Chapters 1 and 2. Recall that we presented natural deduction proofs as linear representations of proof trees. The proof boxes have formulas and/or other boxes inside them. There are rules which dictate how to construct proofs. Boxes open with an assumption; when a box is closed – in accordance with a rule – we say that its assumption is discharged. We would have to consider every Kripke model to prove soundness and completeness of the Every formula must have some justiﬁcation to its right. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. We are entitled to use these rules of constructing propositionsrepeatedly. For example, we are now in a position to form the propositionp ∧q →¬r ∨q. This means that ‘if p and q then not r or q’ But the meaning should not be confused with the often implicit meaning of or in natural language as either . . . or.    ‘p is the case and if q then . .. ’ A computer would require the insertion of brackets, as in p (p) ( In this text or always means at least one of them and should not beconfounded with exclusive or which states that exactly one of the two statements holds. The natural language meaning of ‘if . .. then . . . ’ often implicitly assumes a causal role of somehow enabling its conclusion. For example, ‘If all birds can ﬂy, then Bob Dole was never president of the United States of America’ is a true statement, but there is no known causal connection between penguins and eﬀective campaigning. We humans get annoyed by a pro-liferation of such brackets which is why we adopt certain conventions about the binding priorities of these symbols. 1. Implication → is right-associative: expressions of the form p →q →r denote p →(q → r).1.2 Natural deduction is a form of deduction.",
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-4-subsection-3",
                            "title": "The Semantics of Equality",
                            "content": "an interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nto be {(a, a), (b, b), (c, c)}. Hence the semantics of equality is easy, for it is\nalways modelled extensionally.\n2.5 Undecidability of predicate logic\nWe continue our introduction to predicate logic with some negative results.\nGiven a formula φ in propositional logic we can, at least in principle, de-\ntermine whether ⊨φ holds: if φ has n propositional atoms, then the truth\ntable of φ contains 2n lines; and ⊨φ holds if, and only if, the column for φ\n(of length 2n) contains only T entries.\nThe bad news is that such a mechanical procedure, working for all for-\nmulas φ, cannot be provided in predicate logic. We will give a formal proof\nof this negative result, though we rely on an informal (yet intuitive) notion\nof computability.\nThe problem of determining whether a predicate logic formula is valid is\nknown as a decision problem. A solution to a decision problem is a program\n(written in Java, C, or any other common language) that takes problem\ninstances as input and always terminates, producing a correct ‘yes’ or ‘no’\noutput. In the case of the decision problem for predicate logic, the input to\nthe program is an arbitrary formula φ of predicate logic and the program\n132\n2 Predicate logic\nis correct if it produces ‘yes’ whenever the input formula is valid and ‘no’\nwhenever it is not. Note that the program which solves a decision problem\nmust terminate for all well-formed input: a program which goes on thinking\nabout it for ever is not allowed. The decision problem at hand is this:\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\nouter product, whereas the interleaving model has an outer sum. The latter,\nif used in ∃ˆx′.f (‘for some next state’), can be optimised since sums distribute\nover existential quantiﬁcation; in Chapter 2 this was the equivalence ∃x.(φ ∨\nψ) ≡∃x.φ ∨∃x.ψ. Thus, global states reachable in one step are the ‘union’\nof all the states reachable in one step in the local components; compare the\nformulas in (6.8) and (6.9) with (6.6).\n6.4 A relational mu-calculus\nWe saw in Section 3.7 that evaluating the set of states satisfying a CTL for-\nmula in a model may involve the computation of a ﬁxed point of an operator.\nFor example, [[EF φ]] is the least ﬁxed point of the operator F : P(S) →P(S)\ngiven by F(X) = [[φ]] ∪pre∃(X).\nIn this section, we introduce a syntax for referring to ﬁxed points in the\ncontext of boolean formulas. Fixed-point invariants frequently occur in all\nsorts of applications (for example, the common-knowledge operator CG in\nChapter 5), so it makes sense to have an intermediate language for express-\ning such invariants syntactically. This language also provides a formalism\nfor describing interactions and dependences of such invariants. We will see\nshortly that symbolic model checking in the presence of simple fairness con-\nstraints exhibits such more complex relationships between invariants.\n6.4.1 Syntax and semantics\nDeﬁnition 6.14 The formulas of the relational mu-calculus are given by\nthe grammar\nv ::= x | Z\nf ::= 0 | 1 | v | f | f1 + f2 | f1 · f2 | f1 ⊕f2 |\n∃x.f | ∀x.f | µZ.f | νZ.f | f[ˆx := ˆx′]\n(6.10)\nwhere x and Z are boolean variables, and ˆx is a tuple of variables. In the\nformulas µZ.f and νZ.f, any occurrence of Z in f is required to fall within an\neven number of complementation symbols ¯; such an f is said to be formally\nmonotone in Z. (In exercise 7 on page 410 we consider what happens if we\ndo not require formal monotonicity.)\n6.4 A relational mu-calculus\n391\nConvention 6.15 The binding priorities for the grammar in (6.10) are that\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nand necessary requirements for any sane concept of (extensional) equality.\nWe leave the topic of equality for now to move on to the proof rules for\nquantiﬁers.\nThe proof rules for universal quantification\nThe rule for eliminat-\ning ∀is the following:\n∀x φ\nφ[t/x]\n∀x e.\nIt says: If ∀x φ is true, then you could replace the x in φ by any term t\n(given, as usual, the side condition that t be free for x in φ) and conclude\nthat φ[t/x] is true as well. The intuitive soundness of this rule is self-evident.\nRecall that φ[t/x] is obtained by replacing all free occurrences of x in φ\nby t. You may think of the term t as a more concrete instance of x. Since φ\nis assumed to be true for all x, that should also be the case for any term t.\nExample 2.11 To see the necessity of the proviso that t be free for x in\nφ, consider the case that φ is ∃y (x < y) and the term to be substituted\nfor x is y. Let’s suppose we are reasoning about numbers with the usual\n‘smaller than’ relation. The statement ∀x φ then says that for all numbers\nn there is some bigger number m, which is indeed true of integers or real\nnumbers. However, φ[y/x] is the formula ∃y (y < y) saying that there is a\nnumber which is bigger than itself. This is wrong; and we must not allow a\nproof rule which derives semantically wrong things from semantically valid\n110\n2 Predicate logic\nones. Clearly, what went wrong was that y became bound in the process of\nsubstitution; y is not free for x in φ. Thus, in going from ∀x φ to φ[t/x],\nwe have to enforce the side condition that t be free for x in φ: use a fresh\nvariable for y to change φ to, say, ∃z (x < z) and then apply [y/x] to that\nformula, rendering ∃z (y < z).\nThe rule ∀x i is a bit more complicated. It employs a proof box similar\nto those we have already seen in natural deduction for propositional logic,\nbut this time the box is to stipulate the scope of the ‘dummy variable’ x0\nrather than the scope of an assumption. The rule ∀x i is written\nx0\n...\nφ[x0/x]\n∀x φ\n∀x i.\nx\ny\nS\nQ\n∧\nFigure 2.4. A parse tree for which a substitution has dire consequences.\n2.3 Proof theory of predicate logic\n2.3.1 Natural deduction rules\nProofs in the natural deduction calculus for predicate logic are similar to\nthose for propositional logic in Chapter 1, except that we have new proof\nrules for dealing with the quantiﬁers and with the equality symbol. Strictly\nspeaking, we are overloading the previously established proof rules for the\npropositional connectives ∧, ∨etc. That simply means that any proof rule\nof Chapter 1 is still valid for logical formulas of predicate logic (we origi-\nnally deﬁned those rules for logical formulas of propositional logic). As in\nthe natural deduction calculus for propositional logic, the additional rules\nfor the quantiﬁers and equality will come in two ﬂavours: introduction and\nelimination rules.\nThe proof rules for equality\nFirst, let us state the proof rules for\nequality. Here equality does not mean syntactic, or intensional, equality,\nbut equality in terms of computation results. In either of these senses, any\nterm t has to be equal to itself. This is expressed by the introduction rule\nfor equality:\nt = t\n=i\n(2.5)\nwhich is an axiom (as it does not depend on any premises). Notice that it\n108\n2 Predicate logic\nmay be invoked only if t is a term, our language doesn’t permit us to talk\nabout equality between formulas.\nThis rule is quite evidently sound, but it is not very useful on its own.\nWhat we need is a principle that allows us to substitute equals for equals\nrepeatedly. For example, suppose that y ∗(w + 2) equals y ∗w + y ∗2; then\nit certainly must be the case that z ≥y ∗(w + 2) implies z ≥y ∗w + y ∗2\nand vice versa. We may now express this substitution principle as the rule\n=e:\nt1 = t2\nφ[t1/x]\nφ[t2/x]\n=e.\nNote that t1 and t2 have to be free for x in φ, whenever we want to apply\nthe rule =e; this is an example of a side condition of a proof rule.\nConvention 2.10 Throughout this section, when we write a substitution\nhow SMV could use fairness assumptions which were not expressible entirely\n5 Since we have added the variable u, there are actually six states; they all satisfy the formula.\n6.4 A relational mu-calculus\n397\nwithin CTL and its semantics. The addition of fairness could be achieved\nby restricting the ordinary CTL semantics to fair computation paths, or fair\nstates. Formally, we were given a set C = {ψ1, ψ2, . . . , ψk} of CTL formulas,\ncalled the fairness constraints, and we wanted to check whether s ⊨φ holds\nfor a CTL formula φ and all initial states s, with the additional fairness\nconstraints in C. Since ⊥, ¬, ∧, EX, EU and EG form an adequate set of\nconnectives for CTL, we may restrict this discussion to only these operators.\nClearly, the propositional connectives won’t change their meaning with the\naddition of fairness constraints. Therefore, it suﬃces to provide symbolic\ncodings for the fair connectives ECX, ECU and ECG from Chapter 3. The\nkey is to represent the set of fair states symbolically as a boolean formula\nfair deﬁned as\nfair\ndef\n= fECG⊤\n(6.22)\nwhich uses the (yet to be deﬁned) function fECG φ with ⊤as an instance.\nAssuming that the coding of fECG φ is correct, we see that fair computes 1\nin a state s if, and only if, there is a fair path with respect to C that begins\nin s. We say that such an s is a fair state.\nAs for ECX, note that s ⊨ECXφ if, and only if, there is some next state s′\nwith s →s′ and s′ ⊨φ such that s′ is a fair state. This immediately renders\nfECXφ def\n= ∃ˆx′.(f→· (fφ · fair)[ˆx := ˆx′]).\n(6.23)\nSimilarly, we obtain\nfEC[φ1Uφ2] def\n= µZ. (fφ2 · fair + fφ1 · ∃ˆx′. (f→· Z[ˆx := ˆx′])).\n(6.24)\nThis leaves us with the task of coding fECG φ. It is this last connective\nwhich reveals the complexity of fairness checks at work. Because the coding\nof fECG φ is rather complex, we proceed in steps. It is convenient to have the\nEX and EU functionality also at the level of boolean formulas directly. For\nreplaced by every student’s name in turn. Similarly, when trying to codify\na sentence having to do with the execution of a program, it would be rather\nlaborious to have to write down every state of the computer. Therefore,\nwe employ the concept of a variable. Variables are written u, v, w, x, y, z, . . .\nor x1, y3, u5, . . . and can be thought of as place holders for concrete values\n(like a student, or a program state). Using variables, we can now specify the\nmeanings of S, I and Y more formally:\nS(x) :\nx is a student\nI(x) :\nx is an instructor\nY (x, y) :\nx is younger than y.\nNote that the names of the variables are not important, provided that we\nuse them consistently. We can state the intended meaning of I by writing\nI(y) :\ny is an instructor\nor, equivalently, by writing\nI(z) :\nz is an instructor.\nVariables are mere place holders for objects. The availability of variables is\nstill not suﬃcient for capturing the essence of the example sentence above.\nWe need to convey the meaning of ‘Every student x is younger than some\ninstructor y.’ This is where we need to introduce quantiﬁers ∀(read: ‘for\nall’) and ∃(read: ‘there exists’ or ‘for some’) which always come attached\nto a variable, as in ∀x (‘for all x’) or in ∃z (‘there exists z’, or ‘there is some\nz’). Now we can write the example sentence in an entirely symbolic way as\n∀x (S(x) →(∃y (I(y) ∧Y (x, y)))).\n2.1 The need for a richer language\n95\nActually, this encoding is rather a paraphrase of the original sentence. In\nour example, the re-translation results in\nFor every x, if x is a student, then there is some y which is an\ninstructor such that x is younger than y.\nDiﬀerent predicates can have a diﬀerent number of arguments. The predi-\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ.\nThe equivalence of φ and ψ means that φ and ψ are semantically inter-\nchangeable. If φ is a subformula of some bigger formula χ, and ψ ≡φ, then\nwe can make the substitution of ψ for φ in χ without changing the meaning\nof χ. In propositional logic, we saw that ∧and ∨are duals of each other,\nmeaning that if you push a ¬ past a ∧, it becomes a ∨, and vice versa:\n¬(φ ∧ψ) ≡¬φ ∨¬ψ\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n(Because ∧and ∨are binary, pushing a negation downwards in the parse\ntree past one of them also has the eﬀect of duplicating that negation.)\n3.2 Linear-time temporal logic\n185\nSimilarly, F and G are duals of each other, and X is dual with itself:\n¬G φ ≡F ¬φ\n¬F φ ≡G ¬φ\n¬X φ ≡X ¬φ.\nAlso U and R are duals of each other:\n¬(φ U ψ) ≡¬φ R ¬ψ\n¬(φ R ψ) ≡¬φ U ¬ψ.\nWe should give formal proofs of these equivalences. But they are easy, so we\nleave them as an exercise to the reader. ‘Morally’ there ought to be a dual\nfor W, and you can invent one if you like. Work out what it might mean,\nand then pick a symbol based on the ﬁrst letter of the meaning. However, it\nmight not be very useful.\nIt’s also the case that F distributes over ∨and G over ∧, i.e.,\nF (φ ∨ψ) ≡F φ ∨F ψ\nG (φ ∧ψ) ≡G φ ∧G ψ.\nCompare this with the quantiﬁer equivalences in Section 2.3.2. But F does\nnot distribute over ∧. What this means is that there is a model with a\npath which distinguishes F (φ ∧ψ) and F φ ∧F ψ, for some φ, ψ. Take the\npath s0 →s1 →s0 →s1 →. . . from the system of Figure 3.3, for example;\nit satisﬁes F p ∧F r but it doesn’t satisfy F (p ∧r).\nHere are two more equivalences in LTL:\nF φ ≡⊤U φ\nG φ ≡⊥R φ.\nThe ﬁrst one exploits the fact that the clause for Until states two things:",
                            "summary": "An interpretation function =M to be actual equality on the set A of M. The semantics of equality is easy, for it is always modelled extensionally. The bad news is that such a mechanical procedure, working for all for-                mulas φ, cannot be provided in predicate logic. We continue our introduction to predicate logic with some negative results. Back to Mail Online home. back to the page you came from. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255. The problem of determining whether a predicate logic formula is valid is known as a decision problem. A solution to a decision Problem is a program that takes problem instances as input and always terminates, producing a correct ‘yes’ or ‘no’ output. In the case of the decision problem for predicate logic, the input to the program is an arbitrary formula φ of predicate logic and the program terminates if the formula is not valid. We will give a formal proof of this negative result, though we rely on an informal (yet intuitive) notion of computability. The program which solves this problem must terminate for all well-formed input: a program which goes on thinking about it for ever is not allowed We cannot write a correct C or Java program that works for all φ. The interleaving model has an outer sum. The latter can be optimised since sums distribute over existential quantiﬁcation. The decision problem at hand is this:Given a logical formula φ in predicate logic, does it hold, yes or no? We now show that this problem is not solvable. It is important to be clear about the inner product. In this section, we introduce a syntax for referring to ﬁxed points in the context of boolean formulas. Fixed-point invariants frequently occur in all kinds of applications, so it makes sense to have an intermediate language for express- purposefullying such invariants syntactically. This language also provides a formalism for describing interactions and dependences of such. invariants.    The relational mu-calculus provides a language for expressing these invariants and for describing their interactions with each other and with other states in a model. The language is based on the CTL for-                mula in Section 3.7 of the previous section. We call this the ‘union’ of global states reachable 6.4.1 Syntax and semantics of the relational mu-calculus. We will see that symbolic model checking exhibits such more complex relationships between invariants. We consider what happens if we do not require formal monotonicity in the formulas of the mu-Calculus. In exercise 7 on page 410 we consider what happened if we did not need formal monotone. We conclude with the definition of the semantics of a relational Mu-Calculator. We call this a \"syntactic model\" and call it a \"semantics\" model. The semantics of this model is the \"semantic model\" of the relationship between the variables x and Z. It is the same as that of a binary variable and a We have already pointed out the open-ended nature of the semantics of predicate logic. We need only a non-empty set A equipped with concrete functions or elements fM and concrete predicates P M in A which have the right arities agreed upon in our speciﬁcation. But central notions like that of semantic entailment really depend on all possible models, even the ones that don’t seem to make any sense.Apparently there is no way out of this peculiarity.   We also stressed that most models have natural interpretations of                2.2.4. The semantics of equality is discussed in more detail in the section on equality and its consequences. Where would you draw the line between a model that makes sense and one that doesn’t? And would any such choice, or set of criteria, not be subjective? Such constraints could also forbid a modiﬁcation of your model if this alteration were caused by a slight adjustment of the problem domain you intended to model. You see that there are a lot of good reasons for maintaining such a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. Equality is the special role of equality in the theory of quantification. The proof rules for universal quantification follow from Section 2.3. The rule for eliminatat-                ing is the following: If φ is true, then you could replace the x in φ by any term t and conclude that φ[t/x] is true as well. The intuitive soundness of this rule is self-evident. We discuss itsproof rule in natural deduction already in Sections 2.1 and 2.2. We leave the topic of equality for now to move on to the proofrules for universalquantification. We will discuss the rules for quantification for the first time in this article. Since φ is assumed to be true for all x, that should also be the case for any term t. Clearly, what went wrong was that y became bound in the process ofsubstitution; y is not free for x in φ. This is wrong; and we must not allow aproof rule which derives semantically wrong things from semantically valid. Predicate logic is not a form of logic, it is a way of thinking about the world. We need to be able to think about numbers in a different way, not just in terms of the usual ‘smaller than’ relation, but also about the ‘bigger’ and ‘lesser’ ones. The rules for the natural deduction calculus for predicate logic are similar to those for propositional logic in Chapter 1. We have new proof rules for dealing with quantiﬁers and with the equality symbol. We are overloading the previously established proofrules for the propositional connectives  ,    , ‘’, “”,  ” and ’’. We also have a new rule for the ‘dummy variable’ x0, which is used to enforce the side condition that t be free for x in φ[t/x] Figure 2.4. A parse tree for which a substitution has dire consequences. Any proof rule of Chapter 1 is still valid for logical formulas of predicate logic. As in the natural deduction calculus for propositional logic, the additional rules for quantiﬁers and equality will come in two ﬂavours: introduction andelimination rules. The proof rules for equality are outlined in the next section of the book. The introduction rule for equality is an axiom (as it does not depend on any premises) and the elimination rule is for equality in terms of computation results. In either of these senses, any term t has to be equal to itself. In CTL, equality between formulas is not enough. We need a principle that allows us to substitute equals for equalsrepeatedly. We may now express this substitution principle as the ruleulent=e:t1 = t2. Since we have added the variable u, there are actually six states; they all satisfy the formula. Since t1 and t2 have to be free for x in φ, whenever we want to apply the rule =e, this is an example of a side condition of a proof rule. In the next section, we will look at how SMV could use fairness assumptions which were not expressible entirely in CTL. We will also look at a relational mu-calculus and its semantics. The addition of fairness could be achieved by restricting the ordinary CTL semantics to fair computation paths, or fairstates. The propositional connectives won’t change their meaning with the addition of the fairness constraints. It suﬃces to provide symboliccodings for the fair connectives ECX, ECU and ECG from Chapter 3 of the CTL textbook. The book is published by Oxford University Press and is available for download from the Google Play store and the Amazon Kindle store. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or The set of fair states symbolically is represented as a boolean formula. We say that there is a fair path with respect to C that begins with s and ends with s. The coding of fECG φ is rather complex, we proceed in steps. It is convenient to have the functionality of ECX and EU functionality also at the level of boolean formulas directly. For ECX, note that s ⊨ECXφ if, and only if, there is some next state s′with s →s′ and s′ ≳ such that s′ is aFair state. For EU, we obtainfEC[φ1Uφ2] def= µZ. This immediately rendersfEC The concept of a variable is used to codify sentences. Variables can be thought of as place holders for concrete values. Using variables, we can now specify themeanings of S, I and Y more formally: S(x) : S is a student, I (x) is an instructor. Y (x, y) : Y is younger than y. The names of the variables are not important, provided that we consistentlyuse them. We can state the intended meaning of I by writing I(y) : I am an instructor, or I(z) : Z is a program state, or z is a state. For example, we could write: I(X) : X is younger, I( We need to convey the meaning of ‘Every student x is younger than some                instructor y’ This is where we need to introduce quantiﬁers. The availability of variables is still not suﬃcient for capturing the essence of the example sentence above. Now we can write the example in an entirely symbolic way as. (S(x) → (∃y (I(y) ∧Y (x, y)). 2.1 The need for a richer language. 2.2 The need to create a new type of language called the ‘symbolic language’. 3. A new kind of language known as ‘non-symmetric’ 2.4 Important equivalences between LTL formulas                Deﬁnition 3.9 We say that two LTL. formulas φ and ψ are semantically.equivalent, or simply equivalent, writing φ ≡ ψ. Predicates with                any ﬅnite number of arguments are possible in predicate logic. Another example is the sentence                Not all birds can ﬂy.operators for quantifying over paths, and can express these properties.3.9 The equivalence of φ. and ω means that φ Pushing a negation downwards in the parse tree past one of them also has the eﬀect of duplicating that negation. ‘Morally’ there ought to be a dualfor W, and you can invent one if you like. However, it might not be very useful. We should give formal proofs of these equivalences. But they are easy, so we purposefullyleave them as an exercise to the reader. We see that F and G are duals of each other, and X is dual with itself. We also show that F distributes over  and G over  , i.e., F   over  and G over ’’. There are two more equivalences in LTL. The first one exploits the fact that the clause for Until states two things:. The second is that F does not distribute over  “f’s” in the system of Figure 3.3, for example; it doesn’t satisfy F (p ”f”) There is a model with a path which distinguishes F ( φ) and F (",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-2-section-5",
                    "title": "Undecidability of Predicate Logic",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-2-section-6",
                    "title": "Expressiveness of Predicate Logic",
                    "content": "bols in the same formula, we arrive at fully-ﬂedged second-order logic, e.g.\n∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))).\n(2.15)\nWe have ∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))) iﬀ\nthere is some T such that for all U we have (MT )U ⊨∀x∀y (Q(x, y) →\nQ(y, x)) →∀u∀v (Q(u, v) →P(u, v)), the latter being a model check in ﬁrst-\norder logic.\nIf one wants to quantify over relations of relations, one gets third-order\nlogic etc. Higher-order logics require great care in their design. Typical re-\nsults such as completeness and compactness may quickly fail to hold. Even\nworse, a naive higher-order logic may be inconsistent at the meta-level. Re-\nlated problems were discovered in naive set theory, e.g. in the attempt to\ndeﬁne the ‘set’ A that contains as elements those sets X that do not contain\nthemselves as an element:\nA\ndef\n= {X | X ̸∈X}.\n(2.16)\nWe won’t study higher-order logics in this text, but remark that many the-\norem provers or deductive frameworks rely on higher-order logical frame-\nworks.\n2.7 Micromodels of software\nTwo of the central concepts developed so far are\nr model checking: given a formula φ of predicate logic and a matching model M\ndetermine whether M ⊨φ holds; and\nr semantic entailment: given a set of formulas Γ of predicate logic, is Γ ⊨φ valid?\n142\n2 Predicate logic\nHow can we put these concepts to use in the modelling and reasoning about\nsoftware? In the case of semantic entailment, Γ should contain all the re-\nquirements we impose on a software design and φ may be a property we\nthink should hold in any implementation that meets the requirements Γ.\nSemantic entailment therefore matches well with software speciﬁcation and\nvalidation; alas, it is undecidable in general. Since model checking is de-\ncidable, why not put all the requirements into a model M and then check\nM ⊨φ? The diﬃculty with this approach is that, by comitting to a particu-\nlar model M, we are comitting to a lot of detail which doesn’t form part of\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and\n∆is unsatisﬁable, since the ‘conjunction’ of all sentences in ∆says that\nthere is no path of length 0, no path of length 1, etc. from the node denoted\nby c to the node denoted by c′, but there is a ﬁnite path from c to c′ as\nφ[c/u][c′/v] is true.\n2.6 Expressiveness of predicate logic\n139\nHowever, every ﬁnite subset of ∆is satisﬁable since there are paths of any\nﬁnite length. Therefore, by the Compactness Theorem, ∆itself is satisﬁable.\nThis is a contradiction. Therefore, there cannot be such a formula φ.\n2\n2.6.1 Existential second-order logic\nIf predicate logic cannot express reachability in graphs, then what can, and\nat what cost? We seek an extension of predicate logic that can specify such\nimportant properties, rather than inventing an entirely new syntax, seman-\ntics and proof theory from scratch. This can be realized by applying quan-\ntiﬁers not only to variables, but also to predicate symbols. For a predicate\nsymbol P with n ≥1 arguments, consider formulas of the form\n∃P φ\n(2.11)\nwhere φ is a formula of predicate logic in which P occurs. Formulas of that\nform are the ones of existential second-order logic. An example of arity 2 is\n∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4)\n(2.12)\nwhere each Ci is a Horn clause4\nC1\ndef\n= P(x, x)\nC2\ndef\n= P(x, y) ∧P(y, z) →P(x, z)\nC3\ndef\n= P(u, v) →⊥\nC4\ndef\n= R(x, y) →P(x, y).\nIf we think of R and P as two transition relations on a set of states, then\nC4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive, C2\nspeciﬁes that P is transitive, and C3 ensures that there is no P-path from\nthe node associated to u to the node associated to v.\nGiven a model M with interpretations for all function and predicate sym-\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\nWe conclude this case study by pointing out limitations of Alloy and its\nanalyzer. In order to be able to use a SAT solver for propositional logic\nas an analysis engine, we can only check or run formulas of existential or\nuniversal second-order logic in the bodies of assertions or in the bodies of\nfun-statements (if they are wrapped in existential quantiﬁers for all param-\neters). For example, we cannot even check whether there is an instance of\nAddComponent such that for the resulting PDS a certain scheduling policy is\nimpossible. For less explicit reasons it also seems unlikely that we can check\nin Alloy that every coherent set of components is realizable as P.components\nfor some PDS P. This deﬁciency is due to the inherent complexity of such\nproblems and theorem provers may have to be used if such properties need\nto be guaranteed. On the other hand, the expressiveness of Alloy allows for\nthe rapid prototyping of models and the exploration of simulations and pos-\nsible counterexamples which should enhance once understanding of a design\nand so improve that design’s reliability.\n2.8 Exercises\n157\n2.8 Exercises\nExercises 2.1\n1.\n*\nUse the predicates\nA(x, y) :\nx admires y\nB(x, y) :\nx attended y\nP(x) :\nx is a professor\nS(x) :\nx is a student\nL(x) :\nx is a lecture\nand the nullary function symbol (constant)\nm :\nMary\nto translate the following into predicate logic:\n(a) Mary admires every professor.\n(The answer is not ∀x A(m, P(x)).)\n(b) Some professor admires Mary.\n(c) Mary admires herself.\n(d) No student attended every lecture.\n(e) No lecture was attended by every student.\n(f) No lecture was attended by any student.\n2. Use the predicate speciﬁcations\nB(x, y) :\nx beats y\nF(x) :\nx is an (American) football team\nQ(x, y) :\nx is quarterback of y\nL(x, y) :\nx loses to y\nand the constant symbols\nc :\nWildcats\nj :\nJayhawks\nto translate the following into predicate logic.\n(a) Every football team has a quarterback.\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\n∀x (P(x) →R(x)), ∀x (Q(x) →R(x)) ⊢∃x (P(x) ∧Q(x))\n(c) (∀x P(x)) →L ⊢∀x (P(x) →L), where L has arity 0\n(d)\n*\n∀x ∃y S(x, y) ⊢∃y ∀x S(x, y)\n(e) ∃x P(x), ∃y Q(y) ⊢∃z (P(z) ∧Q(z)).\n(f)\n*\n∃x (¬P(x) ∧Q(x)) ⊢∀x (P(x) →Q(x))\n(g)\n*\n∃x (¬P(x) ∨¬Q(x)) ⊢∀x (P(x) ∨Q(x)).\n2. Assuming that ⊢is sound and complete for ⊨in ﬁrst-order logic, explain in detail\nwhy the undecidability of ⊨implies that satisﬁability, validity, and provability\nare all undecidable for that logic.\n3. To show the soundness of our natural deduction rules for predicate logic, it\nintuitively suﬃces to show that the conclusion of a proof rule is true provided\nthat all its premises are true. What additional complication arises due to the\npresence of variables and quantiﬁers? Can you precisely formalise the necessary\ninduction hypothesis for proving soundness?\nExercises 2.6\n1. In Example 2.23, page 136, does M ⊨l ∃P φ hold if l satisﬁes\n(a)\n*\nl(u) = s3 and l(v) = s1;\n(b) l(u) = s1 and l(v) = s3?\nJustify your answers.\n2. Prove that M ⊨l ∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4) holds iﬀstate l(v) is not reach-\nable from state l(u) in the model M, where the Ci are the ones of (2.12) on\npage 139.\n3. Does Theorem 2.26 from page 138 apply or remain valid if we allow φ to contain\nfunction symbols of any ﬁnite arity?\n4.\n*\nIn the directed graph of Figure 2.5 from page 137, how many paths are there\nthat witness the reachability of node s3 from s2?\n5. Let P and R be predicate symbols of arity 2. Write formulas of existential second-\norder logic of the form ∃P ψ that hold in all models of the form M = (A, RM)\niﬀ\n(a)\n*\nR contains a reﬂexive and symmetric relation;\n(b) R contains an equivalence relation\n(c) there is an R-path that visits each node of the graph exactly once – such a\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\norder logic of the form ∃P ψ that hold in all models of the form M = (A, RM)\niﬀ\n(a)\n*\nR contains a reﬂexive and symmetric relation;\n(b) R contains an equivalence relation\n(c) there is an R-path that visits each node of the graph exactly once – such a\npath is called Hamiltonian\n(d) R can be extended to an equivalence relation: there is some equivalence\nrelation T with RM ⊆T\n(e)\n*\nthe relation ‘there is an R-path of length 2’ is transitive.\n6.\n*\nShow informally that (2.16) on page 141 gives rise to Russell’s paradox: A has\nto be, and cannot be, an element of A.\n7. The second item in the proof of Theorem 2.28 (page 140) relies on the fact\nthat if a binary relation R is contained in a reﬂexive, transitive relation T of\n166\n2 Predicate logic\nthe same type, then T also contains the reﬂexive, transitive closure of R. Prove\nthis.\n8. For the model of Example 2.23 and Figure 2.5 (page 137), determine which model\nchecks hold and justify your answer:\n(a)\n*\n∃P (∀x∀y P(x, y) →¬P(y, x)) ∧(∀u∀v R(u, v) →P(v, u));\n(b) ∀P (∃x∃y∃z P(x, y) ∧P(y, z) ∧¬P(x, z)) →(∀u∀v R(u, v) →P(u, v)); and\n(c) ∀P (∀x ¬P(x, x)) ∨(∀u∀v R(u, v) →P(u, v)).\n9. Express the following statements about a binary relation R in predicate\nlogic, universal second-order logic, or existential second-order logic – if at all\npossible:\n(a) All symmetric, transitive relations either don’t contain R or are equivalence\nrelations.\n(b)\n*\nAll nodes are on at least one R-cycle.\n(c) There is a smallest relation containing R which is symmetric.\n(d) There is a smallest relation containing R which is reﬂexive.\n(e)\n*\nThe relation R is a maximal equivalence relation: R is an equivalence relation;\nand there is no relation contained in R that is an equivalence relation.\nExercises 2.7\n1. (a)\n*\nExplain why the model of Figure 2.11 (page 148) is a counterexample to\nOfLovers in the presence of the fact NoSelfLove.\n(b) Can you identify the set {a, b, c} from Example 2.19 (page 128) with the\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced bols in the same formula, we arrive at fully-ﬂedged second-order logic, e.g.\n∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))).\n(2.15)\nWe have ∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))) iﬀ\nthere is some T such that for all U we have (MT )U ⊨∀x∀y (Q(x, y) →\nQ(y, x)) →∀u∀v (Q(u, v) →P(u, v)), the latter being a model check in ﬁrst-\norder logic.\nIf one wants to quantify over relations of relations, one gets third-order\nlogic etc. Higher-order logics require great care in their design. Typical re-\nsults such as completeness and compactness may quickly fail to hold. Even\nworse, a naive higher-order logic may be inconsistent at the meta-level. Re-\nlated problems were discovered in naive set theory, e.g. in the attempt to\ndeﬁne the ‘set’ A that contains as elements those sets X that do not contain\nthemselves as an element:\nA\ndef\n= {X | X ̸∈X}.\n(2.16)\nWe won’t study higher-order logics in this text, but remark that many the-\norem provers or deductive frameworks rely on higher-order logical frame-\nworks.\n2.7 Micromodels of software\nTwo of the central concepts developed so far are\nr model checking: given a formula φ of predicate logic and a matching model M\ndetermine whether M ⊨φ holds; and\nr semantic entailment: given a set of formulas Γ of predicate logic, is Γ ⊨φ valid?\n142\n2 Predicate logic\nHow can we put these concepts to use in the modelling and reasoning about\nsoftware? In the case of semantic entailment, Γ should contain all the re-\nquirements we impose on a software design and φ may be a property we\nthink should hold in any implementation that meets the requirements Γ.\nSemantic entailment therefore matches well with software speciﬁcation and\nvalidation; alas, it is undecidable in general. Since model checking is de-\ncidable, why not put all the requirements into a model M and then check\nM ⊨φ? The diﬃculty with this approach is that, by comitting to a particu-\nlar model M, we are comitting to a lot of detail which doesn’t form part of\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\n5 In most object-oriented languages, e.g. Java, extends creates a new type. In Alloy 2.0 and 2.1, it\ncreates a subset of a type and not a new type as such, where the subset has additional structure\nand may need to satisfy additional constraints.\n170\n2 Predicate logic\ndetermine whether they can be expressed in ﬁrst-order logic, existential second-\norder logic or universal second-order logic.\n9. Recalling the comment on page 142 that Alloy combines model checking M ⊨φ\nand validity checking Γ ⊨φ, can you discuss to what extent this is so?\n2.9 Bibliographic notes\nMany design decisions have been taken in the development of predicate\nlogic in the form known today. The Greeks and the medievals had systems\nin which many of the examples and exercises in this book could be rep-\nresented, but nothing that we would recognise as predicate logic emerged\nuntil the work of Gottlob Frege in 1879, printed in [Fre03]. An account of\nthe contributions of the many other people involved in the development of\nlogic can be found in the ﬁrst few pages of W. Hodges’ chapter in [Hod83].\nThere are many books covering classical logic and its use in computer sci-\nence; we give a few incomplete pointers to the literature. The books [SA91],\n[vD89] and [Gal87] cover more theoretical applications than those in this\nbook, including type theory, logic programming, algebraic speciﬁcation and\nterm-rewriting systems. An approach focusing on automatic theorem prov-\ning is taken by [Fit96]. Books which study the mathematical aspects of\npredicate logic in greater detail, such as completeness of the proof systems\nand incompleteness of ﬁrst-order arithmetic, include [Ham78] and [Hod83].\nMost of these books present other proof systems besides natural deduction\nsuch as axiomatic systems and tableau systems. Although natural deduction\nhas the advantages of elegance and simplicity over axiomatic methods, there\nare few expositions of it in logic books aimed at a computer science audi-\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and\n∆is unsatisﬁable, since the ‘conjunction’ of all sentences in ∆says that\nthere is no path of length 0, no path of length 1, etc. from the node denoted\nby c to the node denoted by c′, but there is a ﬁnite path from c to c′ as\nφ[c/u][c′/v] is true.\n2.6 Expressiveness of predicate logic\n139\nHowever, every ﬁnite subset of ∆is satisﬁable since there are paths of any\nﬁnite length. Therefore, by the Compactness Theorem, ∆itself is satisﬁable.\nThis is a contradiction. Therefore, there cannot be such a formula φ.\n2\n2.6.1 Existential second-order logic\nIf predicate logic cannot express reachability in graphs, then what can, and\nat what cost? We seek an extension of predicate logic that can specify such\nimportant properties, rather than inventing an entirely new syntax, seman-\ntics and proof theory from scratch. This can be realized by applying quan-\ntiﬁers not only to variables, but also to predicate symbols. For a predicate\nsymbol P with n ≥1 arguments, consider formulas of the form\n∃P φ\n(2.11)\nwhere φ is a formula of predicate logic in which P occurs. Formulas of that\nform are the ones of existential second-order logic. An example of arity 2 is\n∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4)\n(2.12)\nwhere each Ci is a Horn clause4\nC1\ndef\n= P(x, x)\nC2\ndef\n= P(x, y) ∧P(y, z) →P(x, z)\nC3\ndef\n= P(u, v) →⊥\nC4\ndef\n= R(x, y) →P(x, y).\nIf we think of R and P as two transition relations on a set of states, then\nC4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive, C2\nspeciﬁes that P is transitive, and C3 ensures that there is no P-path from\nthe node associated to u to the node associated to v.\nGiven a model M with interpretations for all function and predicate sym-\nfunctional, 321\nlinear, 321\nreﬂexive, 140, 320, 324\nas formula, 109\nserial, 320, 353\nsymmetric, 320\nas formula, 109\ntotal, 321\ntransition, 178\ntransitive, 140, 320, 324\nas formula, 109\nrelational mu-calculus\nﬁxed-point operators, 392\nrequirement\ninformal, 258, 263, 288\nrequirements, 142\nrestriction, 374\nright-associative, 5\nroot of a parse tree, 135\nrule\nderived, 23\nhybrid, 10\nRussell’s paradox, 165\nsafety property, 187, 189, 207\nSAT solver\ncubic, 76\nforcing rules, 71\npermanent marks, 75\ntemporary marks, 74\nsatisfaction\nin a frame, 322\nin a frame for KT45n, 337\nsatisfaction relation\nfor relational mu-calculus, 391\nfor basic modal logic, 310\nfor KT45, 337\nfor LTL, 180\nfor partial correctness, 265\nfor predicate logic, 128\nfor relational mu-calculus, 391\nfor total correctness, 266\nsatisﬁability, 360\n3SAT, 406\ndeciding, 65\nof a propositional logic formula,\n85\nundecidability of predicate logic,\n135\nSCC\nfair, 232\nscheduler\nfair, 197\nscope\nof a dummy variable, 117\nof a variable, 103, 113\nof an assumption, 28, 113, 329\nsearch space, 113, 133\nsecond-order logic, 141\nsemantic entailment\nfor predicate logic, 141\nfor basic modal logic, 313\nfor KT4, 328\nfor normal modal logics, 326\nfor predicate logic, 96\nfor propositional logic, 46\nfor relational mu-calculus, 410\nsemantic equivalence, 39\nsemantics\nof µZ.f, 392\nof νZ.f, 393\nof basic modal logic, 310\nof boolean quantiﬁcation, 392\nof CTL, 211\nof EG, 239\nof equality, 131\nof predicate logic, 122\nof propositional logic, 38\nof relational mu-calculus, 391\nof Until, 181\nsentence\natomic, 4\ncomponents, 93\ndeclarative, 93\nin predicate logic, 128\nsequent, 5\ninvalid, 116\nShannon expansion, 374\nside condition, 108, 110\nSifakis, J., 254\nsmall scope hypothesis, 143\nSMV, 254\nmain program for ABP, 207\nmodule, 193\nreceiver, 205\nsender, 204\nfor channel, 206\ninstantiation, 193\nprocess, 389\nprogram\nexample, 192\nfor Mutex, 195\nspeciﬁcation, 192\nsoftware\nlife-cycle, 142\nmicromodel, 142\nreliability, 149\nrequirements, 142\nspeciﬁcation, 142\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nFloyd, R., 269\nfor-statement, 299\nforall-elimination, 109\nforall-introduction, 110\nformal\npath, 218\nformula\natomic, 175\nheight, 44, 86\nHorn, 65\nill-formed, 177\nimmediate subformula, 223\nof basic modal logic, 314\nof CTL, 208\natomic, 208\nill-formed, 209\nwell-formed, 209\nof LTL\nvalid, 251\nof predicate logic, 100\nof propositional logic, 33, 50\nwell-formed, 32, 33, 44\nof relational mu-calculus, 390\npositive, 328, 343, 348\nscheme, 312, 317\nK, 315\nin propositional logic, 312\ninstance, 312\nsubformula, 35\nframe, 322\nfree for x in φ, 106, 109\nFrege, G., 170\nfunction\nin predicate logic, 124\nmonotone, 240\na non-example, 240\nnullary, 99\nrecursive, 250\nSAT, 225, 227\ntermination, 253\nSATaf, 228\nSATag, 253\nSATeg, 252\nSATeu, 229\nSATex, 228\nsymbol, 96, 98, 157\nbinary, 98\ntranslate, 250\nfunction pre∀(X), 227\nfunction pre∃(X), 227, 385\nfunction pre∀(X), 385\nfunction SAT\ncorrectness, 240\nfuture\nexcludes the present, 249, 353\nincludes the present, 182, 249, 353\nwhether it includes the present, 318\nG-reachable, 338\nin k steps, 338\nG¨odel, K., 96\nGentzen, G., 91\nGlobal Assembly Cache, 149\ngrammar, 33\nclause, 269\nguided simulation, 155\nHalpern, J., 254\nhigher-order logic, 141\nHoare triple, 264\nHoare, C. A. R., 264, 269\nHodges, W., 170\nHorn clause, 65, 139\nhybrid rule, 343\nif-statement, 280\nimplementation\ncompliant, 143\nimplication, 4\nlogical, 278\nimplies-elimination, 9\nimplies-introduction, 12\nin-order representation, 35\ninconsistency, 259\nindex, 132\ninduction\ncourse-of-values, 43\nhypothesis, 41, 42\nin model checking, 229\nmathematical, 40\ninductive step, 41\n422\nIndex\ninﬁx notation, 125, 210\ninformation\nnegative, 343\ninput parameter, 61\ninteger\nexpression, 260\ninteger label, 372\ninteger multiplication, 381\ninterface between logics, 277\ninterleaving\nformulas with code, 275\ntransitions, 188, 194\nintroduction rules, 6, 107\nintrospection\nnegative, 319, 326\npositive, 319, 326\nintuitionistic logic, 30, 120, 327\ninvariants, 273\ndiscovering, 283\nSAT solver, 69\niterative squaring, 412\nJape, 170\nWe saw in the preceding section that there appeared to be a correspondence\nbetween the validity of 2φ →φ and the property that the accessibility re-\nlation R is reﬂexive. The connection between them is that both relied on\nthe intuition that anything which is known by an agent is true. Moreover,\nthere also seemed to be a correspondence between 2φ →22φ and R being\ntransitive; they both seem to assert the property of positive introspection,\ni.e. that which is known is known to be known.\nIn this section, we will see that there is a precise mathematical relation-\nship between these formulas and properties of R. Indeed, to every formula\nscheme there corresponds a property of R. From the point of view of logic\nengineering, it is important to see this relationship, because it helps one to\nunderstand the logic being studied. For example, if you believe that a cer-\ntain formula scheme should be accepted in the system of modal logic you are\nengineering, then it is well worth looking at the corresponding property of\nR and checking that this property makes sense for the application, too. Al-\nternatively, the meaning of some formulas may seem diﬃcult to understand,\nso looking at their corresponding properties of R can help.\nTo state the relationship between formula schemes and their correspond-\ning properties, we need the notion of a (modal) frame.\nDeﬁnition 5.10 A frame F = (W, R) is a set W of worlds and a binary\nrelation R on W.\nA frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-\nbelling function. From any model we can extract a frame, by just forgetting\nabout the labelling function; for example, Figure 5.9 shows the frame ex-\ntracted from the Kripke model of Figure 5.3. A frame is just a set of worlds\nand an accessibility relationship between them. It has no information about\nwhat atomic formulas are true at the various worlds. However, it is useful to\nsay sometimes that the frame, as a whole, satisﬁes a formula. This is deﬁned\nas follows.",
                    "summary": "If we put two. bols in the same formula, we arrive at fully-ﬂedged second-order logic. If one wants to quantify over relations of relations, one gets third-orderLogic etc. Higher-order logics require great care in their design. Typical re-giovernmentsults such as completeness and compactness may quickly fail to hold. Even worse, a naive higher- order logic may be inconsistent at the meta-level. Re-gioght problems were discovered in naive set theory, e.g.    ‘‘’’ ’� We won’t study higher-order logics in this text, but remark that many the-                orem provers or deductive frameworks rely on higher- order logical frame-works. Two of the central concepts developed so far are model checking and semantic entailment. Given a formula φ of predicate logic and a matching model Mdetermine whether M ⊨φ holds; and given a set of formulas Γ, is the formula valid? In the case ofsemantic entailment, φ may be a property we                think should hold in any implementation that meets the requirements of Γ.Semantic entailsment matches well with software speciﬁcation and validateation; alas, it is Since model checking is de-                cidable, why not put all the requirements into a model M and then check it? The diﬃculty with this approach is that we are comitting to a lot of detail which doesn’t form part of the model’sconstants. Let φn be the formula expressing that there is a path of length nfrom c to c′. We deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1, for c = 1, we say R( c, x1, x2)  ‘Conjunction’ of all sentences in We seek an extension of predicate logic that can specify suchimportant properties. This can be realized by applying quan-                tiﬁers not only to variables, but also to predicate symbols. For a predicatesymbol P with n ≥1 arguments, consider formulas of the form P φ(2.11) where φ is a formula of logic in which P occurs. Formulas of thatforming are the ones of existential second-order logic. We show that such aform cannot be found in a graph. An example of arity 2 is P (C1, C2, C3, C4) where each Ci is a Horn clause. C4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive. C3 ensures that there is no P-path from u to the node associated to v. Given a model M with interpretations for all function and predicate sym-phthalon logic for computer science, this is what the model should look like. For example, we could think of R and P as two transition relations on a set This foreword is re-printed in the second edition with its author’s permis-                sion. We developed this theme for propositional, temporal, modal, and program logics. At the heart of this set-up is that one can often specify and implement algorithms for computing. I recommend it to the reader                with greatest enthusiasm and predict that the book will be an enormous                success. The book is published by Oxford University Press, London, priced £16.99. For more information on the book, visit the publisher's website or visit the book's website at: http://www.oxford-uk.com/books/computer-science- The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. We conclude this case study by pointing out limitations of Alloy and itsanalyzer. In order to be able to use a SAT solver for propositional logic                as an analysis engine, we can only check or run formulas of existential oruniversal second-order logic. For example, we cannot even check whether there is an instance of a PDS such that for the resulting PDS a certain scheduling policy is                impossible. For less explicit reasons it also seems unlikely that we can check in Alloy that every coherent set of components is realizable as P.components for some PDS. This deﬁciency is due to the inherent complexity of such problems and theorem provers may have to be used. The expressiveness of Alloy allows for rapid prototyping of models and the exploration of simulations. It should enhance once understanding of a design and so improve that design’s reliability. Use the predicates A(x, y) and L(x) to translate the following into predicate logic: Mary admires every professor. Some professor admires Mary. No student attended every lecture. No lecture was attended by any student. The answer is not A(m, P(x).) But it is the answer to the question ‘What is the number of people in the world who attended the most recent lecture?’ And the answer is ‘Mary’. Every football team has a quarterback. Use the predicate speciﬁcations B(x, y) and F(x) to translate the following into predicate logic. For each sequent a model such that all formulas to the left of T and the sole formula to the right of F (explain why this ensures the non-existence of a proof) is the same for T and F. Use these exercises to prove that the logic is sound and complete for ⊨in ﬁrst-order logic. The undecidability of ⊢implies that validity, and provability, and validity are all undecidable for that logic. Use this logic to explain in detail why the und Exercises 2.5 and 2.6: Prove the soundness of our natural deduction rules for predicate logic. Prove that the conclusion of a proof rule is true provided that all its premises are true. Can you precisely formalise the necessary inductive hypothesis for proving soundness? Can you prove that theorem 2.26 from page 138 applies or remains valid if we allow φ to containfunction symbols of any ﬁnite arity? Can we prove that node s3 is reachable from node s2 in Figure 2. 5 from page 137? How many paths are there that witness the reachability of nodes s3 and s2 from each other? Predicates with any number of arguments are possible in predicate logic. Write formulas of existential second-order logic of the form ∃P ψ that hold in all models. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can can’. The first version is closer to the linguistic structure of the sentence above. For the second version, we could code the sentence as: ‘There is some x which is a bird and cannot ﬁy.’ and the third version as follows: “Not all x can be a bird”. In Section 2.3, we extend our natural deduction calculus of propositional progressivelylogic so that it covers logical formulas of predicate logic as well. In this way we are able to prove the validity of sequents φ1, φ2, . . .    .      in the language we use. We will also explain whyhematicallyformulas like the two above are indeed equivalent semantically. The purpose of this section is to explain how such formulas can be given their meaning in general, and why they should be used in software design and in safety-critical systems. The goal is to reason symbolically orsemantically about the information expressed in those formulas. For example, penguins are birds In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicateLogic can be true or false. We also show that Russell’s paradox gives rise to the idea that A has not to be, and cannot be, an element of A. We conclude the book with a list of some of the things we have learned about the theory of predicatelogic in the last few years. We hope that this will provide a useful starting point for the next section of the book, which will focus on the notion of ‘order’ and ‘theory’ of logic. Theorem 2.28 (page 140) relies on the fact that if a binary relation R is contained in a reﬂexive, transitive relation T of the same type, then T also contains the re-transitive closure of R. For the model of Example 2.23 and Figure 2.5 (page 137), determine which model will hold and justify your answer. Prove this by solving the following equations: P(x, y), P(y, z), P (x, z) The relation R is a maximal equivalence relation. All nodes are on at least one R-cycle. There is a smallest relation containing R which is symmetric. Can you identify the set {a, b, c} from Example 2.19 (page 128) with the defs P M′ and QM′? The answer is “Yes’”. The model of Figure 2.11 (page 148) is a counterexample to NoSelfLove in the presence of the fact NoSelf love. is not a relation. The relation R has the identity “R is an equivalence relations;” and there is no relation contained in R that is a relation that is not an equival We have already pointed out the open-ended nature of the semantics of predicate logic. We need only a non-empty set A equipped with concrete functions or elements fM and concrete predicates P M in A which have the right arities agreed upon in our speciﬁcation. But central notions like that of semantic entailment really depend on all possible models, even the ones that don’t seem to make any sense.Apparently there is no way out of this peculiarity.   We also stressed that most models have natural interpretations of                2.2.4. The semantics of equality is discussed in more detail in the section on equality and its consequences. Where would you draw the line between a model that makes sense and one that doesn’t? And would any such choice, or set of criteria, not be subjective? Such constraints could also forbid a modiﬁcation of your model if this alteration were caused by a slight adjustment of the problem domain you intended to model. You see that there are a lot of good reasons for maintaining such a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. Equality is the special role of equality in second-order logic. We discussed itsuctiveproof rule in natural deduction already in Section 2.3.1. The interpretation =M of equality is forced bols in the same formula, we arrive at fully-ﬂedged second- order logic. If one wants to quantify over relations of relations, one gets third-orderLogic etc. Higher-order logics require great care in their design. Typical re-                sults such as completeness and compactness may quickly fail to hold. For example, given A                def= {a, b, c}, the interpretation of equality  is forced  in the formula. A naive higher-order logic may be inconsistent at the meta-level. Re-lated problems We won’t study higher-order logics in this text, but remark that many the-                orem provers or deductive frameworks rely on higher- order logical frame-works. Two of the central concepts developed so far are model checking and semantic entailment. Given a formula φ of predicate logic and a matching model Mdetermine whether M ⊨φ holds; and given a set of formulas Γ, is the formula valid? In the case ofsemantic entailment, φ may be a property we                think should hold in any implementation that meets the requirements of Γ.Semantic entailsment matches well with software speciﬁcation and validateation; alas, it is This foreword is re-printed in the second edition with its author’s permis- purposefullysion. I recommend it to the reader with greatest enthusiasm and predict that the book will be an enormous success. The book is written in the style of a book on computer science. It is published by Oxford University Press, London, priced £16.99. For more information, visit www.oxfordpub.co.uk or visit the book's website at http://www.ox-pub.com/Computer-Science-Logic-for-Computer-science-2.html. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.sam At the heart of this set-up is that one can often specify and implementgorithms for computing. We developed this theme for propos The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. In most object-oriented languages, e.g. Java, extends creates a new type. In Alloy 2.0 and 2.1, it creates a subset of a type. The Greeks and the medievals had systems that could be rep-resented. But nothing that we would recognise as predicate logic emerged until the work of Gottlob Frege in 1879, printed in Frege [Fre03] The book begins with a discus-                5. It now begins with an example of a predicate logic exercise. The book ends with a discussion of the use of predicate logic in the modern computer science field of computer science. The final chapter is a review of the book's bibliographic notes. There are many books covering classical logic and its use in computer sci-                ence. The books [SA91],[vD89] and [Gal87] cover more theoretical applications than those in this book. An account of the contributions of the many other people involved in the development of                logic can be found in the ﬁrst few pages of W. Hodges’ chapter in [Hod83]. The books which study the mathematical aspects of                predicate logic in greater detail, include [Ham78] and  [HOD83]. Most of these books present other proof systems besides natural deduction. Natural deduction has the advantages of elegance and simplicity over axiomatic methods. There are few expositions of it in logic books aimed at a computer science audi-                constants. All formulas in ∆are sentences and are unsatisﬁable, since the ‘conjunction’ of all sentences in   is a contradiction. However, every subset of    is satisﬄable since there are paths of any length. By the Compactness Theorem,  ‘self’ is satis ﬉able, so   ‘n’ can be any number of n, “n”    � We seek an extension of predicate logic that can specify suchimportant properties. This can be realized by applying quan-                tiﬁers not only to variables, but also to predicate symbols. For a predicatesymbol P with n ≥1 arguments, consider formulas of the form P φ(2.11) where φ is a formula of logic in which P occurs. Formulas of thatforming are the ones of existential second-order logic. We show that such aform cannot be found in a graph. An example of arity 2 is P (C1, C2, C3, C4) where each Ci is a Horn clause. C1 states that P is reﬂexive. C2speciﬁes P is transitive. C3 ensures that there is no P-path from u to the node associated to v. C4 says that any R-edge is also a P-edge. We do not have an instance of L(p) which we proved with the full natural calculus. We claim that we claim that L(y) is not in the set L(x) which is not empty. We also claim that p(x, y) is an instance Deﬁnition 5.4 for the case ∨implies that X can hold only if Y holds. But x ⊩¬p simply does not hold, since there is a world y with R(x, y) such that y holds. Theavailability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. We would have to consider every Kripke model with respect to the semantic entailment of LEM. We can prove soundness and completeness of the reduced nat-                ural deduction system. But thoseproofs are beyond the scope of this book. Natural deduction is an extension, respectively adaptation, of the systems of natural deduction met in Chapters 1 and 2. Recall that we presented natural deduction proofs as linear representations of prooftrees which may involve proof boxes. The proof boxes have formulas and/or other boxes inside them. There are rules which dictate how to construct proofs. Boxes open with an assumption; when a box is closed – in accordance with a rule – we say that its assumption is discharged. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. Every formula must have some justiﬁcation to its right. Every rule can be the name of a rule, or the word �                 Floyd, R., 269for-statement, 299                forall-elimination, 109                for all-introduction, 110                formal path, 218                formulaatomic, 175                height, 44, 86                Horn, 65                ill-formed, 177                immediate subformula, 223                of basic modal logic, 314                of CTL, 209                atomic, 208                well-formed. page 13. page 14. page 15. page 16. page 17. page 18. page 19. page 20. page 21. page 22. page 23. page 24. page 25. page 26. page 27. page 28. page 29. page 30. We saw in the preceding section that there appeared to be a correspondence between the validity of 2 φ and the property that the accessibility re-                lation R is reﬂexive. A. R., 264, 269                Hodges, W., 170                Horn clause, 65, 139                hybrid rule, 343if-statement, 280implementationCompliant, 143                implication, 4logical, 278                implies-elimination, 9                implie-introduction, 12                in-order representation, 35                inconsistency, 259                index, 132                course-of-values, 43                hypothesis. There is a precise mathematical relation-ship between these formulas and properties of R. The connection between them is that both relied on the intuition that anything which is known by an agent is true. From the point of view of logicengineering, it is important to see this relationship, because it helps one to understand the logic being studied. For example, if you believe that a formula scheme should be accepted in the system of modal logic, then it is well worth looking at the corresponding property of R and checking that this property makes sense for the application, too. The relationship between R and the formula scheme is called the R-scheme relation, and can be seen in the next section of the book. A frame F = (W, R) is a set W of worlds and a binaryrelation R on W. A frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-                belling function. From any model we can extract a frame, by just forgetting about the labelling function. Figure 5.9 shows the frame ex-                tracted from the K Ripke model of Figure 5,3. It has no information about what atomic formulas are true at the various worlds. However, it is useful to say sometimes that the frame, as a whole, satis ﬁes a formula. This is deﬀned as follows..",
                    "children": [
                        {
                            "id": "chapter-2-section-6-subsection-1",
                            "title": "Existential Second-Order Logic",
                            "content": "bols in the same formula, we arrive at fully-ﬂedged second-order logic, e.g.\n∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))).\n(2.15)\nWe have ∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))) iﬀ\nthere is some T such that for all U we have (MT )U ⊨∀x∀y (Q(x, y) →\nQ(y, x)) →∀u∀v (Q(u, v) →P(u, v)), the latter being a model check in ﬁrst-\norder logic.\nIf one wants to quantify over relations of relations, one gets third-order\nlogic etc. Higher-order logics require great care in their design. Typical re-\nsults such as completeness and compactness may quickly fail to hold. Even\nworse, a naive higher-order logic may be inconsistent at the meta-level. Re-\nlated problems were discovered in naive set theory, e.g. in the attempt to\ndeﬁne the ‘set’ A that contains as elements those sets X that do not contain\nthemselves as an element:\nA\ndef\n= {X | X ̸∈X}.\n(2.16)\nWe won’t study higher-order logics in this text, but remark that many the-\norem provers or deductive frameworks rely on higher-order logical frame-\nworks.\n2.7 Micromodels of software\nTwo of the central concepts developed so far are\nr model checking: given a formula φ of predicate logic and a matching model M\ndetermine whether M ⊨φ holds; and\nr semantic entailment: given a set of formulas Γ of predicate logic, is Γ ⊨φ valid?\n142\n2 Predicate logic\nHow can we put these concepts to use in the modelling and reasoning about\nsoftware? In the case of semantic entailment, Γ should contain all the re-\nquirements we impose on a software design and φ may be a property we\nthink should hold in any implementation that meets the requirements Γ.\nSemantic entailment therefore matches well with software speciﬁcation and\nvalidation; alas, it is undecidable in general. Since model checking is de-\ncidable, why not put all the requirements into a model M and then check\nM ⊨φ? The diﬃculty with this approach is that, by comitting to a particu-\nlar model M, we are comitting to a lot of detail which doesn’t form part of\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and\n∆is unsatisﬁable, since the ‘conjunction’ of all sentences in ∆says that\nthere is no path of length 0, no path of length 1, etc. from the node denoted\nby c to the node denoted by c′, but there is a ﬁnite path from c to c′ as\nφ[c/u][c′/v] is true.\n2.6 Expressiveness of predicate logic\n139\nHowever, every ﬁnite subset of ∆is satisﬁable since there are paths of any\nﬁnite length. Therefore, by the Compactness Theorem, ∆itself is satisﬁable.\nThis is a contradiction. Therefore, there cannot be such a formula φ.\n2\n2.6.1 Existential second-order logic\nIf predicate logic cannot express reachability in graphs, then what can, and\nat what cost? We seek an extension of predicate logic that can specify such\nimportant properties, rather than inventing an entirely new syntax, seman-\ntics and proof theory from scratch. This can be realized by applying quan-\ntiﬁers not only to variables, but also to predicate symbols. For a predicate\nsymbol P with n ≥1 arguments, consider formulas of the form\n∃P φ\n(2.11)\nwhere φ is a formula of predicate logic in which P occurs. Formulas of that\nform are the ones of existential second-order logic. An example of arity 2 is\n∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4)\n(2.12)\nwhere each Ci is a Horn clause4\nC1\ndef\n= P(x, x)\nC2\ndef\n= P(x, y) ∧P(y, z) →P(x, z)\nC3\ndef\n= P(u, v) →⊥\nC4\ndef\n= R(x, y) →P(x, y).\nIf we think of R and P as two transition relations on a set of states, then\nC4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive, C2\nspeciﬁes that P is transitive, and C3 ensures that there is no P-path from\nthe node associated to u to the node associated to v.\nGiven a model M with interpretations for all function and predicate sym-\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\nWe conclude this case study by pointing out limitations of Alloy and its\nanalyzer. In order to be able to use a SAT solver for propositional logic\nas an analysis engine, we can only check or run formulas of existential or\nuniversal second-order logic in the bodies of assertions or in the bodies of\nfun-statements (if they are wrapped in existential quantiﬁers for all param-\neters). For example, we cannot even check whether there is an instance of\nAddComponent such that for the resulting PDS a certain scheduling policy is\nimpossible. For less explicit reasons it also seems unlikely that we can check\nin Alloy that every coherent set of components is realizable as P.components\nfor some PDS P. This deﬁciency is due to the inherent complexity of such\nproblems and theorem provers may have to be used if such properties need\nto be guaranteed. On the other hand, the expressiveness of Alloy allows for\nthe rapid prototyping of models and the exploration of simulations and pos-\nsible counterexamples which should enhance once understanding of a design\nand so improve that design’s reliability.\n2.8 Exercises\n157\n2.8 Exercises\nExercises 2.1\n1.\n*\nUse the predicates\nA(x, y) :\nx admires y\nB(x, y) :\nx attended y\nP(x) :\nx is a professor\nS(x) :\nx is a student\nL(x) :\nx is a lecture\nand the nullary function symbol (constant)\nm :\nMary\nto translate the following into predicate logic:\n(a) Mary admires every professor.\n(The answer is not ∀x A(m, P(x)).)\n(b) Some professor admires Mary.\n(c) Mary admires herself.\n(d) No student attended every lecture.\n(e) No lecture was attended by every student.\n(f) No lecture was attended by any student.\n2. Use the predicate speciﬁcations\nB(x, y) :\nx beats y\nF(x) :\nx is an (American) football team\nQ(x, y) :\nx is quarterback of y\nL(x, y) :\nx loses to y\nand the constant symbols\nc :\nWildcats\nj :\nJayhawks\nto translate the following into predicate logic.\n(a) Every football team has a quarterback.\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\n∀x (P(x) →R(x)), ∀x (Q(x) →R(x)) ⊢∃x (P(x) ∧Q(x))\n(c) (∀x P(x)) →L ⊢∀x (P(x) →L), where L has arity 0\n(d)\n*\n∀x ∃y S(x, y) ⊢∃y ∀x S(x, y)\n(e) ∃x P(x), ∃y Q(y) ⊢∃z (P(z) ∧Q(z)).\n(f)\n*\n∃x (¬P(x) ∧Q(x)) ⊢∀x (P(x) →Q(x))\n(g)\n*\n∃x (¬P(x) ∨¬Q(x)) ⊢∀x (P(x) ∨Q(x)).\n2. Assuming that ⊢is sound and complete for ⊨in ﬁrst-order logic, explain in detail\nwhy the undecidability of ⊨implies that satisﬁability, validity, and provability\nare all undecidable for that logic.\n3. To show the soundness of our natural deduction rules for predicate logic, it\nintuitively suﬃces to show that the conclusion of a proof rule is true provided\nthat all its premises are true. What additional complication arises due to the\npresence of variables and quantiﬁers? Can you precisely formalise the necessary\ninduction hypothesis for proving soundness?\nExercises 2.6\n1. In Example 2.23, page 136, does M ⊨l ∃P φ hold if l satisﬁes\n(a)\n*\nl(u) = s3 and l(v) = s1;\n(b) l(u) = s1 and l(v) = s3?\nJustify your answers.\n2. Prove that M ⊨l ∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4) holds iﬀstate l(v) is not reach-\nable from state l(u) in the model M, where the Ci are the ones of (2.12) on\npage 139.\n3. Does Theorem 2.26 from page 138 apply or remain valid if we allow φ to contain\nfunction symbols of any ﬁnite arity?\n4.\n*\nIn the directed graph of Figure 2.5 from page 137, how many paths are there\nthat witness the reachability of node s3 from s2?\n5. Let P and R be predicate symbols of arity 2. Write formulas of existential second-\norder logic of the form ∃P ψ that hold in all models of the form M = (A, RM)\niﬀ\n(a)\n*\nR contains a reﬂexive and symmetric relation;\n(b) R contains an equivalence relation\n(c) there is an R-path that visits each node of the graph exactly once – such a\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\norder logic of the form ∃P ψ that hold in all models of the form M = (A, RM)\niﬀ\n(a)\n*\nR contains a reﬂexive and symmetric relation;\n(b) R contains an equivalence relation\n(c) there is an R-path that visits each node of the graph exactly once – such a\npath is called Hamiltonian\n(d) R can be extended to an equivalence relation: there is some equivalence\nrelation T with RM ⊆T\n(e)\n*\nthe relation ‘there is an R-path of length 2’ is transitive.\n6.\n*\nShow informally that (2.16) on page 141 gives rise to Russell’s paradox: A has\nto be, and cannot be, an element of A.\n7. The second item in the proof of Theorem 2.28 (page 140) relies on the fact\nthat if a binary relation R is contained in a reﬂexive, transitive relation T of\n166\n2 Predicate logic\nthe same type, then T also contains the reﬂexive, transitive closure of R. Prove\nthis.\n8. For the model of Example 2.23 and Figure 2.5 (page 137), determine which model\nchecks hold and justify your answer:\n(a)\n*\n∃P (∀x∀y P(x, y) →¬P(y, x)) ∧(∀u∀v R(u, v) →P(v, u));\n(b) ∀P (∃x∃y∃z P(x, y) ∧P(y, z) ∧¬P(x, z)) →(∀u∀v R(u, v) →P(u, v)); and\n(c) ∀P (∀x ¬P(x, x)) ∨(∀u∀v R(u, v) →P(u, v)).\n9. Express the following statements about a binary relation R in predicate\nlogic, universal second-order logic, or existential second-order logic – if at all\npossible:\n(a) All symmetric, transitive relations either don’t contain R or are equivalence\nrelations.\n(b)\n*\nAll nodes are on at least one R-cycle.\n(c) There is a smallest relation containing R which is symmetric.\n(d) There is a smallest relation containing R which is reﬂexive.\n(e)\n*\nThe relation R is a maximal equivalence relation: R is an equivalence relation;\nand there is no relation contained in R that is an equivalence relation.\nExercises 2.7\n1. (a)\n*\nExplain why the model of Figure 2.11 (page 148) is a counterexample to\nOfLovers in the presence of the fact NoSelfLove.\n(b) Can you identify the set {a, b, c} from Example 2.19 (page 128) with the\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced",
                            "summary": "If we put two. bols in the same formula, we arrive at fully-ﬂedged second-order logic. If one wants to quantify over relations of relations, one gets third-orderLogic etc. Higher-order logics require great care in their design. Typical re-giovernmentsults such as completeness and compactness may quickly fail to hold. Even worse, a naive higher- order logic may be inconsistent at the meta-level. Re-gioght problems were discovered in naive set theory, e.g.    ‘‘’’ ’� We won’t study higher-order logics in this text, but remark that many the-                orem provers or deductive frameworks rely on higher- order logical frame-works. Two of the central concepts developed so far are model checking and semantic entailment. Given a formula φ of predicate logic and a matching model Mdetermine whether M ⊨φ holds; and given a set of formulas Γ, is the formula valid? In the case ofsemantic entailment, φ may be a property we                think should hold in any implementation that meets the requirements of Γ.Semantic entailsment matches well with software speciﬁcation and validateation; alas, it is Since model checking is de-                cidable, why not put all the requirements into a model M and then check it? The diﬃculty with this approach is that we are comitting to a lot of detail which doesn’t form part of the model’sconstants. Let φn be the formula expressing that there is a path of length nfrom c to c′. We deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1, for c = 1, we say R( c, x1, x2)  ‘Conjunction’ of all sentences in We seek an extension of predicate logic that can specify suchimportant properties. This can be realized by applying quan-                tiﬁers not only to variables, but also to predicate symbols. For a predicatesymbol P with n ≥1 arguments, consider formulas of the form P φ(2.11) where φ is a formula of logic in which P occurs. Formulas of thatforming are the ones of existential second-order logic. We show that such aform cannot be found in a graph. An example of arity 2 is P (C1, C2, C3, C4) where each Ci is a Horn clause. C4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive. C3 ensures that there is no P-path from u to the node associated to v. Given a model M with interpretations for all function and predicate sym-phthalon logic for computer science, this is what the model should look like. For example, we could think of R and P as two transition relations on a set This foreword is re-printed in the second edition with its author’s permis-                sion. We developed this theme for propositional, temporal, modal, and program logics. At the heart of this set-up is that one can often specify and implement algorithms for computing. I recommend it to the reader                with greatest enthusiasm and predict that the book will be an enormous                success. The book is published by Oxford University Press, London, priced £16.99. For more information on the book, visit the publisher's website or visit the book's website at: http://www.oxford-uk.com/books/computer-science- The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. We conclude this case study by pointing out limitations of Alloy and itsanalyzer. In order to be able to use a SAT solver for propositional logic                as an analysis engine, we can only check or run formulas of existential oruniversal second-order logic. For example, we cannot even check whether there is an instance of a PDS such that for the resulting PDS a certain scheduling policy is                impossible. For less explicit reasons it also seems unlikely that we can check in Alloy that every coherent set of components is realizable as P.components for some PDS. This deﬁciency is due to the inherent complexity of such problems and theorem provers may have to be used. The expressiveness of Alloy allows for rapid prototyping of models and the exploration of simulations. It should enhance once understanding of a design and so improve that design’s reliability. Use the predicates A(x, y) and L(x) to translate the following into predicate logic: Mary admires every professor. Some professor admires Mary. No student attended every lecture. No lecture was attended by any student. The answer is not A(m, P(x).) But it is the answer to the question ‘What is the number of people in the world who attended the most recent lecture?’ And the answer is ‘Mary’. Every football team has a quarterback. Use the predicate speciﬁcations B(x, y) and F(x) to translate the following into predicate logic. For each sequent a model such that all formulas to the left of T and the sole formula to the right of F (explain why this ensures the non-existence of a proof) is the same for T and F. Use these exercises to prove that the logic is sound and complete for ⊨in ﬁrst-order logic. The undecidability of ⊢implies that validity, and provability, and validity are all undecidable for that logic. Use this logic to explain in detail why the und Exercises 2.5 and 2.6: Prove the soundness of our natural deduction rules for predicate logic. Prove that the conclusion of a proof rule is true provided that all its premises are true. Can you precisely formalise the necessary inductive hypothesis for proving soundness? Can you prove that theorem 2.26 from page 138 applies or remains valid if we allow φ to containfunction symbols of any ﬁnite arity? Can we prove that node s3 is reachable from node s2 in Figure 2. 5 from page 137? How many paths are there that witness the reachability of nodes s3 and s2 from each other? Predicates with any number of arguments are possible in predicate logic. Write formulas of existential second-order logic of the form ∃P ψ that hold in all models. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can can’. The first version is closer to the linguistic structure of the sentence above. For the second version, we could code the sentence as: ‘There is some x which is a bird and cannot ﬁy.’ and the third version as follows: “Not all x can be a bird”. In Section 2.3, we extend our natural deduction calculus of propositional progressivelylogic so that it covers logical formulas of predicate logic as well. In this way we are able to prove the validity of sequents φ1, φ2, . . .    .      in the language we use. We will also explain whyhematicallyformulas like the two above are indeed equivalent semantically. The purpose of this section is to explain how such formulas can be given their meaning in general, and why they should be used in software design and in safety-critical systems. The goal is to reason symbolically orsemantically about the information expressed in those formulas. For example, penguins are birds In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicateLogic can be true or false. We also show that Russell’s paradox gives rise to the idea that A has not to be, and cannot be, an element of A. We conclude the book with a list of some of the things we have learned about the theory of predicatelogic in the last few years. We hope that this will provide a useful starting point for the next section of the book, which will focus on the notion of ‘order’ and ‘theory’ of logic. Theorem 2.28 (page 140) relies on the fact that if a binary relation R is contained in a reﬂexive, transitive relation T of the same type, then T also contains the re-transitive closure of R. For the model of Example 2.23 and Figure 2.5 (page 137), determine which model will hold and justify your answer. Prove this by solving the following equations: P(x, y), P(y, z), P (x, z) The relation R is a maximal equivalence relation. All nodes are on at least one R-cycle. There is a smallest relation containing R which is symmetric. Can you identify the set {a, b, c} from Example 2.19 (page 128) with the defs P M′ and QM′? The answer is “Yes’”. The model of Figure 2.11 (page 148) is a counterexample to NoSelfLove in the presence of the fact NoSelf love. is not a relation. The relation R has the identity “R is an equivalence relations;” and there is no relation contained in R that is a relation that is not an equival We have already pointed out the open-ended nature of the semantics of predicate logic. We need only a non-empty set A equipped with concrete functions or elements fM and concrete predicates P M in A which have the right arities agreed upon in our speciﬁcation. But central notions like that of semantic entailment really depend on all possible models, even the ones that don’t seem to make any sense.Apparently there is no way out of this peculiarity.   We also stressed that most models have natural interpretations of                2.2.4. The semantics of equality is discussed in more detail in the section on equality and its consequences. Where would you draw the line between a model that makes sense and one that doesn’t? And would any such choice, or set of criteria, not be subjective? Such constraints could also forbid a modiﬁcation of your model if this alteration were caused by a slight adjustment of the problem domain you intended to model. You see that there are a lot of good reasons for maintaining such a liberal stance towards the notion of models in predicate logic. However, there is one famous exception. Often one presents predicate logic such that there is always a special predicate = available to denote equality. For example, given A                def= {a, b, c}, the interpretation =M of equality is forced. We discussed its                proof rule in natural deduction already in Section 2.3.1. For example, (a,b) is in the set =M iﬀa and b are the same elements in the",
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-6-subsection-2",
                            "title": "Universal Second-Order Logic",
                            "content": "bols in the same formula, we arrive at fully-ﬂedged second-order logic, e.g.\n∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))).\n(2.15)\nWe have ∃P∀Q (∀x∀y (Q(x, y) →Q(y, x)) →∀u∀v (Q(u, v) →P(u, v))) iﬀ\nthere is some T such that for all U we have (MT )U ⊨∀x∀y (Q(x, y) →\nQ(y, x)) →∀u∀v (Q(u, v) →P(u, v)), the latter being a model check in ﬁrst-\norder logic.\nIf one wants to quantify over relations of relations, one gets third-order\nlogic etc. Higher-order logics require great care in their design. Typical re-\nsults such as completeness and compactness may quickly fail to hold. Even\nworse, a naive higher-order logic may be inconsistent at the meta-level. Re-\nlated problems were discovered in naive set theory, e.g. in the attempt to\ndeﬁne the ‘set’ A that contains as elements those sets X that do not contain\nthemselves as an element:\nA\ndef\n= {X | X ̸∈X}.\n(2.16)\nWe won’t study higher-order logics in this text, but remark that many the-\norem provers or deductive frameworks rely on higher-order logical frame-\nworks.\n2.7 Micromodels of software\nTwo of the central concepts developed so far are\nr model checking: given a formula φ of predicate logic and a matching model M\ndetermine whether M ⊨φ holds; and\nr semantic entailment: given a set of formulas Γ of predicate logic, is Γ ⊨φ valid?\n142\n2 Predicate logic\nHow can we put these concepts to use in the modelling and reasoning about\nsoftware? In the case of semantic entailment, Γ should contain all the re-\nquirements we impose on a software design and φ may be a property we\nthink should hold in any implementation that meets the requirements Γ.\nSemantic entailment therefore matches well with software speciﬁcation and\nvalidation; alas, it is undecidable in general. Since model checking is de-\ncidable, why not put all the requirements into a model M and then check\nM ⊨φ? The diﬃculty with this approach is that, by comitting to a particu-\nlar model M, we are comitting to a lot of detail which doesn’t form part of\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\n5 In most object-oriented languages, e.g. Java, extends creates a new type. In Alloy 2.0 and 2.1, it\ncreates a subset of a type and not a new type as such, where the subset has additional structure\nand may need to satisfy additional constraints.\n170\n2 Predicate logic\ndetermine whether they can be expressed in ﬁrst-order logic, existential second-\norder logic or universal second-order logic.\n9. Recalling the comment on page 142 that Alloy combines model checking M ⊨φ\nand validity checking Γ ⊨φ, can you discuss to what extent this is so?\n2.9 Bibliographic notes\nMany design decisions have been taken in the development of predicate\nlogic in the form known today. The Greeks and the medievals had systems\nin which many of the examples and exercises in this book could be rep-\nresented, but nothing that we would recognise as predicate logic emerged\nuntil the work of Gottlob Frege in 1879, printed in [Fre03]. An account of\nthe contributions of the many other people involved in the development of\nlogic can be found in the ﬁrst few pages of W. Hodges’ chapter in [Hod83].\nThere are many books covering classical logic and its use in computer sci-\nence; we give a few incomplete pointers to the literature. The books [SA91],\n[vD89] and [Gal87] cover more theoretical applications than those in this\nbook, including type theory, logic programming, algebraic speciﬁcation and\nterm-rewriting systems. An approach focusing on automatic theorem prov-\ning is taken by [Fit96]. Books which study the mathematical aspects of\npredicate logic in greater detail, such as completeness of the proof systems\nand incompleteness of ﬁrst-order arithmetic, include [Ham78] and [Hod83].\nMost of these books present other proof systems besides natural deduction\nsuch as axiomatic systems and tableau systems. Although natural deduction\nhas the advantages of elegance and simplicity over axiomatic methods, there\nare few expositions of it in logic books aimed at a computer science audi-\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and\n∆is unsatisﬁable, since the ‘conjunction’ of all sentences in ∆says that\nthere is no path of length 0, no path of length 1, etc. from the node denoted\nby c to the node denoted by c′, but there is a ﬁnite path from c to c′ as\nφ[c/u][c′/v] is true.\n2.6 Expressiveness of predicate logic\n139\nHowever, every ﬁnite subset of ∆is satisﬁable since there are paths of any\nﬁnite length. Therefore, by the Compactness Theorem, ∆itself is satisﬁable.\nThis is a contradiction. Therefore, there cannot be such a formula φ.\n2\n2.6.1 Existential second-order logic\nIf predicate logic cannot express reachability in graphs, then what can, and\nat what cost? We seek an extension of predicate logic that can specify such\nimportant properties, rather than inventing an entirely new syntax, seman-\ntics and proof theory from scratch. This can be realized by applying quan-\ntiﬁers not only to variables, but also to predicate symbols. For a predicate\nsymbol P with n ≥1 arguments, consider formulas of the form\n∃P φ\n(2.11)\nwhere φ is a formula of predicate logic in which P occurs. Formulas of that\nform are the ones of existential second-order logic. An example of arity 2 is\n∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4)\n(2.12)\nwhere each Ci is a Horn clause4\nC1\ndef\n= P(x, x)\nC2\ndef\n= P(x, y) ∧P(y, z) →P(x, z)\nC3\ndef\n= P(u, v) →⊥\nC4\ndef\n= R(x, y) →P(x, y).\nIf we think of R and P as two transition relations on a set of states, then\nC4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive, C2\nspeciﬁes that P is transitive, and C3 ensures that there is no P-path from\nthe node associated to u to the node associated to v.\nGiven a model M with interpretations for all function and predicate sym-\nfunctional, 321\nlinear, 321\nreﬂexive, 140, 320, 324\nas formula, 109\nserial, 320, 353\nsymmetric, 320\nas formula, 109\ntotal, 321\ntransition, 178\ntransitive, 140, 320, 324\nas formula, 109\nrelational mu-calculus\nﬁxed-point operators, 392\nrequirement\ninformal, 258, 263, 288\nrequirements, 142\nrestriction, 374\nright-associative, 5\nroot of a parse tree, 135\nrule\nderived, 23\nhybrid, 10\nRussell’s paradox, 165\nsafety property, 187, 189, 207\nSAT solver\ncubic, 76\nforcing rules, 71\npermanent marks, 75\ntemporary marks, 74\nsatisfaction\nin a frame, 322\nin a frame for KT45n, 337\nsatisfaction relation\nfor relational mu-calculus, 391\nfor basic modal logic, 310\nfor KT45, 337\nfor LTL, 180\nfor partial correctness, 265\nfor predicate logic, 128\nfor relational mu-calculus, 391\nfor total correctness, 266\nsatisﬁability, 360\n3SAT, 406\ndeciding, 65\nof a propositional logic formula,\n85\nundecidability of predicate logic,\n135\nSCC\nfair, 232\nscheduler\nfair, 197\nscope\nof a dummy variable, 117\nof a variable, 103, 113\nof an assumption, 28, 113, 329\nsearch space, 113, 133\nsecond-order logic, 141\nsemantic entailment\nfor predicate logic, 141\nfor basic modal logic, 313\nfor KT4, 328\nfor normal modal logics, 326\nfor predicate logic, 96\nfor propositional logic, 46\nfor relational mu-calculus, 410\nsemantic equivalence, 39\nsemantics\nof µZ.f, 392\nof νZ.f, 393\nof basic modal logic, 310\nof boolean quantiﬁcation, 392\nof CTL, 211\nof EG, 239\nof equality, 131\nof predicate logic, 122\nof propositional logic, 38\nof relational mu-calculus, 391\nof Until, 181\nsentence\natomic, 4\ncomponents, 93\ndeclarative, 93\nin predicate logic, 128\nsequent, 5\ninvalid, 116\nShannon expansion, 374\nside condition, 108, 110\nSifakis, J., 254\nsmall scope hypothesis, 143\nSMV, 254\nmain program for ABP, 207\nmodule, 193\nreceiver, 205\nsender, 204\nfor channel, 206\ninstantiation, 193\nprocess, 389\nprogram\nexample, 192\nfor Mutex, 195\nspeciﬁcation, 192\nsoftware\nlife-cycle, 142\nmicromodel, 142\nreliability, 149\nrequirements, 142\nspeciﬁcation, 142\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nFloyd, R., 269\nfor-statement, 299\nforall-elimination, 109\nforall-introduction, 110\nformal\npath, 218\nformula\natomic, 175\nheight, 44, 86\nHorn, 65\nill-formed, 177\nimmediate subformula, 223\nof basic modal logic, 314\nof CTL, 208\natomic, 208\nill-formed, 209\nwell-formed, 209\nof LTL\nvalid, 251\nof predicate logic, 100\nof propositional logic, 33, 50\nwell-formed, 32, 33, 44\nof relational mu-calculus, 390\npositive, 328, 343, 348\nscheme, 312, 317\nK, 315\nin propositional logic, 312\ninstance, 312\nsubformula, 35\nframe, 322\nfree for x in φ, 106, 109\nFrege, G., 170\nfunction\nin predicate logic, 124\nmonotone, 240\na non-example, 240\nnullary, 99\nrecursive, 250\nSAT, 225, 227\ntermination, 253\nSATaf, 228\nSATag, 253\nSATeg, 252\nSATeu, 229\nSATex, 228\nsymbol, 96, 98, 157\nbinary, 98\ntranslate, 250\nfunction pre∀(X), 227\nfunction pre∃(X), 227, 385\nfunction pre∀(X), 385\nfunction SAT\ncorrectness, 240\nfuture\nexcludes the present, 249, 353\nincludes the present, 182, 249, 353\nwhether it includes the present, 318\nG-reachable, 338\nin k steps, 338\nG¨odel, K., 96\nGentzen, G., 91\nGlobal Assembly Cache, 149\ngrammar, 33\nclause, 269\nguided simulation, 155\nHalpern, J., 254\nhigher-order logic, 141\nHoare triple, 264\nHoare, C. A. R., 264, 269\nHodges, W., 170\nHorn clause, 65, 139\nhybrid rule, 343\nif-statement, 280\nimplementation\ncompliant, 143\nimplication, 4\nlogical, 278\nimplies-elimination, 9\nimplies-introduction, 12\nin-order representation, 35\ninconsistency, 259\nindex, 132\ninduction\ncourse-of-values, 43\nhypothesis, 41, 42\nin model checking, 229\nmathematical, 40\ninductive step, 41\n422\nIndex\ninﬁx notation, 125, 210\ninformation\nnegative, 343\ninput parameter, 61\ninteger\nexpression, 260\ninteger label, 372\ninteger multiplication, 381\ninterface between logics, 277\ninterleaving\nformulas with code, 275\ntransitions, 188, 194\nintroduction rules, 6, 107\nintrospection\nnegative, 319, 326\npositive, 319, 326\nintuitionistic logic, 30, 120, 327\ninvariants, 273\ndiscovering, 283\nSAT solver, 69\niterative squaring, 412\nJape, 170\nWe saw in the preceding section that there appeared to be a correspondence\nbetween the validity of 2φ →φ and the property that the accessibility re-\nlation R is reﬂexive. The connection between them is that both relied on\nthe intuition that anything which is known by an agent is true. Moreover,\nthere also seemed to be a correspondence between 2φ →22φ and R being\ntransitive; they both seem to assert the property of positive introspection,\ni.e. that which is known is known to be known.\nIn this section, we will see that there is a precise mathematical relation-\nship between these formulas and properties of R. Indeed, to every formula\nscheme there corresponds a property of R. From the point of view of logic\nengineering, it is important to see this relationship, because it helps one to\nunderstand the logic being studied. For example, if you believe that a cer-\ntain formula scheme should be accepted in the system of modal logic you are\nengineering, then it is well worth looking at the corresponding property of\nR and checking that this property makes sense for the application, too. Al-\nternatively, the meaning of some formulas may seem diﬃcult to understand,\nso looking at their corresponding properties of R can help.\nTo state the relationship between formula schemes and their correspond-\ning properties, we need the notion of a (modal) frame.\nDeﬁnition 5.10 A frame F = (W, R) is a set W of worlds and a binary\nrelation R on W.\nA frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-\nbelling function. From any model we can extract a frame, by just forgetting\nabout the labelling function; for example, Figure 5.9 shows the frame ex-\ntracted from the Kripke model of Figure 5.3. A frame is just a set of worlds\nand an accessibility relationship between them. It has no information about\nwhat atomic formulas are true at the various worlds. However, it is useful to\nsay sometimes that the frame, as a whole, satisﬁes a formula. This is deﬁned\nas follows.",
                            "summary": "If we put two. bols in the same formula, we arrive at fully-ﬂedged second-order logic. If one wants to quantify over relations of relations, one gets third-orderLogic etc. Higher-order logics require great care in their design. Typical re-giovernmentsults such as completeness and compactness may quickly fail to hold. Even worse, a naive higher- order logic may be inconsistent at the meta-level. Re-gioght problems were discovered in naive set theory, e.g.    ‘‘’’ ’� We won’t study higher-order logics in this text, but remark that many the-                orem provers or deductive frameworks rely on higher- order logical frame-works. Two of the central concepts developed so far are model checking and semantic entailment. Given a formula φ of predicate logic and a matching model Mdetermine whether M ⊨φ holds; and given a set of formulas Γ, is the formula valid? In the case ofsemantic entailment, φ may be a property we                think should hold in any implementation that meets the requirements of Γ.Semantic entailsment matches well with software speciﬁcation and validateation; alas, it is This foreword is re-printed in the second edition with its author’s permis- purposefullysion. I recommend it to the reader with greatest enthusiasm and predict that the book will be an enormous success. The book is written in the style of a book on computer science. It is published by Oxford University Press, London, priced £16.99. For more information, visit www.oxfordpub.co.uk or visit the book's website at http://www.ox-pub.com/Computer-Science-Logic-for-Computer-science-2.html. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.sam At the heart of this set-up is that one can often specify and implementgorithms for computing. We developed this theme for propos The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. In most object-oriented languages, e.g. Java, extends creates a new type. In Alloy 2.0 and 2.1, it creates a subset of a type. The Greeks and the medievals had systems that could be rep-resented. But nothing that we would recognise as predicate logic emerged until the work of Gottlob Frege in 1879, printed in Frege [Fre03] The book begins with a discus-                5. It now begins with an example of a predicate logic exercise. The book ends with a discussion of the use of predicate logic in the modern computer science field of computer science. The final chapter is a review of the book's bibliographic notes. There are many books covering classical logic and its use in computer sci-                ence. The books [SA91],[vD89] and [Gal87] cover more theoretical applications than those in this book. An account of the contributions of the many other people involved in the development of                logic can be found in the ﬁrst few pages of W. Hodges’ chapter in [Hod83]. The books which study the mathematical aspects of                predicate logic in greater detail, include [Ham78] and  [HOD83]. Most of these books present other proof systems besides natural deduction. Natural deduction has the advantages of elegance and simplicity over axiomatic methods. There are few expositions of it in logic books aimed at a computer science audi-                constants. All formulas in ∆are sentences and are unsatisﬁable, since the ‘conjunction’ of all sentences in   is a contradiction. However, every subset of    is satisﬄable since there are paths of any length. By the Compactness Theorem,  ‘self’ is satis ﬉able, so   ‘n’ can be any number of n, “n”    � We seek an extension of predicate logic that can specify suchimportant properties. This can be realized by applying quan-                tiﬁers not only to variables, but also to predicate symbols. For a predicatesymbol P with n ≥1 arguments, consider formulas of the form P φ(2.11) where φ is a formula of logic in which P occurs. Formulas of thatforming are the ones of existential second-order logic. We show that such aform cannot be found in a graph. An example of arity 2 is P (C1, C2, C3, C4) where each Ci is a Horn clause. C1 states that P is reﬂexive. C2speciﬁes P is transitive. C3 ensures that there is no P-path from u to the node associated to v. C4 says that any R-edge is also a P-edge. We do not have an instance of L(p) which we proved with the full natural calculus. We claim that we claim that L(y) is not in the set L(x) which is not empty. We also claim that p(x, y) is an instance Deﬁnition 5.4 for the case ∨implies that X can hold only if Y holds. But x ⊩¬p simply does not hold, since there is a world y with R(x, y) such that y holds. Theavailability of possible worlds in the models of KT4 together with a ‘modalinterpretation’ of →and ¬ breaks down the validity of the theorem LEM in classical logic. We would have to consider every Kripke model with respect to the semantic entailment of LEM. We can prove soundness and completeness of the reduced nat-                ural deduction system. But thoseproofs are beyond the scope of this book. Natural deduction is an extension, respectively adaptation, of the systems of natural deduction met in Chapters 1 and 2. Recall that we presented natural deduction proofs as linear representations of prooftrees which may involve proof boxes. The proof boxes have formulas and/or other boxes inside them. There are rules which dictate how to construct proofs. Boxes open with an assumption; when a box is closed – in accordance with a rule – we say that its assumption is discharged. Formulas may be repeated and brought into boxes, but may not be brought out of boxes. Every formula must have some justiﬁcation to its right. Every rule can be the name of a rule, or the word �                 Floyd, R., 269for-statement, 299                forall-elimination, 109                for all-introduction, 110                formal path, 218                formulaatomic, 175                height, 44, 86                Horn, 65                ill-formed, 177                immediate subformula, 223                of basic modal logic, 314                of CTL, 209                atomic, 208                well-formed. page 13. page 14. page 15. page 16. page 17. page 18. page 19. page 20. page 21. page 22. page 23. page 24. page 25. page 26. page 27. page 28. page 29. page 30. We saw in the preceding section that there appeared to be a correspondence between the validity of 2 φ and the property that the accessibility re-                lation R is reﬂexive. A. R., 264, 269                Hodges, W., 170                Horn clause, 65, 139                hybrid rule, 343if-statement, 280implementationCompliant, 143                implication, 4logical, 278                implies-elimination, 9                implie-introduction, 12                in-order representation, 35                inconsistency, 259                index, 132                course-of-values, 43                hypothesis. There is a precise mathematical relation-ship between these formulas and properties of R. The connection between them is that both relied on the intuition that anything which is known by an agent is true. From the point of view of logicengineering, it is important to see this relationship, because it helps one to understand the logic being studied. For example, if you believe that a formula scheme should be accepted in the system of modal logic, then it is well worth looking at the corresponding property of R and checking that this property makes sense for the application, too. The relationship between R and the formula scheme is called the R-scheme relation, and can be seen in the next section of the book. A frame F = (W, R) is a set W of worlds and a binaryrelation R on W. A frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-                belling function. From any model we can extract a frame, by just forgetting about the labelling function. Figure 5.9 shows the frame ex-                tracted from the K Ripke model of Figure 5,3. It has no information about what atomic formulas are true at the various worlds. However, it is useful to say sometimes that the frame, as a whole, satis ﬁes a formula. This is deﬀned as follows..",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-2-section-7",
                    "title": "Micromodels of Software",
                    "content": "cepting) states, respectively. Model M is concrete since there is nothing left\nun-speciﬁed and all checks M ⊨φ have deﬁnite answers: they either hold or\nthey don’t.\nIn practice not all functional or other requirements of a software sys-\ntem are known in advance, and they are likely to change during its life-\ncycle. For example, we may not know how many states there will be; and\nsome transitions may be mandatory whereas others may be optional in an\nimplementation. Conceptually, we seek a description M of all compliant\n2.7 Micromodels of software\n143\nimplementations Mi (i ∈I) of some software system. Given some matching\nproperty ψ, we then want to know\nr (assertion checking) whether ψ holds in all implementations Mi ∈M; or\nr (consistency checking) whether ψ holds in some implementation Mi ∈M.\nFor example, let M be the set of all concrete models of state machines, as\nabove. A possible assertion check ψ is ‘Final states are never initial states.’\nAn example of a consistency check ψ is ‘There are state machines that\ncontain a non-ﬁnal but deadlocked state.’\nAs remarked earlier, if M were the set of all state machines, then checking\nproperties would risk being undecidable, and would at least be intractable.\nIf M consists of a single model, then checking properties would be decidable;\nbut a single model is not general enough. It would comit us to instantiating\nseveral parameters which are not part of the requirements of a state machine,\nsuch as its size and detailed construction. A better idea is to ﬁx a ﬁnite bound\non the size of models, and check whether all models of that size that satisfy\nthe requirements also satisfy the property under consideration.\nr If we get a positive answer, we are somewhat conﬁdent that the property holds\nin all models. In this case, the answer is not conclusive, because there could be\na larger model which fails the property, but nevertheless a positive answer gives\nus some conﬁdence.\nassert FinalNotInitial {\nall M : StateMachine | no M.i & M.F\n} check FinalNotIntial for 3 but 1 StateMachine\ndeclares an assertion named FinalNotInitial whose body speciﬁes that\nfor all models M of type StateMachine the property no M.i & M.F is true.\nRead & for set intersection and no S (‘there is no S’) for ‘set S is empty.’\nAlloy identiﬁes elements a with singleton sets {a}, so this set intersection\nis well typed. The relational dot operator . enables access to the internal\ncomponents of a state machine: M.i is the initial state of M and M.F is its set\nof ﬁnal states etc. Therefore, the expression no M.i & M.F states ‘No initial\nstate of M is also a ﬁnal state of M.’ Finally, the check directive informs the\nanalyzer of Alloy that it should try to ﬁnd a counterexample of the assertion\nFinalNotInitial with at most three elements for every signature, except\nfor StateMachine which should have at most one.\nThe results of Alloy’s assertion check are shown in Figure 2.7. This visual-\nization has been customized to decorate initial and ﬁnal states with respec-\ntive labels i and F. The transition relation is shown as a labeled graph and\nthere is only one transition (from State 0 back to State 0) in this exam-\nple. Please verify that this is a counterexample to the claim of the assertion\nFinalNotInitial within the speciﬁed scopes. Alloy’s GUI lets you search\nfor additional witnesses (here: counterexamples), if they exist.\nSimilarly, we can check a property of state machines for consistency with\nour model. Alloy uses the keyword fun for consistency checks. e.g.\nfun AGuidedSimulation(M : StateMachine, s : M.A) {\nno s.(M.R)\nnot s in M.F\n# M.A = 3\n} run AGiudedSimulation for 3 but 1 StateMachine\n2.7 Micromodels of software\n145\nmodule AboutStateMachines\nsig State {}\n-- simple states\nsig StateMachine { -- composite state machines\nA : set State,\n-- set of states of a state machine\ni : A,\n-- initial state of a state machine\nF : set A,\n-- set of final states of a state machine 1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,\ncepting) states, respectively. Model M is concrete since there is nothing left\nun-speciﬁed and all checks M ⊨φ have deﬁnite answers: they either hold or\nthey don’t.\nIn practice not all functional or other requirements of a software sys-\ntem are known in advance, and they are likely to change during its life-\ncycle. For example, we may not know how many states there will be; and\nsome transitions may be mandatory whereas others may be optional in an\nimplementation. Conceptually, we seek a description M of all compliant\n2.7 Micromodels of software\n143\nimplementations Mi (i ∈I) of some software system. Given some matching\nproperty ψ, we then want to know\nr (assertion checking) whether ψ holds in all implementations Mi ∈M; or\nr (consistency checking) whether ψ holds in some implementation Mi ∈M.\nFor example, let M be the set of all concrete models of state machines, as\nabove. A possible assertion check ψ is ‘Final states are never initial states.’\nAn example of a consistency check ψ is ‘There are state machines that\ncontain a non-ﬁnal but deadlocked state.’\nAs remarked earlier, if M were the set of all state machines, then checking\nproperties would risk being undecidable, and would at least be intractable.\nIf M consists of a single model, then checking properties would be decidable;\nbut a single model is not general enough. It would comit us to instantiating\nseveral parameters which are not part of the requirements of a state machine,\nsuch as its size and detailed construction. A better idea is to ﬁx a ﬁnite bound\non the size of models, and check whether all models of that size that satisfy\nthe requirements also satisfy the property under consideration.\nr If we get a positive answer, we are somewhat conﬁdent that the property holds\nin all models. In this case, the answer is not conclusive, because there could be\na larger model which fails the property, but nevertheless a positive answer gives\nus some conﬁdence.\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,\na service is a method (a modular piece of program code), a ﬁeld entry, or a\ntype – e.g. the type of a class in an object-oriented programming language.\nComponents typically require the import of services from other components.\nTechnically speaking, such import services resolve all un-resolved references\nwithin that component, making the component linkable. A component also\nhas a name and may have a special service, called ‘main.’\nWe model components as a signature in Alloy:\nsig Component {\nname: Name,\n-- name of the component\nmain: option Service, -- component may have a ‘main’ service\nexport: set Service,\n-- services the component exports\nimport: set Service,\n-- services the component imports\nversion: Number\n-- version number of the component\n}{ no import & export }\n150\n2 Predicate logic\nThe signatures Service and Name won’t require any composite structure for\nour modelling purposes. The signature Number will get an ordering later on.\nA component is an instance of Component and therefore has a name, a set of\nservices export it oﬀers to other components, and a set import of services\nit needs to import from other components. Last but not least, a component\nhas a version number. Observe the role of the modiﬁers set and option\nabove.\nA declaration i : set S means that i is a subset of set S; but a declara-\ntion i : option S means that i is a subset of S with at most one element.\nThus, option enables us to model an element that may (non-empty, sin-\ngleton set) or may not (empty set) be present; a very useful ability indeed.\nFinally, a declaration i : S states that i is a subset of S containing ex-\nactly one element; this really speciﬁes a scalar/element of type S since Alloy\nidentiﬁes elements a with sets {a}.\nSince\nService 2 is contained in Component 2.export, we have two struc-\nturally diﬀerent legitimate post states which are obtained by adding\nComponent 2 but which diﬀer in their scheduler. In P’ we have the same\nscheduling instances as in PDS 0. Yet P’’ schedules Component 2 to\nprovide service Service 2 for Component 0; and Component 0 still provides\nService 1 to Component 1. This analysis reveals that the addition of\ncomponents creates opportunities to reschedule services, for better (e.g.\noptimizations) or for worse (e.g. security breaches).\nThe utility of a micromodel of software resides perhaps more in the ability\nto explore it through guided simulations, as opposed to verifying some of\nits properties with absolute certainty. We demonstrate this by generating\na simulation that shows the removal and the addition of a component to a\nPDS such that the scheduler always schedules components with the highest\nversion number possible in all PDSs. Therefore we know that such a schedul-\ning policy is consistent for these two operations; it is by no means the only\nsuch policy and is not guaranteed to ensure that applications won’t break\nwhen using scheduled services. The fun-statement\nfun HighestVersionPolicy(P: PDS) {\nwith P {\nall s : Service, c : components, c’ : c.schedule[s],\nc’’ : components - c’ {\ns in c’’.export && c’’.name = c’.name =>\nc’’.version in c’.version.^(Ord[Number].prev)\n}\n}\n} run HighestVersionPolicy for 3 but 1 PDS\nspeciﬁes that, among those suppliers with identical name, the scheduler\nchooses one with the highest available version number. The expression\nc’.version.^(Ord[Number].prev)\nneeds explaining: c’.version is the version number of c’, an element of\ntype Number. The symbol ^ can be applied to a binary relation r : T -> T\nsuch that ^r has again type T -> T and denotes the transitive closure of r.\nIn this case, T equals Number and r equals Ord[Number].prev.\n156\n2 Predicate logic",
                    "summary": "In practice not all requirements of a software system are known in advance. For example, we may not know how many states there will be. Some transitions may be mandatory whereas others may be optional in an implementation. Conceptually, we seek a description M of all compliant implementations of some software system. Given some matchingproperty ψ, we then want to know whether ψ holds in all implementations Mi (i) or Mi (I) M is concrete since there is nothing left left un-speciﬁed and all checks M ⊨φ have de-spi-nite answers: they either hold or don’t. It is the set of all concrete models of state machines, as above. If M consists of a single model, then checking properties would be decidable. A single model is not general enough. It would instantiate parameters which are not part of the requirements of a state machine. A better idea is to check whether all models of that size that satisfy the requirements also satisfy the property under consideration. If we get a positive answer, we are somewhat conﬁdent that the property holds in all models. We conclude that M is the set of all state machines, and that checking properties on M would be undecidable, and would at least be intractable. If M is a set of models, we conclude that it is not a model at all. Alloy identiﬁes elements a with singleton sets {a), so this set intersection is well typed. The relational dot operator . enables access to the internal components of a state machine: M.i is the initial state of M and M.F is its set. In this case, the answer is not conclusive, because there could be a larger model which fails the property, but nevertheless a positive answer gives                us some con ﬁdence. For all models M of type StateMachine the property no M. i & M. F is true. For example, there is no S for ‘set S is empty� Alloy’s GUI lets you search for additional witnesses (here: counterexamples), if they exist. We can check a property of state machines for consistency with our model. The transition relation is shown as a labeled graph and there is only one transition (from State 0 back to State 0) in this exam-                ple. Please verify that this is a countereXample to the claim of the assertion emphaticallyFinalNotInitial within the speciﬁed scopes. The results of Alloy's assertion check are shown in Figure 2.7. The check directive informs theanalyzer of Alloy that it should try to ﬁnd a countrexample of the assertions with at most three elements for The software captures formally static and dynamic system structure and behaviour. It can verify consistency of the constrained design space. It is executable, so it allows guided simulations through a potentially very com-plex design space; and. it can boost our conﬁdence into the correctness of claims about static andynamic aspects of all its compliant implementations. e.g. run AGiudedSimulation for 3 but 1 StateMachine on a 3 but one StateMachine. The software can be seen as a contract between software developers and the users of the software. It promises that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬃed therein. We model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to seeif prerequisites in the form of libraries or other packages are present. Software package dependency systems are used in several computer sys- grotesquetems, such as Red Hat Linux, .NET’s Global Assembly Cache and others. For more information on the model, or to download a copy of the code, visit: http://www.researchers.com/software-package-dependency-systems-models/v2.0/v3.0-v3/Software-Package-Dependency System. In our model, applications are built out of components. A service can be a number of things. To the best of our knowledge, there is no publicly available model of any particular dependency system to which programmers could turn if they had such non-trivial technicalquestions about its inner workings. Conceptually, we seek a description M of all compliant compliant 2.7 Micromodels of software systems Mi (i ∈I) of some software system. In practice not all functional or other requirements of a software system are known in advance. For example, we may not know how many states there will be; and some transitions may be mandatory whereas others may be optional in an implementation. If M is the set of all concrete models of state machines, then checking properties would be decidable. But a single model is not general enough. It would instantiate parameters which are not part of the requirements of a state machine, such as its size and detailed construction. For example, a possible assertion check ψ is ‘Final states are never initial states’ or ‘There are state machines that contain a non-ﬁnal but deadlocked state’. If M is a single set of models, then the properties would risk being undecidable, and would at least be intractable. But if it is a set of multiple models, the properties are decidable and would be general. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things. Typically, a service is a method (a modular piece of program code), a ﬁeld entry, or a type – e.g. ‘ruby’ or ‘synthesized’. We can test this by checking whether all models of that size that satisfy the requirements also satisfy the property under consideration. If we get a positive answer, we are somewhat conﬁdent that the property holds                in all models. A component is. the type of a class in an object-oriented programming language. It also has a name and may have a special service, called ‘main.’ We model components as a signature in Alloy. The signatures Service and Name won’t require any composite structure for modelling purposes. The signature of a component is the name of the component, and the version number of that component. It is not possible to import or export a component without creating a new component. The component signature is: component.name: Name, component.main: option Service, -- component may. have a � A component is an instance of Component and therefore has a name, a set of services export it oﬀers to other components, and a set import of services it needs to import from other components. A component also has a version number. A declaration i : set S means that i is a subset of set S with at most one element. An option enables us to model an element that may (non-empty, sin-gleton set) or may not (empty set) be present. In P’ we have the same Scheduler instances as in PDS 0. Yet P�’’ schedules Component 2 to provide service Service 2 for Component 0; and Component 0 still provides service Service 1 to Component 1. Since Service 2 is contained in Component 2.export, we have two legitimate post states which are obtained by addingComponent 2 but which diﬀer in their scheduler. This is a very useful ability indeed. The utility of a micromodel of software resides perhaps more in the ability to explore it through guided simulations. We demonstrate this by generating a simulation that shows the removal and the addition of a component to a PDS. The addition ofcomponents creates opportunities to reschedule services, for better (e.g.optimizations) or for worse (e.,g. security breaches). We know that such a schedul-ing policy is consistent for these two operations. It is by no means the only such policy and is not guaranteed to ensure that applications won’t break using scheduled services. The fun-statement                fun HighestVersionPolicy(P: PDS) {.with P {all s : Service, c : components, c’ : c.schedule[s],                c’’: components - c' {. exporting && c�’.name = c‘.name;. importing && c'.version.^(Ord[Number].prev) }. run Highest version policy for 3 but not 1 PDS. The expression                c'.versions is the version number of c', an element of the type Number.",
                    "children": [
                        {
                            "id": "chapter-2-section-7-subsection-1",
                            "title": "State Machines",
                            "content": "cepting) states, respectively. Model M is concrete since there is nothing left\nun-speciﬁed and all checks M ⊨φ have deﬁnite answers: they either hold or\nthey don’t.\nIn practice not all functional or other requirements of a software sys-\ntem are known in advance, and they are likely to change during its life-\ncycle. For example, we may not know how many states there will be; and\nsome transitions may be mandatory whereas others may be optional in an\nimplementation. Conceptually, we seek a description M of all compliant\n2.7 Micromodels of software\n143\nimplementations Mi (i ∈I) of some software system. Given some matching\nproperty ψ, we then want to know\nr (assertion checking) whether ψ holds in all implementations Mi ∈M; or\nr (consistency checking) whether ψ holds in some implementation Mi ∈M.\nFor example, let M be the set of all concrete models of state machines, as\nabove. A possible assertion check ψ is ‘Final states are never initial states.’\nAn example of a consistency check ψ is ‘There are state machines that\ncontain a non-ﬁnal but deadlocked state.’\nAs remarked earlier, if M were the set of all state machines, then checking\nproperties would risk being undecidable, and would at least be intractable.\nIf M consists of a single model, then checking properties would be decidable;\nbut a single model is not general enough. It would comit us to instantiating\nseveral parameters which are not part of the requirements of a state machine,\nsuch as its size and detailed construction. A better idea is to ﬁx a ﬁnite bound\non the size of models, and check whether all models of that size that satisfy\nthe requirements also satisfy the property under consideration.\nr If we get a positive answer, we are somewhat conﬁdent that the property holds\nin all models. In this case, the answer is not conclusive, because there could be\na larger model which fails the property, but nevertheless a positive answer gives\nus some conﬁdence.\nassert FinalNotInitial {\nall M : StateMachine | no M.i & M.F\n} check FinalNotIntial for 3 but 1 StateMachine\ndeclares an assertion named FinalNotInitial whose body speciﬁes that\nfor all models M of type StateMachine the property no M.i & M.F is true.\nRead & for set intersection and no S (‘there is no S’) for ‘set S is empty.’\nAlloy identiﬁes elements a with singleton sets {a}, so this set intersection\nis well typed. The relational dot operator . enables access to the internal\ncomponents of a state machine: M.i is the initial state of M and M.F is its set\nof ﬁnal states etc. Therefore, the expression no M.i & M.F states ‘No initial\nstate of M is also a ﬁnal state of M.’ Finally, the check directive informs the\nanalyzer of Alloy that it should try to ﬁnd a counterexample of the assertion\nFinalNotInitial with at most three elements for every signature, except\nfor StateMachine which should have at most one.\nThe results of Alloy’s assertion check are shown in Figure 2.7. This visual-\nization has been customized to decorate initial and ﬁnal states with respec-\ntive labels i and F. The transition relation is shown as a labeled graph and\nthere is only one transition (from State 0 back to State 0) in this exam-\nple. Please verify that this is a counterexample to the claim of the assertion\nFinalNotInitial within the speciﬁed scopes. Alloy’s GUI lets you search\nfor additional witnesses (here: counterexamples), if they exist.\nSimilarly, we can check a property of state machines for consistency with\nour model. Alloy uses the keyword fun for consistency checks. e.g.\nfun AGuidedSimulation(M : StateMachine, s : M.A) {\nno s.(M.R)\nnot s in M.F\n# M.A = 3\n} run AGiudedSimulation for 3 but 1 StateMachine\n2.7 Micromodels of software\n145\nmodule AboutStateMachines\nsig State {}\n-- simple states\nsig StateMachine { -- composite state machines\nA : set State,\n-- set of states of a state machine\ni : A,\n-- initial state of a state machine\nF : set A,\n-- set of final states of a state machine",
                            "summary": "In practice not all requirements of a software system are known in advance. For example, we may not know how many states there will be. Some transitions may be mandatory whereas others may be optional in an implementation. Conceptually, we seek a description M of all compliant implementations of some software system. Given some matchingproperty ψ, we then want to know whether ψ holds in all implementations Mi (i) or Mi (I) M is concrete since there is nothing left left un-speciﬁed and all checks M ⊨φ have de-spi-nite answers: they either hold or don’t. It is the set of all concrete models of state machines, as above. If M consists of a single model, then checking properties would be decidable. A single model is not general enough. It would instantiate parameters which are not part of the requirements of a state machine. A better idea is to check whether all models of that size that satisfy the requirements also satisfy the property under consideration. If we get a positive answer, we are somewhat conﬁdent that the property holds in all models. We conclude that M is the set of all state machines, and that checking properties on M would be undecidable, and would at least be intractable. If M is a set of models, we conclude that it is not a model at all. Alloy identiﬁes elements a with singleton sets {a), so this set intersection is well typed. The relational dot operator . enables access to the internal components of a state machine: M.i is the initial state of M and M.F is its set. In this case, the answer is not conclusive, because there could be a larger model which fails the property, but nevertheless a positive answer gives                us some con ﬁdence. For all models M of type StateMachine the property no M. i & M. F is true. For example, there is no S for ‘set S is empty� Alloy’s GUI lets you search for additional witnesses (here: counterexamples), if they exist. We can check a property of state machines for consistency with our model. The transition relation is shown as a labeled graph and there is only one transition (from State 0 back to State 0) in this exam-                ple. Please verify that this is a countereXample to the claim of the assertion emphaticallyFinalNotInitial within the speciﬁed scopes. The results of Alloy's assertion check are shown in Figure 2.7. The check directive informs theanalyzer of Alloy that it should try to ﬁnd a countrexample of the assertions with at most three elements for 7 Micromodels of software 145.145.145 modules. e.g. AGuidedSimulation(M : StateMachine, s : M.A) could run AGiudedSimulation for 3 but 1 StateMachine 2.2.7. A Guided Simulation (M: StateMachine) could simulate 3 states of a state machine for 3 minutes.",
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-7-subsection-2",
                            "title": "Alma – Revisited",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-2-section-7-subsection-3",
                            "title": "A Software Micromodel",
                            "content": "1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,\ncepting) states, respectively. Model M is concrete since there is nothing left\nun-speciﬁed and all checks M ⊨φ have deﬁnite answers: they either hold or\nthey don’t.\nIn practice not all functional or other requirements of a software sys-\ntem are known in advance, and they are likely to change during its life-\ncycle. For example, we may not know how many states there will be; and\nsome transitions may be mandatory whereas others may be optional in an\nimplementation. Conceptually, we seek a description M of all compliant\n2.7 Micromodels of software\n143\nimplementations Mi (i ∈I) of some software system. Given some matching\nproperty ψ, we then want to know\nr (assertion checking) whether ψ holds in all implementations Mi ∈M; or\nr (consistency checking) whether ψ holds in some implementation Mi ∈M.\nFor example, let M be the set of all concrete models of state machines, as\nabove. A possible assertion check ψ is ‘Final states are never initial states.’\nAn example of a consistency check ψ is ‘There are state machines that\ncontain a non-ﬁnal but deadlocked state.’\nAs remarked earlier, if M were the set of all state machines, then checking\nproperties would risk being undecidable, and would at least be intractable.\nIf M consists of a single model, then checking properties would be decidable;\nbut a single model is not general enough. It would comit us to instantiating\nseveral parameters which are not part of the requirements of a state machine,\nsuch as its size and detailed construction. A better idea is to ﬁx a ﬁnite bound\non the size of models, and check whether all models of that size that satisfy\nthe requirements also satisfy the property under consideration.\nr If we get a positive answer, we are somewhat conﬁdent that the property holds\nin all models. In this case, the answer is not conclusive, because there could be\na larger model which fails the property, but nevertheless a positive answer gives\nus some conﬁdence.\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,\na service is a method (a modular piece of program code), a ﬁeld entry, or a\ntype – e.g. the type of a class in an object-oriented programming language.\nComponents typically require the import of services from other components.\nTechnically speaking, such import services resolve all un-resolved references\nwithin that component, making the component linkable. A component also\nhas a name and may have a special service, called ‘main.’\nWe model components as a signature in Alloy:\nsig Component {\nname: Name,\n-- name of the component\nmain: option Service, -- component may have a ‘main’ service\nexport: set Service,\n-- services the component exports\nimport: set Service,\n-- services the component imports\nversion: Number\n-- version number of the component\n}{ no import & export }\n150\n2 Predicate logic\nThe signatures Service and Name won’t require any composite structure for\nour modelling purposes. The signature Number will get an ordering later on.\nA component is an instance of Component and therefore has a name, a set of\nservices export it oﬀers to other components, and a set import of services\nit needs to import from other components. Last but not least, a component\nhas a version number. Observe the role of the modiﬁers set and option\nabove.\nA declaration i : set S means that i is a subset of set S; but a declara-\ntion i : option S means that i is a subset of S with at most one element.\nThus, option enables us to model an element that may (non-empty, sin-\ngleton set) or may not (empty set) be present; a very useful ability indeed.\nFinally, a declaration i : S states that i is a subset of S containing ex-\nactly one element; this really speciﬁes a scalar/element of type S since Alloy\nidentiﬁes elements a with sets {a}.\nSince\nService 2 is contained in Component 2.export, we have two struc-\nturally diﬀerent legitimate post states which are obtained by adding\nComponent 2 but which diﬀer in their scheduler. In P’ we have the same\nscheduling instances as in PDS 0. Yet P’’ schedules Component 2 to\nprovide service Service 2 for Component 0; and Component 0 still provides\nService 1 to Component 1. This analysis reveals that the addition of\ncomponents creates opportunities to reschedule services, for better (e.g.\noptimizations) or for worse (e.g. security breaches).\nThe utility of a micromodel of software resides perhaps more in the ability\nto explore it through guided simulations, as opposed to verifying some of\nits properties with absolute certainty. We demonstrate this by generating\na simulation that shows the removal and the addition of a component to a\nPDS such that the scheduler always schedules components with the highest\nversion number possible in all PDSs. Therefore we know that such a schedul-\ning policy is consistent for these two operations; it is by no means the only\nsuch policy and is not guaranteed to ensure that applications won’t break\nwhen using scheduled services. The fun-statement\nfun HighestVersionPolicy(P: PDS) {\nwith P {\nall s : Service, c : components, c’ : c.schedule[s],\nc’’ : components - c’ {\ns in c’’.export && c’’.name = c’.name =>\nc’’.version in c’.version.^(Ord[Number].prev)\n}\n}\n} run HighestVersionPolicy for 3 but 1 PDS\nspeciﬁes that, among those suppliers with identical name, the scheduler\nchooses one with the highest available version number. The expression\nc’.version.^(Ord[Number].prev)\nneeds explaining: c’.version is the version number of c’, an element of\ntype Number. The symbol ^ can be applied to a binary relation r : T -> T\nsuch that ^r has again type T -> T and denotes the transitive closure of r.\nIn this case, T equals Number and r equals Ord[Number].prev.\n156\n2 Predicate logic",
                            "summary": "We will model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to see if prerequisites in the form of libraries or other packages are present. We will also show how this system can be used to test the correctness of software implementations. We hope that this will be a useful tool for developers of software packages and other software products that need to be tested for reliability and correctness. Back to Mail Online home. back to the page you came from.    The open-source software project that built this paper. Back into the page that you came From.  The Open-source Software Project that Built This Paper.  http://www.open-source.org/software Software package dependency systems are used in several computer systems. Users often have to guess how technical questions get resolved within the de-pendency system. There is no publicly available model of any particular dependency system to which programmers could turn if they had non-trivial technicalquestions about its inner workings. In our model, applications are built out of components. Components oﬀerceive services to other components. A service can be a number of things. Typically, these are states of readiness and (re)cepting) states, respectively. For more information on how to use dependency systems in your software, visit www.researchers.com/SoftwarePackageDependencySystems. In practice not all functional or other requirements of a software system are known in advance. For example, we may not know how many states there will be; and some transitions may be mandatory whereas others may be optional in an implementation. Conceptually, we seek a description M of all compliant2.7 Micromodels of software systems. Given some matchingproperty ψ, we then want to know whether ψ holds in all implementations Mi (i) of some software system. We call this model M. Model M is concrete since there is nothing left left that is un-speciﬁed and all checks M ⊨φ have de-species answers. If M consists of a single model, then checking properties would be decidable. A single model is not general enough. It would instantiate parameters which are not part of the requirements of a state machine. A better idea is to check whether all models of that size that satisfy the requirements also satisfy the property under consideration. If we get a positive answer, we are somewhat conﬁdent that the property holds in all models. We conclude that M is the set of all state machines, and that checking properties on M would be undecidable, and would at least be intractable. If M is a set of models, we conclude that it is not a model at all. In our model, applications are built out of components. Components typically require the import of services from other components. A service can be a method (a modular piece of program code), a ﬁeld entry, or a type – e.g. the type of a class in an object-oriented programming language. Such import services resolve all un-resolved referenceswithin that component, making the component linkable. In this case, the answer is not conclusive, because there could be a larger model which fails the property, but nevertheless a positive answer gives us some conﬁ We model components as a signature in Alloy. A component is an instance of Component and therefore has a name, a set of services it needs to import and a version number. The signature Number will get an ordering later on. The signatures Service and Name won’t require any composite structure for our modelling purposes. For more information on Alloy, visit the official website or read the source code on our README.org site, or contact us on Twitter @AlloySig or on our mailing list, or email us at alloy-sig@mailonline.co.uk. Back to the page you came from. The official website, with more details on how to use Alloy. A declaration i : set S means that i is a subset of set S with at most one element. An option enables us to model an element that may (non-empty, sin-gleton set) or may not (empty set) be present. In P’ we have the same Scheduler instances as in PDS 0. Yet P�’’ schedules Component 2 to provide service Service 2 for Component 0; and Component 0 still provides service Service 1 to Component 1. Since Service 2 is contained in Component 2.export, we have two legitimate post states which are obtained by addingComponent 2 but which diﬀer in their scheduler. This is a very useful ability indeed. The utility of a micromodel of software resides perhaps more in the ability to explore it through guided simulations. We demonstrate this by generating a simulation that shows the removal and the addition of a component to a PDS. The addition ofcomponents creates opportunities to reschedule services, for better (e.g.optimizations) or for worse (e.,g. security breaches). We know that such a schedul-ing policy is consistent for these two operations. It is by no means the only such policy and is not guaranteed to ensure that applications won’t break using scheduled services. The fun-statement                fun HighestVersionPolicy(P: PDS) {.with P {all s : Service, c : components, c’ : c.schedule[s],                c’’: components - c' {. exporting && c�’.name = c‘.name;. importing && c'.version.^(Ord[Number].prev) }. run Highest version policy for 3 but not 1 PDS. The expression                c'.versions is the version number of c', an element of the type Number.",
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-3",
            "title": "Verification by Model Checking",
            "content": "perfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nrequest is true. If request is false, the next value of status is not deter-\nmined.\nNote that the case 1: signiﬁes the default case, and that case statements\nare evaluated from the top down: if several expressions to the left of a ‘:’ are\ntrue, then the command corresponding to the ﬁrst, top-most true expression\nwill be executed. The program therefore denotes the transition system shown\nin Figure 3.9; there are four states, each one corresponding to a possible value\nof the two binary variables. Note that we wrote ‘busy’ as a shorthand for\n‘status=busy’ and ‘req’ for ‘request is true.’\nIt takes a while to get used to the syntax of SMV and its meaning. Since\nvariable request functions as a genuine environment in this model, the\nprogram and the transition system are non-deterministic: i.e., the ‘next\nstate’ is not uniquely deﬁned. Any state transition based on the behaviour\nof status comes in a pair: to a successor state where request is false, or\ntrue, respectively. For example, the state ‘¬req, busy’ has four states it can\nmove to (itself and three others).\nLTL speciﬁcations are introduced by the keyword LTLSPEC and are sim-\nply LTL formulas. Notice that SMV uses &, |, -> and ! for ∧, ∨, →and\n¬, respectively, since they are available on standard keyboards. We may\n3.3 Model checking: systems, tools, properties\n193\nreq\nready\nbusy\nreq\n¬req\nbusy\nready\n¬req\nFigure 3.9. The model corresponding to the SMV program in the text.\neasily verify that the speciﬁcation of our module main holds of the model in\nFigure 3.9.\nModules in SMV\nSMV supports breaking a system description into sev-\neral modules, to aid readability and to verify interaction properties. A mod-\nule is instantiated when a variable having that module name as its type is perfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nLiveness: Messages get through eventually. Thus, for any state there is\ninevitably a future state in which the current message has got through. In\nthe module sender, we speciﬁed G F st=sent. (This speciﬁcation could\nequivalently have been written in the main module, as G F S.st=sent.)\nSimilarly, acknowledgements get through eventually. In the module\nreceiver, we write G F st=received.\n3.4 Branching-time logic\nIn our analysis of LTL (linear-time temporal logic) in the preceding sections,\nwe noted that LTL formulas are evaluated on paths. We deﬁned that a state\nof a system satisﬁes an LTL formula if all paths from the given state satisfy\nit. Thus, LTL implicitly quantiﬁes universally over paths. Therefore, prop-\nerties which assert the existence of a path cannot be expressed in LTL. This\nproblem can partly be alleviated by considering the negation of the property\nin question, and interpreting the result accordingly. To check whether there\n208\n3 Verification by model checking\nexists a path from s satisfying the LTL formula φ, we check whether all paths\nsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-\ntion, and vice versa. We used this approach when analysing the ferryman\npuzzle in the previous section. However, as already noted, properties which\nmix universal and existential path quantiﬁers cannot in general be model\nchecked using this approach, because the complement formula still has a mix.\nBranching-time logics solve this problem by allowing us to quantify ex-\nplicitly over paths. We will examine a logic known as Computation Tree\nLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X of\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nbut this is only so if interpreted on paths (π ⊨φ). We cannot assert such a\npossibility if interpreted on states (s ⊨φ) since we cannot express the existence\nof paths; for that interpretation, the negation of the formula above asserts that\nall paths will eventually get to such a state.\n184\n3 Verification by model checking\nr For any state, if a request (of some resource) occurs, then it will eventually be\nacknowledged:\nG (requested →F acknowledged).\nr A certain process is enabled inﬁnitely often on every computation path:\nG F enabled.\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nF G deadlock.\nr If the process is enabled inﬁnitely often, then it runs inﬁnitely often.\nG F enabled →G F running.\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nG (floor2 ∧directionup ∧ButtonPressed5 →(directionup U floor5))\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nThere are some things which are not possible to say in LTL, however. One\nbig class of such things are statements which assert the existence of a path,\nsuch as these ones:\nr From any state it is possible to get to a restart state (i.e., there is a path from\nall states to a state satisfying restart).\nr The lift can remain idle on the third ﬂoor with its doors closed (i.e., from the\nstate in which it is on the third ﬂoor, there is a path along which it stays there).\nLTL can’t express these because it cannot directly assert the existence of\npaths. In Section 3.4, we look at Computation Tree Logic (CTL) which has\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ. resolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\ntime-consuming and local ‘ﬁxes’ often introduce new bugs at other places. Ex-\nperience has shown that verifying programs with respect to formal speciﬁcations\ncan signiﬁcantly cut down the duration of software development and maintenance\nby eliminating most errors in the planning phase and helping in the clariﬁcation\nof the roles and structural aspects of system components.\nr Refactoring: Properly speciﬁed and veriﬁed software is easier to reuse, since\nwe have a clear speciﬁcation of what it is meant to do.\nr Certiﬁcation audits: Safety-critical computer systems – such as the control\nof cooling systems in nuclear power stations, or cockpits of modern aircrafts –\ndemand that their software be speciﬁed and veriﬁed with as much rigour and\nformality as possible. Other programs may be commercially critical, such as ac-\ncountancy software used by banks, and they should be delivered with a warranty:\na guarantee for correct performance within proper use. The proof that a program\nmeets its speciﬁcations is indeed such a warranty.\n258\n4 Program verification\nThe degree to which the software industry accepts the beneﬁts of proper\nveriﬁcation of code depends on the perceived extra cost of producing it and\nthe perceived beneﬁts of having it. As veriﬁcation technology improves, the\ncosts are declining; and as the complexity of software and the extent to which\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nmically by a computer. As we will see, there are often good heuristics\nto help the programmer complete these tasks. This contrasts with the\nsituation of the last chapter, which was fully automatic.\nProperty-oriented. Just like in the previous chapter, we verify proper-\nties of a program rather than a full speciﬁcation of its behaviour.\n256\n4.1 Why should we specify and verify code?\n257\nApplication domain. The domain of application in this chapter is se-\nquential transformational programs. ‘Sequential’ means that we assume\nthe program runs on a single processor and that there are no concur-\nrency issues. ‘Transformational’ means that the program takes an input\nand, after some computation, is expected to terminate with an output.\nFor example, methods of objects in Java are often programmed in this\nstyle. This contrasts with the previous chapter which focuses on reactive\nsystems that are not intended to terminate and that react continually\nwith their environment.\nPre/post-development. The techniques of this chapter should be used\nduring the coding process for small fragments of program that perform\nan identiﬁable (and hence, speciﬁable) task and hence should be used\nduring the development process in order to avoid functional bugs.\n4.1 Why should we specify and verify code?\nThe task of specifying and verifying code is often perceived as an unwel-\ncome addition to the programmer’s job and a dispensable one. Arguments\nin favour of veriﬁcation include the following:\nr Documentation: The speciﬁcation of a program is an important component\nin its documentation and the process of documenting a program may raise or\nresolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\ninto an ‘equivalent’ formula φR of some symbolic logic;\nr Write a program P which is meant to realise φR in the programming environment\nsupplied by your company, or wanted by the particular customer;\nr Prove that the program P satisﬁes the formula φR.\nThis scheme is quite crude – for example, constraints may be actual design\ndecisions for interfaces and data types, or the speciﬁcation may ‘evolve’\n4.2 A framework for software verification\n259\nand may partly be ‘unknown’ in big projects – but it serves well as a ﬁrst\napproximation to trying to deﬁne good programming methodology. Several\nvariations of such a sequence of activities are conceivable. For example,\nyou, as a programmer, might have been given only the formula φR, so you\nmight have little if any insight into the real-world problem which you are\nsupposed to solve. Technically, this poses no problem, but often it is handy\nto have both informal and formal descriptions available. Moreover, crafting\nthe informal requirements R is often a mutual process between the client\nand the programmer, whereby the attempt at formalising R can uncover\nambiguities or undesired consequences and hence lead to revisions of R.\nThis ‘going back and forth’ between the realms of informal and formal\nspeciﬁcations is necessary since it is impossible to ‘verify’ whether an infor-\nmal requirement R is equivalent to a formal description φR. The meaning\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nin an integrated in-house development environment.\nCurrently, many companies struggle with a legacy of ancient code with-\nout proper documentation which has to be adapted to new hardware and\nnetwork environments, as well as ever-changing requirements. Often, the\noriginal programmers who might still remember what certain pieces of code\nare for have moved, or died. Software systems now often have a longer\nlife-expectancy than humans, which necessitates a durable, transparent and\nportable design and implementation process; the year-2000 problem was just\none such example. Software veriﬁcation provides some of this.\n4.2 A framework for software verification\nSuppose you are working for a software company and your task is to write\nprograms which are meant to solve sophisticated problems, or computations.\nTypically, such a project involves an outside customer – a utility company,\nfor example – who has written up an informal description, in plain English,\nof the real-world task that is at hand. In this case, it could be the devel-\nopment and maintenance of a database of electricity accounts with all the\npossible applications of that – automated billing, customer service etc. Since\nthe informality of such descriptions may cause ambiguities which eventually\ncould result in serious and expensive design ﬂaws, it is desirable to condense\nall the requirements of such a project into formal speciﬁcations. These formal\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\n1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically, constraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ.\nThe equivalence of φ and ψ means that φ and ψ are semantically inter-\nchangeable. If φ is a subformula of some bigger formula χ, and ψ ≡φ, then\nwe can make the substitution of ψ for φ in χ without changing the meaning\nof χ. In propositional logic, we saw that ∧and ∨are duals of each other,\nmeaning that if you push a ¬ past a ∧, it becomes a ∨, and vice versa:\n¬(φ ∧ψ) ≡¬φ ∨¬ψ\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n(Because ∧and ∨are binary, pushing a negation downwards in the parse\ntree past one of them also has the eﬀect of duplicating that negation.)\n3.2 Linear-time temporal logic\n185\nSimilarly, F and G are duals of each other, and X is dual with itself:\n¬G φ ≡F ¬φ\n¬F φ ≡G ¬φ\n¬X φ ≡X ¬φ.\nAlso U and R are duals of each other:\n¬(φ U ψ) ≡¬φ R ¬ψ\n¬(φ R ψ) ≡¬φ U ¬ψ.\nWe should give formal proofs of these equivalences. But they are easy, so we\nleave them as an exercise to the reader. ‘Morally’ there ought to be a dual\nfor W, and you can invent one if you like. Work out what it might mean,\nand then pick a symbol based on the ﬁrst letter of the meaning. However, it\nmight not be very useful.\nIt’s also the case that F distributes over ∨and G over ∧, i.e.,\nF (φ ∨ψ) ≡F φ ∨F ψ\nG (φ ∧ψ) ≡G φ ∧G ψ.\nCompare this with the quantiﬁer equivalences in Section 2.3.2. But F does\nnot distribute over ∧. What this means is that there is a model with a\npath which distinguishes F (φ ∧ψ) and F φ ∧F ψ, for some φ, ψ. Take the\npath s0 →s1 →s0 →s1 →. . . from the system of Figure 3.3, for example;\nit satisﬁes F p ∧F r but it doesn’t satisfy F (p ∧r).\nHere are two more equivalences in LTL:\nF φ ≡⊤U φ\nG φ ≡⊥R φ.\nThe ﬁrst one exploits the fact that the clause for Until states two things:\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nConsider the path π = s1 →s2 →. . . . It represents a possible future of\nour system: ﬁrst it is in state s1, then it is in state s2, and so on. We write\nπi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .\n180\n3 Verification by model checking\np, q\nr\nr\nr\nq, r\np, q\nq, r\ns0\ns2\ns2\ns2\ns0\ns1\ns1\nr\ns2\nr\ns2\nFigure 3.5. Unwinding the system of Figure 3.3 as an infinite tree of\nall computation paths beginning in a particular state.\nIt is useful to visualise all possible computation paths from a given state\ns by unwinding the transition system to obtain an inﬁnite computation tree.\nFor example, if we unwind the state graph of Figure 3.3 for the designated\nstarting state s0, then we get the inﬁnite tree in Figure 3.5. The execu-\ntion paths of a model M are explicitly represented in the tree obtained by\nunwinding the model.\nDeﬁnition 3.6 Let M = (S, →, L) be a model and π = s1 →. . . be a path\nin M. Whether π satisﬁes an LTL formula is deﬁned by the satisfaction\nrelation ⊨as follows:\n1.\nπ ⊨⊤\n2.\nπ ̸⊨⊥\n3.\nπ ⊨p iﬀp ∈L(s1)\n4.\nπ ⊨¬φ iﬀπ ̸⊨φ\n5.\nπ ⊨φ1 ∧φ2 iﬀπ ⊨φ1 and π ⊨φ2\n6.\nπ ⊨φ1 ∨φ2 iﬀπ ⊨φ1 or π ⊨φ2\n7.\nπ ⊨φ1 →φ2 iﬀπ ⊨φ2 whenever π ⊨φ1\n8.\nπ ⊨X φ iﬀπ2 ⊨φ\n9.\nπ ⊨G φ iﬀ, for all i ≥1, πi ⊨φ\n3.2 Linear-time temporal logic\n181\ns0\ns1\ns2\ns3\ns4\ns5\ns6\ns7\ns8\ns9\ns10\n\u0001\n\u0002\u0003\n\u0004\np\nq\n. . .\nFigure 3.6. An illustration of the meaning of Until in the semantics of\nLTL. Suppose p is satisfied at (and only at) s3, s4, s5, s6, s7, s8 and q is\nsatisfied at (and only at) s9. Only the states s3 to s9 each satisfy p U q\nalong the path shown.\n10.\nπ ⊨F φ iﬀthere is some i ≥1 such that πi ⊨φ\n11.\nπ ⊨φ U ψ iﬀthere is some i ≥1 such that πi ⊨ψ and for all j = 1, . . . , i −1\nwe have πj ⊨φ\n12.\nπ ⊨φ W ψ iﬀeither there is some i ≥1 such that πi ⊨ψ and for all j =\n1, . . . , i −1 we have πj ⊨φ; or for all k ≥1 we have πk ⊨φ\n13.\nπ ⊨φ R ψ iﬀeither there is some i ≥1 such that πi ⊨φ and for all j = 1, . . . , i\nwe have πj ⊨ψ, or for all k ≥1 we have πk ⊨ψ. exist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nWriting W in terms of U is also possible: W is like U but also allows the\npossibility of the eventuality never occurring:\nφ W ψ ≡φ U ψ ∨G φ.\n(3.3)\nInspection of clauses 12 and 13 reveals that R and W are rather similar. The\ndiﬀerences are that they swap the roles of their arguments φ and ψ; and the\nclause for W has an i −1 where R has i. Therefore, it is not surprising that\nthey are expressible in terms of each other, as follows:\nφ W ψ ≡ψ R (φ ∨ψ)\n(3.4)\nφ R ψ ≡ψ W (φ ∧ψ).\n(3.5)\n3.2.5 Adequate sets of connectives for LTL\nRecall that φ ≡ψ holds iﬀany path in any transition system which sat-\nisﬁes φ also satisﬁes ψ, and vice versa. As in propositional logic, there is\nsome redundancy among the connectives. For example, in Chapter 1 we saw\nthat the set {⊥, ∧, ¬} forms an adequate set of connectives, since the other\nconnectives ∨, →, ⊤, etc., can be written in terms of those three.\nSmall adequate sets of connectives also exist in LTL. Here is a summary\nof the situation.\nr X is completely orthogonal to the other connectives. That is to say, its presence\ndoesn’t help in deﬁning any of the other ones in terms of each other. Moreover,\nX cannot be derived from any combination of the others.\nr Each of the sets {U, X}, {R, X}, {W, X} is adequate. To see this, we note that\n– R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and\nequivalence (3.4) followed by the duality, respectively.\n– U and W may be deﬁned from R, by the duality φ U ψ ≡¬(¬φ R ¬ψ) and\nequivalence (3.4), respectively.\n– R and U may be deﬁned from W, by equivalence (3.5) and the duality φ U\nψ ≡¬(¬φ R ¬ψ) followed by equivalence (3.5).\nSometimes it is useful to look at adequate sets of connectives which do not\nrely on the availability of negation. That’s because it is often convenient to\nassume formulas are written in negation-normal form, where all the negation\nsymbols are applied to propositional atoms (i.e., they are near the leaves\n3.3 Model checking: systems, tools, properties\n187\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\nare not, exhibit a model of one of the pair which is not a model of the\nother:\n(a) EF φ and EG φ\n(b)\n*\nEF φ ∨EF ψ and EF (φ ∨ψ)\n(c)\n*\nAF φ ∨AF ψ and AF (φ ∨ψ)\n(d) AF ¬φ and ¬EG φ\n(e)\n*\nEF ¬φ and ¬AF φ\n(f) A[φ1 U A[φ2 U φ3]] and A[A[φ1 U φ2] U φ3], hint: it might make it simpler\nif you think ﬁrst about models that have just one path\n(g) ⊤and AG φ →EG φ\n(h)\n*\n⊤and EG φ →AG φ.\n11. Find operators to replace the ?, to make the following equivalences:\n250\n3 Verification by model checking\n(a)\n*\nAG (φ ∧ψ) ≡AG φ ? AG ψ\n(b) EF ¬φ ≡¬??φ\n12. State explicitly the meaning of the temporal connectives AR etc., as deﬁned on\npage 217.\n13. Prove the equivalences (3.6) on page 216.\n14.\n*\nWrite pseudo-code for a recursive function TRANSLATE which takes as input\nan arbitrary CTL formula φ and returns as output an equivalent CTL formula\nψ whose only operators are among the set {⊥, ¬, ∧, AF , EU , EX }.\nExercises 3.5\n1. Express the following properties in CTL and LTL whenever possible. If neither\nis possible, try to express the property in CTL*:\n(a)\n*\nWhenever p is followed by q (after ﬁnitely many steps), then the system\nenters an ‘interval’ in which no r occurs until t.\n(b) Event p precedes s and t on all computation paths. (You may ﬁnd it easier\nto code the negation of that speciﬁcation ﬁrst.)\n(c) After p, q is never true. (Where this constraint is meant to apply on all\ncomputation paths.)\n(d) Between the events q and r, event p is never true.\n(e) Transitions to states satisfying p occur at most twice.\n(f)\n*\nProperty p is true for every second state along a path.\n2. Explain in detail why the LTL and CTL formulas for the practical speciﬁcation\npatterns of pages 183 and 215 capture the stated ‘informal’ properties expressed\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec- ‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nrun the speciﬁcation checks, as well as inspect partial results and set various\nparameters. See the NuSMV user manual for more details.\nNuSMV also supports bounded model checking, invoked by the command-\nline option -bmc. Bounded model checking looks for counterexamples in\norder of size, starting with counterexamples of length 1, then 2, etc., up\nto a given threshold (10 by default). Note that bounded model checking\nis incomplete: failure to ﬁnd a counterexample does not mean that there\nis none, but only that there is none of length up to the threshold. For\nrelated reasons, this incompleteness features also in Alloy and its constraint\nanalyzer. Thus, while a negative answer can be relied on (if NuSMV ﬁnds a\ncounterexample, it is valid), a positive one cannot. References on bounded\nmodel checking can be found in the bibliographic notes on page 254. Later\non, we use bounded model checking to prove the optimality of a scheduler.\n3.3.4 Mutual exclusion revisited\nFigure 3.10 gives the SMV code for a mutual exclusion protocol. This code\nconsists of two modules, main and prc. The module main has the variable\nturn, which determines whose turn it is to enter the critical section if both\nare trying to enter (recall the discussion about the states s3 and s9 in Sec-\ntion 3.3.1).\nThe module main also has two instantiations of prc. In each of these\ninstantiations, st is the status of a process (saying whether it is in its critical\nsection, or not, or trying) and other-st is the status of the other process\n(notice how this is passed as a parameter in the third and fourth lines of\nmain).\nThe value of st evolves in the way described in a previous section: when\nit is n, it may stay as n or move to t. When it is t, if the other one is n, it will\ngo straight to c, but if the other one is t, it will check whose turn it is before\ngoing to c. Then, when it is c, it may move back to n. Each instantiation of\nprc gives the turn to the other one when it gets to its critical section.\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nstates satisfying ¬(χi U ψi) ∨ψi. To understand why this condition has the\ndesired eﬀect, imagine the circumstances in which it is false. Suppose we\nhave a run having only ﬁnitely many states satisfying ¬(χi U ψi) ∨ψi. Let\nus advance through all those ﬁnitely many states, taking the suﬃx of the run\nnone of whose states satisﬁes ¬(χi U ψi) ∨ψi, i.e., all of whose states satisfy\n(χi U ψi) ∧¬ψi. That is precisely the sort of run we want to eliminate.\nIf we carry out this construction on a U b, we obtain the automaton shown\nin Figure 3.34. Another example is shown in Figure 3.36, for the formula\n(p U q) ∨(¬p U q). Since that formula has two U subformulas, there are two\nsets speciﬁed in the acceptance condition, namely, the states satisfying p U q\nand the states satisfying ¬p U q.\nHow LTL model checking is implemented in NuSMV\nIn the sec-\ntions above, we described an algorithm for LTL model checking. Given an\nLTL formula φ and a system M and a state s of M, we may check whether\nM, s ⊨φ holds by constructing the automaton A¬φ, combining it with M,\n238\n3 Verification by model checking\n¬(p U q),\n¬(¬p U q),\n¬p, ¬q, ¬φ\n¬(p U q),\n¬(¬p U q),\np U q,\n¬p U q,\n¬p, q, φ\np U q,\n¬(¬p U q),\np, ¬q, φ\np U q,\n¬p U q,\np, q, φ\n¬(p U q),\n¬p U q,\n¬p, ¬q, φ\nq1\nq2\nq3\nq4\nq5\nq6\np, ¬q, ¬φ\nFigure 3.36. Automaton accepting precisely traces satisfying φ\ndef\n= (p U\nq) ∨(¬p U q). The transitions with no arrows can be taken in either direc-\ntion. The acceptance condition asserts that every run must pass infinitely\noften through the set {q1, q3, q4, q5, q6}, and also the set {q1, q2, q3, q5, q6}.\nand checking whether there is a path of the resulting system which satisﬁes\nthe acceptance condition of A¬φ.\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ncaught earlier in the production cycle are less costly to rectify. (It is\nalleged that Intel lost millions of dollars by releasing their Pentium chip\nwith the FDIV error.)\nThis chapter concerns a veriﬁcation method called model checking. In\nterms of the above classiﬁcation, model checking is an automatic, model-\nbased, property-veriﬁcation approach. It is intended to be used for concur-\nrent, reactive systems and originated as a post-development methodology.\nConcurrency bugs are among the most diﬃcult to ﬁnd by testing (the activ-\nity of running several simulations of important scenarios), since they tend to\nbe non-reproducible or not covered by test cases, so it is well worth having\na veriﬁcation technique that can help one to ﬁnd them.\nThe Alloy system described in Chapter 2 is also an automatic, model-\nbased, property-veriﬁcation approach. The way models are used is slightly\ndiﬀerent, however. Alloy ﬁnds models which form counterexamples to asser-\ntions made by the user. Model checking starts with a model described by\nthe user, and discovers whether hypotheses asserted by the user are valid\non the model. If they are not, it can produce counterexamples, consisting of\nexecution traces. Another diﬀerence between Alloy and model checking is\nthat model checking (unlike Alloy) focuses explicitly on temporal properties\nand the temporal evolution of systems.\n174\n3 Verification by model checking\nBy contrast, Chapter 4 describes a very diﬀerent veriﬁcation technique\nwhich in terms of the above classiﬁcation is a proof-based, computer-assisted,\nproperty-veriﬁcation approach. It is intended to be used for programs which\nwe expect to terminate and produce a result.\nModel checking is based on temporal logic. The idea of temporal logic is\nthat a formula is not statically true or false in a model, as it is in propo-\nsitional and predicate logic. Instead, the models of temporal logic contain\nseveral states and a formula can be true in some states and false in others. labels given in Section 3.6.1.\n9.\n*\nFor mutual exclusion, draw a transition system which forces the two processes\nto enter their critical section in strict sequence and show that φ4 is false of its\ninitial state.\n10. Use the deﬁnition of ⊨between states and CTL formulas to explain why s ⊨\nAG AF φ means that φ is true inﬁnitely often along every path starting at s.\n11.\n*\nShow that a CTL formula φ is true on inﬁnitely many states of a computa-\ntion path s0 →s1 →s2 →. . . iﬀfor all n ≥0 there is some m ≥n such that\nsm ⊨φ.\n12. Run the NuSMV system on some examples. Try commenting out, or deleting,\nsome of the fairness constraints, if applicable, and see the counter examples\nNuSMV generates. NuSMV is very easy to run.\n13. In the one-bit channel, there are two fairness constraints. We could have written\nthis as a single one, inserting ‘&’ between running and the long formula, or we\ncould have separated the long formula into two and made it into a total of three\nfairness constraints.\nIn general, what is the diﬀerence between the single fairness constraint φ1 ∧φ2 ∧\n· · · ∧φn and the n fairness constraints φ1, φ2, . . . , φn? Write an SMV program\nwith a fairness constraint a & b which is not equivalent to the two fairness\nconstraints a and b. (You can actually do it in four lines of SMV.)\n14. Explain the construction of formula φ4, used to express that the processes need\nnot enter their critical section in strict sequence. Does it rely on the fact that\nthe safety property φ1 holds?\n15.\n*\nCompute the ECG ⊤labels for Figure 3.11, given the fairness constraints of the\ncode in Figure 3.10 on page 196.\nExercises 3.7\n1. Consider the functions\nH1, H2, H3 : P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}) →P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10})\ndeﬁned by\nH1(Y )\ndef\n= Y −{1, 4, 7}\nH2(Y )\ndef\n= {2, 5, 9} −Y\nH3(Y )\ndef\n= {1, 2, 3, 4, 5} ∩({2, 4, 8} ∪Y )\nfor all Y ⊆{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}.\n(a)\n*\nWhich of these functions are monotone; which ones aren’t? Justify your an-\nswer in each case.\n(b)\n*\nabout expressing properties in LTL are appropriate. Notice that in the\n190\n3 Verification by model checking\nno-strict-sequencing property, we overcame the problem of not being able to\nexpress the existence of paths by instead expressing the complement prop-\nerty, which of course talks about all paths. Then we can perform our check,\nand simply reverse the answer; if the complement property is false, we de-\nclare our property to be true, and vice versa.\nWhy was that tactic not available to us to express the non-blocking prop-\nerty? The reason is that it says: every path to a n1 state may be continued\nby a one-step path to a t1 state. The presence of both universal and exis-\ntential quantiﬁers is the problem. In the no-strict-sequencing property, we\nhad only an existential quantiﬁer; thus, taking the complement property\nturned it into a universal path quantiﬁer, which can be expressed in LTL.\nBut where we have alternating quantiﬁers, taking the complement property\ndoesn’t help in general.\nLet’s go back to the mutual exclusion example. The reason liveness failed\nin our ﬁrst attempt at modelling mutual exclusion is that non-determinism\nmeans it might continually favour one process over another. The problem is\nthat the state s3 does not distinguish between which of the processes ﬁrst\nwent into its trying state. We can solve this by splitting s3 into two states.\nThe second modelling attempt\nThe two states s3 and s9 in Figure 3.8\nboth correspond to the state s3 in our ﬁrst modelling attempt. They both\nrecord that the two processes are in their trying states, but in s3 it is im-\nplicitly recorded that it is process 1’s turn, whereas in s9 it is process 2’s\nturn. Note that states s3 and s9 both have the labelling t1t2; the deﬁnition of\ntransition systems does not preclude this. We can think of there being some\nother, hidden, variables which are not part of the initial labelling, which\ndistinguish s3 and s9. init(st) := sending;\nnext(st) := case\nack = message2 & !(st=sent) : sent;\n1\n: sending;\nesac;\nnext(message1) :=\ncase\nst = sent : {0,1};\n1\n: message1;\nesac;\nnext(message2) :=\ncase\nst = sent : !message2;\n1\n: message2;\nesac;\nFAIRNESS running\nLTLSPEC G F st=sent\nFigure 3.14. The ABP sender in SMV.\nsequentially. The variable message1 is the current bit of the message be-\ning sent, whereas message2 is the control bit. The deﬁnition of the mod-\nule sender is given in Figure 3.14. This module spends most of its time in\nst=sending, going only brieﬂy to st=sent when it receives an acknowledge-\nment corresponding to the control bit of the message it has been sending.\nThe variables message1 and message2 represent the actual data being sent\nand the control bit, respectively. On successful transmission, the module ob-\ntains a new message to send and returns to st=sending. The new message1\nis obtained non-deterministically (i.e., from the environment); message2 al-\nternates in value. We impose FAIRNESS running, i.e., the sender must be\nselected to run inﬁnitely often. The LTLSPEC tests that we can always suc-\nceed in sending the current message. The module receiver is programmed\nin a similar way, in Figure 3.15.\nWe also need to describe the two channels, in Figure 3.16. The acknowl-\nedgement channel is an instance of the one-bit channel one-bit-chan below.\nIts lossy character is speciﬁed by the assignment to forget. The value of\n3.3 Model checking: systems, tools, properties\n205\nMODULE receiver(message1,message2)\nVAR\nst\n: {receiving,received};\nack\n: boolean;\nexpected : boolean;\nASSIGN\ninit(st) := receiving;\nnext(st) := case\nmessage2=expected & !(st=received) : received;\n1\n: receiving;\nesac;\nnext(ack) :=\ncase\nst = received : message2;\n1\n: ack;\nesac;\nnext(expected) :=\ncase\nst = received : !expected;\n1\n: expected;\nesac;\nFAIRNESS running\nLTLSPEC G F st=received\nFigure 3.15. The ABP receiver in SMV.\ninput should be transmitted to output, unless forget is true. The two-bit\na line which can corrupt.)\nThe ABP works as follows. There are four entities, or agents: the sender,\nthe receiver, the message channel and the acknowledgement channel. The\nsender transmits the ﬁrst part of the message together with the ‘control’\nbit 0. If, and when, the receiver receives a message with the control bit 0,\nit sends 0 along the acknowledgement channel. When the sender receives\nthis acknowledgement, it sends the next packet with the control bit 1. If\nand when the receiver receives this, it acknowledges by sending a 1 on the\nacknowledgement channel. By alternating the control bit, both receiver and\nsender can guard against duplicating messages and losing messages (i.e.,\nthey ignore messages that have the unexpected control bit).\nIf the sender doesn’t get the expected acknowledgement, it continually re-\nsends the message, until the acknowledgement arrives. If the receiver doesn’t\nget a message with the expected control bit, it continually resends the pre-\nvious acknowledgement.\nFairness is also important for the ABP. It comes in because, although\nwe want to model the fact that the channel can lose messages, we want to\nassume that, if we send a message often enough, eventually it will arrive.\nIn other words, the channel cannot lose an inﬁnite sequence of messages. If\nwe did not make this assumption, then the channels could lose all messages\nand, in that case, the ABP would not work.\nLet us see this in the concrete setting of SMV. We may assume that\nthe text to be sent is divided up into single-bit messages, which are sent\n204\n3 Verification by model checking\nMODULE sender(ack)\nVAR\nst\n: {sending,sent};\nmessage1 : boolean;\nmessage2 : boolean;\nASSIGN\ninit(st) := sending;\nnext(st) := case\nack = message2 & !(st=sent) : sent;\n1\n: sending;\nesac;\nnext(message1) :=\ncase\nst = sent : {0,1};\n1\n: message1;\nesac;\nnext(message2) :=\ncase\nst = sent : !message2;\n1\n: message2;\nesac;\nFAIRNESS running\nLTLSPEC G F st=sent\nFigure 3.14. The ABP sender in SMV. U cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nc2, or must pass through such a state to reach a labelled state.\nThe pseudo-code of the CTL model-checking algorithm\nWe\npresent the pseudo-code for the basic labelling algorithm. The main function\nSAT (for ‘satisﬁes’) takes as input a CTL formula. The program SAT expects\na parse tree of some CTL formula constructed by means of the grammar in\nDeﬁnition 3.12. This expectation reﬂects an important precondition on the\ncorrectness of the algorithm SAT. For example, the program simply would\nnot know what to do with an input of the form X (⊤∧EF p3), since this is\nnot a CTL formula.\n226\n3 Verification by model checking\ns5\ns0\n0: t1n2\n0: c1n2\n0: t1t2\n0: c1t2\n2: E[¬c2 U c1]\ns3\ns1\ns2\ns6\ns9\ns4\ns7\n1: E[¬c2 U c1]\n1: E[¬c2 U c1]\n2: E[¬c2 U c1]\n3: E[¬c2 U c1]\n0: n1n2\n0: n1t2\n0: t1t2\n0: t1c2\n0: n1c2\nFigure 3.27. An example run of the labelling algorithm in our second\nmodel of mutual exclusion applied to the formula E[¬c2 U c1].\nThe pseudo-code we write for SAT looks a bit like fragments of C or\nJava code; we use functions with a keyword return that indicates which\nresult the function should return. We will also use natural language to\nindicate the case analysis over the root node of the parse tree of φ. The\ndeclaration local var declares some fresh variables local to the current in-\nstance of the procedure in question, whereas repeat until executes the\ncommand which follows it repeatedly, until the condition becomes true. Ad-\nditionally, we employ suggestive notation for the operations on sets, like\nintersection, set complement and so forth. In reality we would need an ab-\nstract data type, together with implementations of these operations, but for\nnow we are interested only in the mechanism in principle of the algorithm\nfor SAT; any (correct and eﬃcient) implementation of sets would do and\nwe study such an implementation in Chapter 6. We assume that SAT has\naccess to all the relevant parts of the model: S, →and L. In particular,\nenabled is inﬁnitely often taken.\nr A certain process is enabled inﬁnitely often on every computation path:\nAG (AF enabled).\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nAF (AG deadlock).\nr From any state it is possible to get to a restart state:\nAG (EF restart).\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nAG (floor2 ∧directionup ∧ButtonPressed5 →A[directionup U floor5])\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nr The lift can remain idle on the third ﬂoor with its doors closed:\nAG (floor3 ∧idle ∧doorclosed →EG (floor3 ∧idle ∧doorclosed)).\nr A process can always request to enter its critical section. Recall that this was\nnot expressible in LTL. Using the propositions of Figure 3.8, this may be written\nAG (n1 →EX t1) in CTL.\nr Processes need not enter their critical section in strict sequence. This was also\nnot expressible in LTL, though we expressed its negation. CTL allows us to\nexpress it directly: EF (c1 ∧E[c1 U (¬c1 ∧E[¬c2 U c1])]).\n3.4.4 Important equivalences between CTL formulas\nDeﬁnition 3.16 Two CTL formulas φ and ψ are said to be semantically\nequivalent if any state in any model which satisﬁes one of them also satisﬁes\nthe other; we denote this by φ ≡ψ.\n216\n3 Verification by model checking\nWe have already noticed that A is a universal quantiﬁer on paths and E\nis the corresponding existential quantiﬁer. Moreover, G and F are also uni-\nversal and existential quantiﬁers, ranging over the states along a particular\npath. In view of these facts, it is not surprising to ﬁnd that de Morgan rules\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the all paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nenabled is inﬁnitely often taken.\nr A certain process is enabled inﬁnitely often on every computation path:\nAG (AF enabled).\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nAF (AG deadlock).\nr From any state it is possible to get to a restart state:\nAG (EF restart).\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nAG (floor2 ∧directionup ∧ButtonPressed5 →A[directionup U floor5])\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nr The lift can remain idle on the third ﬂoor with its doors closed:\nAG (floor3 ∧idle ∧doorclosed →EG (floor3 ∧idle ∧doorclosed)).\nr A process can always request to enter its critical section. Recall that this was\nnot expressible in LTL. Using the propositions of Figure 3.8, this may be written\nAG (n1 →EX t1) in CTL.\nr Processes need not enter their critical section in strict sequence. This was also\nnot expressible in LTL, though we expressed its negation. CTL allows us to\nexpress it directly: EF (c1 ∧E[c1 U (¬c1 ∧E[¬c2 U c1])]).\n3.4.4 Important equivalences between CTL formulas\nDeﬁnition 3.16 Two CTL formulas φ and ψ are said to be semantically\nequivalent if any state in any model which satisﬁes one of them also satisﬁes\nthe other; we denote this by φ ≡ψ.\n216\n3 Verification by model checking\nWe have already noticed that A is a universal quantiﬁer on paths and E\nis the corresponding existential quantiﬁer. Moreover, G and F are also uni-\nversal and existential quantiﬁers, ranging over the states along a particular\npath. In view of these facts, it is not surprising to ﬁnd that de Morgan rules\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nmeets a q, but that is still not capturing the meaning of F p →F q.\nCTL* is a logic which combines the expressive powers of LTL and CTL,\nby dropping the CTL constraint that every temporal operator (X, U, F, G)\nhas to be associated with a unique path quantiﬁer (A, E). It allows us to\nwrite formulas such as\nr A[(p U r) ∨(q U r)]: along all paths, either p is true until r, or q is true until r.\nr A[X p ∨X X p]: along all paths, p is true in the next state, or the next but one.\nr E[G F p]: there is a path along which p is inﬁnitely often true.\nThese formulas are not equivalent to, respectively, A[(p ∨q) U r)], AX p ∨\nAX AX p and EG EF p. It turns out that the ﬁrst of them can be written\nas a (rather long) CTL formula. The second and third do not have a CTL\nequivalent.\nThe syntax of CTL* involves two classes of formulas:\nr state formulas, which are evaluated in states:\nφ ::= ⊤| p | (¬φ) | (φ ∧φ) | A[α] | E[α]\nwhere p is any atomic formula and α any path formula; and\nr path formulas, which are evaluated along paths:\nα ::= φ | (¬α) | (α ∧α) | (α U α) | (G α) | (F α) | (X α)\nwhere φ is any state formula. This is an example of an inductive deﬁnition\nwhich is mutually recursive: the deﬁnition of each class depends upon the\ndeﬁnition of the other, with base cases p and ⊤.\nLTL and CTL as subsets of CTL*\nAlthough the syntax of LTL does\nnot include A and E, the semantic viewpoint of LTL is that we consider\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually resolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\ntime-consuming and local ‘ﬁxes’ often introduce new bugs at other places. Ex-\nperience has shown that verifying programs with respect to formal speciﬁcations\ncan signiﬁcantly cut down the duration of software development and maintenance\nby eliminating most errors in the planning phase and helping in the clariﬁcation\nof the roles and structural aspects of system components.\nr Refactoring: Properly speciﬁed and veriﬁed software is easier to reuse, since\nwe have a clear speciﬁcation of what it is meant to do.\nr Certiﬁcation audits: Safety-critical computer systems – such as the control\nof cooling systems in nuclear power stations, or cockpits of modern aircrafts –\ndemand that their software be speciﬁed and veriﬁed with as much rigour and\nformality as possible. Other programs may be commercially critical, such as ac-\ncountancy software used by banks, and they should be delivered with a warranty:\na guarantee for correct performance within proper use. The proof that a program\nmeets its speciﬁcations is indeed such a warranty.\n258\n4 Program verification\nThe degree to which the software industry accepts the beneﬁts of proper\nveriﬁcation of code depends on the perceived extra cost of producing it and\nthe perceived beneﬁts of having it. As veriﬁcation technology improves, the\ncosts are declining; and as the complexity of software and the extent to which\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nmically by a computer. As we will see, there are often good heuristics\nto help the programmer complete these tasks. This contrasts with the\nsituation of the last chapter, which was fully automatic.\nProperty-oriented. Just like in the previous chapter, we verify proper-\nties of a program rather than a full speciﬁcation of its behaviour.\n256\n4.1 Why should we specify and verify code?\n257\nApplication domain. The domain of application in this chapter is se-\nquential transformational programs. ‘Sequential’ means that we assume\nthe program runs on a single processor and that there are no concur-\nrency issues. ‘Transformational’ means that the program takes an input\nand, after some computation, is expected to terminate with an output.\nFor example, methods of objects in Java are often programmed in this\nstyle. This contrasts with the previous chapter which focuses on reactive\nsystems that are not intended to terminate and that react continually\nwith their environment.\nPre/post-development. The techniques of this chapter should be used\nduring the coding process for small fragments of program that perform\nan identiﬁable (and hence, speciﬁable) task and hence should be used\nduring the development process in order to avoid functional bugs.\n4.1 Why should we specify and verify code?\nThe task of specifying and verifying code is often perceived as an unwel-\ncome addition to the programmer’s job and a dispensable one. Arguments\nin favour of veriﬁcation include the following:\nr Documentation: The speciﬁcation of a program is an important component\nin its documentation and the process of documenting a program may raise or\nresolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\ninto an ‘equivalent’ formula φR of some symbolic logic;\nr Write a program P which is meant to realise φR in the programming environment\nsupplied by your company, or wanted by the particular customer;\nr Prove that the program P satisﬁes the formula φR.\nThis scheme is quite crude – for example, constraints may be actual design\ndecisions for interfaces and data types, or the speciﬁcation may ‘evolve’\n4.2 A framework for software verification\n259\nand may partly be ‘unknown’ in big projects – but it serves well as a ﬁrst\napproximation to trying to deﬁne good programming methodology. Several\nvariations of such a sequence of activities are conceivable. For example,\nyou, as a programmer, might have been given only the formula φR, so you\nmight have little if any insight into the real-world problem which you are\nsupposed to solve. Technically, this poses no problem, but often it is handy\nto have both informal and formal descriptions available. Moreover, crafting\nthe informal requirements R is often a mutual process between the client\nand the programmer, whereby the attempt at formalising R can uncover\nambiguities or undesired consequences and hence lead to revisions of R.\nThis ‘going back and forth’ between the realms of informal and formal\nspeciﬁcations is necessary since it is impossible to ‘verify’ whether an infor-\nmal requirement R is equivalent to a formal description φR. The meaning\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nin an integrated in-house development environment.\nCurrently, many companies struggle with a legacy of ancient code with-\nout proper documentation which has to be adapted to new hardware and\nnetwork environments, as well as ever-changing requirements. Often, the\noriginal programmers who might still remember what certain pieces of code\nare for have moved, or died. Software systems now often have a longer\nlife-expectancy than humans, which necessitates a durable, transparent and\nportable design and implementation process; the year-2000 problem was just\none such example. Software veriﬁcation provides some of this.\n4.2 A framework for software verification\nSuppose you are working for a software company and your task is to write\nprograms which are meant to solve sophisticated problems, or computations.\nTypically, such a project involves an outside customer – a utility company,\nfor example – who has written up an informal description, in plain English,\nof the real-world task that is at hand. In this case, it could be the devel-\nopment and maintenance of a database of electricity accounts with all the\npossible applications of that – automated billing, customer service etc. Since\nthe informality of such descriptions may cause ambiguities which eventually\ncould result in serious and expensive design ﬂaws, it is desirable to condense\nall the requirements of such a project into formal speciﬁcations. These formal\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\n1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically, r A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nmeets a q, but that is still not capturing the meaning of F p →F q.\nCTL* is a logic which combines the expressive powers of LTL and CTL,\nby dropping the CTL constraint that every temporal operator (X, U, F, G)\nhas to be associated with a unique path quantiﬁer (A, E). It allows us to\nwrite formulas such as\nr A[(p U r) ∨(q U r)]: along all paths, either p is true until r, or q is true until r.\nr A[X p ∨X X p]: along all paths, p is true in the next state, or the next but one.\nr E[G F p]: there is a path along which p is inﬁnitely often true.\nThese formulas are not equivalent to, respectively, A[(p ∨q) U r)], AX p ∨\nAX AX p and EG EF p. It turns out that the ﬁrst of them can be written\nas a (rather long) CTL formula. The second and third do not have a CTL\nequivalent.\nThe syntax of CTL* involves two classes of formulas:\nr state formulas, which are evaluated in states:\nφ ::= ⊤| p | (¬φ) | (φ ∧φ) | A[α] | E[α]\nwhere p is any atomic formula and α any path formula; and\nr path formulas, which are evaluated along paths:\nα ::= φ | (¬α) | (α ∧α) | (α U α) | (G α) | (F α) | (X α)\nwhere φ is any state formula. This is an example of an inductive deﬁnition\nwhich is mutually recursive: the deﬁnition of each class depends upon the\ndeﬁnition of the other, with base cases p and ⊤.\nLTL and CTL as subsets of CTL*\nAlthough the syntax of LTL does\nnot include A and E, the semantic viewpoint of LTL is that we consider\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above. exist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\nWriting W in terms of U is also possible: W is like U but also allows the\npossibility of the eventuality never occurring:\nφ W ψ ≡φ U ψ ∨G φ.\n(3.3)\nInspection of clauses 12 and 13 reveals that R and W are rather similar. The\ndiﬀerences are that they swap the roles of their arguments φ and ψ; and the\nclause for W has an i −1 where R has i. Therefore, it is not surprising that\nthey are expressible in terms of each other, as follows:\nφ W ψ ≡ψ R (φ ∨ψ)\n(3.4)\nφ R ψ ≡ψ W (φ ∧ψ).\n(3.5)\n3.2.5 Adequate sets of connectives for LTL\nRecall that φ ≡ψ holds iﬀany path in any transition system which sat-\nisﬁes φ also satisﬁes ψ, and vice versa. As in propositional logic, there is\nsome redundancy among the connectives. For example, in Chapter 1 we saw\nthat the set {⊥, ∧, ¬} forms an adequate set of connectives, since the other\nconnectives ∨, →, ⊤, etc., can be written in terms of those three.\nSmall adequate sets of connectives also exist in LTL. Here is a summary\nof the situation.\nr X is completely orthogonal to the other connectives. That is to say, its presence\ndoesn’t help in deﬁning any of the other ones in terms of each other. Moreover,\nX cannot be derived from any combination of the others.\nr Each of the sets {U, X}, {R, X}, {W, X} is adequate. To see this, we note that\n– R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and\nequivalence (3.4) followed by the duality, respectively.\n– U and W may be deﬁned from R, by the duality φ U ψ ≡¬(¬φ R ¬ψ) and\nequivalence (3.4), respectively.\n– R and U may be deﬁned from W, by equivalence (3.5) and the duality φ U\nψ ≡¬(¬φ R ¬ψ) followed by equivalence (3.5).\nSometimes it is useful to look at adequate sets of connectives which do not\nrely on the availability of negation. That’s because it is often convenient to\nassume formulas are written in negation-normal form, where all the negation\nsymbols are applied to propositional atoms (i.e., they are near the leaves\n3.3 Model checking: systems, tools, properties\n187 constraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLiveness: Messages get through eventually. Thus, for any state there is\ninevitably a future state in which the current message has got through. In\nthe module sender, we speciﬁed G F st=sent. (This speciﬁcation could\nequivalently have been written in the main module, as G F S.st=sent.)\nSimilarly, acknowledgements get through eventually. In the module\nreceiver, we write G F st=received.\n3.4 Branching-time logic\nIn our analysis of LTL (linear-time temporal logic) in the preceding sections,\nwe noted that LTL formulas are evaluated on paths. We deﬁned that a state\nof a system satisﬁes an LTL formula if all paths from the given state satisfy\nit. Thus, LTL implicitly quantiﬁes universally over paths. Therefore, prop-\nerties which assert the existence of a path cannot be expressed in LTL. This\nproblem can partly be alleviated by considering the negation of the property\nin question, and interpreting the result accordingly. To check whether there\n208\n3 Verification by model checking\nexists a path from s satisfying the LTL formula φ, we check whether all paths\nsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-\ntion, and vice versa. We used this approach when analysing the ferryman\npuzzle in the previous section. However, as already noted, properties which\nmix universal and existential path quantiﬁers cannot in general be model\nchecked using this approach, because the complement formula still has a mix.\nBranching-time logics solve this problem by allowing us to quantify ex-\nplicitly over paths. We will examine a logic known as Computation Tree\nLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X of\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.\nMar01. A. Martin. Adequate sets of temporal connectives in CTL. Electronic\nNotes in Theoretical Computer Science 52(1), 2001.\nMcM93. K. L. McMillan. Symbolic Model Checking. Kluwer Academic\nPublishers, 1993.\nMP91. Z. Manna and A. Pnueli. The Temporal Logic of Reactive and\nConcurrent Systems: Speciﬁcation. Springer-Verlag, 1991.\nMP95. Z. Manna and A. Pnueli. Temporal Veriﬁcation of Reactive Systems:\nSafety. Springer-Verlag, 1995.\nMvdH95. J.-J. Ch. Meyer and W. van der Hoek. Epistemic Logic for AI and\nComputer Science, volume 41 of Cambridge Tracts in Theoretical\nComputer Science. Cambridge University Press, 1995.\nPap94. C. H. Papadimitriou. Computational Complexity. Addison Wesley,\n1994.\nPau91. L.C. Paulson. ML for the Working Programmer. Cambridge University\nPress, 1991.\nPnu81. A. Pnueli. A temporal logic of programs. Theoretical Computer\nScience, 13:45–60, 1981.\nPop94. S. Popkorn. First Steps in Modal Logic. Cambridge University Press,\n1994.\nPra65. D. Prawitz. Natural Deduction: A Proof-Theoretical Study. Almqvist &\nWiksell, 1965.\nQS81. J. P. Quielle and J. Sifakis. Speciﬁcation and veriﬁcation of concurrent\nsystems in CESAR. In Proceedings of the Fifth International\nSymposium on Programming, 1981.\nRos97. A. W. Roscoe. The Theory and Practice of Concurrency. Prentice\nHall, 1997.\nSA91. V. Sperschneider and G. Antoniou. Logic, A Foundation for Computer\nScience. Addison Wesley, 1991.\nSch92. U. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag, 1992.\nSch94. D. A. Schmidt. The Structure of Typed Programming Languages.\nFoundations of Computing. The MIT Press, 1994.\nSim94. A. K. Simpson. The Proof Theory and Semantics of Intuitionistic\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nIn this section, we see that the ﬁrst of these restrictions is only apparent;\nwe can ﬁnd equivalents in CTL for formulas having boolean combinations\nof path formulas. The idea is to translate any CTL formula having boolean\ncombinations of path formulas into a CTL formula that doesn’t. For exam-\nple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q ∧EF p] since, if\nwe have F p ∧F q along any path, then either the p must come before the q,\nor the other way around, corresponding to the two disjuncts on the right.\n(If the p and q occur simultaneously, then both disjuncts are true.)\n3.6 Model-checking algorithms\n221\nSince U is like F (only with the extra complication of its ﬁrst argument),\nwe ﬁnd the following equivalence:\nE[(p1 U q1) ∧(p2 U q2)] ≡E[(p1 ∧p2) U (q1 ∧E[p2 U q2])]\n∨E[(p1 ∧p2) U (q2 ∧E[p1 U q1])].\nAnd from the CTL equivalence A[p U q] ≡¬(E[¬q U (¬p ∧¬q)] ∨EG ¬q)\n(see Theorem 3.10) we can obtain E[¬(p U q)]\n≡\nE[¬q U (¬p ∧¬q)] ∨\nEG ¬q. Other identities we need in this translation include E[¬X p]\n≡\nEX ¬p.\n3.5.2 Past operators in LTL\nThe temporal operators X, U, F, etc. which we have seen so far refer to the\nfuture. Sometimes we want to encode properties that refer to the past, such\nas: ‘whenever q occurs, then there was some p in the past.’ To do this, we\nmay add the operators Y, S, O, H. They stand for yesterday, since, once, and\nhistorically, and are the past analogues of X, U, F, G, respectively. Thus,\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker the example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r)) that φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\n‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ndoes the combined system have a path. The acceptance conditions of A¬φ\nare represented as implicit fairness conditions for the CTL model-checking\nprocedure. Explicitly, this amounts to asserting ‘FAIRNESS ¬(χ U ψ) ∨ψ’\nfor each formula χ U ψ occurring in C(φ).\n3.7 The fixed-point characterisation of CTL\nOn page 227, we presented an algorithm which, given a CTL formula φ and\na model M = (S, →, L), computes the set of states s ∈S satisfying φ. We\nwrite this set as [[φ]]. The algorithm works recursively on the structure of\nφ. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. Other\n3.7 The fixed-point characterisation of CTL\n239\nformulas are composed of smaller subformulas combined by a connective of\nCTL. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets\n[[ψ1]] and [[ψ2]] and combines them in a certain way (in this case, by taking\nthe union) in order to obtain [[ψ1 ∨ψ2]].\nThe more interesting cases arise when we deal with a formula such as\nEX ψ, involving a temporal operator. The algorithm computes the set [[ψ]]\nand then computes the set of all states which have a transition to a state in\n[[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is\na state s′ with s →s′ and M, s′ ⊨ψ.\nFor most of these logical operators, we may easily continue this discussion\nto see that the algorithms work just as expected. However, the cases EU,\nAF and EG (where we needed to iterate a certain labelling policy until it\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula call such paths fair computation paths. The presence of fairness constraints\nmeans that, when evaluating the truth of CTL formulas in speciﬁcations,\nthe connectives A and E range only over fair paths.\n3.6 Model-checking algorithms\n231\nWe therefore impose the fairness constraint that !st=c be true inﬁnitely\noften. This means that, whatever state the process is in, there will be a\nstate in the future in which it is not in its critical section. Similar fairness\nconstraints were used for the Alternating Bit Protocol.\nFairness constraints of the form (where φ is a state formula)\nProperty φ is true inﬁnitely often\nare known as simple fairness constraints. Other types include those of the\nform\nIf φ is true inﬁnitely often, then ψ is also true inﬁnitely often.\nSMV can deal only with simple fairness constraints; but how does it do\nthat? To answer that, we now explain how we may adapt our model-checking\nalgorithm so that A and E are assumed to range only over fair computation\npaths.\nDeﬁnition 3.21 Let C\ndef\n= {ψ1, ψ2, . . . , ψn} be a set of n fairness constraints.\nA computation path s0 →s1 →. . . is fair with respect to these fairness\nconstraints iﬀfor each i there are inﬁnitely many j such that sj ⊨ψi, that\nis, each ψi is true inﬁnitely often along the path. Let us write AC and EC\nfor the operators A and E restricted to fair paths.\nFor example, M, s0 ⊨ACG φ iﬀφ is true in every state along all fair paths;\nand similarly for ACF, ACU, etc. Notice that these operators explicitly de-\npend on the chosen set C of fairness constraints. We already know that ECU,\nECG and ECX form an adequate set; this can be shown in the same man-\nner as was done for the temporal connectives without fairness constraints\n(Section 3.4.4). We also have that\nEC[φ U ψ] ≡E[φ U (ψ ∧ECG ⊤)]\nECX φ ≡EX (φ ∧ECG ⊤).\nTo see this, observe that a computation path is fair iﬀany suﬃx of it is\nfair. Therefore, we need only provide an algorithm for ECG φ. It is similar\ntion problems.\nThe last four issues are beyond the scope of this book, but references may\nbe found at the end of this chapter.\n3.6.2 CTL model checking with fairness\nThe veriﬁcation of M, s0 ⊨φ might fail because the model M may contain\nbehaviour which is unrealistic, or guaranteed not to occur in the actual sys-\ntem being analysed. For example, in the mutual exclusion case, we expressed\nthat the process prc can stay in its critical section (st=c) as long as it needs.\nWe modelled this by the non-deterministic assignment\nnext(st) :=\ncase\n...\n(st = c)\n: {c,n};\n...\nesac;\nHowever, if we really allow process 2 to stay in its critical section as\nlong as it likes, then we have a path which violates the liveness constraint\nAG (t1 →AF c1), since, if process 2 stays forever in its critical section, t1\ncan be true without c1 ever becoming true.\nWe would like to ignore this path, i.e., we would like to assume that the\nprocess can stay in its critical section as long as it needs, but will eventually\nexit from its critical section after some ﬁnite time.\nIn LTL, we could handle this by verifying a formula like FG¬c2 →φ,\nwhere φ is the formula we actually want to verify. This whole formula asserts\nthat all paths which satisfy inﬁnitely often ¬c2 also satisfy φ. However,\nwe cannot do this in CTL because we cannot write formulas of the form\nFG¬c2 →φ in CTL. The logic CTL is not expressive enough to allow us\nto pick out the ‘fair’ paths, i.e., those in which process 2 always eventually\nleaves its critical section.\nIt is for that reason that SMV allows us to impose fairness constraints\non top of the transition system it describes. These assumptions state that\na given formula is true inﬁnitely often along every computation path. We\ncall such paths fair computation paths. The presence of fairness constraints\nmeans that, when evaluating the truth of CTL formulas in speciﬁcations,\nthe connectives A and E range only over fair paths.\n3.6 Model-checking algorithms\n231\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ndoes the combined system have a path. The acceptance conditions of A¬φ\nare represented as implicit fairness conditions for the CTL model-checking\nprocedure. Explicitly, this amounts to asserting ‘FAIRNESS ¬(χ U ψ) ∨ψ’\nfor each formula χ U ψ occurring in C(φ).\n3.7 The fixed-point characterisation of CTL\nOn page 227, we presented an algorithm which, given a CTL formula φ and\na model M = (S, →, L), computes the set of states s ∈S satisfying φ. We\nwrite this set as [[φ]]. The algorithm works recursively on the structure of\nφ. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. Other\n3.7 The fixed-point characterisation of CTL\n239\nformulas are composed of smaller subformulas combined by a connective of\nCTL. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets\n[[ψ1]] and [[ψ2]] and combines them in a certain way (in this case, by taking\nthe union) in order to obtain [[ψ1 ∨ψ2]].\nThe more interesting cases arise when we deal with a formula such as\nEX ψ, involving a temporal operator. The algorithm computes the set [[ψ]]\nand then computes the set of all states which have a transition to a state in\n[[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is\na state s′ with s →s′ and M, s′ ⊨ψ.\nFor most of these logical operators, we may easily continue this discussion\nto see that the algorithms work just as expected. However, the cases EU,\nAF and EG (where we needed to iterate a certain labelling policy until it\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\nhow SMV could use fairness assumptions which were not expressible entirely\n5 Since we have added the variable u, there are actually six states; they all satisfy the formula.\n6.4 A relational mu-calculus\n397\nwithin CTL and its semantics. The addition of fairness could be achieved\nby restricting the ordinary CTL semantics to fair computation paths, or fair\nstates. Formally, we were given a set C = {ψ1, ψ2, . . . , ψk} of CTL formulas,\ncalled the fairness constraints, and we wanted to check whether s ⊨φ holds\nfor a CTL formula φ and all initial states s, with the additional fairness\nconstraints in C. Since ⊥, ¬, ∧, EX, EU and EG form an adequate set of\nconnectives for CTL, we may restrict this discussion to only these operators.\nClearly, the propositional connectives won’t change their meaning with the\naddition of fairness constraints. Therefore, it suﬃces to provide symbolic\ncodings for the fair connectives ECX, ECU and ECG from Chapter 3. The\nkey is to represent the set of fair states symbolically as a boolean formula\nfair deﬁned as\nfair\ndef\n= fECG⊤\n(6.22)\nwhich uses the (yet to be deﬁned) function fECG φ with ⊤as an instance.\nAssuming that the coding of fECG φ is correct, we see that fair computes 1\nin a state s if, and only if, there is a fair path with respect to C that begins\nin s. We say that such an s is a fair state.\nAs for ECX, note that s ⊨ECXφ if, and only if, there is some next state s′\nwith s →s′ and s′ ⊨φ such that s′ is a fair state. This immediately renders\nfECXφ def\n= ∃ˆx′.(f→· (fφ · fair)[ˆx := ˆx′]).\n(6.23)\nSimilarly, we obtain\nfEC[φ1Uφ2] def\n= µZ. (fφ2 · fair + fφ1 · ∃ˆx′. (f→· Z[ˆx := ˆx′])).\n(6.24)\nThis leaves us with the task of coding fECG φ. It is this last connective\nwhich reveals the complexity of fairness checks at work. Because the coding\nof fECG φ is rather complex, we proceed in steps. It is convenient to have the\nEX and EU functionality also at the level of boolean formulas directly. For\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nIn this section, we see that the ﬁrst of these restrictions is only apparent;\nwe can ﬁnd equivalents in CTL for formulas having boolean combinations\nof path formulas. The idea is to translate any CTL formula having boolean\ncombinations of path formulas into a CTL formula that doesn’t. For exam-\nple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q ∧EF p] since, if\nwe have F p ∧F q along any path, then either the p must come before the q,\nor the other way around, corresponding to the two disjuncts on the right.\n(If the p and q occur simultaneously, then both disjuncts are true.)\n3.6 Model-checking algorithms\n221\nSince U is like F (only with the extra complication of its ﬁrst argument),\nwe ﬁnd the following equivalence:\nE[(p1 U q1) ∧(p2 U q2)] ≡E[(p1 ∧p2) U (q1 ∧E[p2 U q2])]\n∨E[(p1 ∧p2) U (q2 ∧E[p1 U q1])].\nAnd from the CTL equivalence A[p U q] ≡¬(E[¬q U (¬p ∧¬q)] ∨EG ¬q)\n(see Theorem 3.10) we can obtain E[¬(p U q)]\n≡\nE[¬q U (¬p ∧¬q)] ∨\nEG ¬q. Other identities we need in this translation include E[¬X p]\n≡\nEX ¬p.\n3.5.2 Past operators in LTL\nThe temporal operators X, U, F, etc. which we have seen so far refer to the\nfuture. Sometimes we want to encode properties that refer to the past, such\nas: ‘whenever q occurs, then there was some p in the past.’ To do this, we\nmay add the operators Y, S, O, H. They stand for yesterday, since, once, and\nhistorically, and are the past analogues of X, U, F, G, respectively. Thus,\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres- that φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\n‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\n4 www.cs.indiana.edu/formal-methods-education/\n246\n3 Verification by model checking\nq3\nq1\nq2\nab\nq4\nab\nab\nab\nFigure 3.39. A model M.\n2. Consider the system of Figure 3.39. For each of the formulas φ:\n(a) G a\n(b) a U b\n(c) a U X (a ∧¬b)\n(d) X ¬b ∧G (¬a ∨¬b)\n(e) X (a ∧b) ∧F (¬a ∧¬b)\n(i) Find a path from the initial state q3 which satisﬁes φ.\n(ii) Determine whether M, q3 ⊨φ.\n3. Working from the clauses of Deﬁnition 3.1 (page 175), prove the equivalences:\nφ U ψ ≡φ W ψ ∧F ψ\nφ W ψ ≡φ U ψ ∨G φ\nφ W ψ ≡ψ R (φ ∨ψ)\nφ R ψ ≡ψ W (φ ∧ψ) .\n4. Prove that φ U ψ ≡ψ R (φ ∨ψ) ∧F ψ.\n5. List all subformulas of the LTL formula ¬p U (F r ∨G ¬q →q W ¬r).\n6. ‘Morally’ there ought to be a dual for W. Work out what it might mean, and\nthen pick a symbol based on the ﬁrst letter of the meaning.\n7. Prove that for all paths π of all models, π ⊨φ W ψ ∧F ψ implies π ⊨φ U ψ.\nThat is, prove the remaining half of equivalence (3.2) on page 185.\n8. Recall the algorithm NNF on page 62 which computes the negation normal form\nof propositional logic formulas. Extend this algorithm to LTL: you need to add\nprogram clauses for the additional connectives X, F, G and U, R and W; these\nclauses have to animate the semantic equivalences that we presented in this\nsection.\n3.8 Exercises\n247\nExercises 3.3\n1. Consider the model in Figure 3.9 (page 193).\n(a)\n*\nVerify that G(req -> F busy) holds in all initial states.\n(b) Does ¬(req U ¬busy) hold in all initial states of that model?\n(c) NuSMV has the capability of referring to the next value of a declared vari-\nable v by writing next(v). Consider the model obtained from Figure 3.9\nby removing the self-loop on state !req & busy. Use the NuSMV feature\nnext(...) to code that modiﬁed model as an NuSMV program with the\nspeciﬁcation G(req -> F busy). Then run it.\n2. Verify Remark 3.11 from page 190.\n3.\n*\nDraw the transition system described by the ABP program.\nRemarks: There are 28 reachable states of the ABP program. (Looking at the\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2; for all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\ncode in Figure 3.28, we see that most of these clauses just do the obvious\nand correct thing according to the semantics of CTL. For example, try out\nwhat SAT does when you call it with φ1 →φ2.\nOur aim in this section is to prove the termination and correctness\nof SATAF and SATEU. In fact, we will also write a procedure SATEG and\nprove its termination and correctness1. The procedure SATEG is given in\nFigure 3.37 and is based on the intuitions given in Section 3.6.1: note how\ndeleting the label if none of the successor states is labelled is coded as\nintersecting the labelled set with the set of states which have a labelled\nsuccessor.\nThe semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-\nputation path s0 →s1 →s2 →. . . such that si ⊨φ holds for all i ≥0. We\ncould instead express it as follows: EG φ holds if φ holds and EG φ holds\nin one of the successor states to the current state. This suggests the equiv-\nalence EG φ ≡φ ∧EX EG φ which can easily be proved from the semantic\ndeﬁnitions of the connectives.\nObserving that [[EX ψ]] = pre∃([[ψ]]) we see that the equivalence above\ncan be written as [[EG φ]] = [[φ]] ∩pre∃([[EG φ]]). This does not look like a\nvery promising way of calculating EG φ, because we need to know EG φ in\norder to work out the right-hand side. Fortunately, there is a way around\nthis apparent circularity, known as computing ﬁxed points, and that is the\nsubject of this section.\n1 Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted in Section 3.6.1\nthat EG could be handled directly.\n240\n3 Verification by model checking\nfunction SATEG (φ)\n/* determines the set of states satisfying EG φ */\nlocal var X, Y\nbegin\nY := SAT (φ);\nX := ∅;\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∩pre∃(Y )\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\ntions compute a pre-image of a set of states. The function pre∃(instrumental\nin SATEX and SATEU) takes a subset Y of states and returns the set of states\nwhich can make a transition into Y . The function pre∀, used in SATAF, takes\n228\n3 Verification by model checking\nfunction SATEX (φ)\n/* determines the set of states satisfying EX φ */\nlocal var X, Y\nbegin\nX := SAT (φ);\nY := pre∃(X);\nreturn Y\nend\nFigure 3.29. The function SATEX. It computes the states satisfying φ by\ncalling SAT. Then, it looks backwards along →to find the states satisfying\nEX φ.\nfunction SATAF (φ)\n/* determines the set of states satisfying AF φ */\nlocal var X, Y\nbegin\nX := S;\nY := SAT (φ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪pre∀(Y )\nend\nreturn Y\nend\nFigure 3.30. The function SATAF. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying AF φ in the manner\ndescribed in the labelling algorithm.\na set Y and returns the set of states which make transitions only into Y .\nObserve that pre∀can be expressed in terms of complementation and pre∃,\nas follows:\npre∀(Y ) = S −pre∃(S −Y )\n(3.8)\nwhere we write S −Y for the set of all s ∈S which are not in Y .\nThe correctness of this pseudocode and the model checking algorithm is\ndiscussed in Section 3.7.\n3.6 Model-checking algorithms\n229\nfunction SATEU (φ, ψ)\n/* determines the set of states satisfying E[φ U ψ] */\nlocal var W, X, Y\nbegin\nW := SAT (φ);\nX := S;\nY := SAT (ψ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪(W ∩pre∃(Y ))\nend\nreturn Y\nend\nFigure 3.31. The function SATEU. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying E[φ U ψ] in the manner\ndescribed in the labelling algorithm.\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nlaws to it, and extract a witness to the DAG’s satisﬁability. Explain in what\nsense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is\nnot valid.\n5. Explain in what sense the SAT solving technique, as presented in this chapter,\ncan be used to check whether formulas are tautologies.\n6. For φ from (1.10), can one reverse engineer φ from the DAG of T(φ)?\n7. Consider a modiﬁcation of our method which initially tags a DAG’s root node\nwith ‘1: F.’ In that case,\n(a) are the forcing laws still sound? If so, state the invariant.\n(b) what can we say about the formula(s) a DAG represents if\ni. we detect contradictory constraints?\nii. we compute consistent forced constraints for each node?\n8. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied\nto T(φ) –\nto the marking algorithm – applied to φ. Discuss similarities and\ndiﬀerences of these approaches.\n1.8 Bibliographic notes\n91\n9. Consider Figure 1.20 on page 77. Verify that\n(a) its test produces contradictory constraints\n(b) its cubic analysis does not decide satisﬁability, regardless of whether the\ntwo optimizations we described are present.\n10. Verify that the DAG of Figure 1.17 (page 74) is indeed the one obtained for\nT(φ), where φ is the formula in (1.11) on page 73.\n11.\n*\nAn implementor may be concerned with the possibility that the answers to the\ncubic SAT solver may depend on a particular order in which we test unmarked\nnodes or use the rules in Figure 1.14. Give a semi-formal argument for why the\nanalysis results don’t depend on such an order.\n12. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability\nof T(φ).\n13. Advanced Project: Write a complete implementation of the cubic SAT solver\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nWhen we applied our linear SAT solver, we saw two possible outcomes:\nwe either detected contradictory constraints, meaning that no formula rep-\nresented by the DAG is satisﬁable (e.g. Fig. 1.16); or we managed to force\nconsistent constraints on all nodes, in which case all formulas represented by\nthis DAG are satisﬁable with those constraints as a witness (e.g. Fig. 1.13).\nUnfortunately, there is a third possibility: all forced constraints are consis-\ntent with each other, but not all nodes are constrained! We already remarked\nthat this occurs for formulas of the form ¬(φ1 ∧φ2).\n1.6 SAT solvers\n73\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n1: T\n2: F\n3: T\n4: T\n4: T\n5: F\n6: T\n5: F\n7: T\n8: F\n9: T\n11: F\n10: T\n10: T\n7: T\nits conjunction parent\n– a contradiction\nand ∧frr force F\nits children and\n∧ti force T\nFigure 1.16. The forcing rules, applied to the DAG of Figure 1.15,\ndetect contradictory constraints at the indicated node – implying that\nthe initial constraint ‘1:T’ cannot be realized. Thus, formulas represented\nby this DAG are not satisfiable.\nRecall that checking validity of formulas in CNF is very easy. We already\nhinted at the fact that checking satisﬁability of formulas in CNF is hard. To\nillustrate, consider the formula\n((p ∨(q ∨r)) ∧((p ∨¬q) ∧((q ∨¬r) ∧((r ∨¬p) ∧(¬p ∨(¬q ∨¬r))))))\n(1.11)\nin CNF – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula\nshould not be satisﬁable. The ﬁrst and last clause in (1.11) ‘say’ that at least\none of p, q, and r are false and true (respectively). The remaining three\nclauses, in their conjunction, ‘say’ that p, q, and r all have the same truth\nvalue. This cannot be satisﬁable, and a good SAT solver should discover\nnow we are interested only in the mechanism in principle of the algorithm\nfor SAT; any (correct and eﬃcient) implementation of sets would do and\nwe study such an implementation in Chapter 6. We assume that SAT has\naccess to all the relevant parts of the model: S, →and L. In particular,\nwe ignore the fact that SAT would require a description of M as input as\nwell. We simply assume that SAT operates directly on any such given model.\nNote how SAT translates φ into an equivalent formula of the adequate set\nchosen.\n3.6 Model-checking algorithms\n227\nfunction SAT (φ)\n/* determines the set of states satisfying φ */\nbegin\ncase\nφ is ⊤: return S\nφ is ⊥: return ∅\nφ is atomic: return {s ∈S | φ ∈L(s)}\nφ is ¬φ1 : return S −SAT (φ1)\nφ is φ1 ∧φ2 : return SAT (φ1) ∩SAT (φ2)\nφ is φ1 ∨φ2 : return SAT (φ1) ∪SAT (φ2)\nφ is φ1 →φ2 : return SAT (¬φ1 ∨φ2)\nφ is AX φ1 : return SAT (¬EX ¬φ1)\nφ is EX φ1 : return SATEX(φ1)\nφ is A[φ1 U φ2] : return SAT(¬(E[¬φ2 U (¬φ1 ∧¬φ2)] ∨EG ¬φ2))\nφ is E[φ1 U φ2] : return SATEU(φ1, φ2)\nφ is EF φ1 : return SAT (E(⊤U φ1))\nφ is EG φ1 : return SAT(¬AF ¬φ1)\nφ is AF φ1 : return SATAF (φ1)\nφ is AG φ1 : return SAT (¬EF ¬φ1)\nend case\nend function\nFigure 3.28. The function SAT. It takes a CTL formula as input and\nreturns the set of states satisfying the formula. It calls the functions\nSATEX, SATEU and SATAF, respectively, if EX , EU or AF is the root of the\ninput’s parse tree.\nThe algorithm is presented in Figure 3.28 and its subfunctions in Fig-\nures 3.29–3.31. They use program variables X, Y , V and W which are sets\nof states. The program for SAT handles the easy cases directly and passes\nmore complicated cases on to special procedures, which in turn might call\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\nto write a procedure SATAU. Can you use that routine to handle all calls of the\nform AF φ as well?\n7. Prove that [[A[φ1 U φ2]]] = [[φ2 ∨(φ1 ∧AX (A[φ1 U φ2]))]].\n8. Prove that [[AG φ]] = [[φ ∧AX (AG φ)]].\n9. Show that the repeat-statements in the code for SATEU and SATEG always termi-\nnate. Use this fact to reason informally that the main program SAT terminates\nfor all valid CTL formulas φ. Note that some subclauses, like the one for AU,\ncall SAT recursively and with a more complex formula. Why does this not aﬀect\ntermination?\n254\n3 Verification by model checking\n3.9 Bibliographic notes\nTemporal logic was invented by the philosopher A. Prior in the 1960s; his\nlogic was similar to what we now call LTL. The ﬁrst use of temporal logic for\nreasoning about concurrent programs was by A. Pnueli [Pnu81]. The logic\nCTL was invented by E. Clarke and E. A. Emerson (during the early 1980s);\nand CTL* was invented by E. A. Emerson and J. Halpern (in 1986) to unify\nCTL and LTL.\nCTL model checking was invented by E. Clarke and E. A. Emerson [CE81]\nand by J. Quielle and J. Sifakis [QS81]. The technique we described for LTL\nmodel checking was invented by M. Vardi and P. Wolper [VW84]. Surveys\nof some of these ideas can be found in [CGL93] and [CGP99]. The theorem\nabout adequate sets of CTL connectives is proved in [Mar01].\nThe original SMV system was written by K. McMillan [McM93] and is\navailable with source code from Carnegie Mellon University6. NuSMV7 is a\nreimplementation, developed in Trento by A. Cimatti, and M. Roveri and is\naimed at being customisable and extensible. Extensive documentation about\nNuSMV can be found at that site. NuSMV supports essentially the same\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely We conclude this case study by pointing out limitations of Alloy and its\nanalyzer. In order to be able to use a SAT solver for propositional logic\nas an analysis engine, we can only check or run formulas of existential or\nuniversal second-order logic in the bodies of assertions or in the bodies of\nfun-statements (if they are wrapped in existential quantiﬁers for all param-\neters). For example, we cannot even check whether there is an instance of\nAddComponent such that for the resulting PDS a certain scheduling policy is\nimpossible. For less explicit reasons it also seems unlikely that we can check\nin Alloy that every coherent set of components is realizable as P.components\nfor some PDS P. This deﬁciency is due to the inherent complexity of such\nproblems and theorem provers may have to be used if such properties need\nto be guaranteed. On the other hand, the expressiveness of Alloy allows for\nthe rapid prototyping of models and the exploration of simulations and pos-\nsible counterexamples which should enhance once understanding of a design\nand so improve that design’s reliability.\n2.8 Exercises\n157\n2.8 Exercises\nExercises 2.1\n1.\n*\nUse the predicates\nA(x, y) :\nx admires y\nB(x, y) :\nx attended y\nP(x) :\nx is a professor\nS(x) :\nx is a student\nL(x) :\nx is a lecture\nand the nullary function symbol (constant)\nm :\nMary\nto translate the following into predicate logic:\n(a) Mary admires every professor.\n(The answer is not ∀x A(m, P(x)).)\n(b) Some professor admires Mary.\n(c) Mary admires herself.\n(d) No student attended every lecture.\n(e) No lecture was attended by every student.\n(f) No lecture was attended by any student.\n2. Use the predicate speciﬁcations\nB(x, y) :\nx beats y\nF(x) :\nx is an (American) football team\nQ(x, y) :\nx is quarterback of y\nL(x, y) :\nx loses to y\nand the constant symbols\nc :\nWildcats\nj :\nJayhawks\nto translate the following into predicate logic.\n(a) Every football team has a quarterback.\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\ntions compute a pre-image of a set of states. The function pre∃(instrumental\nin SATEX and SATEU) takes a subset Y of states and returns the set of states\nwhich can make a transition into Y . The function pre∀, used in SATAF, takes\n228\n3 Verification by model checking\nfunction SATEX (φ)\n/* determines the set of states satisfying EX φ */\nlocal var X, Y\nbegin\nX := SAT (φ);\nY := pre∃(X);\nreturn Y\nend\nFigure 3.29. The function SATEX. It computes the states satisfying φ by\ncalling SAT. Then, it looks backwards along →to find the states satisfying\nEX φ.\nfunction SATAF (φ)\n/* determines the set of states satisfying AF φ */\nlocal var X, Y\nbegin\nX := S;\nY := SAT (φ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪pre∀(Y )\nend\nreturn Y\nend\nFigure 3.30. The function SATAF. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying AF φ in the manner\ndescribed in the labelling algorithm.\na set Y and returns the set of states which make transitions only into Y .\nObserve that pre∀can be expressed in terms of complementation and pre∃,\nas follows:\npre∀(Y ) = S −pre∃(S −Y )\n(3.8)\nwhere we write S −Y for the set of all s ∈S which are not in Y .\nThe correctness of this pseudocode and the model checking algorithm is\ndiscussed in Section 3.7.\n3.6 Model-checking algorithms\n229\nfunction SATEU (φ, ψ)\n/* determines the set of states satisfying E[φ U ψ] */\nlocal var W, X, Y\nbegin\nW := SAT (φ);\nX := S;\nY := SAT (ψ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪(W ∩pre∃(Y ))\nend\nreturn Y\nend\nFigure 3.31. The function SATEU. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying E[φ U ψ] in the manner\ndescribed in the labelling algorithm.\n57\nDeﬁnition 1.44 Given a formula φ in propositional logic, we say that φ is\nsatisﬁable if it has a valuation in which is evaluates to T.\nFor example, the formula p ∨q →p is satisﬁable since it computes T if we\nassign T to p. Clearly, p ∨q →p is not valid. Thus, satisﬁability is a weaker\nconcept since every valid formula is by deﬁnition also satisﬁable but not vice\nversa. However, these two notions are just mirror images of each other, the\nmirror being negation.\nProposition 1.45 Let φ be a formula of propositional logic. Then φ is sat-\nisﬁable iﬀ¬φ is not valid.\nProof: First, assume that φ is satisﬁable. By deﬁnition, there exists a\nvaluation of φ in which φ evaluates to T; but that means that ¬φ evaluates\nto F for that same valuation. Thus, ¬φ cannot be valid.\nSecond, assume that ¬φ is not valid. Then there must be a valuation\nof ¬φ in which ¬φ evaluates to F. Thus, φ evaluates to T and is there-\nfore satisﬁable. (Note that the valuations of φ are exactly the valuations of\n¬φ.)\n2\nThis result is extremely useful since it essentially says that we need provide\na decision procedure for only one of these concepts. For example, let’s say\nthat we have a procedure P for deciding whether any φ is valid. We obtain a\ndecision procedure for satisﬁability simply by asking P whether ¬φ is valid.\nIf it is, φ is not satisﬁable; otherwise φ is satisﬁable. Similarly, we may\ntransform any decision procedure for satisﬁability into one for validity. We\nwill encounter both kinds of procedures in this text.\nThere is one scenario in which computing an equivalent formula in CNF\nis really easy; namely, when someone else has already done the work of\nwriting down a full truth table for φ. For example, take the truth table\nof (p →¬q) →(q ∨¬p) in Figure 1.8 (page 40). For each line where (p →\n¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. Since\nthere is only one such line, we have only one conjunct ψ1. That conjunct\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\ncode in Figure 3.28, we see that most of these clauses just do the obvious\nand correct thing according to the semantics of CTL. For example, try out\nwhat SAT does when you call it with φ1 →φ2.\nOur aim in this section is to prove the termination and correctness\nof SATAF and SATEU. In fact, we will also write a procedure SATEG and\nprove its termination and correctness1. The procedure SATEG is given in\nFigure 3.37 and is based on the intuitions given in Section 3.6.1: note how\ndeleting the label if none of the successor states is labelled is coded as\nintersecting the labelled set with the set of states which have a labelled\nsuccessor.\nThe semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-\nputation path s0 →s1 →s2 →. . . such that si ⊨φ holds for all i ≥0. We\ncould instead express it as follows: EG φ holds if φ holds and EG φ holds\nin one of the successor states to the current state. This suggests the equiv-\nalence EG φ ≡φ ∧EX EG φ which can easily be proved from the semantic\ndeﬁnitions of the connectives.\nObserving that [[EX ψ]] = pre∃([[ψ]]) we see that the equivalence above\ncan be written as [[EG φ]] = [[φ]] ∩pre∃([[EG φ]]). This does not look like a\nvery promising way of calculating EG φ, because we need to know EG φ in\norder to work out the right-hand side. Fortunately, there is a way around\nthis apparent circularity, known as computing ﬁxed points, and that is the\nsubject of this section.\n1 Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted in Section 3.6.1\nthat EG could be handled directly.\n240\n3 Verification by model checking\nfunction SATEG (φ)\n/* determines the set of states satisfying EG φ */\nlocal var X, Y\nbegin\nY := SAT (φ);\nX := ∅;\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∩pre∃(Y )\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver",
            "summary": "Linear-time temporal logic, or LTL, is a temporal logic with con-nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of these paths might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or p1, p2) Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. X means ‘neXt state,’ F means. ‘someFuture state’ and G means � ‘all future states (Globally).’ The next three, U,R and W are called ‘Until,  ‘Release  and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. The example formula above can                be written ¬p W q, or equivalently ¬(¬q U (p ∧¬Q) if one wants to avoid W. It is possible to write G (q →O p) without using past operators. The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long and the formula we are interested in checking is quite long. The formula is the basic model-checking question. For more information, visit the LTL website or the CTL website. The CTL version of this article has been updated to include the new model- checking algorithm. For the full version, see the LTCL website. CTL is generally preferred by speciﬁers, as already noted. It is therefore well worth trying to ﬁnd eﬃcient algorithms. We start with CTL model checking because its algorithm is simpler. R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. The unary connectives (consisting of ¬ and the temporal connectives X, F and G) bind most tightly. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. We assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The parse tree of F p →G r is illustrated in Figure 3.2. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities. Others, however, are required to resolve ambiguisms. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would become: F p →G r ∨¬q U p, corresponding to the parse tree of Figure 3. 2. The following are not well-formed formulas: U r – since U is binary, not unary – and p G q – since G is unary, not binary. A subformula of an LTL formula φ is any formula ψ whose parse tree is a subtree of φ’s parse tree. A model as a whole satisﬁes an LTL formula. The formulas G p →p, p →q U p and p →F p are true in every state of every model. We will examine algorithms which implement this calcula-tion later in this chapter. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later in the chapter, we will examine an algorithm which implements this pro-                             cedure. We conclude with the conclusion that the future shall include the present and that the formula G p is true in all states of the system. Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. The kinds of systems we are interested in verifying using LTL may be modelled as transition systems. A transition system models a system by means of states (static structure) and transitions (dynamic structure) The following are not well-formed formulas: U r – since U is binary, not unary. p G q – since G is unary, not binary. p W (q U r), e.g., are p, q, r, q U r and p W   (q  U r) 3.2.2 Semantics of LTL: Verification by model checking. 3.3.2 Verification of the LTL model: Verifying the model by model check. A model has a collection of states S, a relation →, saying how the system can move from state to state. With each state s, one has the set ofatomic propositions L(s) which are true at that particular state. We write                P(Atoms) for the power set of Atoms, aCollection of atomic descriptions. For example, the powerSet of {p, q} is {∅, {p}, {q}, { p, q}}. We may conveniently express all the information about a (ﬁnite) tran- tumultuous system M using directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. For example, if our system has only three states s0, s1 and s2, we check G F φ →ψ. This means: all paths satisfying inﬃnitely often φ also satisfy ψ. It is not possible to express this emphaticallyin CTL. The LTL model-checking algorithm is based on the CTL algorithm for model checking. For more information on the LTL algorithm, see LTL Algorithm. LTL model checking has to adopt a diﬀerent                strategy. We explain that strategy ﬁrst; then, we describe some algo-                rithms in more detail. The basic strategy is: Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along paths of M starting at s. Almost all LTL model Checking algorithms proceed along the following three steps:Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton The program has four states, each one corresponding to a possible value of the two binary variables. The program therefore denotes the transition system shown in Figure 3.9. If request is false, the next value of status is not deter-                mined. If several expressions to the left of a ‘:’ aretrue, then the command corresponding to the ﬁrst, top-most true expression will be executed. The construction has theproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other words, the automaton A ω encodes precisely the traces which satisfy ψ: ω: � It takes a while to get used to the syntax of SMV and its meaning. Sincevariable request functions as a genuine environment in this model, the program and the transition system are non-deterministic. For example, the state ‘¬req, busy’ has four states it can move to (itself and three others). LTL speciﬁcations are introduced by the keyword LTLSPEC and are sim-reprehensible LTL formulas. Notice that SMV uses &, |, -> and ! for  and  respectively, since they are available on standard keyboards. We may also use &, →, → and ! as well for the LTL specifiers. SMV supports breaking a system description into sev-                eral modules, to aid readability and to verify interaction properties. A mod-                ule is instantiated when a variable having that module name as its type is perfect circles, or an experiment without friction. These abstractions are very powerful, for they allow us to focus on the essentials of our particular concern. We can easily verify that the speciﬁcation of our module main holds of the model in Figure 3.9.2.Figure 3. 9.2 is the model corresponding to the SMV program in the text. The model is called Linear-time temporal logic (LTL) Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form: p is any propositional atom from some set Atoms. In general, the future is not determined, so we consider several paths, representing diﬀerent possiblefutures, any one of which might be the ‘actual’ path that is realised. We work with a ﬁxed set of atomic formulas (such as p, q, r, . . . ). These atoms stand for atomic facts which may hold of a system, like ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended’ and ‘The content of register R1 The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms. The connectives X, F, G, U, R, and W are called temporal connectives. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of the LTL symbols. The parse tree of (F (p →G r)  is an LTL formula if φ is one, etc. The syntax of LTL is as follows: (F p) (G q) (U p) U p (R r) R p Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E.weak-until (W) and release (R) are not included in CTL, but they are derivable. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) in LTL. Any p is eventually followed by a q in both LTL and CTL. We just saw that some (but not all) LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For more information on CTL and LTL click here. In fact, AF AG p is strictly stronger than F G p. While the LTL formulas X F p and F X p are equivalent, they are not equivalent to AF AX p. CTL* is more expressive than either of them, but is computationally more expensive. The choice between LTL and CTL depends on the application at hand, and on personal prefer-iness. LTL lacks CTL’s ability to quantify over paths, and C TL lacks LTL”s ability. to describe individual paths. We have seen that they have incomparable expressivepowers. We discuss two more negative examples: F G and AF AG. The latter has quite a strange meaning (try working it out). LTL can be viewed as a subset of CTL*. CTL* is a fragment of LTL* in which we restrict the form of path formulas. LTL formula α is equivalent to the C TL* formula α[A] Figure 3.23 shows the relationship among the expressive powers of C TL, LTL, and CTL*, as well as some examples of formulas in each of the subsets. The expressive power of the two subsets is shown in the figure 3.5. The relationship between CTL and LTL is also shown inFigure 3.3. The expression LTL-CTL is the same as the expression CTL-CTL*. The difference between the two is that LTL The proof that AG EF p is not expressible in LTL is as follows. Let M′ be as shown in the right-hand diagram. The paths from s into M′ are a subset of those from s in M. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. The proof is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given in the references. The expressive powers of CTL, LTL and CTL*.shown:                In CTL but not in L TL: ψ1def= AG EF. p. This expresses: wherever we                have got to, we can always get In LTL but not in CTL: ψ3apologetic= A[G F p →F q], saying that if there are in-                ﬁnitely many p along the path, then there is an occurrence of q. (Why is it not expressible in LTL?) For any state there is inevitably a future state in which the current message has got through. In LTL and CTL, G (p →Fq) is the same as G F st in the main module, or G F S.st in the module sender. We just saw that some (but not all) LTL formulas can be written in a similar way to CTL. In our analysis of LTL (linear-time temporal logic) in the preceding sections, we noted that LTL formulas are evaluated on paths. A state of a system satisﬁes an LTL formula if all paths from the given state satisfy it. We used this approach when analysing the ferrymancompetitivepuzzle in the previous section. In the module grotesquereceiver, we write G F st=received. We then check whether all pathsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-                tion, and vice versa. We conclude that theorem LTL can only be expressed in terms of paths. Branching-time logics solve this problem by allowing us to quantify ex-plicitly over paths. We will examine a logic known as Computation TreeLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X, we also have quantiﬁers A and E which express ‘all paths’ and ‘exists a path’, respectively. For example, we can write: There is a reachable state satisfying q: this is written EF q. From all reachable states satisfying p, it is possible to maintain p continuously in which the future excludes the present. A consequence of adopting the convention that the future shall include the A model as a whole is an LTL formula. This is deﬁned to hold whenever every possible execution path of the model sits on the formula. Later in this chapter, we will examine algorithms which implement this calcula-                cyntion. We write M, s ⊨φ if, for every execution path π of M starting at the beginning of the formula, we have π ⋅. If M is clear from the context, we may abbreviate M,  by s ⋉. We have outlined the formal foundations of a pro-                cure that can check whether Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. NuSMV supports past operators in LTL. One could also add past opera-tors to CTL (AY, ES, etc.) but NuSMV does not support them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. However, recall that LTL equivalence is quite crude: it says that the two formulas are satisﬁed by exactly the same set of paths. The past operators allow us to travel backwards along the path, but only to reach points we could have reached by travelling forwards from its beginning. The example formula above can be written ¬p W q, or equival The semantic deﬁnitions for LTL and CTL are presented in Sections 3.2 and 3.4. We start with CTL model checking because its algorithm is simpler. In general, inter-esting transition systems will have a huge number of states. Verification by model checking can take a long time, so it is well worth trying to develop an eﬃcient algorithm. We conclude by looking at the results of our model-checking algorithm for CTL and LTL. The results are published in the book CTL: A Model-checking Algorithm for Inter-esting Transition Systems, published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. This is only so if interpreted on paths (π ⊨φ). However For any state, if a request (of some resource) occurs, then it will eventually be acknowledged. A certain process is enabled inﬁnitely often on every computation path. Whatever happens, a certain process will eventually become permanently deadlocked. An upwards travelling lift at the second ﬂoor does not change its direction when passengers wish to go to the ﬁfth. The atomic descriptions are boolean expressions built from system vari-ables, e.g., floor2. There are some things which are not possible to say in LTL, however. For example, we cannot assert such a                possibility if interpreted on states (s ⊨φ) since we cannot express the existence of paths LTL can’t express these because it cannot directly assert the existence of Paths. In Section 3.4, we look at Computation Tree Logic (CTL) which hasoperators for quantifying over paths, and can express these properties. We say that two LTL formulas φ and ψ are semanticallyequivalent, or simply equivalent, writing φ  i u p u in CTL. We also say that for all models M and all Paths π in M: π ⊨φ iﬀπ ≉ resolve important issues. In section 3.2.4 we show that the equivalences between LTL and CTL formulas are The logical structure of the formal speciﬁcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. Debugging big systems during the testing phase is costly and time Properly speciﬁed software is easier to reuse, since it has a clear speci ﬁcation of what it is meant to do. Safety-critical computer systems – such as the control of cooling systems in nuclear power stations, or cockpits of modern aircrafts – demand that their software be speci credible. Other programs may be commercially critical, such as ac countancy software used by banks, and they should be delivered with a warranty: a guarantee for correct performance within proper use. Ex-perience has shown that verifying programs with respect to formal specians can cut down the duration of software development and maintenance. The degree to which the software industry accepts the beneﬁts of proper Verification depends on the perceived extra cost of producing it. Microsoft’s emergent technology. # combines program veri ﬁcation, testing, and model-checking techniques. As we will see, there are often good heuristics to help the programmer complete these tasks. This contrasts with the.situation of the last chapter, which was fully automatic. The importance of Verification to industry will.continue to increase over the next decades. The proof that a program.meets its speciﬅcations is indeed such a warranty. The domain of application in this chapter is se-quential transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems that are not intended to terminate and that react continually with their environment.Pre/post-development. Pre- and post-development of programs. Pre/post development of programs that are intended to run on a single processor and that have no concur-rency issues. Pre and post development of a program that is intended The techniques of this chapter should be used.during the coding process for small fragments of program that perform. an identiﬁable task. The techniques should also be used during the development process in order to avoid functional bugs. 4.1 Why should we specify and verify code? The task of specifying and verifying code is often perceived as an unwel-                come addition to the programmer’s job and a dispensable one. The logical structure of the formal speciﬃcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The process of documenting a program may raise or alleviate important issues. A framework for producing the software could be: Convert the informal description R of requirements for an application domain into an ‘equivalent’ formula φR of some symbolic logic. Write a program P which is meant to realise that formula. Prove that the program P satisﬁes the formula. This scheme is quite crude – for example, constraints may be actual design decisions for interfaces and data types, or the speci ﬁcation may ‘evolve’4.2 A framework for software verification may partly be ‘unknown’ in big projects – but it serves well as a approximation to good programming methodology. For example, as a programmer, might have been given only the The meaning of R as a piece of natural language is grounded in common sense. The attempt at formalising R can uncoverambiguities or undesired consequences and hence lead to revisions of R. It is impossible to ‘verify’ whether an infor-cular requirement R is equivalent to a formal description φR. The meaningof R is based on heuristics or quantitative reasoning and often based on real-world knowledge about the domain. The ‘going back and forth’ between the realms of informal and formalspeciﬁcations Microsoft’s emergent technology seamlessly combines program veriﬁcation, testing, and model-checking techniques in an integrated in-house development environment. Software systems now often have a longer life-expectancy than humans, which necessitates a durable, transparent and                portable design and implementation process. The meaning of a logic formula φR, on the other hand, is de ﬁned in a precise mathematical, qualitative and compositional way. As society depends on it more and more, the beneﬃts are becoming more important. We can expect that the importance of veri-cation to industry will continue to increase over the next decades. Software veriﬁcation provides some of this framework for software verification. It is a way of condensing the requirements of such a project into formal speci ﬁcations. These formalspeciﬀcations are usually symbolic encodings of real-world constraints into some sort of logic. For example, it could be the devel-                opment and maintenance of a database of electricity accounts with all the possible applications of that – automated billing, customer service etc. It could also be the creation of an online bank account database. For more information on software verification, see the Software Verification Handbook. The book, published by Oxford University Press, is available in English and French. Convert the informal description R of requirements for an application domain into a logical formula R. R is grounded in common sense and gen-                eral knowledge about the real-world domain. The meaning of a logic formula φR is deﬁned in a precise mathematical, qualitative and compositional way by structural induction on the parse tree of R. To make matters worse, the requirements R are often inconsistent; customers usually have a fairly vagueception of what exactly a program should do for them. Thus, a framework for producing the software could be: Convert R into a formalisation of the formalisation R of the application domain R as a piece of natural language. The process of formalising R requires the utmost care. Producing a clear and coherent description R of the requirements for an application do-                main is already a crucial step in successful programming. We address this ﬁrst item only implicitly in this text, but you should certainly be aware of its importance in practice. The programming language which we set out to study here is the typicalcore language of most imperative programming languages. The next phase of the software development framework involves construct-                ing the program P and after that the last task is to verify that P satisﬁes φR. The correspondence between proving and program-                ming can be stated quite precisely, but that is beyond the scope of this book. The book includes a core programming language for imperative languages Program verification is a subset of Pascal, C, C++ and Java. Our lan-guage consists of assignments to integer- and boolean-valued variables. If-and refer to a method’s object. Upon validation, this contract.establishes that all calls to withdraw leave (the ‘object. invariant’) 0 <= 0 <= balance invariant 4.7 Bibliographic notes. Backhouse’S book [Bac86] describes program logic and weakest precondi-tions and also contains numerous examples and exercises. Other books [AO91, Fra92] extend the basic core language to in-clude features such as procedures and parallelism. In propositional or predicate logic, formulas are either true, or false, in any model. Propositional logic and predicate logic do not allow for any further possibilities. The issue of writing to.                arrays and the problem of array cell. aliasing are described in [Fra92]. The. article describing the minimal-sum section problem is [Gri82]. A text on functional programming on the freely available. Standard ML of New Jersey is [Pau91].8 www.opensource.org                9 www.sims.berkeley.edu/~pam/papers.html676.5. Modal logics and agents                5.1 Modes of truth The tool was developed by D. Jackson at the Massachusetts Institute of Technology. The tool has a dedicated repository website at                alloy.mit.edu. More information on typed higher-order logics and their use in the.modelling and verifying of programming frameworks can be found on F.Pfenning’s course homepage7 on Computation and. Deduction. The book, The Typed Higher-order Logics of Programming, is published by Oxford University Press, priced £16.99, is available in hard copy and soft copy for £12.99. Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The veriﬁcation method consists of trying to prove that a formula is a formula. This typically requires guidance and expertise from the user. We will model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to see if prerequisites in the form of libraries or other packages are present. The formal models attached to software products can be seen as aiability contract; a promise that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬁed therein. We will use a formula that captures formally static and dynamic system structure and behaviour. This formula can be used to verify consistency of the constrained design space and to test the correctness of claims about static andynamic aspects of all its compliant implementations. It can also boost our conﬀdence into the Software package dependency systems are used in several computer systems. Users often have to guess how technical questions get resolved within the system. To the best of our knowledge, there is no publicly available model of any particular dependency system to which application programmers could turn if they had non-trivial technicalquestions about its inner workings. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things, such as a database or a file system, for example. The requirements on a software package dependency system are not straightfor-                ward. The upgrading process can go wrong in various ways. For example, upgrading a package can involve replacing older versions of shared Some LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) We discuss two more negative examples: F G p and AF AG p are not equivalent. The latter is strictly stronger, and has quite a strange meaning (try working it out). There is a considerable literature comparing linear-time and branching-time logics. For more information, see the book ‘LTL and Branching Time Logics’, published by Oxford University Press, priced £16.99, £19.99. CTL* is more expressive than either of them, but is computationallymuch more expensive. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL's ability to describe individual paths. To many people, LTL ap- grotesquepears to be more straightforward to use; as noted above, CTL formulas likeAF AX p seem hard to understand. CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn’t allow nest-inducing of path modalities X, F and G. The choice between CTL and LTL depends on the application at hand, and on personal prefer-                ence. There is some redundancy among the CTL connectives. For example, the connective AX can be written ¬EX ¬; and AG, AF, EG and EF can't be written in terms of AU and EU. The equivalences between CTL and LTL are similar to the corresponding equivalences in LTL. In LTL, the equivalences for CTL are: AF φ ≡A[⊤U φ] EG φ  equivalent to EF φ equivalence of AG (3.4.6) and E[ ⊥U � Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX, AF, AU, EG, EU, and EX. Theorem is proved in a paper referenced in the bibliographic notes at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it is valid in the logic CTL* introduced in the next section. For example, we have the equivalence: A[φ U ψ] ≡¬(E[¬ φ U (¬φ ∧¬hy),  “EG” U ( The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in CTL. The temporal connectives AR, ER, AW and EW are all deﬁnable in the same way as the connectives EU, W, ER and EW. The equivalences are justiﬃed by LTL equivalences in Sections 3.2.4 and 3.5.    Theorem: The connectives E, W and W are all justi ﬁrable in a similar way to the connective E, R and W in theorems such as those in the theory of relativity. For example, the intuition for the third one is the following: in order to have AF φ in a particular state, φ must be true at some point along each path                from that state. Notice how this equivalence appears to deﬁne AF in terms of AX and AF itself, an apparently circular de nition. In fact, these equivalences can be used to de ﬁnition the six connectives on the left in a non-circular way, in a way that is not circular at all. For example, in the equivalence between AF and AX, we can say that AF is true now, but not in the future. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. NuSMV supports past operators in LTL, but not CTL. Past operators do not increase the expres-                sive power of LTL. Every LTL formula with past operators can be written equivalently without them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. For example, the formula AF p →AF q means2182182183 Verification by model checking                something quite diﬀerent: it says ‘if all paths have a p along them, then                allpaths have a q along them’ One could also add past opera-                tors to CTL The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long and the formula we are interested in checking is quite long. The formula is the basic model-checking question. For more information, visit the LTL website or the CTL website. The CTL version of this article has been updated to include the new model- checking algorithm. For the full version, see the LTCL website. CTL is generally preferred by speciﬁers, but we start with CTL model checking because its algorithm is simpler. We say that two LTL formulas φ and ψ are semanticallyequivalent, or simply equivalent, writing φ  i ⊨φ iﬀ ω. If φ is a subformula of some bigger formula χ, we can make the substitution of ψ for φ in χ without changing the meaning of χ. We can express these properties in a model checker for quantifying over paths, and can express the equivalence between LTL and CTL in 3.6.2. Pushing a negation downwards in the parse tree past one of them also has the eﬀect of duplicating that negation. ‘Morally’ there ought to be a dualfor W, and you can invent one if you like. However, it might not be very useful. We should give formal proofs of these equivalences. But they are easy, so we purposefullyleave them as an exercise to the reader. We see that F and G are duals of each other, and X is dual with itself. We also show that F distributes over  and G over  , i.e., F   over  and G over ’’. There are two more equivalences in LTL: F φ and G φ. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. The parse tree of this formula is illustrated in Figure 3.1. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities, for example, p could be written p →F q without ambiguity. The formula for Until can be written P W (q W r) with the same syntax as for Until (p W) (q Q r) (P W r (q q) (Q Q r The unary connectives (consisting of ¬ and the temporalconnectives X, F and G) bind most tightly. Next in the order come U, R and W; then come �; and after that comes →. These binding priorities allow us to drop some brackets without introducing ambiguity. Others, however, are required to resolve ambiguities. In order to omit some of those, we assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would becomeF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.3. A subformula of an LTL formula φ is any formula ψ whoseaple tree is a subtree of φ’s parse tree. Therefore, the LTL. formula α is equivalent to the CTL* formula α[α].  The following are not well-formed formulas:. U r – since U is binary, not unary Figure 3.23 shows the relationship among the expressive powers of CTL, LTL, CTL* and CTL*. Here are some examples of formulas in each of the subsets. The proof that AG EF p is not expressible in LTL is as follows. Let φ be an LTL formula such that A[φ] is allegedly equivalent to AG EF. p. In CTL but not in L TL: ψ1defreprehensive=AG EF p. This expresses: wherever we have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof that this is not expressible in CTL is quite complex and may. be found in the papers co-authored by E. A. Emerson with others. In CTL and LTL, any p is eventually followed by a q. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. This is an interesting thing to be able to say; for example, many fairness.constraints are of the form ‘inﬁnitely often requested implies eventually.acknowledged’. (Why is it not expressable in LTL?) The problem is that some (but not all) LTL formulas can be transformed into CTL formulas. Unwinding the system of Figure 3.3 as an infinite tree of all computation paths beginning in a particular state gives an inﬁnite computation tree. We write                πi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .. Verification by model checking is achieved by checking the transition system for all possible computation paths from a given state. For example, if we unwind the state graph of Figure.3 for the designatedstarting state s0, then we get the in-nite tree in Figure. 3.5. Let M = (S, →, L) be a model and π = s Whether π satisﬁes an LTL formula is deﬀned by the satisfaction.relation ⊨as follows. The satisfactionrelation is the product of p and q. Only the states s3 to s9 each satisfy p U q along the path shown. Figure 3.6. An illustration of the meaning of Until in the semantics of the LTL. The formula p is satisfied at (and only at) s3, s4, s5, s6, s7, s8 and q isatisfied at s9. The satisfying state of p is p U U q. The satisfied state of q is q U U Q. For all k ≥1 we have πk ⊨ψ. There is some redundancy among the CTL connectives. AU, EU and EX form an adequate set of temporal connectives, and EG, EU, and EX are also adequate. Theorem 3.10 is proven by elementary manipu-rophiclation. The remainder is proved by Theorem. 3.4. Adequate sets of C TL connectives are proved by the equivalence of the connective AX to the connectives AG, AF, EG and EF. For example, write AG φ as ¬EF ¬φ, using (3.6), and then useAF φ ≡A[⊤U � Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX,EG, AF, AU } and EU. The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in C TL. The temporal connective AR, ER, AW and EW are all deﬁnable in the logic CTL* and the expressive powers of LTL and CTL. Theorem is proved in a paper referenced in the bibliographic notes referenced at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it Inspection of clauses 12 and 13 reveals that R and W are rather similar. W is like U but also allows the possibility of the eventuality never occurring. Small adequate sets of connectives also exist in LTL. As in propositional logic, there is some redundancy among the connectives. For example, in Chapter 1 we sawthat the set {⊥,  ¬, ¬} forms an adequate set of connective, since the other three connectives can be written in terms of those three. In LTL we see that the set  “”, “ ” and ”” can also be written as such. Sometimes it is useful to look at adequate sets of connectives which do not rely on the availability of negation. Here is a summary of the situation. Each of the sets {U, X,. {R, X}, {W, X} is adequate. X is completely orthogonal to the other connectives. Its presence doesn’t help in deﬁning any of the other ones in terms of each other. Moreover, X cannot be derived from any combination of the others. We note that R and W may be de�ì�ned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and equivalence (3 If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective of φ (i.e., the connective occurring top-most in the tree of χ) is a boolean connective, then the satisfactionquestion is answered by the usual truth-table deﬁnition and further recursion down φ. The result of removing A or E is not strictly an LTLformula, for it may contain further As or Es below.  The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. The parse tree of this formula is illustrated inFigure 3.1. The formulas are illustrated in Figure 3.2 and 3.3. The syntax of the formulas is shown in Figure 4.1 and 4.2. It is easy to see that the formulas are written with brackets. The brackets can be omitted without introducing ambiguities, but some are required to resolve them. For example, p could be written p →F q without ambiguity. We assume similar binding priorities for the LTL connectives to those we assumed forpropositional and predicate logic. The unary connectives (consisting of ¬ and the temporalconnectives X, F and G) bind most tightly. These binding priorities allow us to drop some brackets without introduc-ing ambiguity. In order to omit some of those, we assume binding pri-orities of Convention 3.2.3. The parse tree of F p →G r ∨¬q U p, assuming binding The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would becomeF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.3. An adequate set of connectives for propositional logic is a set such that for every                formula of propositional. logic there is an equivalent formula with only connectivesfrom that set. The examples above can be written:. F p ∧G q →p W r                r F (p →.G r) (q W r)                r G Prove that the set {¬,  ,   is adequate for propositional logic. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that, with respect to the relation  “Idempotent”, the terms  “idempotents” and “ idempotence” are idempotsent. Prove that a relation is symmetric if it holds for all φ and transitive if it’s symmetric for all ”“”. Proving the truth value of a formula  construct a formula in CNF based on each of the following truth tables:. Construct an adequate set as far as the propositional connectives are concerned;. AF , EU and EX form an adequateSet of temporal connectives;. Construct a formula based on the truth tables;. Use the de Morgan rules;. The formula is then written as follows: CNF 89.7 Exercises. CNF89.7.1 Exercise 1. Exercised 1.7exercises 2.2 Exercising 2.3 Exercis 3.4 Exercism 4.5 Exercisms 5.6 Exercisers 6.6Exercises 7. The model-checking algorithm is based on an arbitrary CTL formula φ. The algorithm labels states with subformulas of the form AF ψ1. It then repeats the process until no change is made in the states. The result is the set of states of M which satisfy the subformula of φ, or TRANSLATE ( φ) in terms of the connectives AF, EU, EX, ¬ and ⊥ using the equivalences given earlier in the chapter. For more details on the algorithm, see page 3.6 of the book, ‘Model-checking Algorithms’, published by Oxford University Press, priced £16.99. We determine by a case analysis which states to label with ψ. This step is illustrated in Figure 3.24. If ψ is. ⊥, then no states are labelled with ≥. Then label s with p if p ∈L(s). Then label any state with AF ψ1 if all successor states are. labelled withAF ω1, until there is no change. If s is already labelled with. ω, then label it with ¬ ω if s is not already labelled. with ω. If it is labelled with both ω and ω2, then it should be labelled with the latter. Then, if it is not labelled with either, it should 25. Label any state with EX ψ1 if one of its successors is labelled with ω1. 26. Find operators to replace the ?, to make the following equivalences: 26. Verification by model checking. 27. State explicitly the meaning of the temporal connectives AR etc., as deﬁned on page 217 of the book. 28. Find a model of one of the pair which is not a models of the other. 29. Find an equivalence between the two models, and a way to test whether they are models of each other. 30. Find the difference between two models that are not models of one another, and one of them that is. Pseudo-code for a function TRANSLATE which takes as input an arbitrary CTL formula φ and returns as output an equivalent formula. Prove the equivalences (3.6) on page 216. Express the following properties in CTL and LTL whenever possible: p is true for every second state along a path, q is never true after p, and r occurs at most twice. If neither is possible, try to express the property in the form CTL*: CTL: P, Q, R, r, p, q, r. Exercises 3.5 and 3.6 are shown in detail in the next section of the book. For more information, see the book’s 2. Explain in detail why the LTL and CTL formulas for the practical speciﬁcationpatterns of pages 183 and 215 capture the stated ‘informal’ properties expressed in plain English. 3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →                AF q)}. 4. Describe how the terms of the Ki and CG is de﬉ned in terms of EG. 5. Explain why the CTL and LTL formulas are more general than those for the modal logic KT45n, for which there is a single accessi-bility relation. Let M = (W, (Ri)i∈A, L) be a model for KT45n                338                5 Modal logics and agents. We say that y is G-reachable in k steps from x if there are some k such that it is. G- Reachable in K steps if there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. We prove that x ⊩Ki1Ki2 for any i1, i2, . .. . , ik ∈G and any w1, w2,. . . , wk+1 and y. The formula K holds for the connec- ‘New Symbolic Model Veriﬁer’ NuSMV is an Open Source product, is ac-tively supported and has a substantial user community. For details on how to obtain it, see the bibliographic notes at the end of the chapter. SMV takes as input a text describing a model and some speci-ca-cular logic formulas. It directly checks thevalidity of LTL (and also CTL) formulas on those models. It also provides a language for describing the models we have been drawing as diagrams. For more information on SMV, see http://www.nuSMV.org/. SMV programs consist of one or more modules. As in the programminglanguage C, or Java, one of the modules must be called main. Modules can declare variables and assign to them. Assignments usually give the initial value of a variable and its next value as an expression. This expression can be non-deterministic (denoted by several expressions in braces, or no assignment at all). Non-determinism isused to model the environment and for abstraction. Verification by model checking. The following input to SMV:. Request : boolean;status : {ready,busy; next: case; request : busy; request: busy; status: ready; next : case; requests: busy, Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction. It was also developed by K.K. and is called NuSMV. The program has two variables, request of type boolean and status of enumeration type {ready, busy}: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent values of variable request are not determined within this program; this conserva-                tively models that these values are determined by an external environment. The value of variable status is partially determined: initially, it is ready; and it becomes busy whenever it is not ready. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. Dillon. The model checker Spin, which is geared towards asynchronous systems and is based on the temporal logic LTL, can be found at the Spin website. Current research in model checking includes attempts to exploit ab There are many textbooks about veriﬁcation of reactive systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The Edinburgh Concurrency Workbench12 and the Concurity Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. An example of a customisable and extensible modular model checking framework for the veri ﬉cation of concurrent software is Bogor14. The code for FDR2, a model checker based on the process algebra CSP, NuSMV also supports bounded model checking, invoked by the command-line option -BMc. Bounded model checking looks for counterexamples in order of size, starting with countereXamples of length 1, then 2, etc., up to a given threshold (10 by default) Note that bounded model Checking is incomplete: failure to find a countere X does not mean that there is none of length up to the threshold. Later on, we use bounded modelchecking to prove the optimality of a scheduler. Figure 3.10 gives the SMV code for a mutual exclusion protocol. This codeconsumingconsists of two modules, main and prc.    The module main has the variable turn, which determines whose turn it is to enter the critical section if both are trying to enter. The module main also has two instantiations of prc. In each of theseinstantiations, st is the status of a process (saying whether it is in its critical section, or not, or trying) and other-st is thestatus of the other process. The value of st evolves in the way described in a previous section: when it is n, it may stay as n or move to t. When it is t, it will go straight to c, but if the other one is t it will check its turn before going to c. The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.2. Representing OBDDs.6.3 Representing states as OBDD subsets. 7. Theorems for the analysis of states and their subsets, and how to use them in a computer model. 8. The theory of state-based computing, and its application to the computer model of states, is discussed in more detail in the next section of the book. The book is published by Oxford University Press, London, and is available in paperback and hardback. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org. More information on typed higher-order logics and their use can be found on F.Pfenning’s course homepage7 on Computation and Deduction. The tool has a dedicated repository website at grotesquealloy.mit.edu. There is a great advantage in being able to verify the correctness of computer systems, whether they are hardware, software, or a combination. This is most obvious in the case of safety-critical systems, but also applies to those that are commercially critical, such as mass-produced chips, mission critical, etc. The methods have quite recently become usable by industry and there is a growing demand for professionals able to apply them. In this chapter and the next one, we examine two applications of logics to the question of verifying the correctness of computer systems, or programs. Formal veriﬁcation techniques can be thought of as comprising three parts: a framework for modelling systems, a description language of some sort, and a method to establish whether the description of a system is correct. We examine two approaches to this question: proof-based and model-based. We conclude with a discussion of the implications of these two approaches for computer systems and programs, and their potential to be tampered with in a variety of ways. Back to Mail Online home. Back To the page you came from.    The next chapter will be published on November The NuSMV model checker is again represented by a formula. The CTL model-checking algorithm is also called a \"CTL model checking with fairness\" The correctness of SATEG functions is called the \"SATEU model checking algorithm\" The author concludes that the theory of software veriﬁcation is a good basis for a modern programming language. He concludes that this theory can be used to develop new programming languages and tools. The author also argues that the CTL language is a useful tool for developing new software languages and applications. The book is published by Oxford University Press, London, priced £16.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samar In Figure 3.34 and 3.36, we show how LTL model checking is implemented in NuSMV. To understand why this condition has the desired eﬀect, imagine the circumstances in which it is false. For example, suppose we want to eliminate a run with only ﬁnitely many states satisfying ¬(χi U ψi) ∨ψi. If we carry out this construction on a U b, we obtain the automaton shown in Figure 4.1 and 4.2. In Figure 5.1 we show an example of how this construction is applied to a formula with two U subformulas, p U q and p u q. The acceptance condition asserts that every run must pass infinitely often through the set {q1, q3, q4, q5, q6}. NuSMV checks whether there is a path of the resulting system which satisﬁes the acceptance condition of A¬φ. It is possible to implement the check for such a path in terms of CTLmodel checking, and this is in fact what Nu SMV does. The transitions with no arrows can be taken in either direc or direc-functional mode, depending on the state of the automaton. The automaton accepts precisely traces satisfying the condition that the system is in a state s of M. This chapter concerns a veriﬁcation method called model checking. It is intended to be used for concur-                rent, reactive systems and originated as a post-development methodology. The combined system is represented as the system to be model checked in NuSMV, and the formula to be checked is simply EG ⊤. The Alloy system described in Chapter 2 is also an automatic, model-                based, property-veri ﬃcation approach. The method can be used to find and fix bugs that are not covered by test cases, such as the FDIV error in Intel's Pentium chip. It can also help to find bugs that can't be fixed by testing, since they tend to be Model checking is based on temporal logic. It is intended to be used for programs which we expect to terminate and produce a result. The idea of temporal logic is that a formula is not statically true or false in a model, as it is in propo-                sitional and predicate logic. Verification by model checking is a proof-based, computer-assisted, property-veriﬁcation approach. It can produce counterexamples, consisting ofexecution traces. The way models are used is slightly different from the way Alloy is used. It focuses explicitly on temporal properties and the temporal evolution of systems. It also focuses on the use of models to test hypotheses made by the user. The models of temporal logic containseveral states and a formula can be true in some states and false in others. Run the NuSMV system on some examples. Try commenting out, or deleting, some of the fairness constraints, if applicable, and see the counter examples that Nu SMV generates. The one-bit channel is very easy to run and has two fairness constraints. In the one- bit channel, there are two fairness constraint.  In the two-bit channels, there is one fairness constraint and one fairness constraints for each channel. For example, in Section 3.6.1, the fairness constraint for channel 1 is that channel 2 is equal to channel 1. For channel 2, the fairness constraint is that Compute the ECG ⊤labels for Figure 3.11, given the fairness constraints of the SMV code. Explain the construction of formula φ4, used to express that the processes need not enter their critical section in strict sequence. Write an SMV program with a fairness constraint a & b which is not equivalent to the two fairnessconstraints a and b. Use these questions to help you understand the code and the rules in the book. The book is available in English, German, French, Spanish and Italian. For more information on the book, visit the publisher's website or read the book’s online version. For the full version of this article, see the Amazon.com site. In LTL, the functions P, H1, H2, H3 are monotone. Consider the functions: P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}) →H1(Y), H2(Y) and H3 (Y) H1(A) H2 (B) H3(C) H4 (D) H5 (E) H6 (F) H7 (H8) H8 (H9) H9 (H10) H10 (H11) H11 (H12) H12 (H13) H13 (H14) H14 (H15) H15 (H16 The presence of both universal and exis-tential quantiﬁers is the problem. The reason liveness failed is that non-determinism means it might continually favour one process over another. We can solve this by splitting s3 into two states. The two states s3 and s9 in Figure 3.8 both correspond to the state s3 in our ﬁrst modelling attempt. The problem is that the state does not distinguish between which of the processes  went into its trying state. The second modelling attempt is more successful and shows that s3 can be used to model mutual exclusion in a number of ways. The deﬁnition of the ABP sender is given in Figure 3.14. The variable message1 is the current bit of the message sent, whereas message2 is the control bit. The ABP sends the message in two stages, s3 and s9. In s3 it is im-plicitly recorded that it is process 1’s turn, whereas in s9 it is processes 2 and 3’turn. We can think of there being some other, hidden, variables which are not part of the initial labelling, which would separate s3 from s9 and vice versa. The de-forming of ABP systems does not preclude the existence of hidden variables. The variables message1 and message2 represent the actual data being sent and the control bit, respectively. On successful transmission, the module ob-                tains a new message to send and returns to st=sending. The new message1is obtained non-deterministically (i.e., from the environment) and the new message2 al-                cyternates in value. We impose FAIRNESS running, i.e. the sender must be selected to run inﬁnitely often. The module receiver is programmed in a similar way, in Figure 3.15. We also need to describe the two channels. The acknowl-                edgement channel is an instance of the one-bit channel one The ABP works as follows. There are four entities, or agents: the sender, the receiver, the message channel and the acknowledgement channel. The sender transmits the ﬁrst part of the message together with the ‘control’ bit 0. If, and when the receiver receives a message with the control bit 0, it sends 0 along the acknowledgement channels. The value of the ABP receiver in SMV.15.3 should be transmitted to output, unless forget is true. The two-bit line which can corrupt is called ‘forget’ and is used to check that a message is sent to the right place in the message stream. When the sender receives this acknowledgement, it sends the next packet with the control bit 1. When the receiver receives this, it acknowledges by sending a 1 on the acknowledgement channel. If the receiver doesn’t get a message with the expected control bit, it continually resends the pre-ishlyvious acknowledgement. By alternating the control bits, both receiver andsender can guard against duplicating messages and losing messages (i.e., they ignore messages that have the unexpected control bit). If the sender doesn't get the expected acknowledgement, It continually re- hypertlysends the message, until the acknowledgement arrives. In other words, the channel cannot lose an inﬁnite sequence of messages. We may assume that the text to be sent is divided up into single-bit messages, which are sent. If we did not make this assumption, then the channels could lose all messages. In that case, the ABP would not work. Let us see this in the concrete setting of SMV. The ABP sender in SMV is shown in Figure 3.14. It is running on the SMV version 2.3 of the language, which is called SMV 2.4.1. It runs on the version 3.2.1 of the software, which runs on a version Every A or E must have one of X, F, G and U to accompany it. U cannot occur without being preceded by an A or an E. Weak-until (W) and release (R) are not included in CTL, but they are derivable (see Section 3.4.5). We assume similar binding priorities for the CTL con-                nectives to what we did for propositional and predicate logic. Let us see some examples of well-formed CTL formulas and some examples                which are not well- formed, in order to understand the syntax. The unary                connectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF It is worth spending some time seeing how the syntax rules allow us toconstruct each of these. The following are well-formed CTLformulas: AG (q →EG r), EF (r U q) and EF G (r G r) The problem with this string is that U can occur only when paired with an A or an E. To make this into a well- formed CTL formula, we would have to write EF E[r Uq] or EF A[r R q] The formula for EF G r is not well-formatted because G can only be written with an F or an A, not with an E or a U. The formula is also not well formed because the E we Notice that we use square brackets after the A or E. When the pairedLTL we also have quantiﬁers A and E which express ‘all paths’ and Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. The symbols weak-until (W) and release (R) are not included in CTL, but they are derivable. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.   The CTL formula AG (p →AF) expresses in terms of the order of occurrence of events p, s and t. Explain what exactly exactly the CTL Formula AG ( p →AF (s ∧AX (AF t) does.   See Section 3.4.5 for more information on CTL. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any CTL model) Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment intosemantically equivalent formulas in that fragment and deﬁne f φ to be f ψ. Prove that the evaluation of φ depends only on the values ρ(xi) and that it does not matter what ρ assigns Exercises 6.16 and 6.17 are based on the CTL model M = (S, →, L) Given a model M, we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. The former deﬁnes fair in terms of f ECG for general φ. Why is this unproblem-phthalatic, i.e. non-circular? Exercises (6.16) and (7) consider the coding without consideration of simple fairness constraints. The last exercise is based on f E[x1∨¬x2Ux1]. All subformulas of f φ are formally monotone. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write it in an equivalent form in terms of the adequate set of connectives. Figure 3.24. The iteration step of the procedure for labelling states with subsections of the form AF ψ1. The model-checking algorithm would then repeat the iteration step until no change is made to the formula. The algorithm is called the model-checker algorithm and is described in more detail in the next section of the book. The book is published by Oxford University Press, London, in the US and in the UK by request of the author. The algorithm uses a CTL model M and a formula φ. It labels states of M with the subformulas of φ that are satisﬁed there, starting with the smallest subformula and working outwards. Here is the algorithm:INPUT: a model M = (S, →, L)OUTPUT: the set ofStates of M which satisfy φ, i.e., the output of TRANSLATE ( φ) The algorithm is based on the CTL algorithm. The LTL formula is equivalent to the CTL* formula. If ψ is ⊥, then no states are labelled with ≥. If p is p, then label s with p if p ∈L(s). If ω is ω, then the state is labelled with ω1 or ω2. This step is illustrated in Figure 3.24. The next step is to label all successor states with AF ψ1, until there is no change. The final step is called E[ψ1 U ψ2] and is the same as the previous step. It is the first step in the next section of the LTL algorithm. Figure 3.23 shows the relationship among the expressive powers of CTL, LTL, CTL* and CTL*. Here are some examples of formulas in each of the subsets. The proof that AG EF p is not expressible in LTL is as follows. Let φ be an LTL formula such that A[φ] is allegedly equivalent to AG EF. p. In CTL but not in L TL: ψ1defreprehensive=AG EF p. This expresses: wherever we have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof that this is not expressible in CTL is quite complex. It may be found in the papers co-authored by E. A. Emerson with others, given                in the references. (Why is it not expressable in LTL?) It is not the case that M′, s ⊨AG EF p; a contradiction. Yet, it is not a contradiction that there is a path with inﬁnitely many p along the path, then there is an occurrence of q. The algorithm SAT takes as input a CTL formula. The program SAT expects a parse tree of some LTL formula constructed by means of the grammar in Deﬁnition 3.12.18 We just saw that some (but not all) LTL formulas can be or must pass through such a state to reach a labelled state. This expectation reﬂects an important precondition on thecorrectness of the algorithm SAT. The pseudo-code of the CTL model-checking algorithm can be found at: http://www.satis.org/satis-algorithm/ctl-model-checking.html. The pseudo-code we write for SAT looks a bit like fragments of C orJava code. We use functions with a keyword return that indicates which result the function should return. We will also use natural language toindicate the case analysis over the root node of the parse tree of φ. For example, the program simply would not know what to do with an input of the form X (⊤∧EF p3), since this is not a CTL formula. We repeat until executes thecommand which follows it repeatedly, until the condition becomes true. The code is shown in the figure 3.27 section of the book. The book can be downloaded from: http://www.academia.edu/s We assume that SAT has access to all the relevant parts of the model: S, →and L. Ad-ditionally, we employ suggestive notation for the operations on sets, like intersection, set complement and so forth. In reality we would need an ab-                 abstract data type, together with implementations of these operations, but for now we are interested only in the mechanism in principle of the algorithm. A certain process is enabled inﬁnitely often on every computation path. Whatever happens, a certain process will eventually be permanently deadlocked. Processes need not enter their critical section in strict sequence. An upwards travelling lift at the second ﬂoor does not change its direction when passengers wish to go to the ﬁfth. The lift can remain idle on the third ﬀoor with its doors closed. A process can always request to enter its critical section. Using the propositions of Figure 3.8, this may be written as CTLAG (n1 →EX t1) in CTL. The atomic descriptions are boolean expressions built from system vari-ables, e.g., floor2 Two CTL formulas φ and ψ are said to be semanticallyequivalent if any state in any model which satisﬁes one of them also satis ﬁed the other. This was also not expressible in LTL, though we expressed its negation. CTL allows us to directly express it directly: EF (c1 ∧E[c1 U (¬c1  U c1) )   3.4.4 Important equivalences between CTL and LTL formulas. 3.5 Adequate sets of CTL connectives. 4. Verification by model checking. 5. An explanation of de Morgan rules. LTL can be viewed as a subset of CTL*. CTL* is the fragment in which we restrict the form of path formulas. LTL formula α is equivalent to the C TL* formula                A[α]. Figure 3.23 shows the relationship among the expressive powers of LTL, CTL, and CTL*, as well as CTL and LTL* The expressive powers are shown in terms of formulas in each of the three subsets. For example, in CTL but not in LTL: ψ1 defends= AG EF p. This expresses: wherever we get to, we can always get to a state in which p is true. This is also useful, e.g., in deadlocks In CTL*, but neither in CTL nor in LTL: ψ4defdef= E[G F p],                saying that there is a path with inﬁnitely many p. The paths from s in M′ are a subset of those in M, so we have M′, s ⊨A[φ]. Yet, it is not the case that M′,. s ⋅AG EF p; a contradiction. The proof that this is not expressible in C TL is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given given the references. (Why is it not expressable in L TL?) Theorem 6.19 is valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment into equivalent formulas in that fragment. Prove that the evaluation of f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to X or Z. Recall the way the two labelling algorithms operate in Chapter 3. Does oursymbolic coding mimic either or both of them, or neither? Exercises 6.16-16: Consider the equations in (6.22-6.27) and 6.27-7. Proving that f AF (¬x1-1) holds for the model in Figure 6.32( Given a CTL model M = (S, →, L), we saw how to code formulas f φ. The former deﬁnes fair in terms of f ECG for general φ, whereas the latter is unproblematic, i.e. non-circular. We now want to modify the model so that the resulting output is not a set, or an OBDD, but a formula                LTL. We also have quanti ﬁers A and E which express ‘all paths’ and ‘exists a path’, respectively. We show that the free variables of f. φ are among ˆx, and that all subformulas of Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. The symbols weak-until (W) and release (R) are not included in CTL, but they are derivable. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.   The CTL formula AG (p →AF) expresses in terms of the order of occurrence of events p, s and t. Explain what exactly exactly the CTL Formula AG ( p →AF (s ∧AX (AF t) does.   See Section 3.4.5 for more information on CTL. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any model) using de Morgan rules and the LTL equivalence. Here, our atomic descriptions are boolean expressions built from systemvari-ables, e.g., floor2. For example, a lift can remain idle on the third ﬂoor with its doors closed. A process can always request to enter its critical section. A certain process is enabled inﬁnitely often on Using the propositions of Figure 3.8, this may be written asAG (n1 →EX t1) in CTL. Processes need not enter their critical section in strict sequence. This was also not expressible in LTL, though we expressed its negation. Two CTL formulas φ and ψ are said to be semanticallyequivalent if any state in any model which satisﬁes one of them also satis ﬁed the other. We denote this by φ ≡ ψ. We have already noticed that A is a universal quanti-versal on paths and E is the corresponding existential quanti versal. In CTL, every A or E must have one of X, F, G and U to accompany it. The unary connectives AG, EG, AF, EF,AX and EX bind most tightly. Weak-until (W) and release (R) are not included in CTL. But they are derivable (see Section 3.4.5).Convention 3.13 We assume similar binding priorities for the CTL con-                nectives to what we did for propositional and predicate logic. Next in the order come  ‘’; and after that come ’’, ‘ ’ and ‘–’. Let us see some examples of well-formed CTL formulas and some examples which are not well- formed. Let us see how the syntax rules allow us toconstruct each of these. For example, take EF (r U q). The problem with this string is that U can occur only when paired with an A or an E. The E we have is                paired with the F. We can also see why we can’t use EF (p U r) or EF EG (p →AF r) to construct these. We will also see how we can use EF G (r G r) and EF E (r E r) in the next section of this article. CTL is a logic which combines the expressive powers of LTL and CTL, by dropping the CTL constraint that every temporal operator (X, U, F, G) has to be associated with a unique path. To make this into a well-formed CTL formula, we would have to write EF E[r U q] or EF A[ r U q]. The parse tree of a CTL Formula without infix notation can be seen in the figure 3.18 of the model checking section of this article. The model checking process can be carried out by using the following code: EUAX¬¬                 ‘EX’, ‘X,’ ‘G’ The syntax of CTL* involves two classes of formulas: state formulas, which are evaluated in states, and path formulas, evaluated along paths. It turns out that the ﬁrst of them can be written as a (rather long) CTL formula. It allows us to write formulas such as A[(p U r) ∨(q U r), where either p is true until r, or q istrue until r. These formulas are not equivalent to, respectively, A[ (p ∨q) U r, AX p, EG EF p and AX p. The second and third do not have a CTL formulas that are equivalent to them. LTL can be viewed as a subset of CTL*.CTL is also a subset. LTL does not include A and E, but the semantic viewpoint of LTL is that we consider all paths. Therefore, the LTL formula α is equivalent to the CTL* formula autoimmuneA[α]. This is an example of an inductive deﬁnition which is mutually recursive. The de�arynition of each class depends upon the de�aries of the other, with base cases p and ⊤. For example, we restrict the form of path formulas to (φ U φ) | (G φ), and then use the second one. For example, the intuition for the third one is the following: in order to have AF φ in a particular state, φ must be true at some point along each path                from that state. Notice how this equivalence appears to deﬁne AF in terms of AX and AF itself, an apparently circular de nition. In fact, these equivalences can be used to de ﬁnition the six connectives on the left in a non-circular way, in a way that is not circular at all. For example, in the equivalence between AF and AX, we can say that AF is true now, but not in the future. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. The logical structure of the formal speciﬁcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The formula AF p →AF q means2182182183 Verification by model checking                something quite diﬀerent: it says ‘if all paths have a p along them, then                allpaths have a q along them’ One might write AG (p →AFq), which is closer, since it says that every way of extending Properly speciﬁed software is easier to reuse, since it has a clear speci ﬁcation of what it is meant to do. Safety-critical computer systems – such as the control of cooling systems in nuclear power stations, or cockpits of modern aircrafts – demand that their software be speci credible. Other programs may be commercially critical, such as ac countancy software used by banks, and they should be delivered with a warranty: a guarantee for correct performance within proper use. Ex-perience has shown that verifying programs with respect to formal specians can cut down the duration of software development and maintenance. The degree to which the software industry accepts the beneﬁts of proper Verification depends on the perceived extra cost of producing it. Microsoft’s emergent technology. # combines program veri ﬁcation, testing, and model-checking techniques. As we will see, there are often good heuristics to help the programmer complete these tasks. This contrasts with the.situation of the last chapter, which was fully automatic. The importance of Verification to industry will.continue to increase over the next decades. The proof that a program.meets its speciﬅcations is indeed such a warranty. The domain of application in this chapter is se-quential transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems that are not intended to terminate and that react continually with their environment.Pre/post-development. Pre- and post-development of programs. Pre/post development of programs that are intended to run on a single processor and that have no concur-rency issues. Pre and post development of a program that is intended The techniques of this chapter should be used.during the coding process for small fragments of program that perform. an identiﬁable task. The techniques should also be used during the development process in order to avoid functional bugs. 4.1 Why should we specify and verify code? The task of specifying and verifying code is often perceived as an unwel-                come addition to the programmer’s job and a dispensable one. The logical structure of the formal speciﬃcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The process of documenting a program may raise or alleviate important issues. A framework for producing the software could be: Convert the informal description R of requirements for an application domain into an ‘equivalent’ formula φR of some symbolic logic. Write a program P which is meant to realise that formula. Prove that the program P satisﬁes the formula. This scheme is quite crude – for example, constraints may be actual design decisions for interfaces and data types, or the speci ﬁcation may ‘evolve’4.2 A framework for software verification may partly be ‘unknown’ in big projects – but it serves well as a approximation to good programming methodology. For example, as a programmer, might have been given only the The meaning of R as a piece of natural language is grounded in common sense. The attempt at formalising R can uncoverambiguities or undesired consequences and hence lead to revisions of R. It is impossible to ‘verify’ whether an infor-cular requirement R is equivalent to a formal description φR. The meaningof R is based on heuristics or quantitative reasoning and often based on real-world knowledge about the domain. The ‘going back and forth’ between the realms of informal and formalspeciﬁcations Microsoft’s emergent technology seamlessly combines program veriﬁcation, testing, and model-checking techniques in an integrated in-house development environment. Software systems now often have a longer life-expectancy than humans, which necessitates a durable, transparent and                portable design and implementation process. The meaning of a logic formula φR, on the other hand, is de ﬁned in a precise mathematical, qualitative and compositional way. As society depends on it more and more, the beneﬃts are becoming more important. We can expect that the importance of veri-cation to industry will continue to increase over the next decades. Software veriﬁcation provides some of this framework for software verification. It is a way of condensing the requirements of such a project into formal speci ﬁcations. These formalspeciﬀcations are usually symbolic encodings of real-world constraints into some sort of logic. For example, it could be the devel-                opment and maintenance of a database of electricity accounts with all the possible applications of that – automated billing, customer service etc. It could also be the creation of an online bank account database. For more information on software verification, see the Software Verification Handbook. The book, published by Oxford University Press, is available in English and French. Convert the informal description R of requirements for an application domain into a logical formula R. R is grounded in common sense and gen-                eral knowledge about the real-world domain. The meaning of a logic formula φR is deﬁned in a precise mathematical, qualitative and compositional way by structural induction on the parse tree of R. To make matters worse, the requirements R are often inconsistent; customers usually have a fairly vagueception of what exactly a program should do for them. Thus, a framework for producing the software could be: Convert R into a formalisation of the formalisation R of the application domain R as a piece of natural language. The process of formalising R requires the utmost care. Producing a clear and coherent description R of the requirements for an application do-                main is already a crucial step in successful programming. We address this ﬁrst item only implicitly in this text, but you should certainly be aware of its importance in practice. The programming language which we set out to study here is the typicalcore language of most imperative programming languages. The next phase of the software development framework involves construct-                ing the program P and after that the last task is to verify that P satisﬁes φR. The correspondence between proving and program-                ming can be stated quite precisely, but that is beyond the scope of this book. The book includes a core programming language for imperative languages Program verification is a subset of Pascal, C, C++ and Java. Our lan-guage consists of assignments to integer- and boolean-valued variables. If-and refer to a method’s object. Upon validation, this contract.establishes that all calls to withdraw leave (the ‘object. invariant’) 0 <= 0 <= balance invariant 4.7 Bibliographic notes. Backhouse’S book [Bac86] describes program logic and weakest precondi-tions and also contains numerous examples and exercises. Other books [AO91, Fra92] extend the basic core language to in-clude features such as procedures and parallelism. In propositional or predicate logic, formulas are either true, or false, in any model. Propositional logic and predicate logic do not allow for any further possibilities. The issue of writing to.                arrays and the problem of array cell. aliasing are described in [Fra92]. The. article describing the minimal-sum section problem is [Gri82]. A text on functional programming on the freely available. Standard ML of New Jersey is [Pau91].8 www.opensource.org                9 www.sims.berkeley.edu/~pam/papers.html676.5. Modal logics and agents                5.1 Modes of truth The tool was developed by D. Jackson at the Massachusetts Institute of Technology. The tool has a dedicated repository website at                alloy.mit.edu. More information on typed higher-order logics and their use in the.modelling and verifying of programming frameworks can be found on F.Pfenning’s course homepage7 on Computation and. Deduction. The book, The Typed Higher-order Logics of Programming, is published by Oxford University Press, priced £16.99, is available in hard copy and soft copy for £12.99. Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The veriﬁcation method consists of trying to prove that a formula is a formula. This typically requires guidance and expertise from the user. We will model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to see if prerequisites in the form of libraries or other packages are present. The formal models attached to software products can be seen as aiability contract; a promise that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬁed therein. We will use a formula that captures formally static and dynamic system structure and behaviour. This formula can be used to verify consistency of the constrained design space and to test the correctness of claims about static andynamic aspects of all its compliant implementations. It can also boost our conﬀdence into the Software package dependency systems are used in several computer systems. Users often have to guess how technical questions get resolved within the system. To the best of our knowledge, there is no publicly available model of any particular dependency system to which application programmers could turn if they had non-trivial technicalquestions about its inner workings. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things, such as a database or a file system, for example. The requirements on a software package dependency system are not straightfor-                ward. The upgrading process can go wrong in various ways. For example, upgrading a package can involve replacing older versions of shared These deﬁnitions are justi�ken by LTL equivalences in Sections 3.2.4 and 3.5. In order to have AF φ in a particular state, φ must be true at some point along each path from that state to that state. These equivalences can be used to de�ir�ne the six connectives on the left in terms of AX and EX, in a non-circular way. The equivalence for the third one is the following: In order for AF to be true now, we must have it true in each of the next three states we go through, or we must postpone one of them. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. The formula AF p →AF q means ‘if all paths have a p along them, then                allpaths have a q along them’ Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas φ which are not in the adequate fragment intosemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ. Prove that the evaluation of φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ worrisomei or Z′ horrifyingi. Proving that ρ does not depend on the value of x′. Exercises 6.16 and 6.17 are based on the CTL model M = (S, →, L) Given a model M, we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. The former deﬁnes fair in terms of f ECG for general φ. Why is this unproblem-phthalatic, i.e. non-circular? Exercises (6.16) and (7) consider the coding without consideration of simple fairness constraints. The last exercise is based on f E[x1∨¬x2Ux1]. Consider the pseudo-code for the function SAT on page 227. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.  Explain what exactly the CTL formula AG expresses in terms of the order of occurrence of events p, s and t. Explain what the formula AG (p →AF (s ∧AX (AF t)) does in plain English. Find a model in which no formula of F holds. Show these two assertions if f φ also encodes simple fairness constraints. Show that all the subformulas of f χ are formally monotone. Find the only formula in F that is not a set, or an OBDD. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� Figure 3.23 shows the relationship among the expressive powers of CTL, LTL and CTL*. The LTL formula α is equivalent to the CTL* formula A[α]. LTL can be viewed as a subset of C TL*. CTL is also a subset of CTL*, since it is the fragment of Ctl* in which we restrict the form of path formulas to α. Here are some examples of formulas in each of the subsets3.5 C TL* and LTL* and the expressive power of LTL, CTL andCTL* shown in Figure 3.22. The expressive powers are shown in Figures 3.3 and 3.4. The proof that AG EF p is not expressible in LTL is as follows. Let M′ be as shown in the right-hand diagram. The paths from sin M′ are a subset of those from s in M. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. This expresses: wherever we                have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given in the references. CTL* is a logic that combines the expressive powers of LTL and CTL. It does this by dropping the CTL constraint that every temporal operator (X, U, F, G) has to be associated with a unique path quantiﬁer (A, E) It is based on the fact that LTL formulas can be verified by model checking. For example, in CTL, AG (p →AF q) can be written as F p →F q. In LTL, it can be rewritten as G (p ·F q) or G p ·Fq in LTL. The result is that any p is eventually followed by a q. The syntax of CTL* involves two classes of formulas: state formulas, which are evaluated in states, and path formulas, evaluated along paths. It turns out that the ﬁrst of them can be written as a (rather long) CTL formula. It allows us to write formulas such as A[(p U r) ∨(q U r), where either p is true until r, or q istrue until r. These formulas are not equivalent to, respectively, A[ (p ∨q) U r, AX p, EG EF p and AX p. The second and third do not have a CTL formulas that are equivalent to them. LTL and CTL as subsets of CTL* are mutually recursive. The deﬁnition of each class depends upon the de ﬁNition of the other. LTL does not include A and E, but the semantic viewpoint of LTL is that we consider all paths. Therefore, the LTL CTL is a subset of CTL* in which we restrict the form of path formulas to (φ U φ) | (G φ), (F φ, (X X) LTL can be viewed as a subset to CTL*. If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective begins with E, then Satisfaction holds if some path from s satisfies the LTL formula. The result of removing A or E is not strictly an LTLformula, for it The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path There Exists a path beginning in s such that φ holds Globally along the path. The equivalencesAF and EF are similar to the corresponding equivalences in LTL. For example, the connective AX can be written ¬EX ¬;. AG, AF, EG and EF can bewritten in terms of AU and EU as follows:. write AG φ as ¬EF ¬φ and EG φ. as ¼AF ¬ φ, using (3.6), and then use. (2.6) to write EF and EF as ¹AF and ¹EF, using. (1) and (2) respectively. Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX, AF, AU, EG, EU, and EX. Theorem is proved in a paper referenced in the bibliographic notes at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it is valid in the logic CTL* introduced in the next section. For example, we have the equivalence: A[φ U ψ] ≡¬(E[¬ φ U (¬φ ∧¬hy),  “EG” U ( Neither weak-until W nor release R are primitive in CTL. The connective EU plays a special role in that theorems. The temporal connectives AR, ER, AW and EW are all deﬁnable in C TL. LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For a positive example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p ·AF q) in LTL. Some other noteworthy equivalences are the following:AG φ  ‘in’ and ‘out’ are of the form ‘in. often requested implies eventuallyacknowledged’ In fact, AF AG p is strictly stronger than F G p. While the LTL formulas X F p and F X p are equivalent, they are not equivalent to AF AX p. CTL* is more expressive than either of them, but is computationally more expensive. The choice between LTL and CTL depends on the application at hand, and on personal prefer-iness. LTL lacks CTL’s ability to quantify over paths, and C TL lacks LTL”s ability. to describe individual paths. We have seen that they have incomparable expressivepowers. We discuss two more negative examples: F G and AF AG. The latter has quite a strange meaning (try working it out). CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn't allow nest-ing of path modalities X, F and G. To many people, LTL ap-                pears to be more straightforward to use; as noted above, CTL formulas like                AF AX p seem hard to understand. The equivalences between CTL and LTL are similar to the corresponding equivalences in LTL. As in propositional logic, there is some redundancy among the CTL connectives, but the equivalences are equivalent to those for LTL and CTL in the same way. In LTL, the equivalence between the two sets of connectives is similar to that for CTL AU, EU and EX form an adequate set of temporal connectives. AG, AF, EG and EF can be written in terms of AU and EU as follows. For example, the connective AX can bewritten ¬EX ¬;. And AG, EF, EG, EF and AF can be. written interms of AU, EU, and EX as follows:. write AG φ as ¬EF ¬φ;. write EG υ as EG;. Write AF and EF using (3.6);. Use EF and EF as AU;. Use AU as EU; and so on. Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX,EG, AF, AU } and EU. The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in C TL. The temporal connective AR, ER, AW and EW are all deﬁnable in the logic CTL* and the expressive powers of LTL and CTL. Theorem is proved in a paper referenced in the bibliographic notes referenced at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it The algorithm for labelling states with subformulas of the form AF is called the model-checking algorithm. Here is the algorithm:. A CTL model M = (S, →, L) and a CTL formula φ: the set of states of M. which satisfy φ. First, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms of the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given earlier in the chapter. Figure 3.24. The iteration step of the procedure for labelled states withsubformulas is the ‘model- checking algorithm’ Label the states of M with the subformulas of φ that are satisﬁed there, starting with the smallest subformula and working outwards towards φ. We determine by a case analysis which states to label with ψ. This step is illustrated in Figure 3.24. If a state is labelled with ⊥ and no states are labelled with p, then label s with p if p ∈L(s). If ψ is a subformulum of ω, label it with ω if it is already labelled with φ and with ρ if it isn't. If ω is not a sub formula of ψ, label the state with a different subform Theorem 6.19 remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment into equivalent formulas in that fragment. Prove that the evaluation of f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ or Z. Theorem is illustrated in Figure 3.25 in the next section of the paper. The next step is to prove that the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407 is equivalent to f E[x1 Ux1] (x1, x2, x3) (0, 1 Exercises 6.16 and 6.27. Recall the way the two labelling algorithms operate in Chapter 3. Given a CTL model M = (S, →, L), we saw how to code formulas f φ. The former deﬁnes fair in terms of                f ECG⊤, whereas the latter deﰁnes f ECG φ for general φ, i.e. non-circular. Does our Symbolic coding mimic either or both of them, or neither? The answers to these questions can be found in (6.22) and (6,27) in the appendix to the book. The final chapter of the book is available on Amazon. If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective begins with E, then Satisfaction holds if some path from s satisfies the LTL formula. In the last two cases, the result of removing A or E is not strictly an LTLformula, for it may contain further As or Es below. We now want to modify it so that the resulting output is not a set, or an OBDD, but a formula                roughly understood as follows. The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path An adequate set of connectives for propositional logic is a set such that for every formula of logic there is an equivalent formula with only connectives from that set. For example, the set {¬, ∨} is adequate for logic, because any occurrence of  and  can be removed by using the equivalences. The set C is adequate because it is a nullary con-nective, and we are treating ⊥ as a Nullary Connective in this case. We show that C ⊆{¬,.    ,    ”, “C’s” is adequate. We also show that if C is an adequate set, Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that the relation ≡ is reﬂexive, symmetric, transitive, commutative, associative, distributive, and absorptive. Prove your answer to the question Is {↔, ¬} adequate? Proving your answer will help you understand the de Morgan rules. Proving the truth value of a formula φ, formed by using only the connectives in C, can be done by using the word \"proving\" in the form C = C + T.  construct a formula in CNF based on each of the following truth tables. Exercises include the following:. Construct a model in which no formula of F holds. Explain what exactly the CTL formula AG expresses in terms of the order of occurrence of events p, s and t. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.  The final exercise is to find a model of F in which all formulas hold in it. For example, consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →apologeticAF q)}. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any                model): A[p U q] (¬p  G p) ( G  P) (P U q) (G  P) (Q U Q) (U U Q (G P) U (Q Q) Q (U Q) U  Q (Q q) G (Q p) U(Q Q q) Q( Let us see some examples of well-formed CTL formulas and some examples which are not well- formed. Let us see how the syntax rules allow us toconstruct each of these. For example, take EF (r U q). The problem with this string is that U can occur only when paired with an A or an E. The E we have is                paired with the F. We can also see why we can’t use EF (p U r) or EF EG (p →AF r) to construct these. We will also see how we can use EF G (r G r) and EF E (r E r) in the next section of this article. Inspection of clauses 12 and 13 reveals that R and W are rather similar. They swap the roles of their arguments φ and ψ; and the clause for W has an i where R has i. Therefore, it is not surprising that they are expressible in terms of each other. As in propositional logic, there is some redundancy among the connectives in the CTL formula. For example, W is like U but also allows the eventuality of never occurring: W ψ U ψ  G φ (3.3) W is also possible to write W  U  (3.4) W   U    (4.5) W (5) U  Small adequate sets of connectives also exist in LTL. The set X is completely orthogonal to the other connectives. X cannot be derived from any combination of the others. Each of the sets {U, X}. {R, X}, {W, X} is adequate.  The set {⊥, ∧, ¬} forms an adequate set of connective. For example, in Chapter 1 we saw that the set { ≹, ≳, Sometimes it is useful to look at adequate sets of connectives which do notrely on the availability of negation. To see this, we note that R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) andequivalence (3.4) followed by a duality, respectively. We also note that U and W can be de-de Some LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) In LTL, any p is eventually followed by a q. In CTL, p is always followed by an F, and F is followed by another p. The CTL formula AG is written in negation-normal form, where all the negationsymbols are applied to propositional atoms (i.e., they are near the leaves of an atom) In fact, AF AG p is strictly stronger than F G p. While the LTL formulas X F p and F X p are equivalent, they are not equivalent to AF AX p. CTL* is more expressive than either of them, but is computationally more expensive. The choice between LTL and CTL depends on the application at hand, and on personal prefer-iness. LTL lacks CTL’s ability to quantify over paths, and C TL lacks LTL”s ability. to describe individual paths. We have seen that they have incomparable expressivepowers. We discuss two more negative examples: F G and AF AG. The latter has quite a strange meaning (try working it out). The syntax of CTL is restricted in two ways. It does not allow nesting of the path modalities X, F and G. A model as a whole satisﬁes an LTL formula. The future shall include the present. The formulas G p →p, p →q U p and p →F p are true in every state of every model. The satisfaction relation between paths and LTL for-mulas can be verified by a model as large as the whole of the CTL system. For example, the formula G p is true in all states of the LTL system, even if only some of the states are true. The formula F p can be proved to be true in any state of M, s ⊨φ is a formula that holds whenever every possible execution path of the model is found. Later in this chapter, we will examine algorithms which implement this calcula-                tion. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s  holds. We will then examine the algorithms that implement this pro-reprehensibility. Back to Mail Online home. back to the page you came from. Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. Linear-time temporal logic is a temporal logic with con-                nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or                p1, p2, .. . . ). Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. For any state there is inevitably a future state in which the current message has got through. Messages get through eventually. In the module sender, we speciﬁed G F st=sent. The next three, U,R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives in the next section; for now, we concentrate on their syntax. We de-analysed LTL (linear-time temporal logic) in the preceding sections. We noted that LTL formulas are evaluated on paths. A state is an LTL formula if all paths from the given state satisfy the formula. We will examine a logic known as Computation TreeLogic, or CTL. LTL implicitly quantiﬁes universally over paths. Therefore, prop-phthalerties which assert the existence of a path cannot be expressed in LTL. Thisproblem can partly be alleviated by considering the negation of the property in question, and interpreting the result accordingly. We used this approach when analysing the ferrymanpuzzle in the previous section. However, properties which seamlesslymix universal and existential path quanti ﬁers cannot in general be modelchecked using this approach, because the complement formula still has a mix. We will examine this problem by allowing us to quantify ex-oplicitly over paths in CTL In CTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists The NuSMV model checker is used to test the correctness of software programs. The CTL model-checking algorithm is also used to check correctness of CTL connectives. The programming language is called a core programming language. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255 or visit www.suicidepreventionlifeline.org. C. Y. Lee. Representation of switching circuits by binary-decisionprograms. Bell System Technical Journal, 38:985–999, 1959. D. E. Long. Model Checking, Abstraction, and CompositionalVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon University, July 1983. C. H. Papadimitriou. Computational Complexity. Addison Wesley, November 1994. L.C. Paulson. Epistemic Logic for AI and Computer Science. Cambridge University Press, 1995. Z. Manna and A. Pnueli. The Temporal Logic of Reactive and A temporal logic of programs. Theoretical ComputerScience, 13:45–60, 1981. First Steps in Modal Logic. The Structure of Typed Programming Languages. The MIT Press, 1994. The Theory and Practice of Concurrency. ML for the Working Programmer. Cambridge University Press, 1991. A. Pnueli. Theory of Programming. A Foundation for Computer.Science. Addison Wesley, 1992. P. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag,. 1992. D. Prawitz. Natural Deduction: The Proof Theory and Semantics of Intuitionistic Proof does not allow nesting of path modalities X, F and G. The idea is to translate any CTL formula having booleancombinations of path formulas into a CTL form that doesn’t. We see that the ﬁrst of these restrictions is only apparent; we can find equivalents in CTL for formulas having boolean combinations of path formula. We also see that CTL does not let us nest path mod The temporal operators X, U, F, etc. which we have seen so far refer to the future. For exam-ple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q  EF p] since, if we have F p  along any path, then either the p must come before the q, or the other way around. Other identities we need in this translation include E[¬X p] and E [¬P p] Theorem 3.10: If the p and q occur simultaneously, then both disjuncts are true. Theorems 3.5.2 and 3.6: The Sometimes we want to encode properties that refer to the past, such as ‘whenever q occurs, then there was some p in the past’ To do this, we add the operators Y, S, O, H. They stand for yesterday, since, once, and are the past analogues of X, U, F, G, respectively. Thus, the example formula may be written G (q →O p). NuSMV supports past operators in LTL. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. That is to say, every LTL formula with past operators can be written equivalently without them The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In contrast, adding past operators to CTL does increase its expressive power. This is because they can let us examine states not forward-reachable from the present one. The results are surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. For more details on the model-checking algorithms used in this article, please visit: http://www.npr.org/2013/01 NuSMV supports past operators in LTL. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. Every LTL formula with past operators can be written equivalently without them. LTL is generally preferred by speciﬁers, as already noted, but we start with CTL model checking because its algorithm is simpler. In general, inter-                esting transition systems will have a huge number of states. Verification by model checking may be quite long. It is therefore well worth trying to ﬁnd eﬃcient algorithms. For example, if we think of implementing a model checker the example formula may The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 provide a basic model-checking question. The example formula above can                be written ¬p W q, or equivalently ¬(¬q U (p ∧¬Q) if one wants to avoid W. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. In contrast, adding past operators to CTL does increase its expressive power, because they can allow us to examine states not forward-reachable from the present one. For example, the past operators let us to travel backwards In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long. It is therefore well worth trying to ﬁnd eﬃcient algorithms. Although LTL is generally preferred by speciﬁers, as already noted, we start with CTL model checking because its algorithm is simpler. The CTL algorithm is based on the following formula: G p →p, p →q U p and p →F p. The formulas are true in every state of every model. We call the algorithm CTL because the future shall include the present, and LTL because it excludes the present. We conclude that CTL is a better algorithm than L A model as a whole is an LTL formula. This is deﬁned to hold whenever every possible execution path of the model sits on the formula. Later in this chapter, we will examine algorithms which implement this calcula-                cyntion. We write M, s ⊨φ if, for every execution path π of M starting at the beginning of the formula, we have π ⋅. If M is clear from the context, we may abbreviate M,  by s ⋉. We have outlined the formal foundations of a pro-                cure that can check whether Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. Linear-time temporal logic is a temporal logic with con-                nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or                p1, p2, .. . . ). Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. X means ‘neXt state,’ F mean ‘some                Future state’ and G means � ‘all future states (Globally).’ The next three, U,R and W are called ‘Until,” ‘Release, and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of the LTL formulas. The syntax of LTL is as follows:(F p) (G q) (U r) (W r The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-reprehensiblemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the                literature. Nearly all of them adopt the same basic strategy. Almost all LTL model checking algorithms proceed along the following three steps. Construct an automaton, also known as a tableau, for the formula ¬φ. A trace is a sequence of valuations of the proposi-                tional atoms. From a path, we can abstract its trace. The CTL model-checking algorithm makes it easier to do model checks on the unwindings of models into inﬁnite trees, given a designated initial state, for then all possible paths are plainly visible. We explain that strategy ﬁrst; then, we describe some algo-774rithms in more detail. The basic strategy is: Let M = (S, →, L We need to develop new insights into the semantics of CTL. Such adeeper understanding will provide the basis for an eﬃcient algorithm. Such an algorithm can be augmented to produce an ac-                tual path (= run) of the system demonstrating that M cannot satisfy φ. That way, we may debug a system by trying to ﬁx what enables runs which enables us to prove that M, s0 ⊨φ does not hold. For example, one could have the model M, the formula φ and a state s0 as input; one would then expect a reply of the form ‘yes’ (M, m0 holds) or ‘no’ The algorithm is based on the New Symbolic Model Veriﬁer. NuSMV is an Open Source product, is ac-                tively supported and has a substantial user community. We present an algorithm which, given a model and a CTL formula, outputs the set of states of the model that satisfy the formula. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                ∧form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is called ‘NuSMV’ and can be downloaded from here. SMV provides a language for describing the models we have been drawing as diagrams. It directly checks thevalidity of LTL (and also CTL) formulas on those models. SMV programs consist of one or more modules. As in the programminglanguage C, or Java, one of the modules must be called main. Modules can declare variables and assign to them. Assignments usually give the initialvalue of a variable and its next value as an expression in terms of the current values of variables. For details on how to obtain it, see the bibliographic notes at the end of the chapter.                NuSMV (sometimes called simply SMV) is a programming language. The following input to SMV is used to model the environment and for abstraction. Non-determinism is used for verification by model checking. The SMV program consists of a program and a speciﬁcation. The program has two variables, request of type boolean and status of enumeration type {ready, busy]: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent valuesof variable request are not determined within this program; this conserva-                tively models that these values are determined by an external environment. This under-speciﬁcation of request implies that the value of variable status. is partially determined: initially, it is ready; and it becomes busy whenever. The NuSMV model checker is used to test the correctness of the CTL model-checking algorithm. The program is written in a programming language called ‘Guideline’. The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.3. Representing OBDDs.6.4. The system description language as CMU SMV, but it has an improved user in-terface and a greater variety of algorithms. The term                emphasises that individual states are not represented; rather, sets of states are represented symbolically, namely, those which satisfy the formula beingchecked. The way to do this in general is to assign to each element of S aunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, werepresent a subset T by the boolean function fT which maps ( Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction as ways of addressing the state explosion problem. NuSMV supports LTL and CTL. Spin is geared towards asynchronous systems and is based on the temporal logic LTL, can be found at the Spin website10. Current research in model checking includes attempts to exploit abstrac-aryl symmetries and compositionality in order to reduce the impact of the state Explosion problem. For example, whereas CMU SMVchecks only CTL speciﬁcation, Nu SMV supports CTL and LTL. For more information on model checking, visit the CTL/LTL/C A model checker called FDR2 based on the process algebra CSP is available. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. The Edinburgh Concurrency Workbench12 and the Concurity Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The algorithm works recursively on the structure of CTL φ. The acceptance conditions of A¬φ are represented as implicit fairness conditions for the CTL model-checking procedure. The code for NuSMV can be found at: http://www.dcs.ed.edu/~cwb/, http://bogor.projects.cis.ksu.org/774/NuSMV-CTL-Model-Checking-Algorithm-Code-1-2-3-4-5-6. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. The algorithm computes the set of all states which have a transition to a state in                [[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is a state s′ with s →s′. The more interesting cases arise when we deal with a formula such as EX ω involving a temporal operator. For example, if φ is ψ1 ∨ψ2, then the algorithm compute the sets                [[ ω1] and [[ ω2] and combines them. Inspecting the pseudo-analyzer [JSS01] has been developed by D. Jackson at the Laboratory for Computer Science at the Massachusetts Institute of Technology. More information on typed higher-order logics and their use in the modelling and verifying of programming frameworks can be found on F. Pfenning’s course homepage7 on Computation and Deduction. The tool has a dedicated repository website at                alloy.mit.edu/repositories/jss01. The topic of this section is to provide semantic insights into these operators that allow us to provide acomplete proof for their termination Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The speciﬁcation is again representation by a formula call such paths fair computation paths. The presence of fairness constraints means that, when evaluating the truth of CTL formulas in speci ﬁcations, connectives A and E range only over fair paths. We therefore impose the fairness constraint that !st=c be true inﬃnitely often. This means that whatever state the process is in, there will be a state in the future in which it is not in its critical section.    In a Proof-based Approach, the process consists of trying to Constraints of the form (where φ is a state formula) are known as simple fairness constraints. Similar fairness constraints were used for the Alternating Bit Protocol. We now explain how we may adapt our model-checking algorithm so that A and E are assumed to range only over fair computation paths. For example, M, s0 ⊨ACG φ iﬀφ is true in every state along all fair paths; similarly for ACF, ACU, etc.    The algorithm can deal only with simple fairness constraint; but how does it do that? We show how to make the algorithm work with other types of constraints, such as those of theform. The last four issues are beyond the scope of this book, but references may                be found at the end of this chapter. The veriﬁcation of M, s0 ⊨φ might fail because the model M may contain unrealisticbehaviour which is unrealistic, or guaranteed not to occur in the actualsys- tumultuous being analysed. The algorithm for ECG φ is similar to the one for temporal connectives without fairness constraints. We already know that ECU, ECG and ECX form an adequate set; this can be shown in the same man-                ner as was done in Section 3.4.4 (Section 3.6.2 CTL model checking with fairness) We modelled this by the non-deterministic assignment assignment. For example, in the mutual exclusion case, we expressedthat the process prc can stay in its critical section (st=c) as long as it needs. However, if we really allow process 2 to stay in the critical section aslong as it likes, then we have a path which violates the liveness constraint (t1 →AF c1) We would like to ignore this path, i.e., we would like. to assume that the process canStay in itscritical section as longas it needs, but will eventuallyexit from its critical. section after some ﬁnite time. In LTL, we could handle this by verifying CTL is not expressive enough to pick out the ‘fair’ paths, i.e., those in which process 2 always eventually eventuallyleaves its critical section. SMV allows us to impose fairness constraints on top of the transition system it describes. These assumptions state that a given formula is true inﬁnitely often along every computation path. The presence of fairness constraintsmeans that, when evaluating the truth of CTL formulas, only connectives A and E range only over fair paths. 3.6 Model-checking algorithms for CTL and SMV. 4.7 Model- checking algorithms for SMV and CTL. 5. A model-checking algorithm for the CTL, SMV, and The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-reprehensiblemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the                literature. Nearly all of them adopt the same basic strategy. Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. Almost all LTL model checking algorithms proceed along the following three steps. Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton has a notion of accepting a trace. A trace is a sequence of valuations of the proposi-                tional atoms. NuSMV encodes precisely the traces which satisfy ψ. In otherwords, the automaton A ω encodes exactly the traces that satisfy ω. It is possible to implement the check for such a path in terms of CTL. model checking, and this is in fact what NuSMV does. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255. The acceptance conditions of A¬φare represented as implicit fairness conditions for the CTL model-checking procedure. The algorithm works recursively on the structure of CTL formula φ. For formulas φ of height 1 (⊥, ⊤or p), [[φ] is computed directly. Other CTL formulas are composed of smaller subformulas combined by a connective of                CTL. The combined system is represented as the system to be model checked in NuSMV, and the formula to be checked is simply EG ⊥. We ask the question:does the combined system have a path? The answer is ‘yes’. For most of these logical operators, we may easily continue this discussion. However, the cases EU, EUAF and EG are not so obvious to reason about. The topic of this section is todevelop the semantic insights into these operators that allow us to provide acomplete proof for their termination and correctness. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets[[ψ1] and [[ ω2] and combines them in a certain way. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is a state s′ with s →s′ and M, S, s′ � The addition of fairness could be achieved by restricting the ordinary CTL semantics to fair computation paths. The propositional connectives won’t change their meaning with theaddition of fairness constraints. Therefore, it suﬃces to provide symboliccodings for the fair connectives ECX, ECU and ECG from Chapter 3 of the CTL textbook, CTL: An Introduction to the Theory of Relational Computation. The book is published by Oxford University Press, London, UK, and is available in paperback and Kindle editions, with prices starting at £9.99 (US) and £14.99 ($19.99) for the paperback version and £16.99 for the Kindle edition. The set of fair states symbolically is represented as a boolean formula. We say that there is a fair path with respect to C that begins with s and ends with s. The coding of fECG φ is rather complex, we proceed in steps. It is convenient to have the functionality of ECX and EU functionality also at the level of boolean formulas directly. For ECX, note that s ⊨ECXφ if, and only if, there is some next state s′with s →s′ and s′ ≳ such that s′ is aFair state. For EU, we obtainfEC[φ1Uφ2] def= µZ. This immediately rendersfEC We need to develop new insights into the semantics of CTL. Such adeeper understanding will provide the basis for an eﬃcient algorithm. In the case that M is not satisﬁed, such an algorithm can be augmented to produce an ac-                tual path (= run) of the system demonstrating that M cannot satisfy φ. That way, we may debug a system by trying to ﬁx what enables runs which                refute φ, for example. For                3.6.1 The CTL model-checking algorithm. The algorithm is based on a model-checker that looks at the unwindings of models into in-                nite trees. We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. In this section, we see that the ﬁrst of these restrictions is only apparent in CTL. The idea is to translate any CTL formula having boolean combinations of path formulas into a CTL form that doesn’t. For example, we can write the formula φ in order to write the CTLformula φ. We can also use the formula F in the same way, but with a different CTLFormula, such as F-F-G. The temporal operators X, U, F, etc. which we have seen so far refer to the future. For exam-ple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q  EF p] since, if we have F p  along any path, then either the p must come before the q, or the other way around. Other identities we need in this translation include E[¬X p] and E [¬P p] Theorem 3.10: If the p and q occur simultaneously, then both disjuncts are true. Theorems 3.5.2 and 3.6: The NuSMV supports past operators in LTL. One could also add past opera-tors to CTL (AY, ES, etc.) but NuSMV does not support them. Past operators do not increase the expres- that φ is inﬁnitely often true, we check G F φ → ψ. It is not possible to express past operators as operands in CTL. In particular, any way of adding As or Es to G F will result in a formula with a diﬀerent meaning from the intended one. The result is that the formula may be written G (q →O p) rather than G F (q) The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-reprehensiblemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the                literature. Nearly all of them adopt the same basic strategy. Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. Almost all LTL model checking algorithms proceed along the following three steps.Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton has a                notion of accepting a trace. A trace is a sequence of valuations of the proposi-                tional atoms. From a path, we can abstract its trace. The construction has theproperty that for all paths SMV provides a language for describing the models we have been drawing as diagrams. It directly checks thevalidity of LTL (and also CTL) formulas on those models. SMV programs consist of one or more modules. As in the programminglanguage C, or Java, one of the modules must be called main. Modules can declare variables and assign to them. Assignments usually give the initialvalue of a variable and its next value as an expression in terms of the current values of variables. For details on how to obtain it, see the bibliographic notes at the end of the chapter.                NuSMV (sometimes called simply SMV) is a programming language. Non-determinism is used to model the environment and for abstraction. The program has two variables, request of type boolean and status of enumeration type {ready, busy}. The initial and subsequent values of variable request are not determined within this program. The value of variable status is partially determined: initially, it is ready; and it becomes busy whenever it is not ready. The system was developed in the early 1990s, because they have allowed systems with much larger state spaces to be veriﬁed. It is based on an early version of SMV, which was written in the 1980s and 1990s. The current version is written in C and has a more modern version of the SMV The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.3. Representing OBDDs.6.4 Representing sets of states in the form of a set of boolean values. 6,5. The term ‘state’ is used to emphasise that individual states are not represented; rather, sets are represented symbolically, namely, those which satisfy the formula beingchecked. 6,.5. A set is called a ‘set of states’ if it contains all the states that satisfy the condition ‘s’ = ‘S’ and ‘t’ means ‘to be’. 7. The concept of an OBDD is called ‘O A model as a whole satisﬁes an LTL formula. The formulas G p →p, p →q U p and p →F p are true in every state of every model. We will examine algorithms which implement this calcula-tion later in this chapter. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later in the chapter, we will examine an algorithm which implements this pro-                             cedure. We conclude with the conclusion that the future shall include the present and that the formula G p is true in all states of the system. Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. Humans may ﬁnd it easier to do model checks on the unwindings of models                into inﬁnite trees, given a designated initial state. However, if we think of implementing a model checker on a computer, we certainly cannot unwind transition systems. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. Such adeeper understanding will provide the basis for an eﬃcient algorithm which, given M, s ∈S and φ, computes whether M,  ⊨φ holds. This says that if                3.6.1 The CTL model-checking algorithm is We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write                4 www.cs.indiana.edu/formal-methods-education/246246.3 Verification by model checking. Figure 3.39. A model M. For each of the formulas φ: G, U, X, Q, F, G, X (a, b, c, d, e, f, g, h, j, k, l, m, n, p, q, r, t, w, y, z, s, w,. For each path π of all models, π ⊨φ W ψ implies π The ABP program has 28 reachable states. The LTL program has the additional connectives X, F, G and U, R and W. The program has to animate the semantic equivalences that we presented in this section. It has the capability of referring to the next value of a declared vari-able v by writing next(v) The program is written as an NuSMV program with the G(req -> F busy) clause. It also has the ability to draw the transition system described by the ABPProgram program. It can be used to test the correctness of the LTL Program. The code can be downloaded from the following website: http://www.lttl.org/programs/program NuSMV im-plements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely new model checker focused on compositional systems. It was also developed by K. McMillan and its description language resembles but much extends the original SMV. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. D Current research in model checking includes attempts to exploit abstrac-                tions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to reduce the impact of the state explosion problem. The model checker Spin, which is geared towards asynchronous systems, can be found at the Spin website. The Edinburgh Concurity Workbench12 and the Concurrency Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The kinds of systems we are interested in verifying using LTL may be modelled as transition systems. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The following are not well-formed formulas: U r – since U is binary, not unary. p G q – since G is unary, not binary. p W (q U r), e.g., are p, q, r, q U r and p W   (q W U r). Transition systems are also simply called models in this chapter. A model has a collection of states S, a relation →, saying how the system can move from state to state, and, associated with each state s, one has the set ofatomic propositions L(s) which are true at that particular state. A good way of thinking about L is that it is just an assignment of truth values to all the atoms in a system. We write P(Atoms) for the power set of Atoms, a collection. of atomic descriptions. We call a system a transition system by means of states (static structure) and transitions (dynamic structure). More                formally:                Deﬁnition 3.4 We may conveniently express all the information about a (ﬁnite) tran-                sition system M using directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. The assignment depends on which state s the system is in: L(s) contains                all atoms which aretrue in state s. For example, if the system has only three states s0, s1 and s2, then the only possible transi-tions between states are s0 →s1, s0→s2. ‘true’ marks generalize into � We will execute this marking algorithm on the parse tree of formulas. At the same time, (1.9) serves as a guide for designing an algorithm and as an invariantfor proving its correctness. We will translate formulas into the adequate fragment of the resulting parse tree. We then share common subformulas, making the resulting tree into a directed, acyclic graph (DAG) The set of valuations for which φ is true equals the set ofValuation for which T(φ) is true. The latter ensures that the diagnostics of a SAT solver, applied to the original formula φ, is meaningful for the original form of the formula. For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) = p  ¬ (¬q  p) In the exercises, you are asked to prove these claims. The formal set of rules for forcing new constraints from old ones is depicted in Figure 1.14. The forcestabilised (or forced) constraints are not so obvious to reason about. The topic of this section is todevelop the semantic insights into these operators that allow us to provide a complete proof for their termination and correctness. The time stamps ‘1:’ etc.indicate the order in which we applied our intuitive reasoning about these criteria. In Figure 3.28, we see that most of these clauses just do the obvious and correct thing according to the semantics of CTL. The aim in this section is to prove the termination and correctness of SATAF and SATEU. In fact, we will also write a procedure SATEG and try to prove itstermination and correctness1. The procedure is based on the intuitions given in Section 3.6.1: note howdeleting the label if none of the successor states is labelled is coded as intersecting the labelled set with the set of states which have a labelledsuccessor. We could instead express it as follows: EG φ holds if φ hold and EG χ holds if s0 � EG φ can be written as EG φ = pre∃([[EG χ]]. This does not look like a very promising way of calculating EG χ. Fortunately, there is a way around this apparent circularity, known as computing ﬁxed points. Section 3.6.1 handles EG by translating it into ¬AF ¬φ, but we already noted that EG could be handled directly. The function SATEG (φ) determines the set of states satisfying the equivalence EG ω. This is the subject of section 3.14 of the DAG theory book, ‘DAG Theory’, published by Oxford University Press in 2010. We can apply SAT solvers to checking whether sequents are valid. The DAG of T(φ) is depicted in Figure 1.15. Notice that such DAGs may be constructed by applying the translation clauses for T to sub-formulas in a bottom-up manner – sharing equal subgraphs were applicable. A post-processing phase takes the marks for all. all nodes and re-computes marks of all other nodes. Only if the resulting marks match the. resulting marks we computed have we found a witness. Please verify that this is the case in Figure1.13. The annotations “1” etc. etc.indicate which nodes represent which sub- formulas. Figure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →                r). Labels ‘‘1’’ etc indicate which nodes represent what subformulas are unsatisﬁable. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T(φ)whose DAG equals that of this ﬁgure are not satisﬃable. In particular, all all the formulas of the form ¬( φ1) are unworkable. The function pre takes a subset Y of states and returns the set of states which can make a transition into Y. ‘Pre’ denotes travelling backwards along the transition relation. The function pre∀, used in SATAF, takes228228228. Verification by model checking is carried out using the model checking function (SATAF, SATU, SATEX, SATAF) and the function pre(Y), used in SATEU, takes Y, S, pre (Y, S), pre (S, Y) and pre (U, Y, pre, pre(S), pre(U, pre),pre (U),pre(S, pre)(S, SAT), pre-(Y, The correctness of this pseudocode and the model checking algorithm isdiscussed in Section 3.7. The function SATEU computes the states satisfying φ by calling SAT. Then, it accumulates states satisfying AF φ in the manner described in the labelling algorithm. It returns the set of states which make transitions only into Y .Observe that pre∀can be expressed in terms of complementation and pre∃, as follows:pre∀(Y ) = S −pre∃(S −Y )(3.8) 20. Figure 3.31. Model-checking algorithms: The algorithm for calculating states satisfying E[φ U ψ] */. The SAT solving technique, as presented in this chapter, can be used to check whether formulas are tautologies. For φ from (1.10), can one reverse engineer φ  from the DAG of T(φ)? For the formula(s) a DAG represents if we detect contradictory constraints, what can we say about the formula (s) that it represents? The SAT solver does not employ any case-reversal analysis. The method is described in more detail in the next section of the book, ‘The SAT Solving Technique’, which is published by Oxford University Press, priced £16.99. The book is available in paperback and hardback. Theorem: Given an arbitrary Horn formula φ, compare our linear SAT solver – applied to T(φ) – with the marking algorithm applied to φ. Theorem: Find a formula such that our cubic SATsolver cannot decide the satisﬁability of T( φ) Theorem is based on the fact that the DAG of Figure 1.17 (page 74) is indeed the one obtained for T(T), where φ is the formula in (1.11) on page 73. It is also the same as the formula obtained for theorem: T is the number of nodes in a graph that is consistent with the size of the graph. Our SAT solver has a linear running time in the length of the formula. This linearity came with a price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2) The next step is to write a complete implementation of the cubic SAT solaver. The final result is a DAG that can be used to solve complex equations. The DAG can also be used as a basis for solving complex problems in the Bayes algorithm. The next stage is to implement the DAG as a cubic solver. The forcing rules, applied to the DAG of Figure 1.15,detect contradictory constraints at the indicated node – implying that the initial constraint ‘1:T’ cannot be realized. Thus, formulas represented by this DAG are not satisfiable. We already remarked that this occurs for formulas of the form ¬(φ1 ∧φ2). 1.6 SAT solvers73p.p.qr: P.P.R: R. P. R: Q. R. T: T. T. F: T: F: F. A: T, T, F, T. A. B. C: F, F. F. We assume that SAT has access to all the relevant parts of the model: S, →and L. In particular, we ignore the fact that SAT would require a description of M as input as well. We are interested only in the mechanism in principle of the algorithm for SAT. Any (correct and eﬃcient) implementation of sets would do and we will study such an implementation in Chapter 6. We assume SAT hasaccess to all of the relevantParts of the Model: S,. →, L, and M. In. particular,we ignore the. fact that. SAT would need to describe M as The function SAT takes a CTL formula as input and returns the set of states satisfying the formula. We simply assume that SAT operates directly on any such given model. Figure 3.28 shows how SAT translates φ into an equivalent formula of the adequate set.3.6 Model-checking algorithms for SAT (φ) and other CTL-like algorithms. The model-checking algorithm for SAT is called SATEX(φ1, φ2) and the algorithm for SATEU( φ1) is known as the SATE algorithm. It is based on the model- checking algorithm for the CTL algorithm, which is called SAT ( φ, SAT). The algorithm is presented in Figure 3.28 and its subfunctions in Fig-                ures 3.29–3.31. It calls the functions                SATEX, SATEU and SATAF, respectively, if EX , EU or AF is the root of the parse tree. The program for SAT handles the easy cases directly and passes the more complicated cases on to special procedures, which in turn might call SAT recursively on subexpressions. These special procedures rely on imple-                mentations of the functions pre, pre and pre-. The code for SATEG always termi-                nate, and the repeat-statements in the code are always correct. Temporal logic was invented by the philosopher A. Prior in the 1960s. CTL* was invented in 1986 to unifyCTL and LTL. The technique we described for LTL is used to verify model checking for CTL. Use this fact to reason informally that the main program SAT terminates for all valid CTL formulas φ. Some subclauses, like the one for AU, call SAT recursively and with a more complex formula. Why does this not aﬀect terminating? Why does SAT not terminate with a complex formula, but not with a simple one? Why is SAT not terminated with a simpler formula? Why isn't SAT terminated with the more complex one? The original SMV system was written by K. McMillan [McM93] and is available with source code from Carnegie Mellon University6. NuSMV7 is a                reimplementation, developed in Trento by A. Cimatti, and M. Roveri and is aimed at being customisable and extensible. We conclude this case study by pointing out limitations of Alloy and its Analyzer analyzer. The theorem about adequate sets of CTL connectives is proved in [Mar01] and can be found at [NuSMV] The Cadence SMV8 is an entirely In order to be able to use a SAT solver for propositional logic as an analysis engine, we can only check or run formulas of existential oruniversal second-order logic. For example, we cannot even check whether there is an instance of AddComponent such that for the resulting PDS a certain scheduling policy is impossible. For less explicit reasons it also seems unlikely that we can check that every coherent set of components is realizable as P.components for some PDS. This deﬁciency is due to the inherent complexity of such problems and theorem provers may have to be used if such properties need to be guaranteed The expressiveness of Alloy allows for rapid prototyping of models and the exploration of simulations. It should enhance once understanding of a design and so improve that design’s reliability. Use the predicates A(x, y) and L(x) to translate the following into predicate logic: Mary admires every professor. Some professor admires Mary. No student attended every lecture. No lecture was attended by any student. The answer is not A(m, P(x).) But it is the answer to the question ‘What is the number of people in the world who attended the most recent lecture?’ And the answer is ‘Mary’. Use the predicate speciﬁcations B(x, y) and F(x) to translate the following into predicate logic. ‘True’ marks generalize into ‘true’ and ‘false’ Marks generalize to subformu-las; and “true” generalizes to “false” marks. We will execute this marking algorithm on the parse tree of formulas, except that we will translate formulas into the adequate fragment p. We then share common subformulas of the resulting parse tree, making the resulting tree into a directed, acyclic graph (DAG) The algorithm can be used to design an algorithm and to prove correctness. The inductively deﬁned transla-tion T(p) = pT(¬φ) = ¬T( φ)transforms formulas generated by (1.3) into formulas. The parse tree and DAG of T( ω) are depicted in Fig-                ure 1.12. The set of valuations for which φ is true equals the set of values for which T(ω) is true. The latter ensures that the diagnostics of a SAT solver, applied to T(phi) is meaningful for the original formula φ. In the exercises, you are asked to prove these claims. For example, in Figure 1.48 we compute T( The formal set of rules for forcing new constraints from old ones is depicted in Figure 1.14. A small circle indicates any node (¬, � or atom) The forcenectives such as →and ¬. are hard to use in practice. Gentzenimproved the situation by inventing the idea of working with assumptions. The linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the U.S. of America. Propositional and predicate logic can be found in the bibliographic remarks at the end of Chapter 2, and in other contemporary books. In the ﬁrst chapter, we developed propositional logic by examining it from three angles: its proof theory, its syntax and its semantics. We begin this second chapter by pointing out the limitations of propo-centric logic with respect to encoding declarative sentences. What can we do with modiﬁers like not, and, or                and if . . . then, then, and so on? And how can we create a richer language for these modi-propositional-logic terms? We conclude this chapter by asking: What do we want to say in a language that is richer than propositional-proprietary-logics? In propositional logic, we could identify this assertion with a propositionalSAT recursively on subexpressions. The desire to express more subtle declarative sentences led to the design of predicate logic, which is also called ﬁrst-order logic. The function pre∃(Y) takes a subset Y of states and returns the set of states which can make a transition into Y. Pre’ denotes travelling backwards along the transition relation. Both func-                tions compute a pre-image of a set ofStates. The ‘pre’ part of the function is used to denote a transition from one state to the next. function SATEX determines the set of states satisfying EX φ. The function SATAF computes the states satisfying φ by looking backwards along the line. The pre∀, used in SATAF, takes the number of states and is called pre∃. Verification by model checking can be carried out by using the model checker. The model checkers can be used to test the correctness of the model. For example, the model can be checked by checking whether the state is a positive or negative positive. For more information on the model checking technique, see: http://www.f The correctness of this pseudocode and the model checking algorithm is discussed in Section 3.7. The function SATEU computes the states satisfying φ by calling SAT. Then, it accumulates states satisfying AF φ in the manner described in the labelling algorithm. The model-checking algorithm can be expressed in terms of complementation and pre∃, as follows: pre∀(Y ) = S −pre∃(S −Y ) (3.8) (2.4) (1) ( 2) (3) ( 3) (4) 4) (5) (6) (7) (9) (10) (11) (12) (13) (14 Given a formula φ in propositional logic, we say that φ is                satisﬁable if it has a valuation in which is evaluates to T. For example, the formula p ∨q →p is satis﬋able since it computes T if we assigning T to p. However, this is a weaker concept since every valid formula is by de ﬁnition also satis ﬉able but not vice versa. The two notions are just mirror images of each other, the mirror being negation. The proof is given in the next section of the book. The book is published by Oxford University Press, London, UK, priced £16.99. We obtain a decision procedure for satisﬁability simply by asking P whether ¬φ is valid. If it is not, φ is not satis ﬁable; otherwise, it is. We may transform any decision procedure into one for validity. For each line where (p →¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. The result is extremely useful since it essentially says that we need provide only one procedure for each of these concepts. We will encounter both kinds of procedures in this text. For example, take the truth table autoimmuneof (p ) in Figure 1.8 (page 40) In Figure 3.28, we see that most of these clauses just do the obvious and correct thing according to the semantics of CTL. Since there is only one such line, we have only one conjunct ψ1. That conjuncts are not so obvious to reason about. The topic of this section is todevelop the semantic insights into these operators that allow us to provide acomplete proof for their termination and correctness. In fact, we will also write a procedure SATEG and SATEU to prove its termination and. correctness1. The procedure SATEG is given in Figure 3.37 and is based on the intuitions given in Section 3.6.1. The semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-putation path s0 →s1 →s2 →. . . such that si ≹ holds for all i ≥0. We could instead express it as follows: EG υ holds if φ hold and EG ω holds if the state is in one of the successor states to the current state. The equivalence above can be written as [[EG υ] = pre∃ [[EG ω]]. Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted that EG could be handled directly. Fortunately, there is a way around this apparent circularity, known as computing ﬁxed points, and that is the subject of this section. Section 3. 6.3 Verification by model checking is the final section of the book. The book is published by Oxford University Press. This foreword is re-printed in the second edition with its author’s permis-                sion. We developed this theme for propositional, temporal, modal, and program logics. At the heart of this set-up is that one can often specify and implement algorithms for computing. I recommend it to the reader                with greatest enthusiasm and predict that the book will be an enormous                success. The book is published by Oxford University Press, London, priced £16.99. For more information on the book, visit the publisher's website or visit the book's website at: http://www.oxford-uk.com/books/computer-science- The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. We can apply SAT solvers to checking whether sequents are valid. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc.indicate which nodes represent which sub-formulas. A post-processing phase takes the marks for all grotesqueatoms and re-computes marks of all other nodes in a bottom-up manner, as done in Section 1.4 on parse trees. Only if the resulting marks match the ones we computed have we found a witness. It now begins with a discus-                Figure 1.14. Rules for flow of constraints in a formula’s DAG. Small Carbunclecircles indicate arbitrary nodes (¬ The SAT solver can be seen in Figure 1.16. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T(φ)whose DAG equals that of this ﬁgure are not satisﬁable. In particular, all propositions T( φ) whose DAG is less than this DAG are unsatisﬅable. This SAT solaver has a linear running time in the size of the DAG for T(phi) T( Phi) T (T(phi), T (phi, T (t(phi, t(t(t (t ( 6.2 A cubic solver. This linearity came with a price: our linear sol",
            "children": [
                {
                    "id": "chapter-3-section-1",
                    "title": "Motivation for Verification",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-3-section-2",
                    "title": "Linear-Time Temporal Logic",
                    "content": "perfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nrequest is true. If request is false, the next value of status is not deter-\nmined.\nNote that the case 1: signiﬁes the default case, and that case statements\nare evaluated from the top down: if several expressions to the left of a ‘:’ are\ntrue, then the command corresponding to the ﬁrst, top-most true expression\nwill be executed. The program therefore denotes the transition system shown\nin Figure 3.9; there are four states, each one corresponding to a possible value\nof the two binary variables. Note that we wrote ‘busy’ as a shorthand for\n‘status=busy’ and ‘req’ for ‘request is true.’\nIt takes a while to get used to the syntax of SMV and its meaning. Since\nvariable request functions as a genuine environment in this model, the\nprogram and the transition system are non-deterministic: i.e., the ‘next\nstate’ is not uniquely deﬁned. Any state transition based on the behaviour\nof status comes in a pair: to a successor state where request is false, or\ntrue, respectively. For example, the state ‘¬req, busy’ has four states it can\nmove to (itself and three others).\nLTL speciﬁcations are introduced by the keyword LTLSPEC and are sim-\nply LTL formulas. Notice that SMV uses &, |, -> and ! for ∧, ∨, →and\n¬, respectively, since they are available on standard keyboards. We may\n3.3 Model checking: systems, tools, properties\n193\nreq\nready\nbusy\nreq\n¬req\nbusy\nready\n¬req\nFigure 3.9. The model corresponding to the SMV program in the text.\neasily verify that the speciﬁcation of our module main holds of the model in\nFigure 3.9.\nModules in SMV\nSMV supports breaking a system description into sev-\neral modules, to aid readability and to verify interaction properties. A mod-\nule is instantiated when a variable having that module name as its type is perfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nLiveness: Messages get through eventually. Thus, for any state there is\ninevitably a future state in which the current message has got through. In\nthe module sender, we speciﬁed G F st=sent. (This speciﬁcation could\nequivalently have been written in the main module, as G F S.st=sent.)\nSimilarly, acknowledgements get through eventually. In the module\nreceiver, we write G F st=received.\n3.4 Branching-time logic\nIn our analysis of LTL (linear-time temporal logic) in the preceding sections,\nwe noted that LTL formulas are evaluated on paths. We deﬁned that a state\nof a system satisﬁes an LTL formula if all paths from the given state satisfy\nit. Thus, LTL implicitly quantiﬁes universally over paths. Therefore, prop-\nerties which assert the existence of a path cannot be expressed in LTL. This\nproblem can partly be alleviated by considering the negation of the property\nin question, and interpreting the result accordingly. To check whether there\n208\n3 Verification by model checking\nexists a path from s satisfying the LTL formula φ, we check whether all paths\nsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-\ntion, and vice versa. We used this approach when analysing the ferryman\npuzzle in the previous section. However, as already noted, properties which\nmix universal and existential path quantiﬁers cannot in general be model\nchecked using this approach, because the complement formula still has a mix.\nBranching-time logics solve this problem by allowing us to quantify ex-\nplicitly over paths. We will examine a logic known as Computation Tree\nLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X of\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nbut this is only so if interpreted on paths (π ⊨φ). We cannot assert such a\npossibility if interpreted on states (s ⊨φ) since we cannot express the existence\nof paths; for that interpretation, the negation of the formula above asserts that\nall paths will eventually get to such a state.\n184\n3 Verification by model checking\nr For any state, if a request (of some resource) occurs, then it will eventually be\nacknowledged:\nG (requested →F acknowledged).\nr A certain process is enabled inﬁnitely often on every computation path:\nG F enabled.\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nF G deadlock.\nr If the process is enabled inﬁnitely often, then it runs inﬁnitely often.\nG F enabled →G F running.\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nG (floor2 ∧directionup ∧ButtonPressed5 →(directionup U floor5))\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nThere are some things which are not possible to say in LTL, however. One\nbig class of such things are statements which assert the existence of a path,\nsuch as these ones:\nr From any state it is possible to get to a restart state (i.e., there is a path from\nall states to a state satisfying restart).\nr The lift can remain idle on the third ﬂoor with its doors closed (i.e., from the\nstate in which it is on the third ﬂoor, there is a path along which it stays there).\nLTL can’t express these because it cannot directly assert the existence of\npaths. In Section 3.4, we look at Computation Tree Logic (CTL) which has\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ. resolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\ntime-consuming and local ‘ﬁxes’ often introduce new bugs at other places. Ex-\nperience has shown that verifying programs with respect to formal speciﬁcations\ncan signiﬁcantly cut down the duration of software development and maintenance\nby eliminating most errors in the planning phase and helping in the clariﬁcation\nof the roles and structural aspects of system components.\nr Refactoring: Properly speciﬁed and veriﬁed software is easier to reuse, since\nwe have a clear speciﬁcation of what it is meant to do.\nr Certiﬁcation audits: Safety-critical computer systems – such as the control\nof cooling systems in nuclear power stations, or cockpits of modern aircrafts –\ndemand that their software be speciﬁed and veriﬁed with as much rigour and\nformality as possible. Other programs may be commercially critical, such as ac-\ncountancy software used by banks, and they should be delivered with a warranty:\na guarantee for correct performance within proper use. The proof that a program\nmeets its speciﬁcations is indeed such a warranty.\n258\n4 Program verification\nThe degree to which the software industry accepts the beneﬁts of proper\nveriﬁcation of code depends on the perceived extra cost of producing it and\nthe perceived beneﬁts of having it. As veriﬁcation technology improves, the\ncosts are declining; and as the complexity of software and the extent to which\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nmically by a computer. As we will see, there are often good heuristics\nto help the programmer complete these tasks. This contrasts with the\nsituation of the last chapter, which was fully automatic.\nProperty-oriented. Just like in the previous chapter, we verify proper-\nties of a program rather than a full speciﬁcation of its behaviour.\n256\n4.1 Why should we specify and verify code?\n257\nApplication domain. The domain of application in this chapter is se-\nquential transformational programs. ‘Sequential’ means that we assume\nthe program runs on a single processor and that there are no concur-\nrency issues. ‘Transformational’ means that the program takes an input\nand, after some computation, is expected to terminate with an output.\nFor example, methods of objects in Java are often programmed in this\nstyle. This contrasts with the previous chapter which focuses on reactive\nsystems that are not intended to terminate and that react continually\nwith their environment.\nPre/post-development. The techniques of this chapter should be used\nduring the coding process for small fragments of program that perform\nan identiﬁable (and hence, speciﬁable) task and hence should be used\nduring the development process in order to avoid functional bugs.\n4.1 Why should we specify and verify code?\nThe task of specifying and verifying code is often perceived as an unwel-\ncome addition to the programmer’s job and a dispensable one. Arguments\nin favour of veriﬁcation include the following:\nr Documentation: The speciﬁcation of a program is an important component\nin its documentation and the process of documenting a program may raise or\nresolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\ninto an ‘equivalent’ formula φR of some symbolic logic;\nr Write a program P which is meant to realise φR in the programming environment\nsupplied by your company, or wanted by the particular customer;\nr Prove that the program P satisﬁes the formula φR.\nThis scheme is quite crude – for example, constraints may be actual design\ndecisions for interfaces and data types, or the speciﬁcation may ‘evolve’\n4.2 A framework for software verification\n259\nand may partly be ‘unknown’ in big projects – but it serves well as a ﬁrst\napproximation to trying to deﬁne good programming methodology. Several\nvariations of such a sequence of activities are conceivable. For example,\nyou, as a programmer, might have been given only the formula φR, so you\nmight have little if any insight into the real-world problem which you are\nsupposed to solve. Technically, this poses no problem, but often it is handy\nto have both informal and formal descriptions available. Moreover, crafting\nthe informal requirements R is often a mutual process between the client\nand the programmer, whereby the attempt at formalising R can uncover\nambiguities or undesired consequences and hence lead to revisions of R.\nThis ‘going back and forth’ between the realms of informal and formal\nspeciﬁcations is necessary since it is impossible to ‘verify’ whether an infor-\nmal requirement R is equivalent to a formal description φR. The meaning\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nin an integrated in-house development environment.\nCurrently, many companies struggle with a legacy of ancient code with-\nout proper documentation which has to be adapted to new hardware and\nnetwork environments, as well as ever-changing requirements. Often, the\noriginal programmers who might still remember what certain pieces of code\nare for have moved, or died. Software systems now often have a longer\nlife-expectancy than humans, which necessitates a durable, transparent and\nportable design and implementation process; the year-2000 problem was just\none such example. Software veriﬁcation provides some of this.\n4.2 A framework for software verification\nSuppose you are working for a software company and your task is to write\nprograms which are meant to solve sophisticated problems, or computations.\nTypically, such a project involves an outside customer – a utility company,\nfor example – who has written up an informal description, in plain English,\nof the real-world task that is at hand. In this case, it could be the devel-\nopment and maintenance of a database of electricity accounts with all the\npossible applications of that – automated billing, customer service etc. Since\nthe informality of such descriptions may cause ambiguities which eventually\ncould result in serious and expensive design ﬂaws, it is desirable to condense\nall the requirements of such a project into formal speciﬁcations. These formal\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\n1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically, constraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ.\nThe equivalence of φ and ψ means that φ and ψ are semantically inter-\nchangeable. If φ is a subformula of some bigger formula χ, and ψ ≡φ, then\nwe can make the substitution of ψ for φ in χ without changing the meaning\nof χ. In propositional logic, we saw that ∧and ∨are duals of each other,\nmeaning that if you push a ¬ past a ∧, it becomes a ∨, and vice versa:\n¬(φ ∧ψ) ≡¬φ ∨¬ψ\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n(Because ∧and ∨are binary, pushing a negation downwards in the parse\ntree past one of them also has the eﬀect of duplicating that negation.)\n3.2 Linear-time temporal logic\n185\nSimilarly, F and G are duals of each other, and X is dual with itself:\n¬G φ ≡F ¬φ\n¬F φ ≡G ¬φ\n¬X φ ≡X ¬φ.\nAlso U and R are duals of each other:\n¬(φ U ψ) ≡¬φ R ¬ψ\n¬(φ R ψ) ≡¬φ U ¬ψ.\nWe should give formal proofs of these equivalences. But they are easy, so we\nleave them as an exercise to the reader. ‘Morally’ there ought to be a dual\nfor W, and you can invent one if you like. Work out what it might mean,\nand then pick a symbol based on the ﬁrst letter of the meaning. However, it\nmight not be very useful.\nIt’s also the case that F distributes over ∨and G over ∧, i.e.,\nF (φ ∨ψ) ≡F φ ∨F ψ\nG (φ ∧ψ) ≡G φ ∧G ψ.\nCompare this with the quantiﬁer equivalences in Section 2.3.2. But F does\nnot distribute over ∧. What this means is that there is a model with a\npath which distinguishes F (φ ∧ψ) and F φ ∧F ψ, for some φ, ψ. Take the\npath s0 →s1 →s0 →s1 →. . . from the system of Figure 3.3, for example;\nit satisﬁes F p ∧F r but it doesn’t satisfy F (p ∧r).\nHere are two more equivalences in LTL:\nF φ ≡⊤U φ\nG φ ≡⊥R φ.\nThe ﬁrst one exploits the fact that the clause for Until states two things:\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nConsider the path π = s1 →s2 →. . . . It represents a possible future of\nour system: ﬁrst it is in state s1, then it is in state s2, and so on. We write\nπi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .\n180\n3 Verification by model checking\np, q\nr\nr\nr\nq, r\np, q\nq, r\ns0\ns2\ns2\ns2\ns0\ns1\ns1\nr\ns2\nr\ns2\nFigure 3.5. Unwinding the system of Figure 3.3 as an infinite tree of\nall computation paths beginning in a particular state.\nIt is useful to visualise all possible computation paths from a given state\ns by unwinding the transition system to obtain an inﬁnite computation tree.\nFor example, if we unwind the state graph of Figure 3.3 for the designated\nstarting state s0, then we get the inﬁnite tree in Figure 3.5. The execu-\ntion paths of a model M are explicitly represented in the tree obtained by\nunwinding the model.\nDeﬁnition 3.6 Let M = (S, →, L) be a model and π = s1 →. . . be a path\nin M. Whether π satisﬁes an LTL formula is deﬁned by the satisfaction\nrelation ⊨as follows:\n1.\nπ ⊨⊤\n2.\nπ ̸⊨⊥\n3.\nπ ⊨p iﬀp ∈L(s1)\n4.\nπ ⊨¬φ iﬀπ ̸⊨φ\n5.\nπ ⊨φ1 ∧φ2 iﬀπ ⊨φ1 and π ⊨φ2\n6.\nπ ⊨φ1 ∨φ2 iﬀπ ⊨φ1 or π ⊨φ2\n7.\nπ ⊨φ1 →φ2 iﬀπ ⊨φ2 whenever π ⊨φ1\n8.\nπ ⊨X φ iﬀπ2 ⊨φ\n9.\nπ ⊨G φ iﬀ, for all i ≥1, πi ⊨φ\n3.2 Linear-time temporal logic\n181\ns0\ns1\ns2\ns3\ns4\ns5\ns6\ns7\ns8\ns9\ns10\n\u0001\n\u0002\u0003\n\u0004\np\nq\n. . .\nFigure 3.6. An illustration of the meaning of Until in the semantics of\nLTL. Suppose p is satisfied at (and only at) s3, s4, s5, s6, s7, s8 and q is\nsatisfied at (and only at) s9. Only the states s3 to s9 each satisfy p U q\nalong the path shown.\n10.\nπ ⊨F φ iﬀthere is some i ≥1 such that πi ⊨φ\n11.\nπ ⊨φ U ψ iﬀthere is some i ≥1 such that πi ⊨ψ and for all j = 1, . . . , i −1\nwe have πj ⊨φ\n12.\nπ ⊨φ W ψ iﬀeither there is some i ≥1 such that πi ⊨ψ and for all j =\n1, . . . , i −1 we have πj ⊨φ; or for all k ≥1 we have πk ⊨φ\n13.\nπ ⊨φ R ψ iﬀeither there is some i ≥1 such that πi ⊨φ and for all j = 1, . . . , i\nwe have πj ⊨ψ, or for all k ≥1 we have πk ⊨ψ. exist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nWriting W in terms of U is also possible: W is like U but also allows the\npossibility of the eventuality never occurring:\nφ W ψ ≡φ U ψ ∨G φ.\n(3.3)\nInspection of clauses 12 and 13 reveals that R and W are rather similar. The\ndiﬀerences are that they swap the roles of their arguments φ and ψ; and the\nclause for W has an i −1 where R has i. Therefore, it is not surprising that\nthey are expressible in terms of each other, as follows:\nφ W ψ ≡ψ R (φ ∨ψ)\n(3.4)\nφ R ψ ≡ψ W (φ ∧ψ).\n(3.5)\n3.2.5 Adequate sets of connectives for LTL\nRecall that φ ≡ψ holds iﬀany path in any transition system which sat-\nisﬁes φ also satisﬁes ψ, and vice versa. As in propositional logic, there is\nsome redundancy among the connectives. For example, in Chapter 1 we saw\nthat the set {⊥, ∧, ¬} forms an adequate set of connectives, since the other\nconnectives ∨, →, ⊤, etc., can be written in terms of those three.\nSmall adequate sets of connectives also exist in LTL. Here is a summary\nof the situation.\nr X is completely orthogonal to the other connectives. That is to say, its presence\ndoesn’t help in deﬁning any of the other ones in terms of each other. Moreover,\nX cannot be derived from any combination of the others.\nr Each of the sets {U, X}, {R, X}, {W, X} is adequate. To see this, we note that\n– R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and\nequivalence (3.4) followed by the duality, respectively.\n– U and W may be deﬁned from R, by the duality φ U ψ ≡¬(¬φ R ¬ψ) and\nequivalence (3.4), respectively.\n– R and U may be deﬁned from W, by equivalence (3.5) and the duality φ U\nψ ≡¬(¬φ R ¬ψ) followed by equivalence (3.5).\nSometimes it is useful to look at adequate sets of connectives which do not\nrely on the availability of negation. That’s because it is often convenient to\nassume formulas are written in negation-normal form, where all the negation\nsymbols are applied to propositional atoms (i.e., they are near the leaves\n3.3 Model checking: systems, tools, properties\n187\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\nare not, exhibit a model of one of the pair which is not a model of the\nother:\n(a) EF φ and EG φ\n(b)\n*\nEF φ ∨EF ψ and EF (φ ∨ψ)\n(c)\n*\nAF φ ∨AF ψ and AF (φ ∨ψ)\n(d) AF ¬φ and ¬EG φ\n(e)\n*\nEF ¬φ and ¬AF φ\n(f) A[φ1 U A[φ2 U φ3]] and A[A[φ1 U φ2] U φ3], hint: it might make it simpler\nif you think ﬁrst about models that have just one path\n(g) ⊤and AG φ →EG φ\n(h)\n*\n⊤and EG φ →AG φ.\n11. Find operators to replace the ?, to make the following equivalences:\n250\n3 Verification by model checking\n(a)\n*\nAG (φ ∧ψ) ≡AG φ ? AG ψ\n(b) EF ¬φ ≡¬??φ\n12. State explicitly the meaning of the temporal connectives AR etc., as deﬁned on\npage 217.\n13. Prove the equivalences (3.6) on page 216.\n14.\n*\nWrite pseudo-code for a recursive function TRANSLATE which takes as input\nan arbitrary CTL formula φ and returns as output an equivalent CTL formula\nψ whose only operators are among the set {⊥, ¬, ∧, AF , EU , EX }.\nExercises 3.5\n1. Express the following properties in CTL and LTL whenever possible. If neither\nis possible, try to express the property in CTL*:\n(a)\n*\nWhenever p is followed by q (after ﬁnitely many steps), then the system\nenters an ‘interval’ in which no r occurs until t.\n(b) Event p precedes s and t on all computation paths. (You may ﬁnd it easier\nto code the negation of that speciﬁcation ﬁrst.)\n(c) After p, q is never true. (Where this constraint is meant to apply on all\ncomputation paths.)\n(d) Between the events q and r, event p is never true.\n(e) Transitions to states satisfying p occur at most twice.\n(f)\n*\nProperty p is true for every second state along a path.\n2. Explain in detail why the LTL and CTL formulas for the practical speciﬁcation\npatterns of pages 183 and 215 capture the stated ‘informal’ properties expressed\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-",
                    "summary": "Linear-time temporal logic, or LTL, is a temporal logic with con-nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of these paths might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or p1, p2) Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. X means ‘neXt state,’ F means. ‘someFuture state’ and G means � ‘all future states (Globally).’ The next three, U,R and W are called ‘Until,  ‘Release  and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. The example formula above can                be written ¬p W q, or equivalently ¬(¬q U (p ∧¬Q) if one wants to avoid W. It is possible to write G (q →O p) without using past operators. The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long and the formula we are interested in checking is quite long. The formula is the basic model-checking question. For more information, visit the LTL website or the CTL website. The CTL version of this article has been updated to include the new model- checking algorithm. For the full version, see the LTCL website. CTL is generally preferred by speciﬁers, as already noted. It is therefore well worth trying to ﬁnd eﬃcient algorithms. We start with CTL model checking because its algorithm is simpler. R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. The unary connectives (consisting of ¬ and the temporal connectives X, F and G) bind most tightly. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. We assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The parse tree of F p →G r is illustrated in Figure 3.2. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities. Others, however, are required to resolve ambiguisms. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would become: F p →G r ∨¬q U p, corresponding to the parse tree of Figure 3. 2. The following are not well-formed formulas: U r – since U is binary, not unary – and p G q – since G is unary, not binary. A subformula of an LTL formula φ is any formula ψ whose parse tree is a subtree of φ’s parse tree. A model as a whole satisﬁes an LTL formula. The formulas G p →p, p →q U p and p →F p are true in every state of every model. We will examine algorithms which implement this calcula-tion later in this chapter. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later in the chapter, we will examine an algorithm which implements this pro-                             cedure. We conclude with the conclusion that the future shall include the present and that the formula G p is true in all states of the system. Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. The kinds of systems we are interested in verifying using LTL may be modelled as transition systems. A transition system models a system by means of states (static structure) and transitions (dynamic structure) The following are not well-formed formulas: U r – since U is binary, not unary. p G q – since G is unary, not binary. p W (q U r), e.g., are p, q, r, q U r and p W   (q  U r) 3.2.2 Semantics of LTL: Verification by model checking. 3.3.2 Verification of the LTL model: Verifying the model by model check. A model has a collection of states S, a relation →, saying how the system can move from state to state. With each state s, one has the set ofatomic propositions L(s) which are true at that particular state. We write                P(Atoms) for the power set of Atoms, aCollection of atomic descriptions. For example, the powerSet of {p, q} is {∅, {p}, {q}, { p, q}}. We may conveniently express all the information about a (ﬁnite) tran- tumultuous system M using directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. For example, if our system has only three states s0, s1 and s2, we check G F φ →ψ. This means: all paths satisfying inﬃnitely often φ also satisfy ψ. It is not possible to express this emphaticallyin CTL. The LTL model-checking algorithm is based on the CTL algorithm for model checking. For more information on the LTL algorithm, see LTL Algorithm. LTL model checking has to adopt a diﬀerent                strategy. We explain that strategy ﬁrst; then, we describe some algo-                rithms in more detail. The basic strategy is: Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along paths of M starting at s. Almost all LTL model Checking algorithms proceed along the following three steps:Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton The program has four states, each one corresponding to a possible value of the two binary variables. The program therefore denotes the transition system shown in Figure 3.9. If request is false, the next value of status is not deter-                mined. If several expressions to the left of a ‘:’ aretrue, then the command corresponding to the ﬁrst, top-most true expression will be executed. The construction has theproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other words, the automaton A ω encodes precisely the traces which satisfy ψ: ω: � It takes a while to get used to the syntax of SMV and its meaning. Sincevariable request functions as a genuine environment in this model, the program and the transition system are non-deterministic. For example, the state ‘¬req, busy’ has four states it can move to (itself and three others). LTL speciﬁcations are introduced by the keyword LTLSPEC and are sim-reprehensible LTL formulas. Notice that SMV uses &, |, -> and ! for  and  respectively, since they are available on standard keyboards. We may also use &, →, → and ! as well for the LTL specifiers. SMV supports breaking a system description into sev-                eral modules, to aid readability and to verify interaction properties. A mod-                ule is instantiated when a variable having that module name as its type is perfect circles, or an experiment without friction. These abstractions are very powerful, for they allow us to focus on the essentials of our particular concern. We can easily verify that the speciﬁcation of our module main holds of the model in Figure 3.9.2.Figure 3. 9.2 is the model corresponding to the SMV program in the text. The model is called Linear-time temporal logic (LTL) Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form: p is any propositional atom from some set Atoms. In general, the future is not determined, so we consider several paths, representing diﬀerent possiblefutures, any one of which might be the ‘actual’ path that is realised. We work with a ﬁxed set of atomic formulas (such as p, q, r, . . . ). These atoms stand for atomic facts which may hold of a system, like ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended’ and ‘The content of register R1 The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms. The connectives X, F, G, U, R, and W are called temporal connectives. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of the LTL symbols. The parse tree of (F (p →G r)  is an LTL formula if φ is one, etc. The syntax of LTL is as follows: (F p) (G q) (U p) U p (R r) R p Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E.weak-until (W) and release (R) are not included in CTL, but they are derivable. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) in LTL. Any p is eventually followed by a q in both LTL and CTL. We just saw that some (but not all) LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For more information on CTL and LTL click here. In fact, AF AG p is strictly stronger than F G p. While the LTL formulas X F p and F X p are equivalent, they are not equivalent to AF AX p. CTL* is more expressive than either of them, but is computationally more expensive. The choice between LTL and CTL depends on the application at hand, and on personal prefer-iness. LTL lacks CTL’s ability to quantify over paths, and C TL lacks LTL”s ability. to describe individual paths. We have seen that they have incomparable expressivepowers. We discuss two more negative examples: F G and AF AG. The latter has quite a strange meaning (try working it out). LTL can be viewed as a subset of CTL*. CTL* is a fragment of LTL* in which we restrict the form of path formulas. LTL formula α is equivalent to the C TL* formula α[A] Figure 3.23 shows the relationship among the expressive powers of C TL, LTL, and CTL*, as well as some examples of formulas in each of the subsets. The expressive power of the two subsets is shown in the figure 3.5. The relationship between CTL and LTL is also shown inFigure 3.3. The expression LTL-CTL is the same as the expression CTL-CTL*. The difference between the two is that LTL The proof that AG EF p is not expressible in LTL is as follows. Let M′ be as shown in the right-hand diagram. The paths from s into M′ are a subset of those from s in M. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. The proof is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given in the references. The expressive powers of CTL, LTL and CTL*.shown:                In CTL but not in L TL: ψ1def= AG EF. p. This expresses: wherever we                have got to, we can always get In LTL but not in CTL: ψ3apologetic= A[G F p →F q], saying that if there are in-                ﬁnitely many p along the path, then there is an occurrence of q. (Why is it not expressible in LTL?) For any state there is inevitably a future state in which the current message has got through. In LTL and CTL, G (p →Fq) is the same as G F st in the main module, or G F S.st in the module sender. We just saw that some (but not all) LTL formulas can be written in a similar way to CTL. In our analysis of LTL (linear-time temporal logic) in the preceding sections, we noted that LTL formulas are evaluated on paths. A state of a system satisﬁes an LTL formula if all paths from the given state satisfy it. We used this approach when analysing the ferrymancompetitivepuzzle in the previous section. In the module grotesquereceiver, we write G F st=received. We then check whether all pathsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-                tion, and vice versa. We conclude that theorem LTL can only be expressed in terms of paths. Branching-time logics solve this problem by allowing us to quantify ex-plicitly over paths. We will examine a logic known as Computation TreeLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X, we also have quantiﬁers A and E which express ‘all paths’ and ‘exists a path’, respectively. For example, we can write: There is a reachable state satisfying q: this is written EF q. From all reachable states satisfying p, it is possible to maintain p continuously in which the future excludes the present. A consequence of adopting the convention that the future shall include the A model as a whole is an LTL formula. This is deﬁned to hold whenever every possible execution path of the model sits on the formula. Later in this chapter, we will examine algorithms which implement this calcula-                cyntion. We write M, s ⊨φ if, for every execution path π of M starting at the beginning of the formula, we have π ⋅. If M is clear from the context, we may abbreviate M,  by s ⋉. We have outlined the formal foundations of a pro-                cure that can check whether Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. NuSMV supports past operators in LTL. One could also add past opera-tors to CTL (AY, ES, etc.) but NuSMV does not support them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. However, recall that LTL equivalence is quite crude: it says that the two formulas are satisﬁed by exactly the same set of paths. The past operators allow us to travel backwards along the path, but only to reach points we could have reached by travelling forwards from its beginning. The example formula above can be written ¬p W q, or equival The semantic deﬁnitions for LTL and CTL are presented in Sections 3.2 and 3.4. We start with CTL model checking because its algorithm is simpler. In general, inter-esting transition systems will have a huge number of states. Verification by model checking can take a long time, so it is well worth trying to develop an eﬃcient algorithm. We conclude by looking at the results of our model-checking algorithm for CTL and LTL. The results are published in the book CTL: A Model-checking Algorithm for Inter-esting Transition Systems, published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. This is only so if interpreted on paths (π ⊨φ). However For any state, if a request (of some resource) occurs, then it will eventually be acknowledged. A certain process is enabled inﬁnitely often on every computation path. Whatever happens, a certain process will eventually become permanently deadlocked. An upwards travelling lift at the second ﬂoor does not change its direction when passengers wish to go to the ﬁfth. The atomic descriptions are boolean expressions built from system vari-ables, e.g., floor2. There are some things which are not possible to say in LTL, however. For example, we cannot assert such a                possibility if interpreted on states (s ⊨φ) since we cannot express the existence of paths LTL can’t express these because it cannot directly assert the existence of Paths. In Section 3.4, we look at Computation Tree Logic (CTL) which hasoperators for quantifying over paths, and can express these properties. We say that two LTL formulas φ and ψ are semanticallyequivalent, or simply equivalent, writing φ  i u p u in CTL. We also say that for all models M and all Paths π in M: π ⊨φ iﬀπ ≉ resolve important issues. In section 3.2.4 we show that the equivalences between LTL and CTL formulas are The logical structure of the formal speciﬁcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. Debugging big systems during the testing phase is costly and time Properly speciﬁed software is easier to reuse, since it has a clear speci ﬁcation of what it is meant to do. Safety-critical computer systems – such as the control of cooling systems in nuclear power stations, or cockpits of modern aircrafts – demand that their software be speci credible. Other programs may be commercially critical, such as ac countancy software used by banks, and they should be delivered with a warranty: a guarantee for correct performance within proper use. Ex-perience has shown that verifying programs with respect to formal specians can cut down the duration of software development and maintenance. The degree to which the software industry accepts the beneﬁts of proper Verification depends on the perceived extra cost of producing it. Microsoft’s emergent technology. # combines program veri ﬁcation, testing, and model-checking techniques. As we will see, there are often good heuristics to help the programmer complete these tasks. This contrasts with the.situation of the last chapter, which was fully automatic. The importance of Verification to industry will.continue to increase over the next decades. The proof that a program.meets its speciﬅcations is indeed such a warranty. The domain of application in this chapter is se-quential transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems that are not intended to terminate and that react continually with their environment.Pre/post-development. Pre- and post-development of programs. Pre/post development of programs that are intended to run on a single processor and that have no concur-rency issues. Pre and post development of a program that is intended The techniques of this chapter should be used.during the coding process for small fragments of program that perform. an identiﬁable task. The techniques should also be used during the development process in order to avoid functional bugs. 4.1 Why should we specify and verify code? The task of specifying and verifying code is often perceived as an unwel-                come addition to the programmer’s job and a dispensable one. The logical structure of the formal speciﬃcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The process of documenting a program may raise or alleviate important issues. A framework for producing the software could be: Convert the informal description R of requirements for an application domain into an ‘equivalent’ formula φR of some symbolic logic. Write a program P which is meant to realise that formula. Prove that the program P satisﬁes the formula. This scheme is quite crude – for example, constraints may be actual design decisions for interfaces and data types, or the speci ﬁcation may ‘evolve’4.2 A framework for software verification may partly be ‘unknown’ in big projects – but it serves well as a approximation to good programming methodology. For example, as a programmer, might have been given only the The meaning of R as a piece of natural language is grounded in common sense. The attempt at formalising R can uncoverambiguities or undesired consequences and hence lead to revisions of R. It is impossible to ‘verify’ whether an infor-cular requirement R is equivalent to a formal description φR. The meaningof R is based on heuristics or quantitative reasoning and often based on real-world knowledge about the domain. The ‘going back and forth’ between the realms of informal and formalspeciﬁcations Microsoft’s emergent technology seamlessly combines program veriﬁcation, testing, and model-checking techniques in an integrated in-house development environment. Software systems now often have a longer life-expectancy than humans, which necessitates a durable, transparent and                portable design and implementation process. The meaning of a logic formula φR, on the other hand, is de ﬁned in a precise mathematical, qualitative and compositional way. As society depends on it more and more, the beneﬃts are becoming more important. We can expect that the importance of veri-cation to industry will continue to increase over the next decades. Software veriﬁcation provides some of this framework for software verification. It is a way of condensing the requirements of such a project into formal speci ﬁcations. These formalspeciﬀcations are usually symbolic encodings of real-world constraints into some sort of logic. For example, it could be the devel-                opment and maintenance of a database of electricity accounts with all the possible applications of that – automated billing, customer service etc. It could also be the creation of an online bank account database. For more information on software verification, see the Software Verification Handbook. The book, published by Oxford University Press, is available in English and French. Convert the informal description R of requirements for an application domain into a logical formula R. R is grounded in common sense and gen-                eral knowledge about the real-world domain. The meaning of a logic formula φR is deﬁned in a precise mathematical, qualitative and compositional way by structural induction on the parse tree of R. To make matters worse, the requirements R are often inconsistent; customers usually have a fairly vagueception of what exactly a program should do for them. Thus, a framework for producing the software could be: Convert R into a formalisation of the formalisation R of the application domain R as a piece of natural language. The process of formalising R requires the utmost care. Producing a clear and coherent description R of the requirements for an application do-                main is already a crucial step in successful programming. We address this ﬁrst item only implicitly in this text, but you should certainly be aware of its importance in practice. The programming language which we set out to study here is the typicalcore language of most imperative programming languages. The next phase of the software development framework involves construct-                ing the program P and after that the last task is to verify that P satisﬁes φR. The correspondence between proving and program-                ming can be stated quite precisely, but that is beyond the scope of this book. The book includes a core programming language for imperative languages Program verification is a subset of Pascal, C, C++ and Java. Our lan-guage consists of assignments to integer- and boolean-valued variables. If-and refer to a method’s object. Upon validation, this contract.establishes that all calls to withdraw leave (the ‘object. invariant’) 0 <= 0 <= balance invariant 4.7 Bibliographic notes. Backhouse’S book [Bac86] describes program logic and weakest precondi-tions and also contains numerous examples and exercises. Other books [AO91, Fra92] extend the basic core language to in-clude features such as procedures and parallelism. In propositional or predicate logic, formulas are either true, or false, in any model. Propositional logic and predicate logic do not allow for any further possibilities. The issue of writing to.                arrays and the problem of array cell. aliasing are described in [Fra92]. The. article describing the minimal-sum section problem is [Gri82]. A text on functional programming on the freely available. Standard ML of New Jersey is [Pau91].8 www.opensource.org                9 www.sims.berkeley.edu/~pam/papers.html676.5. Modal logics and agents                5.1 Modes of truth The tool was developed by D. Jackson at the Massachusetts Institute of Technology. The tool has a dedicated repository website at                alloy.mit.edu. More information on typed higher-order logics and their use in the.modelling and verifying of programming frameworks can be found on F.Pfenning’s course homepage7 on Computation and. Deduction. The book, The Typed Higher-order Logics of Programming, is published by Oxford University Press, priced £16.99, is available in hard copy and soft copy for £12.99. Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The veriﬁcation method consists of trying to prove that a formula is a formula. This typically requires guidance and expertise from the user. We will model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to see if prerequisites in the form of libraries or other packages are present. The formal models attached to software products can be seen as aiability contract; a promise that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬁed therein. We will use a formula that captures formally static and dynamic system structure and behaviour. This formula can be used to verify consistency of the constrained design space and to test the correctness of claims about static andynamic aspects of all its compliant implementations. It can also boost our conﬀdence into the Software package dependency systems are used in several computer systems. Users often have to guess how technical questions get resolved within the system. To the best of our knowledge, there is no publicly available model of any particular dependency system to which application programmers could turn if they had non-trivial technicalquestions about its inner workings. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things, such as a database or a file system, for example. The requirements on a software package dependency system are not straightfor-                ward. The upgrading process can go wrong in various ways. For example, upgrading a package can involve replacing older versions of shared Some LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) We discuss two more negative examples: F G p and AF AG p are not equivalent. The latter is strictly stronger, and has quite a strange meaning (try working it out). There is a considerable literature comparing linear-time and branching-time logics. For more information, see the book ‘LTL and Branching Time Logics’, published by Oxford University Press, priced £16.99, £19.99. CTL* is more expressive than either of them, but is computationallymuch more expensive. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL's ability to describe individual paths. To many people, LTL ap- grotesquepears to be more straightforward to use; as noted above, CTL formulas likeAF AX p seem hard to understand. CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn’t allow nest-inducing of path modalities X, F and G. The choice between CTL and LTL depends on the application at hand, and on personal prefer-                ence. There is some redundancy among the CTL connectives. For example, the connective AX can be written ¬EX ¬; and AG, AF, EG and EF can't be written in terms of AU and EU. The equivalences between CTL and LTL are similar to the corresponding equivalences in LTL. In LTL, the equivalences for CTL are: AF φ ≡A[⊤U φ] EG φ  equivalent to EF φ equivalence of AG (3.4.6) and E[ ⊥U � Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX, AF, AU, EG, EU, and EX. Theorem is proved in a paper referenced in the bibliographic notes at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it is valid in the logic CTL* introduced in the next section. For example, we have the equivalence: A[φ U ψ] ≡¬(E[¬ φ U (¬φ ∧¬hy),  “EG” U ( The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in CTL. The temporal connectives AR, ER, AW and EW are all deﬁnable in the same way as the connectives EU, W, ER and EW. The equivalences are justiﬃed by LTL equivalences in Sections 3.2.4 and 3.5.    Theorem: The connectives E, W and W are all justi ﬁrable in a similar way to the connective E, R and W in theorems such as those in the theory of relativity. For example, the intuition for the third one is the following: in order to have AF φ in a particular state, φ must be true at some point along each path                from that state. Notice how this equivalence appears to deﬁne AF in terms of AX and AF itself, an apparently circular de nition. In fact, these equivalences can be used to de ﬁnition the six connectives on the left in a non-circular way, in a way that is not circular at all. For example, in the equivalence between AF and AX, we can say that AF is true now, but not in the future. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. NuSMV supports past operators in LTL, but not CTL. Past operators do not increase the expres-                sive power of LTL. Every LTL formula with past operators can be written equivalently without them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. For example, the formula AF p →AF q means2182182183 Verification by model checking                something quite diﬀerent: it says ‘if all paths have a p along them, then                allpaths have a q along them’ One could also add past opera-                tors to CTL The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long and the formula we are interested in checking is quite long. The formula is the basic model-checking question. For more information, visit the LTL website or the CTL website. The CTL version of this article has been updated to include the new model- checking algorithm. For the full version, see the LTCL website. CTL is generally preferred by speciﬁers, but we start with CTL model checking because its algorithm is simpler. We say that two LTL formulas φ and ψ are semanticallyequivalent, or simply equivalent, writing φ  i ⊨φ iﬀ ω. If φ is a subformula of some bigger formula χ, we can make the substitution of ψ for φ in χ without changing the meaning of χ. We can express these properties in a model checker for quantifying over paths, and can express the equivalence between LTL and CTL in 3.6.2. Pushing a negation downwards in the parse tree past one of them also has the eﬀect of duplicating that negation. ‘Morally’ there ought to be a dualfor W, and you can invent one if you like. However, it might not be very useful. We should give formal proofs of these equivalences. But they are easy, so we purposefullyleave them as an exercise to the reader. We see that F and G are duals of each other, and X is dual with itself. We also show that F distributes over  and G over  , i.e., F   over  and G over ’’. There are two more equivalences in LTL: F φ and G φ. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. The parse tree of this formula is illustrated in Figure 3.1. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities, for example, p could be written p →F q without ambiguity. The formula for Until can be written P W (q W r) with the same syntax as for Until (p W) (q Q r) (P W r (q q) (Q Q r The unary connectives (consisting of ¬ and the temporalconnectives X, F and G) bind most tightly. Next in the order come U, R and W; then come �; and after that comes →. These binding priorities allow us to drop some brackets without introducing ambiguity. Others, however, are required to resolve ambiguities. In order to omit some of those, we assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would becomeF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.3. A subformula of an LTL formula φ is any formula ψ whoseaple tree is a subtree of φ’s parse tree. Therefore, the LTL. formula α is equivalent to the CTL* formula α[α].  The following are not well-formed formulas:. U r – since U is binary, not unary Figure 3.23 shows the relationship among the expressive powers of CTL, LTL, CTL* and CTL*. Here are some examples of formulas in each of the subsets. The proof that AG EF p is not expressible in LTL is as follows. Let φ be an LTL formula such that A[φ] is allegedly equivalent to AG EF. p. In CTL but not in L TL: ψ1defreprehensive=AG EF p. This expresses: wherever we have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof that this is not expressible in CTL is quite complex and may. be found in the papers co-authored by E. A. Emerson with others. In CTL and LTL, any p is eventually followed by a q. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. This is an interesting thing to be able to say; for example, many fairness.constraints are of the form ‘inﬁnitely often requested implies eventually.acknowledged’. (Why is it not expressable in LTL?) The problem is that some (but not all) LTL formulas can be transformed into CTL formulas. Unwinding the system of Figure 3.3 as an infinite tree of all computation paths beginning in a particular state gives an inﬁnite computation tree. We write                πi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .. Verification by model checking is achieved by checking the transition system for all possible computation paths from a given state. For example, if we unwind the state graph of Figure.3 for the designatedstarting state s0, then we get the in-nite tree in Figure. 3.5. Let M = (S, →, L) be a model and π = s Whether π satisﬁes an LTL formula is deﬀned by the satisfaction.relation ⊨as follows. The satisfactionrelation is the product of p and q. Only the states s3 to s9 each satisfy p U q along the path shown. Figure 3.6. An illustration of the meaning of Until in the semantics of the LTL. The formula p is satisfied at (and only at) s3, s4, s5, s6, s7, s8 and q isatisfied at s9. The satisfying state of p is p U U q. The satisfied state of q is q U U Q. For all k ≥1 we have πk ⊨ψ. There is some redundancy among the CTL connectives. AU, EU and EX form an adequate set of temporal connectives, and EG, EU, and EX are also adequate. Theorem 3.10 is proven by elementary manipu-rophiclation. The remainder is proved by Theorem. 3.4. Adequate sets of C TL connectives are proved by the equivalence of the connective AX to the connectives AG, AF, EG and EF. For example, write AG φ as ¬EF ¬φ, using (3.6), and then useAF φ ≡A[⊤U � Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX,EG, AF, AU } and EU. The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in C TL. The temporal connective AR, ER, AW and EW are all deﬁnable in the logic CTL* and the expressive powers of LTL and CTL. Theorem is proved in a paper referenced in the bibliographic notes referenced at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it Inspection of clauses 12 and 13 reveals that R and W are rather similar. W is like U but also allows the possibility of the eventuality never occurring. Small adequate sets of connectives also exist in LTL. As in propositional logic, there is some redundancy among the connectives. For example, in Chapter 1 we sawthat the set {⊥,  ¬, ¬} forms an adequate set of connective, since the other three connectives can be written in terms of those three. In LTL we see that the set  “”, “ ” and ”” can also be written as such. Sometimes it is useful to look at adequate sets of connectives which do not rely on the availability of negation. Here is a summary of the situation. Each of the sets {U, X,. {R, X}, {W, X} is adequate. X is completely orthogonal to the other connectives. Its presence doesn’t help in deﬁning any of the other ones in terms of each other. Moreover, X cannot be derived from any combination of the others. We note that R and W may be de�ì�ned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and equivalence (3 If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective of φ (i.e., the connective occurring top-most in the tree of χ) is a boolean connective, then the satisfactionquestion is answered by the usual truth-table deﬁnition and further recursion down φ. The result of removing A or E is not strictly an LTLformula, for it may contain further As or Es below.  The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. The parse tree of this formula is illustrated inFigure 3.1. The formulas are illustrated in Figure 3.2 and 3.3. The syntax of the formulas is shown in Figure 4.1 and 4.2. It is easy to see that the formulas are written with brackets. The brackets can be omitted without introducing ambiguities, but some are required to resolve them. For example, p could be written p →F q without ambiguity. We assume similar binding priorities for the LTL connectives to those we assumed forpropositional and predicate logic. The unary connectives (consisting of ¬ and the temporalconnectives X, F and G) bind most tightly. These binding priorities allow us to drop some brackets without introduc-ing ambiguity. In order to omit some of those, we assume binding pri-orities of Convention 3.2.3. The parse tree of F p →G r ∨¬q U p, assuming binding The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would becomeF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.3. An adequate set of connectives for propositional logic is a set such that for every                formula of propositional. logic there is an equivalent formula with only connectivesfrom that set. The examples above can be written:. F p ∧G q →p W r                r F (p →.G r) (q W r)                r G Prove that the set {¬,  ,   is adequate for propositional logic. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that, with respect to the relation  “Idempotent”, the terms  “idempotents” and “ idempotence” are idempotsent. Prove that a relation is symmetric if it holds for all φ and transitive if it’s symmetric for all ”“”. Proving the truth value of a formula  construct a formula in CNF based on each of the following truth tables:. Construct an adequate set as far as the propositional connectives are concerned;. AF , EU and EX form an adequateSet of temporal connectives;. Construct a formula based on the truth tables;. Use the de Morgan rules;. The formula is then written as follows: CNF 89.7 Exercises. CNF89.7.1 Exercise 1. Exercised 1.7exercises 2.2 Exercising 2.3 Exercis 3.4 Exercism 4.5 Exercisms 5.6 Exercisers 6.6Exercises 7. The model-checking algorithm is based on an arbitrary CTL formula φ. The algorithm labels states with subformulas of the form AF ψ1. It then repeats the process until no change is made in the states. The result is the set of states of M which satisfy the subformula of φ, or TRANSLATE ( φ) in terms of the connectives AF, EU, EX, ¬ and ⊥ using the equivalences given earlier in the chapter. For more details on the algorithm, see page 3.6 of the book, ‘Model-checking Algorithms’, published by Oxford University Press, priced £16.99. We determine by a case analysis which states to label with ψ. This step is illustrated in Figure 3.24. If ψ is. ⊥, then no states are labelled with ≥. Then label s with p if p ∈L(s). Then label any state with AF ψ1 if all successor states are. labelled withAF ω1, until there is no change. If s is already labelled with. ω, then label it with ¬ ω if s is not already labelled. with ω. If it is labelled with both ω and ω2, then it should be labelled with the latter. Then, if it is not labelled with either, it should 25. Label any state with EX ψ1 if one of its successors is labelled with ω1. 26. Find operators to replace the ?, to make the following equivalences: 26. Verification by model checking. 27. State explicitly the meaning of the temporal connectives AR etc., as deﬁned on page 217 of the book. 28. Find a model of one of the pair which is not a models of the other. 29. Find an equivalence between the two models, and a way to test whether they are models of each other. 30. Find the difference between two models that are not models of one another, and one of them that is. Pseudo-code for a function TRANSLATE which takes as input an arbitrary CTL formula φ and returns as output an equivalent formula. Prove the equivalences (3.6) on page 216. Express the following properties in CTL and LTL whenever possible: p is true for every second state along a path, q is never true after p, and r occurs at most twice. If neither is possible, try to express the property in the form CTL*: CTL: P, Q, R, r, p, q, r. Exercises 3.5 and 3.6 are shown in detail in the next section of the book. For more information, see the book’s 2. Explain in detail why the LTL and CTL formulas for the practical speciﬁcationpatterns of pages 183 and 215 capture the stated ‘informal’ properties expressed in plain English. 3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →                AF q)}. 4. Describe how the terms of the Ki and CG is de﬉ned in terms of EG. 5. Explain why the CTL and LTL formulas are more general than those for the modal logic KT45n, for which there is a single accessi-bility relation. Let M = (W, (Ri)i∈A, L) be a model for KT45n                338                5 Modal logics and agents. We say that y is G-reachable in k steps from x if there are some k such that it is. G- Reachable in K steps if there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. We prove that x ⊩Ki1Ki2 for any i1, i2, . .. . , ik ∈G and any w1, w2,. . . , wk+1 and y. The formula K holds for the connec-. ik by G-reachability. Take i1, i2, . . . , ik and assume y is G- reachable from x in k steps. We have y ⊩φ by our assumption, so x ⊉Ki1Ki2 . .. Kik φ as required. The argument is similar to that in KT45n.",
                    "children": [
                        {
                            "id": "chapter-3-section-2-subsection-1",
                            "title": "Syntax of LTL",
                            "content": "perfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nrequest is true. If request is false, the next value of status is not deter-\nmined.\nNote that the case 1: signiﬁes the default case, and that case statements\nare evaluated from the top down: if several expressions to the left of a ‘:’ are\ntrue, then the command corresponding to the ﬁrst, top-most true expression\nwill be executed. The program therefore denotes the transition system shown\nin Figure 3.9; there are four states, each one corresponding to a possible value\nof the two binary variables. Note that we wrote ‘busy’ as a shorthand for\n‘status=busy’ and ‘req’ for ‘request is true.’\nIt takes a while to get used to the syntax of SMV and its meaning. Since\nvariable request functions as a genuine environment in this model, the\nprogram and the transition system are non-deterministic: i.e., the ‘next\nstate’ is not uniquely deﬁned. Any state transition based on the behaviour\nof status comes in a pair: to a successor state where request is false, or\ntrue, respectively. For example, the state ‘¬req, busy’ has four states it can\nmove to (itself and three others).\nLTL speciﬁcations are introduced by the keyword LTLSPEC and are sim-\nply LTL formulas. Notice that SMV uses &, |, -> and ! for ∧, ∨, →and\n¬, respectively, since they are available on standard keyboards. We may\n3.3 Model checking: systems, tools, properties\n193\nreq\nready\nbusy\nreq\n¬req\nbusy\nready\n¬req\nFigure 3.9. The model corresponding to the SMV program in the text.\neasily verify that the speciﬁcation of our module main holds of the model in\nFigure 3.9.\nModules in SMV\nSMV supports breaking a system description into sev-\neral modules, to aid readability and to verify interaction properties. A mod-\nule is instantiated when a variable having that module name as its type is",
                            "summary": "Linear-time temporal logic, or LTL, is a temporal logic with con-nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of these paths might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or p1, p2) Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. X means ‘neXt state,’ F means. ‘someFuture state’ and G means � ‘all future states (Globally).’ The next three, U,R and W are called ‘Until,  ‘Release  and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. The example formula above can                be written ¬p W q, or equivalently ¬(¬q U (p ∧¬Q) if one wants to avoid W. It is possible to write G (q →O p) without using past operators. The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long and the formula we are interested in checking is quite long. The formula is the basic model-checking question. For more information, visit the LTL website or the CTL website. The CTL version of this article has been updated to include the new model- checking algorithm. For the full version, see the LTCL website. CTL is generally preferred by speciﬁers, as already noted. It is therefore well worth trying to ﬁnd eﬃcient algorithms. We start with CTL model checking because its algorithm is simpler. R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. The unary connectives (consisting of ¬ and the temporal connectives X, F and G) bind most tightly. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. We assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The parse tree of F p →G r is illustrated in Figure 3.2. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities. Others, however, are required to resolve ambiguisms. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would become: F p →G r ∨¬q U p, corresponding to the parse tree of Figure 3. 2. The following are not well-formed formulas: U r – since U is binary, not unary – and p G q – since G is unary, not binary. A subformula of an LTL formula φ is any formula ψ whose parse tree is a subtree of φ’s parse tree. A model as a whole satisﬁes an LTL formula. The formulas G p →p, p →q U p and p →F p are true in every state of every model. We will examine algorithms which implement this calcula-tion later in this chapter. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later in the chapter, we will examine an algorithm which implements this pro-                             cedure. We conclude with the conclusion that the future shall include the present and that the formula G p is true in all states of the system. Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. The kinds of systems we are interested in verifying using LTL may be modelled as transition systems. A transition system models a system by means of states (static structure) and transitions (dynamic structure) The following are not well-formed formulas: U r – since U is binary, not unary. p G q – since G is unary, not binary. p W (q U r), e.g., are p, q, r, q U r and p W   (q  U r) 3.2.2 Semantics of LTL: Verification by model checking. 3.3.2 Verification of the LTL model: Verifying the model by model check. A model has a collection of states S, a relation →, saying how the system can move from state to state. With each state s, one has the set ofatomic propositions L(s) which are true at that particular state. We write                P(Atoms) for the power set of Atoms, aCollection of atomic descriptions. For example, the powerSet of {p, q} is {∅, {p}, {q}, { p, q}}. We may conveniently express all the information about a (ﬁnite) tran- tumultuous system M using directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. For example, if our system has only three states s0, s1 and s2, we check G F φ →ψ. This means: all paths satisfying inﬃnitely often φ also satisfy ψ. It is not possible to express this emphaticallyin CTL. The LTL model-checking algorithm is based on the CTL algorithm for model checking. For more information on the LTL algorithm, see LTL Algorithm. LTL model checking has to adopt a diﬀerent                strategy. We explain that strategy ﬁrst; then, we describe some algo-                rithms in more detail. The basic strategy is: Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along paths of M starting at s. Almost all LTL model Checking algorithms proceed along the following three steps:Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton The program has four states, each one corresponding to a possible value of the two binary variables. The program therefore denotes the transition system shown in Figure 3.9. If request is false, the next value of status is not deter-                mined. If several expressions to the left of a ‘:’ aretrue, then the command corresponding to the ﬁrst, top-most true expression will be executed. The construction has theproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other words, the automaton A ω encodes precisely the traces which satisfy ψ: ω: � It takes a while to get used to the syntax of SMV and its meaning. Sincevariable request functions as a genuine environment in this model, the program and the transition system are non-deterministic. For example, the state ‘¬req, busy’ has four states it can move to (itself and three others). LTL speciﬁcations are introduced by the keyword LTLSPEC and are sim-reprehensible LTL formulas. Notice that SMV uses &, |, -> and ! for  and  respectively, since they are available on standard keyboards. We may also use &, →, → and ! as well for the LTL specifiers. SMV supports breaking a system description into sev-eral modules, to aid readability and to verify interaction properties. A mod-                ule is instantiated when a variable having that module name as its type is. The model corresponding to the SMV program in the text can be used to verify",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-2-subsection-2",
                            "title": "Semantics of LTL",
                            "content": "perfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nLiveness: Messages get through eventually. Thus, for any state there is\ninevitably a future state in which the current message has got through. In\nthe module sender, we speciﬁed G F st=sent. (This speciﬁcation could\nequivalently have been written in the main module, as G F S.st=sent.)\nSimilarly, acknowledgements get through eventually. In the module\nreceiver, we write G F st=received.\n3.4 Branching-time logic\nIn our analysis of LTL (linear-time temporal logic) in the preceding sections,\nwe noted that LTL formulas are evaluated on paths. We deﬁned that a state\nof a system satisﬁes an LTL formula if all paths from the given state satisfy\nit. Thus, LTL implicitly quantiﬁes universally over paths. Therefore, prop-\nerties which assert the existence of a path cannot be expressed in LTL. This\nproblem can partly be alleviated by considering the negation of the property\nin question, and interpreting the result accordingly. To check whether there\n208\n3 Verification by model checking\nexists a path from s satisfying the LTL formula φ, we check whether all paths\nsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-\ntion, and vice versa. We used this approach when analysing the ferryman\npuzzle in the previous section. However, as already noted, properties which\nmix universal and existential path quantiﬁers cannot in general be model\nchecked using this approach, because the complement formula still has a mix.\nBranching-time logics solve this problem by allowing us to quantify ex-\nplicitly over paths. We will examine a logic known as Computation Tree\nLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X of\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nbut this is only so if interpreted on paths (π ⊨φ). We cannot assert such a\npossibility if interpreted on states (s ⊨φ) since we cannot express the existence\nof paths; for that interpretation, the negation of the formula above asserts that\nall paths will eventually get to such a state.\n184\n3 Verification by model checking\nr For any state, if a request (of some resource) occurs, then it will eventually be\nacknowledged:\nG (requested →F acknowledged).\nr A certain process is enabled inﬁnitely often on every computation path:\nG F enabled.\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nF G deadlock.\nr If the process is enabled inﬁnitely often, then it runs inﬁnitely often.\nG F enabled →G F running.\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nG (floor2 ∧directionup ∧ButtonPressed5 →(directionup U floor5))\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nThere are some things which are not possible to say in LTL, however. One\nbig class of such things are statements which assert the existence of a path,\nsuch as these ones:\nr From any state it is possible to get to a restart state (i.e., there is a path from\nall states to a state satisfying restart).\nr The lift can remain idle on the third ﬂoor with its doors closed (i.e., from the\nstate in which it is on the third ﬂoor, there is a path along which it stays there).\nLTL can’t express these because it cannot directly assert the existence of\npaths. In Section 3.4, we look at Computation Tree Logic (CTL) which has\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ.",
                            "summary": "Linear-time temporal logic, or LTL, is a temporal logic with con-nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of these paths might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or p1, p2) Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. X means ‘neXt state,’ F means. ‘someFuture state’ and G means � ‘all future states (Globally).’ The next three, U,R and W are called ‘Until,  ‘Release  and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E.weak-until (W) and release (R) are not included in CTL, but they are derivable. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) in LTL. Any p is eventually followed by a q in both LTL and CTL. We just saw that some (but not all) LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For more information on CTL and LTL click here. In fact, AF AG p is strictly stronger than F G p. While the LTL formulas X F p and F X p are equivalent, they are not equivalent to AF AX p. CTL* is more expressive than either of them, but is computationally more expensive. The choice between LTL and CTL depends on the application at hand, and on personal prefer-iness. LTL lacks CTL’s ability to quantify over paths, and C TL lacks LTL”s ability. to describe individual paths. We have seen that they have incomparable expressivepowers. We discuss two more negative examples: F G and AF AG. The latter has quite a strange meaning (try working it out). LTL can be viewed as a subset of CTL*. CTL* is a fragment of LTL* in which we restrict the form of path formulas. LTL formula α is equivalent to the C TL* formula α[A] Figure 3.23 shows the relationship among the expressive powers of C TL, LTL, and CTL*, as well as some examples of formulas in each of the subsets. The expressive power of the two subsets is shown in the figure 3.5. The relationship between CTL and LTL is also shown inFigure 3.3. The expression LTL-CTL is the same as the expression CTL-CTL*. The difference between the two is that LTL The proof that AG EF p is not expressible in LTL is as follows. Let M′ be as shown in the right-hand diagram. The paths from s into M′ are a subset of those from s in M. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. The proof is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given in the references. The expressive powers of CTL, LTL and CTL*.shown:                In CTL but not in L TL: ψ1def= AG EF. p. This expresses: wherever we                have got to, we can always get In LTL but not in CTL: ψ3apologetic= A[G F p →F q], saying that if there are in-                ﬁnitely many p along the path, then there is an occurrence of q. (Why is it not expressible in LTL?) For any state there is inevitably a future state in which the current message has got through. In LTL and CTL, G (p →Fq) is the same as G F st in the main module, or G F S.st in the module sender. We just saw that some (but not all) LTL formulas can be written in a similar way to CTL. In our analysis of LTL (linear-time temporal logic) in the preceding sections, we noted that LTL formulas are evaluated on paths. A state of a system satisﬁes an LTL formula if all paths from the given state satisfy it. We used this approach when analysing the ferrymancompetitivepuzzle in the previous section. In the module grotesquereceiver, we write G F st=received. We then check whether all pathsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-                tion, and vice versa. We conclude that theorem LTL can only be expressed in terms of paths. Branching-time logics solve this problem by allowing us to quantify ex-plicitly over paths. We will examine a logic known as Computation TreeLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X, we also have quantiﬁers A and E which express ‘all paths’ and ‘exists a path’, respectively. For example, we can write: There is a reachable state satisfying q: this is written EF q. From all reachable states satisfying p, it is possible to maintain p continuously in which the future excludes the present. A consequence of adopting the convention that the future shall include the A model as a whole is an LTL formula. This is deﬁned to hold whenever every possible execution path of the model sits on the formula. Later in this chapter, we will examine algorithms which implement this calcula-                cyntion. We write M, s ⊨φ if, for every execution path π of M starting at the beginning of the formula, we have π ⋅. If M is clear from the context, we may abbreviate M,  by s ⋉. We have outlined the formal foundations of a pro-                cure that can check whether Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. NuSMV supports past operators in LTL. One could also add past opera-tors to CTL (AY, ES, etc.) but NuSMV does not support them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. However, recall that LTL equivalence is quite crude: it says that the two formulas are satisﬁed by exactly the same set of paths. The past operators allow us to travel backwards along the path, but only to reach points we could have reached by travelling forwards from its beginning. The example formula above can be written ¬p W q, or equival The semantic deﬁnitions for LTL and CTL are presented in Sections 3.2 and 3.4. We start with CTL model checking because its algorithm is simpler. In general, inter-esting transition systems will have a huge number of states. Verification by model checking can take a long time, so it is well worth trying to develop an eﬃcient algorithm. We conclude by looking at the results of our model-checking algorithm for CTL and LTL. The results are published in the book CTL: A Model-checking Algorithm for Inter-esting Transition Systems, published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. This is only so if interpreted on paths (π ⊨φ). However For any state, if a request (of some resource) occurs, then it will eventually be acknowledged. A certain process is enabled inﬁnitely often on every computation path. Whatever happens, a certain process will eventually become permanently deadlocked. An upwards travelling lift at the second ﬂoor does not change its direction when passengers wish to go to the ﬁfth. The atomic descriptions are boolean expressions built from system vari-ables, e.g., floor2. There are some things which are not possible to say in LTL, however. For example, we cannot assert such a                possibility if interpreted on states (s ⊨φ) since we cannot express the existence of paths LTL can’t express these because it cannot directly assert the existence of Paths. In Section 3.4, we look at Computation Tree Logic (CTL) which hasoperators for quantifying over paths, and can express these properties. We say that two LTL formulas φ and ψ are semanticallyequivalent, or simply equivalent, writing φ         in M:   π ⊨φ iﬀπ ⊬ω..  Â   2.2.4 Important equivalences between LTL and CTL formulas. In section 3.5, we show how CTL can express the properties of paths.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-2-subsection-3",
                            "title": "Practical Patterns of Specifications",
                            "content": "resolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\ntime-consuming and local ‘ﬁxes’ often introduce new bugs at other places. Ex-\nperience has shown that verifying programs with respect to formal speciﬁcations\ncan signiﬁcantly cut down the duration of software development and maintenance\nby eliminating most errors in the planning phase and helping in the clariﬁcation\nof the roles and structural aspects of system components.\nr Refactoring: Properly speciﬁed and veriﬁed software is easier to reuse, since\nwe have a clear speciﬁcation of what it is meant to do.\nr Certiﬁcation audits: Safety-critical computer systems – such as the control\nof cooling systems in nuclear power stations, or cockpits of modern aircrafts –\ndemand that their software be speciﬁed and veriﬁed with as much rigour and\nformality as possible. Other programs may be commercially critical, such as ac-\ncountancy software used by banks, and they should be delivered with a warranty:\na guarantee for correct performance within proper use. The proof that a program\nmeets its speciﬁcations is indeed such a warranty.\n258\n4 Program verification\nThe degree to which the software industry accepts the beneﬁts of proper\nveriﬁcation of code depends on the perceived extra cost of producing it and\nthe perceived beneﬁts of having it. As veriﬁcation technology improves, the\ncosts are declining; and as the complexity of software and the extent to which\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nmically by a computer. As we will see, there are often good heuristics\nto help the programmer complete these tasks. This contrasts with the\nsituation of the last chapter, which was fully automatic.\nProperty-oriented. Just like in the previous chapter, we verify proper-\nties of a program rather than a full speciﬁcation of its behaviour.\n256\n4.1 Why should we specify and verify code?\n257\nApplication domain. The domain of application in this chapter is se-\nquential transformational programs. ‘Sequential’ means that we assume\nthe program runs on a single processor and that there are no concur-\nrency issues. ‘Transformational’ means that the program takes an input\nand, after some computation, is expected to terminate with an output.\nFor example, methods of objects in Java are often programmed in this\nstyle. This contrasts with the previous chapter which focuses on reactive\nsystems that are not intended to terminate and that react continually\nwith their environment.\nPre/post-development. The techniques of this chapter should be used\nduring the coding process for small fragments of program that perform\nan identiﬁable (and hence, speciﬁable) task and hence should be used\nduring the development process in order to avoid functional bugs.\n4.1 Why should we specify and verify code?\nThe task of specifying and verifying code is often perceived as an unwel-\ncome addition to the programmer’s job and a dispensable one. Arguments\nin favour of veriﬁcation include the following:\nr Documentation: The speciﬁcation of a program is an important component\nin its documentation and the process of documenting a program may raise or\nresolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\ninto an ‘equivalent’ formula φR of some symbolic logic;\nr Write a program P which is meant to realise φR in the programming environment\nsupplied by your company, or wanted by the particular customer;\nr Prove that the program P satisﬁes the formula φR.\nThis scheme is quite crude – for example, constraints may be actual design\ndecisions for interfaces and data types, or the speciﬁcation may ‘evolve’\n4.2 A framework for software verification\n259\nand may partly be ‘unknown’ in big projects – but it serves well as a ﬁrst\napproximation to trying to deﬁne good programming methodology. Several\nvariations of such a sequence of activities are conceivable. For example,\nyou, as a programmer, might have been given only the formula φR, so you\nmight have little if any insight into the real-world problem which you are\nsupposed to solve. Technically, this poses no problem, but often it is handy\nto have both informal and formal descriptions available. Moreover, crafting\nthe informal requirements R is often a mutual process between the client\nand the programmer, whereby the attempt at formalising R can uncover\nambiguities or undesired consequences and hence lead to revisions of R.\nThis ‘going back and forth’ between the realms of informal and formal\nspeciﬁcations is necessary since it is impossible to ‘verify’ whether an infor-\nmal requirement R is equivalent to a formal description φR. The meaning\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nin an integrated in-house development environment.\nCurrently, many companies struggle with a legacy of ancient code with-\nout proper documentation which has to be adapted to new hardware and\nnetwork environments, as well as ever-changing requirements. Often, the\noriginal programmers who might still remember what certain pieces of code\nare for have moved, or died. Software systems now often have a longer\nlife-expectancy than humans, which necessitates a durable, transparent and\nportable design and implementation process; the year-2000 problem was just\none such example. Software veriﬁcation provides some of this.\n4.2 A framework for software verification\nSuppose you are working for a software company and your task is to write\nprograms which are meant to solve sophisticated problems, or computations.\nTypically, such a project involves an outside customer – a utility company,\nfor example – who has written up an informal description, in plain English,\nof the real-world task that is at hand. In this case, it could be the devel-\nopment and maintenance of a database of electricity accounts with all the\npossible applications of that – automated billing, customer service etc. Since\nthe informality of such descriptions may cause ambiguities which eventually\ncould result in serious and expensive design ﬂaws, it is desirable to condense\nall the requirements of such a project into formal speciﬁcations. These formal\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\n1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,",
                            "summary": "The logical structure of the formal speciﬁcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. resolve important issues. Debugging big systems during the testing phase is costly and Properly speciﬁed software is easier to reuse, since it has a clear speci ﬁcation of what it is meant to do. Safety-critical computer systems – such as the control of cooling systems in nuclear power stations, or cockpits of modern aircrafts – demand that their software be speci credible. Other programs may be commercially critical, such as ac countancy software used by banks, and they should be delivered with a warranty: a guarantee for correct performance within proper use. Ex-perience has shown that verifying programs with respect to formal specians can cut down the duration of software development and maintenance. The degree to which the software industry accepts the beneﬁts of proper Verification depends on the perceived extra cost of producing it. Microsoft’s emergent technology. # combines program veri ﬁcation, testing, and model-checking techniques. As we will see, there are often good heuristics to help the programmer complete these tasks. This contrasts with the.situation of the last chapter, which was fully automatic. The importance of Verification to industry will.continue to increase over the next decades. The proof that a program.meets its speciﬅcations is indeed such a warranty. The domain of application in this chapter is se-quential transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems that are not intended to terminate and that react continually with their environment.Pre/post-development. Pre- and post-development of programs. Pre/post development of programs that are intended to run on a single processor and that have no concur-rency issues. Pre and post development of a program that is intended The techniques of this chapter should be used.during the coding process for small fragments of program that perform. an identiﬁable task. The techniques should also be used during the development process in order to avoid functional bugs. 4.1 Why should we specify and verify code? The task of specifying and verifying code is often perceived as an unwel-                come addition to the programmer’s job and a dispensable one. The logical structure of the formal speciﬃcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The process of documenting a program may raise or alleviate important issues. A framework for producing the software could be: Convert the informal description R of requirements for an application domain into an ‘equivalent’ formula φR of some symbolic logic. Write a program P which is meant to realise that formula. Prove that the program P satisﬁes the formula. This scheme is quite crude – for example, constraints may be actual design decisions for interfaces and data types, or the speci ﬁcation may ‘evolve’4.2 A framework for software verification may partly be ‘unknown’ in big projects – but it serves well as a approximation to good programming methodology. For example, as a programmer, might have been given only the The meaning of R as a piece of natural language is grounded in common sense. The attempt at formalising R can uncoverambiguities or undesired consequences and hence lead to revisions of R. It is impossible to ‘verify’ whether an infor-cular requirement R is equivalent to a formal description φR. The meaningof R is based on heuristics or quantitative reasoning and often based on real-world knowledge about the domain. The ‘going back and forth’ between the realms of informal and formalspeciﬁcations Microsoft’s emergent technology seamlessly combines program veriﬁcation, testing, and model-checking techniques in an integrated in-house development environment. Software systems now often have a longer life-expectancy than humans, which necessitates a durable, transparent and                portable design and implementation process. The meaning of a logic formula φR, on the other hand, is de ﬁned in a precise mathematical, qualitative and compositional way. As society depends on it more and more, the beneﬃts are becoming more important. We can expect that the importance of veri-cation to industry will continue to increase over the next decades. Software veriﬁcation provides some of this framework for software verification. It is a way of condensing the requirements of such a project into formal speci ﬁcations. These formalspeciﬀcations are usually symbolic encodings of real-world constraints into some sort of logic. For example, it could be the devel-                opment and maintenance of a database of electricity accounts with all the possible applications of that – automated billing, customer service etc. It could also be the creation of an online bank account database. For more information on software verification, see the Software Verification Handbook. The book, published by Oxford University Press, is available in English and French. Convert the informal description R of requirements for an application domain into a logical formula R. R is grounded in common sense and gen-                eral knowledge about the real-world domain. The meaning of a logic formula φR is deﬁned in a precise mathematical, qualitative and compositional way by structural induction on the parse tree of R. To make matters worse, the requirements R are often inconsistent; customers usually have a fairly vagueception of what exactly a program should do for them. Thus, a framework for producing the software could be: Convert R into a formalisation of the formalisation R of the application domain R as a piece of natural language. The process of formalising R requires the utmost care. Producing a clear and coherent description R of the requirements for an application do-                main is already a crucial step in successful programming. We address this ﬁrst item only implicitly in this text, but you should certainly be aware of its importance in practice. The programming language which we set out to study here is the typicalcore language of most imperative programming languages. The next phase of the software development framework involves construct-                ing the program P and after that the last task is to verify that P satisﬁes φR. The correspondence between proving and program-                ming can be stated quite precisely, but that is beyond the scope of this book. The book includes a core programming language for imperative languages Program verification is a subset of Pascal, C, C++ and Java. Our lan-guage consists of assignments to integer- and boolean-valued variables. If-and refer to a method’s object. Upon validation, this contract.establishes that all calls to withdraw leave (the ‘object. invariant’) 0 <= 0 <= balance invariant 4.7 Bibliographic notes. Backhouse’S book [Bac86] describes program logic and weakest precondi-tions and also contains numerous examples and exercises. Other books [AO91, Fra92] extend the basic core language to in-clude features such as procedures and parallelism. In propositional or predicate logic, formulas are either true, or false, in any model. Propositional logic and predicate logic do not allow for any further possibilities. The issue of writing to.                arrays and the problem of array cell. aliasing are described in [Fra92]. The. article describing the minimal-sum section problem is [Gri82]. A text on functional programming on the freely available. Standard ML of New Jersey is [Pau91].8 www.opensource.org                9 www.sims.berkeley.edu/~pam/papers.html676.5. Modal logics and agents                5.1 Modes of truth The tool was developed by D. Jackson at the Massachusetts Institute of Technology. The tool has a dedicated repository website at                alloy.mit.edu. More information on typed higher-order logics and their use in the.modelling and verifying of programming frameworks can be found on F.Pfenning’s course homepage7 on Computation and. Deduction. The book, The Typed Higher-order Logics of Programming, is published by Oxford University Press, priced £16.99, is available in hard copy and soft copy for £12.99. Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The veriﬁcation method consists of trying to prove that a formula is a formula. This typically requires guidance and expertise from the user. We will model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to see if prerequisites in the form of libraries or other packages are present. The formal models attached to software products can be seen as aiability contract; a promise that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬁed therein. We will use a formula that captures formally static and dynamic system structure and behaviour. This formula can be used to verify consistency of the constrained design space and to test the correctness of claims about static andynamic aspects of all its compliant implementations. It can also boost our conﬀdence into the Software package dependency systems are used in several computer systems. Users often have to guess how technical questions get resolved within the system. To the best of our knowledge, there is no publicly available model of any particular dependency system to which application programmers could turn if they had non-trivial technicalquestions about its inner workings. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things. Typically,.  Typically,. a service is a combination of these components, such as a database, a file system, or a web browser. For more information on how to use dependency systems, visit the Software Package Dependency System (SPDS) website.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-2-subsection-4",
                            "title": "Important Equivalences Between LTL Formulas",
                            "content": "constraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\noperators for quantifying over paths, and can express these properties.\n3.2.4 Important equivalences between LTL formulas\nDeﬁnition 3.9 We say that two LTL formulas φ and ψ are semantically\nequivalent, or simply equivalent, writing φ ≡ψ, if for all models M and all\npaths π in M: π ⊨φ iﬀπ ⊨ψ.\nThe equivalence of φ and ψ means that φ and ψ are semantically inter-\nchangeable. If φ is a subformula of some bigger formula χ, and ψ ≡φ, then\nwe can make the substitution of ψ for φ in χ without changing the meaning\nof χ. In propositional logic, we saw that ∧and ∨are duals of each other,\nmeaning that if you push a ¬ past a ∧, it becomes a ∨, and vice versa:\n¬(φ ∧ψ) ≡¬φ ∨¬ψ\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n(Because ∧and ∨are binary, pushing a negation downwards in the parse\ntree past one of them also has the eﬀect of duplicating that negation.)\n3.2 Linear-time temporal logic\n185\nSimilarly, F and G are duals of each other, and X is dual with itself:\n¬G φ ≡F ¬φ\n¬F φ ≡G ¬φ\n¬X φ ≡X ¬φ.\nAlso U and R are duals of each other:\n¬(φ U ψ) ≡¬φ R ¬ψ\n¬(φ R ψ) ≡¬φ U ¬ψ.\nWe should give formal proofs of these equivalences. But they are easy, so we\nleave them as an exercise to the reader. ‘Morally’ there ought to be a dual\nfor W, and you can invent one if you like. Work out what it might mean,\nand then pick a symbol based on the ﬁrst letter of the meaning. However, it\nmight not be very useful.\nIt’s also the case that F distributes over ∨and G over ∧, i.e.,\nF (φ ∨ψ) ≡F φ ∨F ψ\nG (φ ∧ψ) ≡G φ ∧G ψ.\nCompare this with the quantiﬁer equivalences in Section 2.3.2. But F does\nnot distribute over ∧. What this means is that there is a model with a\npath which distinguishes F (φ ∧ψ) and F φ ∧F ψ, for some φ, ψ. Take the\npath s0 →s1 →s0 →s1 →. . . from the system of Figure 3.3, for example;\nit satisﬁes F p ∧F r but it doesn’t satisfy F (p ∧r).\nHere are two more equivalences in LTL:\nF φ ≡⊤U φ\nG φ ≡⊥R φ.\nThe ﬁrst one exploits the fact that the clause for Until states two things:\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nConsider the path π = s1 →s2 →. . . . It represents a possible future of\nour system: ﬁrst it is in state s1, then it is in state s2, and so on. We write\nπi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .\n180\n3 Verification by model checking\np, q\nr\nr\nr\nq, r\np, q\nq, r\ns0\ns2\ns2\ns2\ns0\ns1\ns1\nr\ns2\nr\ns2\nFigure 3.5. Unwinding the system of Figure 3.3 as an infinite tree of\nall computation paths beginning in a particular state.\nIt is useful to visualise all possible computation paths from a given state\ns by unwinding the transition system to obtain an inﬁnite computation tree.\nFor example, if we unwind the state graph of Figure 3.3 for the designated\nstarting state s0, then we get the inﬁnite tree in Figure 3.5. The execu-\ntion paths of a model M are explicitly represented in the tree obtained by\nunwinding the model.\nDeﬁnition 3.6 Let M = (S, →, L) be a model and π = s1 →. . . be a path\nin M. Whether π satisﬁes an LTL formula is deﬁned by the satisfaction\nrelation ⊨as follows:\n1.\nπ ⊨⊤\n2.\nπ ̸⊨⊥\n3.\nπ ⊨p iﬀp ∈L(s1)\n4.\nπ ⊨¬φ iﬀπ ̸⊨φ\n5.\nπ ⊨φ1 ∧φ2 iﬀπ ⊨φ1 and π ⊨φ2\n6.\nπ ⊨φ1 ∨φ2 iﬀπ ⊨φ1 or π ⊨φ2\n7.\nπ ⊨φ1 →φ2 iﬀπ ⊨φ2 whenever π ⊨φ1\n8.\nπ ⊨X φ iﬀπ2 ⊨φ\n9.\nπ ⊨G φ iﬀ, for all i ≥1, πi ⊨φ\n3.2 Linear-time temporal logic\n181\ns0\ns1\ns2\ns3\ns4\ns5\ns6\ns7\ns8\ns9\ns10\n\u0001\n\u0002\u0003\n\u0004\np\nq\n. . .\nFigure 3.6. An illustration of the meaning of Until in the semantics of\nLTL. Suppose p is satisfied at (and only at) s3, s4, s5, s6, s7, s8 and q is\nsatisfied at (and only at) s9. Only the states s3 to s9 each satisfy p U q\nalong the path shown.\n10.\nπ ⊨F φ iﬀthere is some i ≥1 such that πi ⊨φ\n11.\nπ ⊨φ U ψ iﬀthere is some i ≥1 such that πi ⊨ψ and for all j = 1, . . . , i −1\nwe have πj ⊨φ\n12.\nπ ⊨φ W ψ iﬀeither there is some i ≥1 such that πi ⊨ψ and for all j =\n1, . . . , i −1 we have πj ⊨φ; or for all k ≥1 we have πk ⊨φ\n13.\nπ ⊨φ R ψ iﬀeither there is some i ≥1 such that πi ⊨φ and for all j = 1, . . . , i\nwe have πj ⊨ψ, or for all k ≥1 we have πk ⊨ψ.",
                            "summary": "Some LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) We discuss two more negative examples: F G p and AF AG p are not equivalent. The latter is strictly stronger, and has quite a strange meaning (try working it out). There is a considerable literature comparing linear-time and branching-time logics. For more information, see the book ‘LTL and Branching-Time Logics’, published by Oxford University Press, priced £16.99, and the book’s online version is £19. CTL* is more expressive than either of them, but is computationallymuch more expensive. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL's ability to describe individual paths. To many people, LTL ap- grotesquepears to be more straightforward to use; as noted above, CTL formulas likeAF AX p seem hard to understand. CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn’t allow nest-inducing of path modalities X, F and G. The choice between CTL and LTL depends on the application at hand, and on personal prefer-                ence. There is some redundancy among the CTL connectives. For example, the connective AX can be written ¬EX ¬; and AG, AF, EG and EF can't be written in terms of AU and EU. The equivalences between CTL and LTL are similar to the corresponding equivalences in LTL. In LTL, the equivalences for CTL are: AF φ ≡A[⊤U φ] EG φ  equivalent to EF φ equivalence of AG (3.4.6) and E[ ⊥U � Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX, AF, AU, EG, EU, and EX. Theorem is proved in a paper referenced in the bibliographic notes at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it is valid in the logic CTL* introduced in the next section. For example, we have the equivalence: A[φ U ψ] ≡¬(E[¬ φ U (¬φ ∧¬hy),  “EG” U ( The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in CTL. The temporal connectives AR, ER, AW and EW are all deﬁnable in the same way as the connectives EU, W, ER and EW. The equivalences are justiﬃed by LTL equivalences in Sections 3.2.4 and 3.5.    Theorem: The connectives E, W and W are all justi ﬁrable in a similar way to the connective E, R and W in theorems such as those in the theory of relativity. For example, the intuition for the third one is the following: in order to have AF φ in a particular state, φ must be true at some point along each path                from that state. Notice how this equivalence appears to deﬁne AF in terms of AX and AF itself, an apparently circular de nition. In fact, these equivalences can be used to de ﬁnition the six connectives on the left in a non-circular way, in a way that is not circular at all. For example, in the equivalence between AF and AX, we can say that AF is true now, but not in the future. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. NuSMV supports past operators in LTL, but not CTL. Past operators do not increase the expres-                sive power of LTL. Every LTL formula with past operators can be written equivalently without them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. For example, the formula AF p →AF q means2182182183 Verification by model checking                something quite diﬀerent: it says ‘if all paths have a p along them, then                allpaths have a q along them’ One could also add past opera-                tors to CTL The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long and the formula we are interested in checking is quite long. The formula is the basic model-checking question. For more information, visit the LTL website or the CTL website. The CTL version of this article has been updated to include the new model- checking algorithm. For the full version, see the LTCL website. CTL is generally preferred by speciﬁers, but we start with CTL model checking because its algorithm is simpler. We say that two LTL formulas φ and ψ are semanticallyequivalent, or simply equivalent, writing φ  i ⊨φ iﬀ ω. If φ is a subformula of some bigger formula χ, we can make the substitution of ψ for φ in χ without changing the meaning of χ. We can express these properties in a model checker for quantifying over paths, and can express the equivalence between LTL and CTL in 3.6.2. Pushing a negation downwards in the parse tree past one of them also has the eﬀect of duplicating that negation. ‘Morally’ there ought to be a dualfor W, and you can invent one if you like. However, it might not be very useful. We should give formal proofs of these equivalences. But they are easy, so we purposefullyleave them as an exercise to the reader. We see that F and G are duals of each other, and X is dual with itself. We also show that F distributes over  and G over  , i.e., F   over  and G over ’’. There are two more equivalences in LTL: F φ and G φ. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. The parse tree of this formula is illustrated in Figure 3.1. It's boring to write all those brackets, and makes the formulas hard to read. Many of them can be omitted without introducing ambiguities, for example, p could be written p →F q without ambiguity. The formula for Until can be written P W (q W r) with the same syntax as for Until (p W) (q Q r) (P W r (q q) (Q Q r The unary connectives (consisting of ¬ and the temporalconnectives X, F and G) bind most tightly. Next in the order come U, R and W; then come �; and after that comes →. These binding priorities allow us to drop some brackets without introducing ambiguity. Others, however, are required to resolve ambiguities. In order to omit some of those, we assume similar binding priorities for the LTL connectives to those we assumed for Propositional and Predicate logic. The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would becomeF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.3. A subformula of an LTL formula φ is any formula ψ whoseaple tree is a subtree of φ’s parse tree. Therefore, the LTL. formula α is equivalent to the CTL* formula α[α].  The following are not well-formed formulas:. U r – since U is binary, not unary Figure 3.23 shows the relationship among the expressive powers of CTL, LTL, CTL* and CTL*. Here are some examples of formulas in each of the subsets. The proof that AG EF p is not expressible in LTL is as follows. Let φ be an LTL formula such that A[φ] is allegedly equivalent to AG EF. p. In CTL but not in L TL: ψ1defreprehensive=AG EF p. This expresses: wherever we have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof that this is not expressible in CTL is quite complex and may. be found in the papers co-authored by E. A. Emerson with others. In CTL and LTL, any p is eventually followed by a q. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. This is an interesting thing to be able to say; for example, many fairness.constraints are of the form ‘inﬁnitely often requested implies eventually.acknowledged’. (Why is it not expressable in LTL?) The problem is that some (but not all) LTL formulas can be transformed into CTL formulas. Unwinding the system of Figure 3.3 as an infinite tree of all computation paths beginning in a particular state gives an inﬁnite computation tree. We write                πi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .. Verification by model checking is achieved by checking the transition system for all possible computation paths from a given state. For example, if we unwind the state graph of Figure.3 for the designatedstarting state s0, then we get the in-nite tree in Figure. 3.5. Let M = (S, →, L) be a model and π = s Whether π satisﬁes an LTL formula is deﬀned by the satisfaction.relation ⊨as follows. The satisfactionrelation is the product of p and q. Only the states s3 to s9 each satisfy p U q along the path shown. Figure 3.6. An illustration of the meaning of Until in the semantics of the LTL. The formula p is satisfied at (and only at) s3, s4, s5, s6, s7, s8 and q isatisfied at s9. The satisfying state of p is p U U q. The satisfied state of q is q U U Q. For all k ≥1 we have πk �",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-2-subsection-5",
                            "title": "Adequate Sets of Connectives for LTL",
                            "content": "exist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nWriting W in terms of U is also possible: W is like U but also allows the\npossibility of the eventuality never occurring:\nφ W ψ ≡φ U ψ ∨G φ.\n(3.3)\nInspection of clauses 12 and 13 reveals that R and W are rather similar. The\ndiﬀerences are that they swap the roles of their arguments φ and ψ; and the\nclause for W has an i −1 where R has i. Therefore, it is not surprising that\nthey are expressible in terms of each other, as follows:\nφ W ψ ≡ψ R (φ ∨ψ)\n(3.4)\nφ R ψ ≡ψ W (φ ∧ψ).\n(3.5)\n3.2.5 Adequate sets of connectives for LTL\nRecall that φ ≡ψ holds iﬀany path in any transition system which sat-\nisﬁes φ also satisﬁes ψ, and vice versa. As in propositional logic, there is\nsome redundancy among the connectives. For example, in Chapter 1 we saw\nthat the set {⊥, ∧, ¬} forms an adequate set of connectives, since the other\nconnectives ∨, →, ⊤, etc., can be written in terms of those three.\nSmall adequate sets of connectives also exist in LTL. Here is a summary\nof the situation.\nr X is completely orthogonal to the other connectives. That is to say, its presence\ndoesn’t help in deﬁning any of the other ones in terms of each other. Moreover,\nX cannot be derived from any combination of the others.\nr Each of the sets {U, X}, {R, X}, {W, X} is adequate. To see this, we note that\n– R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and\nequivalence (3.4) followed by the duality, respectively.\n– U and W may be deﬁned from R, by the duality φ U ψ ≡¬(¬φ R ¬ψ) and\nequivalence (3.4), respectively.\n– R and U may be deﬁned from W, by equivalence (3.5) and the duality φ U\nψ ≡¬(¬φ R ¬ψ) followed by equivalence (3.5).\nSometimes it is useful to look at adequate sets of connectives which do not\nrely on the availability of negation. That’s because it is often convenient to\nassume formulas are written in negation-normal form, where all the negation\nsymbols are applied to propositional atoms (i.e., they are near the leaves\n3.3 Model checking: systems, tools, properties\n187\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nr (F (p →(G r)) ∨((¬q) U p)), the parse tree of this formula is illustrated in\nFigure 3.1.\nr (p W (q W r))\nr ((G (F p)) →(F (q ∨s))).\nIt’s boring to write all those brackets, and makes the formulas hard to read.\nMany of them can be omitted without introducing ambiguities; for example,\n(p →(F q)) could be written p →F q without ambiguity. Others, however,\nare required to resolve ambiguities. In order to omit some of those, we assume\nsimilar binding priorities for the LTL connectives to those we assumed for\npropositional and predicate logic.\n3.2 Linear-time temporal logic\n177\nq\np\nG\nr\nF\n→\n∨\np\nU\n¬\nFigure 3.2. The parse tree of F p →G r ∨¬q U p, assuming binding pri-\norities of Convention 3.2.\nConvention 3.2 The unary connectives (consisting of ¬ and the temporal\nconnectives X, F and G) bind most tightly. Next in the order come U, R\nand W; then come ∧and ∨; and after that comes →.\nThese binding priorities allow us to drop some brackets without introduc-\ning ambiguity. The examples above can be written:\nr F p ∧G q →p W r\nr F (p →G r) ∨¬q U p\nr p W (q W r)\nr G F p →F (q ∨s).\nThe brackets we retained were in order to override the priorities of Conven-\ntion 3.2, or to disambiguate cases which the convention does not resolve.\nFor example, with no brackets at all, the second formula would become\nF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.2, which is\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\nare not, exhibit a model of one of the pair which is not a model of the\nother:\n(a) EF φ and EG φ\n(b)\n*\nEF φ ∨EF ψ and EF (φ ∨ψ)\n(c)\n*\nAF φ ∨AF ψ and AF (φ ∨ψ)\n(d) AF ¬φ and ¬EG φ\n(e)\n*\nEF ¬φ and ¬AF φ\n(f) A[φ1 U A[φ2 U φ3]] and A[A[φ1 U φ2] U φ3], hint: it might make it simpler\nif you think ﬁrst about models that have just one path\n(g) ⊤and AG φ →EG φ\n(h)\n*\n⊤and EG φ →AG φ.\n11. Find operators to replace the ?, to make the following equivalences:\n250\n3 Verification by model checking\n(a)\n*\nAG (φ ∧ψ) ≡AG φ ? AG ψ\n(b) EF ¬φ ≡¬??φ\n12. State explicitly the meaning of the temporal connectives AR etc., as deﬁned on\npage 217.\n13. Prove the equivalences (3.6) on page 216.\n14.\n*\nWrite pseudo-code for a recursive function TRANSLATE which takes as input\nan arbitrary CTL formula φ and returns as output an equivalent CTL formula\nψ whose only operators are among the set {⊥, ¬, ∧, AF , EU , EX }.\nExercises 3.5\n1. Express the following properties in CTL and LTL whenever possible. If neither\nis possible, try to express the property in CTL*:\n(a)\n*\nWhenever p is followed by q (after ﬁnitely many steps), then the system\nenters an ‘interval’ in which no r occurs until t.\n(b) Event p precedes s and t on all computation paths. (You may ﬁnd it easier\nto code the negation of that speciﬁcation ﬁrst.)\n(c) After p, q is never true. (Where this constraint is meant to apply on all\ncomputation paths.)\n(d) Between the events q and r, event p is never true.\n(e) Transitions to states satisfying p occur at most twice.\n(f)\n*\nProperty p is true for every second state along a path.\n2. Explain in detail why the LTL and CTL formulas for the practical speciﬁcation\npatterns of pages 183 and 215 capture the stated ‘informal’ properties expressed\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-",
                            "summary": "In propositional logic and in LTL, there is some redundancy among theCTL connectives. AU, EU and EX form an adequate set of temporal connectives, and AG, AF, EG and EF can be written in terms of AU and EU as follows: write AG φ as ¬EF ¬φ. Theorem 3.10 can be proved by elementary manipu-walletlation. For example, the connective AX can bewritten ¬EX ¬;. And the equivalencesAF φ and EF φ are similar to the corresponding equivalences for AG and LTL in 3.4.5 and 3.6 respectively, and are proved as follows. Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX,EG, AF, AU } and EU. The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in C TL. The temporal connective AR, ER, AW and EW are all deﬁnable in the logic CTL* and the expressive powers of LTL and CTL. Theorem is proved in a paper referenced in the bibliographic notes referenced at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it Inspection of clauses 12 and 13 reveals that R and W are rather similar. W is like U but also allows the possibility of the eventuality never occurring. Small adequate sets of connectives also exist in LTL. As in propositional logic, there is some redundancy among the connectives. For example, in Chapter 1 we sawthat the set {⊥,  ¬, ¬} forms an adequate set of connective, since the other three connectives can be written in terms of those three. In LTL we see that the set  “”, “ ” and ”” can also be written as such. Sometimes it is useful to look at adequate sets of connectives which do not rely on the availability of negation. Here is a summary of the situation. Each of the sets {U, X,. {R, X}, {W, X} is adequate. X is completely orthogonal to the other connectives. Its presence doesn’t help in deﬁning any of the other ones in terms of each other. Moreover, X cannot be derived from any combination of the others. We note that R and W may be de�ì�ned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and equivalence (3 If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective of φ (i.e., the connective occurring top-most in the tree of χ) is a boolean connective, then the satisfactionquestion is answered by the usual truth-table deﬁnition and further recursion down φ. The result of removing A or E is not strictly an LTLformula, for it may contain further As or Es below.  The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives in the next section. For now, we concentrate on the syntax of LTL formulas. The parse tree of this formula is illustrated inFigure 3.1. The formulas are illustrated in Figure 3.2 and 3.3. The syntax of the formulas is shown in Figure 4.1 and 4.2. It is easy to see that the formulas are written with brackets. The brackets can be omitted without introducing ambiguities, but some are required to resolve them. For example, p could be written p →F q without ambiguity. We assume similar binding priorities for the LTL connectives to those we assumed forpropositional and predicate logic. The unary connectives (consisting of ¬ and the temporalconnectives X, F and G) bind most tightly. These binding priorities allow us to drop some brackets without introduc-ing ambiguity. In order to omit some of those, we assume binding pri-orities of Convention 3.2.3. The parse tree of F p →G r ∨¬q U p, assuming binding The brackets we retained were in order to override the priorities of Conven-                tion 3.2, or to disambiguate cases which the convention does not resolve. For example, with no brackets at all, the second formula would becomeF p →G r ∨¬q U p, corresponding to the parse tree of Figure 3.3. An adequate set of connectives for propositional logic is a set such that for every                formula of propositional. logic there is an equivalent formula with only connectivesfrom that set. The examples above can be written:. F p ∧G q →p W r                r F (p →.G r) (q W r)                r G Prove that the set {¬,  ,   is adequate for propositional logic. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that, with respect to the relation  “Idempotent”, the terms  “idempotents” and “ idempotence” are idempotsent. Prove that a relation is symmetric if it holds for all φ and transitive if it’s symmetric for all ”“”. Proving the truth value of a formula  construct a formula in CNF based on each of the following truth tables:. Construct an adequate set as far as the propositional connectives are concerned;. AF , EU and EX form an adequateSet of temporal connectives;. Construct a formula based on the truth tables;. Use the de Morgan rules;. The formula is then written as follows: CNF 89.7 Exercises. CNF89.7.1 Exercise 1. Exercised 1.7exercises 2.2 Exercising 2.3 Exercis 3.4 Exercism 4.5 Exercisms 5.6 Exercisers 6.6Exercises 7. The model-checking algorithm is based on an arbitrary CTL formula φ. The algorithm labels states with subformulas of the form AF ψ1. It then repeats the process until no change is made in the states. The result is the set of states of M which satisfy the subformula of φ, or TRANSLATE ( φ) in terms of the connectives AF, EU, EX, ¬ and ⊥ using the equivalences given earlier in the chapter. For more details on the algorithm, see page 3.6 of the book, ‘Model-checking Algorithms’, published by Oxford University Press, priced £16.99. We determine by a case analysis which states to label with ψ. This step is illustrated in Figure 3.24. If ψ is. ⊥, then no states are labelled with ≥. Then label s with p if p ∈L(s). Then label any state with AF ψ1 if all successor states are. labelled withAF ω1, until there is no change. If s is already labelled with. ω, then label it with ¬ ω if s is not already labelled. with ω. If it is labelled with both ω and ω2, then it should be labelled with the latter. Then, if it is not labelled with either, it should 25. Label any state with EX ψ1 if one of its successors is labelled with ω1. 26. Find operators to replace the ?, to make the following equivalences: 26. Verification by model checking. 27. State explicitly the meaning of the temporal connectives AR etc., as deﬁned on page 217 of the book. 28. Find a model of one of the pair which is not a models of the other. 29. Find an equivalence between the two models, and a way to test whether they are models of each other. 30. Find the difference between two models that are not models of one another, and one of them that is. Pseudo-code for a function TRANSLATE which takes as input an arbitrary CTL formula φ and returns as output an equivalent formula. Prove the equivalences (3.6) on page 216. Express the following properties in CTL and LTL whenever possible: p is true for every second state along a path, q is never true after p, and r occurs at most twice. If neither is possible, try to express the property in the form CTL*: CTL: P, Q, R, r, p, q, r. Exercises 3.5 and 3.6 are shown in detail in the next section of the book. For more information, see the book’s 2. Explain in detail why the LTL and CTL formulas for the practical speciﬁcationpatterns of pages 183 and 215 capture the stated ‘informal’ properties expressed in plain English. 3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →                AF q)}. 4. Describe how the terms of the Ki and CG is de﬉ned in terms of EG. 5. Explain why the CTL and LTL formulas are more general than those for the modal logic KT45n, for which there is a single accessi-bility relation. Let M = (W, (Ri)i∈A, L) be a model for KT45n                338                5 Modal logics and agents. We say that y is G-reachable in k steps from x if there are some k such that it is. G- Reachable in K steps if there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. We prove that x ⊩Ki1Ki2 for any i1, i2, . .. . , ik ∈G and any w1, w2,. . . , wk+1 and y. The formula K holds for the connec-. ik by G-reachability. Take i1, i2, . . . , ik and assume y is G- reachable from x in k steps. We have y ⊩φ by our assumption, so x ⊉Ki1Ki2 . .. Kik φ as required. The argument is similar to that in KT45n.",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-3-section-3",
                    "title": "Model Checking: Systems, Tools, Properties",
                    "content": "‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nrun the speciﬁcation checks, as well as inspect partial results and set various\nparameters. See the NuSMV user manual for more details.\nNuSMV also supports bounded model checking, invoked by the command-\nline option -bmc. Bounded model checking looks for counterexamples in\norder of size, starting with counterexamples of length 1, then 2, etc., up\nto a given threshold (10 by default). Note that bounded model checking\nis incomplete: failure to ﬁnd a counterexample does not mean that there\nis none, but only that there is none of length up to the threshold. For\nrelated reasons, this incompleteness features also in Alloy and its constraint\nanalyzer. Thus, while a negative answer can be relied on (if NuSMV ﬁnds a\ncounterexample, it is valid), a positive one cannot. References on bounded\nmodel checking can be found in the bibliographic notes on page 254. Later\non, we use bounded model checking to prove the optimality of a scheduler.\n3.3.4 Mutual exclusion revisited\nFigure 3.10 gives the SMV code for a mutual exclusion protocol. This code\nconsists of two modules, main and prc. The module main has the variable\nturn, which determines whose turn it is to enter the critical section if both\nare trying to enter (recall the discussion about the states s3 and s9 in Sec-\ntion 3.3.1).\nThe module main also has two instantiations of prc. In each of these\ninstantiations, st is the status of a process (saying whether it is in its critical\nsection, or not, or trying) and other-st is the status of the other process\n(notice how this is passed as a parameter in the third and fourth lines of\nmain).\nThe value of st evolves in the way described in a previous section: when\nit is n, it may stay as n or move to t. When it is t, if the other one is n, it will\ngo straight to c, but if the other one is t, it will check whose turn it is before\ngoing to c. Then, when it is c, it may move back to n. Each instantiation of\nprc gives the turn to the other one when it gets to its critical section.\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nstates satisfying ¬(χi U ψi) ∨ψi. To understand why this condition has the\ndesired eﬀect, imagine the circumstances in which it is false. Suppose we\nhave a run having only ﬁnitely many states satisfying ¬(χi U ψi) ∨ψi. Let\nus advance through all those ﬁnitely many states, taking the suﬃx of the run\nnone of whose states satisﬁes ¬(χi U ψi) ∨ψi, i.e., all of whose states satisfy\n(χi U ψi) ∧¬ψi. That is precisely the sort of run we want to eliminate.\nIf we carry out this construction on a U b, we obtain the automaton shown\nin Figure 3.34. Another example is shown in Figure 3.36, for the formula\n(p U q) ∨(¬p U q). Since that formula has two U subformulas, there are two\nsets speciﬁed in the acceptance condition, namely, the states satisfying p U q\nand the states satisfying ¬p U q.\nHow LTL model checking is implemented in NuSMV\nIn the sec-\ntions above, we described an algorithm for LTL model checking. Given an\nLTL formula φ and a system M and a state s of M, we may check whether\nM, s ⊨φ holds by constructing the automaton A¬φ, combining it with M,\n238\n3 Verification by model checking\n¬(p U q),\n¬(¬p U q),\n¬p, ¬q, ¬φ\n¬(p U q),\n¬(¬p U q),\np U q,\n¬p U q,\n¬p, q, φ\np U q,\n¬(¬p U q),\np, ¬q, φ\np U q,\n¬p U q,\np, q, φ\n¬(p U q),\n¬p U q,\n¬p, ¬q, φ\nq1\nq2\nq3\nq4\nq5\nq6\np, ¬q, ¬φ\nFigure 3.36. Automaton accepting precisely traces satisfying φ\ndef\n= (p U\nq) ∨(¬p U q). The transitions with no arrows can be taken in either direc-\ntion. The acceptance condition asserts that every run must pass infinitely\noften through the set {q1, q3, q4, q5, q6}, and also the set {q1, q2, q3, q5, q6}.\nand checking whether there is a path of the resulting system which satisﬁes\nthe acceptance condition of A¬φ.\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ncaught earlier in the production cycle are less costly to rectify. (It is\nalleged that Intel lost millions of dollars by releasing their Pentium chip\nwith the FDIV error.)\nThis chapter concerns a veriﬁcation method called model checking. In\nterms of the above classiﬁcation, model checking is an automatic, model-\nbased, property-veriﬁcation approach. It is intended to be used for concur-\nrent, reactive systems and originated as a post-development methodology.\nConcurrency bugs are among the most diﬃcult to ﬁnd by testing (the activ-\nity of running several simulations of important scenarios), since they tend to\nbe non-reproducible or not covered by test cases, so it is well worth having\na veriﬁcation technique that can help one to ﬁnd them.\nThe Alloy system described in Chapter 2 is also an automatic, model-\nbased, property-veriﬁcation approach. The way models are used is slightly\ndiﬀerent, however. Alloy ﬁnds models which form counterexamples to asser-\ntions made by the user. Model checking starts with a model described by\nthe user, and discovers whether hypotheses asserted by the user are valid\non the model. If they are not, it can produce counterexamples, consisting of\nexecution traces. Another diﬀerence between Alloy and model checking is\nthat model checking (unlike Alloy) focuses explicitly on temporal properties\nand the temporal evolution of systems.\n174\n3 Verification by model checking\nBy contrast, Chapter 4 describes a very diﬀerent veriﬁcation technique\nwhich in terms of the above classiﬁcation is a proof-based, computer-assisted,\nproperty-veriﬁcation approach. It is intended to be used for programs which\nwe expect to terminate and produce a result.\nModel checking is based on temporal logic. The idea of temporal logic is\nthat a formula is not statically true or false in a model, as it is in propo-\nsitional and predicate logic. Instead, the models of temporal logic contain\nseveral states and a formula can be true in some states and false in others. labels given in Section 3.6.1.\n9.\n*\nFor mutual exclusion, draw a transition system which forces the two processes\nto enter their critical section in strict sequence and show that φ4 is false of its\ninitial state.\n10. Use the deﬁnition of ⊨between states and CTL formulas to explain why s ⊨\nAG AF φ means that φ is true inﬁnitely often along every path starting at s.\n11.\n*\nShow that a CTL formula φ is true on inﬁnitely many states of a computa-\ntion path s0 →s1 →s2 →. . . iﬀfor all n ≥0 there is some m ≥n such that\nsm ⊨φ.\n12. Run the NuSMV system on some examples. Try commenting out, or deleting,\nsome of the fairness constraints, if applicable, and see the counter examples\nNuSMV generates. NuSMV is very easy to run.\n13. In the one-bit channel, there are two fairness constraints. We could have written\nthis as a single one, inserting ‘&’ between running and the long formula, or we\ncould have separated the long formula into two and made it into a total of three\nfairness constraints.\nIn general, what is the diﬀerence between the single fairness constraint φ1 ∧φ2 ∧\n· · · ∧φn and the n fairness constraints φ1, φ2, . . . , φn? Write an SMV program\nwith a fairness constraint a & b which is not equivalent to the two fairness\nconstraints a and b. (You can actually do it in four lines of SMV.)\n14. Explain the construction of formula φ4, used to express that the processes need\nnot enter their critical section in strict sequence. Does it rely on the fact that\nthe safety property φ1 holds?\n15.\n*\nCompute the ECG ⊤labels for Figure 3.11, given the fairness constraints of the\ncode in Figure 3.10 on page 196.\nExercises 3.7\n1. Consider the functions\nH1, H2, H3 : P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}) →P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10})\ndeﬁned by\nH1(Y )\ndef\n= Y −{1, 4, 7}\nH2(Y )\ndef\n= {2, 5, 9} −Y\nH3(Y )\ndef\n= {1, 2, 3, 4, 5} ∩({2, 4, 8} ∪Y )\nfor all Y ⊆{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}.\n(a)\n*\nWhich of these functions are monotone; which ones aren’t? Justify your an-\nswer in each case.\n(b)\n*\nabout expressing properties in LTL are appropriate. Notice that in the\n190\n3 Verification by model checking\nno-strict-sequencing property, we overcame the problem of not being able to\nexpress the existence of paths by instead expressing the complement prop-\nerty, which of course talks about all paths. Then we can perform our check,\nand simply reverse the answer; if the complement property is false, we de-\nclare our property to be true, and vice versa.\nWhy was that tactic not available to us to express the non-blocking prop-\nerty? The reason is that it says: every path to a n1 state may be continued\nby a one-step path to a t1 state. The presence of both universal and exis-\ntential quantiﬁers is the problem. In the no-strict-sequencing property, we\nhad only an existential quantiﬁer; thus, taking the complement property\nturned it into a universal path quantiﬁer, which can be expressed in LTL.\nBut where we have alternating quantiﬁers, taking the complement property\ndoesn’t help in general.\nLet’s go back to the mutual exclusion example. The reason liveness failed\nin our ﬁrst attempt at modelling mutual exclusion is that non-determinism\nmeans it might continually favour one process over another. The problem is\nthat the state s3 does not distinguish between which of the processes ﬁrst\nwent into its trying state. We can solve this by splitting s3 into two states.\nThe second modelling attempt\nThe two states s3 and s9 in Figure 3.8\nboth correspond to the state s3 in our ﬁrst modelling attempt. They both\nrecord that the two processes are in their trying states, but in s3 it is im-\nplicitly recorded that it is process 1’s turn, whereas in s9 it is process 2’s\nturn. Note that states s3 and s9 both have the labelling t1t2; the deﬁnition of\ntransition systems does not preclude this. We can think of there being some\nother, hidden, variables which are not part of the initial labelling, which\ndistinguish s3 and s9. init(st) := sending;\nnext(st) := case\nack = message2 & !(st=sent) : sent;\n1\n: sending;\nesac;\nnext(message1) :=\ncase\nst = sent : {0,1};\n1\n: message1;\nesac;\nnext(message2) :=\ncase\nst = sent : !message2;\n1\n: message2;\nesac;\nFAIRNESS running\nLTLSPEC G F st=sent\nFigure 3.14. The ABP sender in SMV.\nsequentially. The variable message1 is the current bit of the message be-\ning sent, whereas message2 is the control bit. The deﬁnition of the mod-\nule sender is given in Figure 3.14. This module spends most of its time in\nst=sending, going only brieﬂy to st=sent when it receives an acknowledge-\nment corresponding to the control bit of the message it has been sending.\nThe variables message1 and message2 represent the actual data being sent\nand the control bit, respectively. On successful transmission, the module ob-\ntains a new message to send and returns to st=sending. The new message1\nis obtained non-deterministically (i.e., from the environment); message2 al-\nternates in value. We impose FAIRNESS running, i.e., the sender must be\nselected to run inﬁnitely often. The LTLSPEC tests that we can always suc-\nceed in sending the current message. The module receiver is programmed\nin a similar way, in Figure 3.15.\nWe also need to describe the two channels, in Figure 3.16. The acknowl-\nedgement channel is an instance of the one-bit channel one-bit-chan below.\nIts lossy character is speciﬁed by the assignment to forget. The value of\n3.3 Model checking: systems, tools, properties\n205\nMODULE receiver(message1,message2)\nVAR\nst\n: {receiving,received};\nack\n: boolean;\nexpected : boolean;\nASSIGN\ninit(st) := receiving;\nnext(st) := case\nmessage2=expected & !(st=received) : received;\n1\n: receiving;\nesac;\nnext(ack) :=\ncase\nst = received : message2;\n1\n: ack;\nesac;\nnext(expected) :=\ncase\nst = received : !expected;\n1\n: expected;\nesac;\nFAIRNESS running\nLTLSPEC G F st=received\nFigure 3.15. The ABP receiver in SMV.\ninput should be transmitted to output, unless forget is true. The two-bit\na line which can corrupt.)\nThe ABP works as follows. There are four entities, or agents: the sender,\nthe receiver, the message channel and the acknowledgement channel. The\nsender transmits the ﬁrst part of the message together with the ‘control’\nbit 0. If, and when, the receiver receives a message with the control bit 0,\nit sends 0 along the acknowledgement channel. When the sender receives\nthis acknowledgement, it sends the next packet with the control bit 1. If\nand when the receiver receives this, it acknowledges by sending a 1 on the\nacknowledgement channel. By alternating the control bit, both receiver and\nsender can guard against duplicating messages and losing messages (i.e.,\nthey ignore messages that have the unexpected control bit).\nIf the sender doesn’t get the expected acknowledgement, it continually re-\nsends the message, until the acknowledgement arrives. If the receiver doesn’t\nget a message with the expected control bit, it continually resends the pre-\nvious acknowledgement.\nFairness is also important for the ABP. It comes in because, although\nwe want to model the fact that the channel can lose messages, we want to\nassume that, if we send a message often enough, eventually it will arrive.\nIn other words, the channel cannot lose an inﬁnite sequence of messages. If\nwe did not make this assumption, then the channels could lose all messages\nand, in that case, the ABP would not work.\nLet us see this in the concrete setting of SMV. We may assume that\nthe text to be sent is divided up into single-bit messages, which are sent\n204\n3 Verification by model checking\nMODULE sender(ack)\nVAR\nst\n: {sending,sent};\nmessage1 : boolean;\nmessage2 : boolean;\nASSIGN\ninit(st) := sending;\nnext(st) := case\nack = message2 & !(st=sent) : sent;\n1\n: sending;\nesac;\nnext(message1) :=\ncase\nst = sent : {0,1};\n1\n: message1;\nesac;\nnext(message2) :=\ncase\nst = sent : !message2;\n1\n: message2;\nesac;\nFAIRNESS running\nLTLSPEC G F st=sent\nFigure 3.14. The ABP sender in SMV.",
                    "summary": "New Symbolic Model Veriﬁer. ‘NuSMV’ is an Open Source product, is ac-                tively supported and has a substantial user community. SMV takes as input a program describing a model and some speciﬃca-tions (temporal logic formulas) It produces as output either the word ‘true’ or ‘false’ if the formulas hold, or a trace showing why the speci ﬁcation is false for the model represented by our program. For details on how to obtain SMV, see the bibliographic notes at the end of the chapter. Back to the page you came from. Non-determinism is used to model the environment and for abstraction. This expression can be non-deterministic (denoted by several expressions in braces, or no assignment at all) Verification by model checking is done by using SMV's model checking function. For example, the following input to SMV would look like this: Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction. It was also developed by K.K. and is called NuSMV. The program has two variables, request of type boolean and status of enumeration type {ready, busy}: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent values of variable request are not determined within this program; this conserva-                tively models that these values are determined by an external environment. The value of variable status is partially determined: initially, it is ready; and it becomes busy whenever it is not ready. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. Dillon. The model checker Spin, which is geared towards asynchronous systems and is based on the temporal logic LTL, can be found at the Spin website. Current research in model checking includes attempts to exploit ab There are many textbooks about veriﬁcation of reactive systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The Edinburgh Concurrency Workbench12 and the Concurity Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. An example of a customisable and extensible modular model checking framework for the veri ﬉cation of concurrent software is Bogor14. The code for FDR2, a model checker based on the process algebra CSP, NuSMV also supports bounded model checking, invoked by the command-line option -BMc. Bounded model checking looks for counterexamples in order of size, starting with countereXamples of length 1, then 2, etc., up to a given threshold (10 by default) Note that bounded model Checking is incomplete: failure to find a countere X does not mean that there is none of length up to the threshold. Later on, we use bounded modelchecking to prove the optimality of a scheduler. Figure 3.10 gives the SMV code for a mutual exclusion protocol. This codeconsumingconsists of two modules, main and prc.    The module main has the variable turn, which determines whose turn it is to enter the critical section if both are trying to enter. The module main also has two instantiations of prc. In each of theseinstantiations, st is the status of a process (saying whether it is in its critical section, or not, or trying) and other-st is thestatus of the other process. The value of st evolves in the way described in a previous section: when it is n, it may stay as n or move to t. When it is t, it will go straight to c, but if the other one is t it will check its turn before going to c. The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.2. Representing OBDDs.6.3 Representing states as OBDD subsets. 7. Theorems for the analysis of states and their subsets, and how to use them in a computer model. 8. The theory of state-based computing, and its application to the computer model of states, is discussed in more detail in the next section of the book. The book is published by Oxford University Press, London, and is available in paperback and hardback. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org. More information on typed higher-order logics and their use can be found on F.Pfenning’s course homepage7 on Computation and Deduction. The tool has a dedicated repository website at grotesquealloy.mit.edu. There is a great advantage in being able to verify the correctness of computer systems, whether they are hardware, software, or a combination. This is most obvious in the case of safety-critical systems, but also applies to those that are commercially critical, such as mass-produced chips, mission critical, etc. The methods have quite recently become usable by industry and there is a growing demand for professionals able to apply them. In this chapter and the next one, we examine two applications of logics to the question of verifying the correctness of computer systems, or programs. Formal veriﬁcation techniques can be thought of as comprising three parts: a framework for modelling systems, a description language of some sort, and a method to establish whether the description of a system is correct. We examine two approaches to this question: proof-based and model-based. We conclude with a discussion of the implications of these two approaches for computer systems and programs, and their potential to be tampered with in a variety of ways. Back to Mail Online home. Back To the page you came from.    The next chapter will be published on November The NuSMV model checker is again represented by a formula. The CTL model-checking algorithm is also called a \"CTL model checking with fairness\" The correctness of SATEG functions is called the \"SATEU model checking algorithm\" The author concludes that the theory of software veriﬁcation is a good basis for a modern programming language. He concludes that this theory can be used to develop new programming languages and tools. The author also argues that the CTL language is a useful tool for developing new software languages and applications. The book is published by Oxford University Press, London, priced £16.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samar In Figure 3.34 and 3.36, we show how LTL model checking is implemented in NuSMV. To understand why this condition has the desired eﬀect, imagine the circumstances in which it is false. For example, suppose we want to eliminate a run with only ﬁnitely many states satisfying ¬(χi U ψi) ∨ψi. If we carry out this construction on a U b, we obtain the automaton shown in Figure 4.1 and 4.2. In Figure 5.1 we show an example of how this construction is applied to a formula with two U subformulas, p U q and p u q. The acceptance condition asserts that every run must pass infinitely often through the set {q1, q3, q4, q5, q6}. NuSMV checks whether there is a path of the resulting system which satisﬁes the acceptance condition of A¬φ. It is possible to implement the check for such a path in terms of CTLmodel checking, and this is in fact what Nu SMV does. The transitions with no arrows can be taken in either direc or direc-functional mode, depending on the state of the automaton. The automaton accepts precisely traces satisfying the condition that the system is in a state s of M. This chapter concerns a veriﬁcation method called model checking. It is intended to be used for concur-                rent, reactive systems and originated as a post-development methodology. The combined system is represented as the system to be model checked in NuSMV, and the formula to be checked is simply EG ⊤. The Alloy system described in Chapter 2 is also an automatic, model-                based, property-veri ﬃcation approach. The method can be used to find and fix bugs that are not covered by test cases, such as the FDIV error in Intel's Pentium chip. It can also help to find bugs that can't be fixed by testing, since they tend to be Model checking is based on temporal logic. It is intended to be used for programs which we expect to terminate and produce a result. The idea of temporal logic is that a formula is not statically true or false in a model, as it is in propo-                sitional and predicate logic. Verification by model checking is a proof-based, computer-assisted, property-veriﬁcation approach. It can produce counterexamples, consisting ofexecution traces. The way models are used is slightly different from the way Alloy is used. It focuses explicitly on temporal properties and the temporal evolution of systems. It also focuses on the use of models to test hypotheses made by the user. The models of temporal logic containseveral states and a formula can be true in some states and false in others. Run the NuSMV system on some examples. Try commenting out, or deleting, some of the fairness constraints, if applicable, and see the counter examples that Nu SMV generates. The one-bit channel is very easy to run and has two fairness constraints. In the one- bit channel, there are two fairness constraint.  In the two-bit channels, there is one fairness constraint and one fairness constraints for each channel. For example, in Section 3.6.1, the fairness constraint for channel 1 is that channel 2 is equal to channel 1. For channel 2, the fairness constraint is that Compute the ECG ⊤labels for Figure 3.11, given the fairness constraints of the SMV code. Explain the construction of formula φ4, used to express that the processes need not enter their critical section in strict sequence. Write an SMV program with a fairness constraint a & b which is not equivalent to the two fairnessconstraints a and b. Use these questions to help you understand the code and the rules in the book. The book is available in English, German, French, Spanish and Italian. For more information on the book, visit the publisher's website or read the book’s online version. For the full version of this article, see the Amazon.com site. In LTL, the functions P, H1, H2, H3 are monotone. Consider the functions: P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}) →H1(Y), H2(Y) and H3 (Y) H1(A) H2 (B) H3(C) H4 (D) H5 (E) H6 (F) H7 (H8) H8 (H9) H9 (H10) H10 (H11) H11 (H12) H12 (H13) H13 (H14) H14 (H15) H15 (H16 The presence of both universal and exis-tential quantiﬁers is the problem. The reason liveness failed is that non-determinism means it might continually favour one process over another. We can solve this by splitting s3 into two states. The two states s3 and s9 in Figure 3.8 both correspond to the state s3 in our ﬁrst modelling attempt. The problem is that the state does not distinguish between which of the processes  went into its trying state. The second modelling attempt is more successful and shows that s3 can be used to model mutual exclusion in a number of ways. The deﬁnition of the ABP sender is given in Figure 3.14. The variable message1 is the current bit of the message sent, whereas message2 is the control bit. The ABP sends the message in two stages, s3 and s9. In s3 it is im-plicitly recorded that it is process 1’s turn, whereas in s9 it is processes 2 and 3’turn. We can think of there being some other, hidden, variables which are not part of the initial labelling, which would separate s3 from s9 and vice versa. The de-forming of ABP systems does not preclude the existence of hidden variables. The variables message1 and message2 represent the actual data being sent and the control bit, respectively. On successful transmission, the module ob-                tains a new message to send and returns to st=sending. The new message1is obtained non-deterministically (i.e., from the environment) and the new message2 al-                cyternates in value. We impose FAIRNESS running, i.e. the sender must be selected to run inﬁnitely often. The module receiver is programmed in a similar way, in Figure 3.15. We also need to describe the two channels. The acknowl-                edgement channel is an instance of the one-bit channel one The ABP works as follows. There are four entities, or agents: the sender, the receiver, the message channel and the acknowledgement channel. The sender transmits the ﬁrst part of the message together with the ‘control’ bit 0. If, and when the receiver receives a message with the control bit 0, it sends 0 along the acknowledgement channels. The value of the ABP receiver in SMV.15.3 should be transmitted to output, unless forget is true. The two-bit line which can corrupt is called ‘forget’ and is used to check that a message is sent to the right place in the message stream. When the sender receives this acknowledgement, it sends the next packet with the control bit 1. When the receiver receives this, it acknowledges by sending a 1 on the acknowledgement channel. If the receiver doesn’t get a message with the expected control bit, it continually resends the pre-ishlyvious acknowledgement. By alternating the control bits, both receiver andsender can guard against duplicating messages and losing messages (i.e., they ignore messages that have the unexpected control bit). If the sender doesn't get the expected acknowledgement, It continually re- hypertlysends the message, until the acknowledgement arrives. In other words, the channel cannot lose an inﬁnite sequence of messages. We may assume that the text to be sent is divided up into single-bit messages, which are sent. If we did not make this assumption, then the channels could lose all messages. In that case, the ABP would not work. Let us see this in the concrete setting of SMV.Figure 3.14. The ABP sender in SMV..  The AB P sender inSMV... The message sent by SMV to the sender is called a \"message\" and the message is sent by the sender to the receiving channel.",
                    "children": [
                        {
                            "id": "chapter-3-section-3-subsection-1",
                            "title": "Example: Mutual Exclusion",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-3-subsection-2",
                            "title": "The NuSMV Model Checker",
                            "content": "‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nrun the speciﬁcation checks, as well as inspect partial results and set various\nparameters. See the NuSMV user manual for more details.\nNuSMV also supports bounded model checking, invoked by the command-\nline option -bmc. Bounded model checking looks for counterexamples in\norder of size, starting with counterexamples of length 1, then 2, etc., up\nto a given threshold (10 by default). Note that bounded model checking\nis incomplete: failure to ﬁnd a counterexample does not mean that there\nis none, but only that there is none of length up to the threshold. For\nrelated reasons, this incompleteness features also in Alloy and its constraint\nanalyzer. Thus, while a negative answer can be relied on (if NuSMV ﬁnds a\ncounterexample, it is valid), a positive one cannot. References on bounded\nmodel checking can be found in the bibliographic notes on page 254. Later\non, we use bounded model checking to prove the optimality of a scheduler.\n3.3.4 Mutual exclusion revisited\nFigure 3.10 gives the SMV code for a mutual exclusion protocol. This code\nconsists of two modules, main and prc. The module main has the variable\nturn, which determines whose turn it is to enter the critical section if both\nare trying to enter (recall the discussion about the states s3 and s9 in Sec-\ntion 3.3.1).\nThe module main also has two instantiations of prc. In each of these\ninstantiations, st is the status of a process (saying whether it is in its critical\nsection, or not, or trying) and other-st is the status of the other process\n(notice how this is passed as a parameter in the third and fourth lines of\nmain).\nThe value of st evolves in the way described in a previous section: when\nit is n, it may stay as n or move to t. When it is t, if the other one is n, it will\ngo straight to c, but if the other one is t, it will check whose turn it is before\ngoing to c. Then, when it is c, it may move back to n. Each instantiation of\nprc gives the turn to the other one when it gets to its critical section.\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nstates satisfying ¬(χi U ψi) ∨ψi. To understand why this condition has the\ndesired eﬀect, imagine the circumstances in which it is false. Suppose we\nhave a run having only ﬁnitely many states satisfying ¬(χi U ψi) ∨ψi. Let\nus advance through all those ﬁnitely many states, taking the suﬃx of the run\nnone of whose states satisﬁes ¬(χi U ψi) ∨ψi, i.e., all of whose states satisfy\n(χi U ψi) ∧¬ψi. That is precisely the sort of run we want to eliminate.\nIf we carry out this construction on a U b, we obtain the automaton shown\nin Figure 3.34. Another example is shown in Figure 3.36, for the formula\n(p U q) ∨(¬p U q). Since that formula has two U subformulas, there are two\nsets speciﬁed in the acceptance condition, namely, the states satisfying p U q\nand the states satisfying ¬p U q.\nHow LTL model checking is implemented in NuSMV\nIn the sec-\ntions above, we described an algorithm for LTL model checking. Given an\nLTL formula φ and a system M and a state s of M, we may check whether\nM, s ⊨φ holds by constructing the automaton A¬φ, combining it with M,\n238\n3 Verification by model checking\n¬(p U q),\n¬(¬p U q),\n¬p, ¬q, ¬φ\n¬(p U q),\n¬(¬p U q),\np U q,\n¬p U q,\n¬p, q, φ\np U q,\n¬(¬p U q),\np, ¬q, φ\np U q,\n¬p U q,\np, q, φ\n¬(p U q),\n¬p U q,\n¬p, ¬q, φ\nq1\nq2\nq3\nq4\nq5\nq6\np, ¬q, ¬φ\nFigure 3.36. Automaton accepting precisely traces satisfying φ\ndef\n= (p U\nq) ∨(¬p U q). The transitions with no arrows can be taken in either direc-\ntion. The acceptance condition asserts that every run must pass infinitely\noften through the set {q1, q3, q4, q5, q6}, and also the set {q1, q2, q3, q5, q6}.\nand checking whether there is a path of the resulting system which satisﬁes\nthe acceptance condition of A¬φ.\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ncaught earlier in the production cycle are less costly to rectify. (It is\nalleged that Intel lost millions of dollars by releasing their Pentium chip\nwith the FDIV error.)\nThis chapter concerns a veriﬁcation method called model checking. In\nterms of the above classiﬁcation, model checking is an automatic, model-\nbased, property-veriﬁcation approach. It is intended to be used for concur-\nrent, reactive systems and originated as a post-development methodology.\nConcurrency bugs are among the most diﬃcult to ﬁnd by testing (the activ-\nity of running several simulations of important scenarios), since they tend to\nbe non-reproducible or not covered by test cases, so it is well worth having\na veriﬁcation technique that can help one to ﬁnd them.\nThe Alloy system described in Chapter 2 is also an automatic, model-\nbased, property-veriﬁcation approach. The way models are used is slightly\ndiﬀerent, however. Alloy ﬁnds models which form counterexamples to asser-\ntions made by the user. Model checking starts with a model described by\nthe user, and discovers whether hypotheses asserted by the user are valid\non the model. If they are not, it can produce counterexamples, consisting of\nexecution traces. Another diﬀerence between Alloy and model checking is\nthat model checking (unlike Alloy) focuses explicitly on temporal properties\nand the temporal evolution of systems.\n174\n3 Verification by model checking\nBy contrast, Chapter 4 describes a very diﬀerent veriﬁcation technique\nwhich in terms of the above classiﬁcation is a proof-based, computer-assisted,\nproperty-veriﬁcation approach. It is intended to be used for programs which\nwe expect to terminate and produce a result.\nModel checking is based on temporal logic. The idea of temporal logic is\nthat a formula is not statically true or false in a model, as it is in propo-\nsitional and predicate logic. Instead, the models of temporal logic contain\nseveral states and a formula can be true in some states and false in others.",
                            "summary": "New Symbolic Model Veriﬁer. ‘NuSMV’ is an Open Source product, is ac-                tively supported and has a substantial user community. SMV takes as input a program describing a model and some speciﬃca-tions (temporal logic formulas) It produces as output either the word ‘true’ or ‘false’ if the formulas hold, or a trace showing why the speci ﬁcation is false for the model represented by our program. For details on how to obtain SMV, see the bibliographic notes at the end of the chapter. Back to the page you came from. Non-determinism is used to model the environment and for abstraction. This expression can be non-deterministic (denoted by several expressions in braces, or no assignment at all) Verification by model checking is done by using SMV's model checking function. For example, the following input to SMV would look like this: Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction. It was also developed by K.K. and is called NuSMV. The program has two variables, request of type boolean and status of enumeration type {ready, busy}: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent values of variable request are not determined within this program; this conserva-                tively models that these values are determined by an external environment. The value of variable status is partially determined: initially, it is ready; and it becomes busy whenever it is not ready. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. Dillon. The model checker Spin, which is geared towards asynchronous systems and is based on the temporal logic LTL, can be found at the Spin website. Current research in model checking includes attempts to exploit ab There are many textbooks about veriﬁcation of reactive systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The Edinburgh Concurrency Workbench12 and the Concurity Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. An example of a customisable and extensible modular model checking framework for the veri ﬉cation of concurrent software is Bogor14. The code for FDR2, a model checker based on the process algebra CSP, NuSMV also supports bounded model checking, invoked by the command-line option -BMc. Bounded model checking looks for counterexamples in order of size, starting with countereXamples of length 1, then 2, etc., up to a given threshold (10 by default) Note that bounded model Checking is incomplete: failure to find a countere X does not mean that there is none of length up to the threshold. Later on, we use bounded modelchecking to prove the optimality of a scheduler. Figure 3.10 gives the SMV code for a mutual exclusion protocol. This codeconsumingconsists of two modules, main and prc.    The module main has the variable turn, which determines whose turn it is to enter the critical section if both are trying to enter. The module main also has two instantiations of prc. In each of theseinstantiations, st is the status of a process (saying whether it is in its critical section, or not, or trying) and other-st is thestatus of the other process. The value of st evolves in the way described in a previous section: when it is n, it may stay as n or move to t. When it is t, it will go straight to c, but if the other one is t it will check its turn before going to c. The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.2. Representing OBDDs.6.3 Representing states as OBDD subsets. 7. Theorems for the analysis of states and their subsets, and how to use them in a computer model. 8. The theory of state-based computing, and its application to the computer model of states, is discussed in more detail in the next section of the book. The book is published by Oxford University Press, London, and is available in paperback and hardback. For confidential support, call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org. More information on typed higher-order logics and their use can be found on F.Pfenning’s course homepage7 on Computation and Deduction. The tool has a dedicated repository website at grotesquealloy.mit.edu. There is a great advantage in being able to verify the correctness of computer systems, whether they are hardware, software, or a combination. This is most obvious in the case of safety-critical systems, but also applies to those that are commercially critical, such as mass-produced chips, mission critical, etc. The methods have quite recently become usable by industry and there is a growing demand for professionals able to apply them. In this chapter and the next one, we examine two applications of logics to the question of verifying the correctness of computer systems, or programs. Formal veriﬁcation techniques can be thought of as comprising three parts: a framework for modelling systems, a description language of some sort, and a method to establish whether the description of a system is correct. We examine two approaches to this question: proof-based and model-based. We conclude with a discussion of the implications of these two approaches for computer systems and programs, and their potential to be tampered with in a variety of ways. Back to Mail Online home. Back To the page you came from.    The next chapter will be published on November The NuSMV model checker is again represented by a formula. The CTL model-checking algorithm is also called a \"CTL model checking with fairness\" The correctness of SATEG functions is called the \"SATEU model checking algorithm\" The author concludes that the theory of software veriﬁcation is a good basis for a modern programming language. He concludes that this theory can be used to develop new programming languages and tools. The author also argues that the CTL language is a useful tool for developing new software languages and applications. The book is published by Oxford University Press, London, priced £16.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samar In Figure 3.34 and 3.36, we show how LTL model checking is implemented in NuSMV. To understand why this condition has the desired eﬀect, imagine the circumstances in which it is false. For example, suppose we want to eliminate a run with only ﬁnitely many states satisfying ¬(χi U ψi) ∨ψi. If we carry out this construction on a U b, we obtain the automaton shown in Figure 4.1 and 4.2. In Figure 5.1 we show an example of how this construction is applied to a formula with two U subformulas, p U q and p u q. The acceptance condition asserts that every run must pass infinitely often through the set {q1, q3, q4, q5, q6}. NuSMV checks whether there is a path of the resulting system which satisﬁes the acceptance condition of A¬φ. It is possible to implement the check for such a path in terms of CTLmodel checking, and this is in fact what Nu SMV does. The transitions with no arrows can be taken in either direc or direc-functional mode, depending on the state of the automaton. The automaton accepts precisely traces satisfying the condition that the system is in a state s of M. This chapter concerns a veriﬁcation method called model checking. It is intended to be used for concur-                rent, reactive systems and originated as a post-development methodology. The combined system is represented as the system to be model checked in NuSMV, and the formula to be checked is simply EG ⊤. The Alloy system described in Chapter 2 is also an automatic, model-                based, property-veri ﬃcation approach. The method can be used to find and fix bugs that are not covered by test cases, such as the FDIV error in Intel's Pentium chip. It can also help to find bugs that can't be fixed by testing, since they tend to be Model checking is based on temporal logic. It is intended to be used for programs which we expect to terminate and produce a result. The idea of temporal logic is that a formula is not statically true or false in a model, as it is in propo-                sitional and predicate logic. Verification by model checking is a proof-based, computer-assisted, property-veriﬁcation approach. It can produce counterexamples, consisting ofexecution traces. The way models are used is slightly different from the way Alloy is used. It focuses explicitly on temporal properties and the temporal evolution of systems. It also focuses on the use of models to test hypotheses made by the user.  temporal logic models containseveral states and a formula can be true in some states and false in",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-3-subsection-3",
                            "title": "Running NuSMV",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-3-subsection-4",
                            "title": "Mutual Exclusion Revisited",
                            "content": "labels given in Section 3.6.1.\n9.\n*\nFor mutual exclusion, draw a transition system which forces the two processes\nto enter their critical section in strict sequence and show that φ4 is false of its\ninitial state.\n10. Use the deﬁnition of ⊨between states and CTL formulas to explain why s ⊨\nAG AF φ means that φ is true inﬁnitely often along every path starting at s.\n11.\n*\nShow that a CTL formula φ is true on inﬁnitely many states of a computa-\ntion path s0 →s1 →s2 →. . . iﬀfor all n ≥0 there is some m ≥n such that\nsm ⊨φ.\n12. Run the NuSMV system on some examples. Try commenting out, or deleting,\nsome of the fairness constraints, if applicable, and see the counter examples\nNuSMV generates. NuSMV is very easy to run.\n13. In the one-bit channel, there are two fairness constraints. We could have written\nthis as a single one, inserting ‘&’ between running and the long formula, or we\ncould have separated the long formula into two and made it into a total of three\nfairness constraints.\nIn general, what is the diﬀerence between the single fairness constraint φ1 ∧φ2 ∧\n· · · ∧φn and the n fairness constraints φ1, φ2, . . . , φn? Write an SMV program\nwith a fairness constraint a & b which is not equivalent to the two fairness\nconstraints a and b. (You can actually do it in four lines of SMV.)\n14. Explain the construction of formula φ4, used to express that the processes need\nnot enter their critical section in strict sequence. Does it rely on the fact that\nthe safety property φ1 holds?\n15.\n*\nCompute the ECG ⊤labels for Figure 3.11, given the fairness constraints of the\ncode in Figure 3.10 on page 196.\nExercises 3.7\n1. Consider the functions\nH1, H2, H3 : P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}) →P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10})\ndeﬁned by\nH1(Y )\ndef\n= Y −{1, 4, 7}\nH2(Y )\ndef\n= {2, 5, 9} −Y\nH3(Y )\ndef\n= {1, 2, 3, 4, 5} ∩({2, 4, 8} ∪Y )\nfor all Y ⊆{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}.\n(a)\n*\nWhich of these functions are monotone; which ones aren’t? Justify your an-\nswer in each case.\n(b)\n*\nabout expressing properties in LTL are appropriate. Notice that in the\n190\n3 Verification by model checking\nno-strict-sequencing property, we overcame the problem of not being able to\nexpress the existence of paths by instead expressing the complement prop-\nerty, which of course talks about all paths. Then we can perform our check,\nand simply reverse the answer; if the complement property is false, we de-\nclare our property to be true, and vice versa.\nWhy was that tactic not available to us to express the non-blocking prop-\nerty? The reason is that it says: every path to a n1 state may be continued\nby a one-step path to a t1 state. The presence of both universal and exis-\ntential quantiﬁers is the problem. In the no-strict-sequencing property, we\nhad only an existential quantiﬁer; thus, taking the complement property\nturned it into a universal path quantiﬁer, which can be expressed in LTL.\nBut where we have alternating quantiﬁers, taking the complement property\ndoesn’t help in general.\nLet’s go back to the mutual exclusion example. The reason liveness failed\nin our ﬁrst attempt at modelling mutual exclusion is that non-determinism\nmeans it might continually favour one process over another. The problem is\nthat the state s3 does not distinguish between which of the processes ﬁrst\nwent into its trying state. We can solve this by splitting s3 into two states.\nThe second modelling attempt\nThe two states s3 and s9 in Figure 3.8\nboth correspond to the state s3 in our ﬁrst modelling attempt. They both\nrecord that the two processes are in their trying states, but in s3 it is im-\nplicitly recorded that it is process 1’s turn, whereas in s9 it is process 2’s\nturn. Note that states s3 and s9 both have the labelling t1t2; the deﬁnition of\ntransition systems does not preclude this. We can think of there being some\nother, hidden, variables which are not part of the initial labelling, which\ndistinguish s3 and s9.",
                            "summary": "NuSMV is very easy to run. In the one-bit channel, there are two fairness constraints. Run the NuSMV system on some examples. Try commenting out, or deleting, some of the fairness constraints, if applicable. See the counter examples to see how the system works. Use the. labels given in Section 3.6.1 to help you understand the system. Use. the deﬁnition of ⊨between states and CTL formulas to explain why s. ≢AG AF φ means that φ is true in.ﬀnitely often along every path starting at s.       Compute the ECG ⊤labels for Figure 3.11, given the fairness constraints of the SMV code. Explain the construction of formula φ4, used to express that the processes need not enter their critical section in strict sequence. Write an SMV program with a fairness constraint a & b which is not equivalent to the two fairnessconstraints a and b. Use these questions to help you understand the code and the rules in the book. The book is available in English, German, French, Spanish and Italian. For more information on the book, visit the publisher's website or read the book’s online version. For the full version of this article, see the Amazon.com site. In LTL, the functions P, H1, H2, H3 are monotone. Consider the functions: P({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}) →H1(Y), H2(Y) and H3 (Y) H1(A) H2 (B) H3(C) H4 (D) H5 (E) H6 (F) H7 (H8) H8 (H9) H9 (H10) H10 (H11) H11 (H12) H12 (H13) H13 (H14) H14 (H15) H15 (H16 The presence of both universal and exis-tential quantiﬁers is the problem. The reason liveness failed is that non-determinism means it might continually favour one process over another. We can solve this by splitting s3 into two states. The two states s3 and s9 in Figure 3.8 both correspond to the state s3 in our ﬁrst modelling attempt. The problem is that the state does not distinguish between which of the processes  went into its trying state. The second modelling attempt is more successful and shows that s3 can be used to model mutual exclusion in a number of ways. S3 and s9 both have the labelling t1t2. They both record that the two processes are in their trying states. But in s3 it is im-plicitly recorded that it is process 1’s turn, whereas in s9 it's process 2's turn. We can think of there being some other, hidden, variables which",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-3-subsection-5",
                            "title": "The Ferryman",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-3-subsection-6",
                            "title": "The Alternating Bit Protocol",
                            "content": "init(st) := sending;\nnext(st) := case\nack = message2 & !(st=sent) : sent;\n1\n: sending;\nesac;\nnext(message1) :=\ncase\nst = sent : {0,1};\n1\n: message1;\nesac;\nnext(message2) :=\ncase\nst = sent : !message2;\n1\n: message2;\nesac;\nFAIRNESS running\nLTLSPEC G F st=sent\nFigure 3.14. The ABP sender in SMV.\nsequentially. The variable message1 is the current bit of the message be-\ning sent, whereas message2 is the control bit. The deﬁnition of the mod-\nule sender is given in Figure 3.14. This module spends most of its time in\nst=sending, going only brieﬂy to st=sent when it receives an acknowledge-\nment corresponding to the control bit of the message it has been sending.\nThe variables message1 and message2 represent the actual data being sent\nand the control bit, respectively. On successful transmission, the module ob-\ntains a new message to send and returns to st=sending. The new message1\nis obtained non-deterministically (i.e., from the environment); message2 al-\nternates in value. We impose FAIRNESS running, i.e., the sender must be\nselected to run inﬁnitely often. The LTLSPEC tests that we can always suc-\nceed in sending the current message. The module receiver is programmed\nin a similar way, in Figure 3.15.\nWe also need to describe the two channels, in Figure 3.16. The acknowl-\nedgement channel is an instance of the one-bit channel one-bit-chan below.\nIts lossy character is speciﬁed by the assignment to forget. The value of\n3.3 Model checking: systems, tools, properties\n205\nMODULE receiver(message1,message2)\nVAR\nst\n: {receiving,received};\nack\n: boolean;\nexpected : boolean;\nASSIGN\ninit(st) := receiving;\nnext(st) := case\nmessage2=expected & !(st=received) : received;\n1\n: receiving;\nesac;\nnext(ack) :=\ncase\nst = received : message2;\n1\n: ack;\nesac;\nnext(expected) :=\ncase\nst = received : !expected;\n1\n: expected;\nesac;\nFAIRNESS running\nLTLSPEC G F st=received\nFigure 3.15. The ABP receiver in SMV.\ninput should be transmitted to output, unless forget is true. The two-bit\na line which can corrupt.)\nThe ABP works as follows. There are four entities, or agents: the sender,\nthe receiver, the message channel and the acknowledgement channel. The\nsender transmits the ﬁrst part of the message together with the ‘control’\nbit 0. If, and when, the receiver receives a message with the control bit 0,\nit sends 0 along the acknowledgement channel. When the sender receives\nthis acknowledgement, it sends the next packet with the control bit 1. If\nand when the receiver receives this, it acknowledges by sending a 1 on the\nacknowledgement channel. By alternating the control bit, both receiver and\nsender can guard against duplicating messages and losing messages (i.e.,\nthey ignore messages that have the unexpected control bit).\nIf the sender doesn’t get the expected acknowledgement, it continually re-\nsends the message, until the acknowledgement arrives. If the receiver doesn’t\nget a message with the expected control bit, it continually resends the pre-\nvious acknowledgement.\nFairness is also important for the ABP. It comes in because, although\nwe want to model the fact that the channel can lose messages, we want to\nassume that, if we send a message often enough, eventually it will arrive.\nIn other words, the channel cannot lose an inﬁnite sequence of messages. If\nwe did not make this assumption, then the channels could lose all messages\nand, in that case, the ABP would not work.\nLet us see this in the concrete setting of SMV. We may assume that\nthe text to be sent is divided up into single-bit messages, which are sent\n204\n3 Verification by model checking\nMODULE sender(ack)\nVAR\nst\n: {sending,sent};\nmessage1 : boolean;\nmessage2 : boolean;\nASSIGN\ninit(st) := sending;\nnext(st) := case\nack = message2 & !(st=sent) : sent;\n1\n: sending;\nesac;\nnext(message1) :=\ncase\nst = sent : {0,1};\n1\n: message1;\nesac;\nnext(message2) :=\ncase\nst = sent : !message2;\n1\n: message2;\nesac;\nFAIRNESS running\nLTLSPEC G F st=sent\nFigure 3.14. The ABP sender in SMV.",
                            "summary": "The deﬁnition of the ABP sender is given in Figure 3.14. The variables message1 and message2 represent the actual data being sent and the control bit, respectively. The new message1 is obtained non-deterministically (i.e., from the environment) and the new message2 al-handedly. The ABP module spends most of its time in st=sending, going only brieﬂy to st=sent when it receives an acknowledge-                ment corresponding to the control bits of the message it has been sending. On successful transmission, the module ob-                tains a new message to send and returns to st =sending. The ABP receiver in SMV should be transmitted to output, unless forget is true. We impose FAIRNESS running, i.e., the sender must be                selected to run inﬁnitely often. The LTLSPEC tests that we can always suc-                ceed in sending the current message. The module receiver is programmedin a similar way, in Figure 3.15.Figure 3.16. We also need to describe the two channels. The acknowl-                edgement channel is an instance of the one-bit channel one- bit-chan below. Its lossy character is speci﬋ed by the assignment to forget. The value of sizeof3.3 Model checking: systems, The ABP works as follows. There are four entities, or agents: the sender, the receiver, the message channel and the acknowledgement channel. The sender transmits the ﬁrst part of the message together with the ‘control’bit 0. If the receiver receives a message with the control bit 0, it sends 0 along the acknowledgement channels. When the sender receives this acknowledgement, it receives the next packet with a control bit 1. By alternating the control bits, both receiver and sender can guard against duplicating messages and losing messages (i.e., they ignore messages that have the unexpected control bit). The two-bit                a line which can corrupt.) The two If the receiver doesn’t get a message with the expected control bit, it continually resends the pre-                vious acknowledgement. We want to assume that, if we send a message often enough, eventually it will arrive. If we did not make this assumption, then the channels could lose all messages. In that case, the ABP would not work. Let us see this in the concrete setting of SMV. It comes in because, although we want to model the fact that the channel can We may assume that the text to be sent is divided up into single-bit messages, which are sent. Figure 3.14 shows the ABP sender in SMV. We can verify this by checking the model's ABP sending and receiving code. The ABP message is sent by sending a single bit to the sender. The message is then sent by receiving the single bit back. The sender is called a \"sender\"",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-3-section-4",
                    "title": "Branching-Time Logic",
                    "content": "U cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nc2, or must pass through such a state to reach a labelled state.\nThe pseudo-code of the CTL model-checking algorithm\nWe\npresent the pseudo-code for the basic labelling algorithm. The main function\nSAT (for ‘satisﬁes’) takes as input a CTL formula. The program SAT expects\na parse tree of some CTL formula constructed by means of the grammar in\nDeﬁnition 3.12. This expectation reﬂects an important precondition on the\ncorrectness of the algorithm SAT. For example, the program simply would\nnot know what to do with an input of the form X (⊤∧EF p3), since this is\nnot a CTL formula.\n226\n3 Verification by model checking\ns5\ns0\n0: t1n2\n0: c1n2\n0: t1t2\n0: c1t2\n2: E[¬c2 U c1]\ns3\ns1\ns2\ns6\ns9\ns4\ns7\n1: E[¬c2 U c1]\n1: E[¬c2 U c1]\n2: E[¬c2 U c1]\n3: E[¬c2 U c1]\n0: n1n2\n0: n1t2\n0: t1t2\n0: t1c2\n0: n1c2\nFigure 3.27. An example run of the labelling algorithm in our second\nmodel of mutual exclusion applied to the formula E[¬c2 U c1].\nThe pseudo-code we write for SAT looks a bit like fragments of C or\nJava code; we use functions with a keyword return that indicates which\nresult the function should return. We will also use natural language to\nindicate the case analysis over the root node of the parse tree of φ. The\ndeclaration local var declares some fresh variables local to the current in-\nstance of the procedure in question, whereas repeat until executes the\ncommand which follows it repeatedly, until the condition becomes true. Ad-\nditionally, we employ suggestive notation for the operations on sets, like\nintersection, set complement and so forth. In reality we would need an ab-\nstract data type, together with implementations of these operations, but for\nnow we are interested only in the mechanism in principle of the algorithm\nfor SAT; any (correct and eﬃcient) implementation of sets would do and\nwe study such an implementation in Chapter 6. We assume that SAT has\naccess to all the relevant parts of the model: S, →and L. In particular,\nenabled is inﬁnitely often taken.\nr A certain process is enabled inﬁnitely often on every computation path:\nAG (AF enabled).\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nAF (AG deadlock).\nr From any state it is possible to get to a restart state:\nAG (EF restart).\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nAG (floor2 ∧directionup ∧ButtonPressed5 →A[directionup U floor5])\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nr The lift can remain idle on the third ﬂoor with its doors closed:\nAG (floor3 ∧idle ∧doorclosed →EG (floor3 ∧idle ∧doorclosed)).\nr A process can always request to enter its critical section. Recall that this was\nnot expressible in LTL. Using the propositions of Figure 3.8, this may be written\nAG (n1 →EX t1) in CTL.\nr Processes need not enter their critical section in strict sequence. This was also\nnot expressible in LTL, though we expressed its negation. CTL allows us to\nexpress it directly: EF (c1 ∧E[c1 U (¬c1 ∧E[¬c2 U c1])]).\n3.4.4 Important equivalences between CTL formulas\nDeﬁnition 3.16 Two CTL formulas φ and ψ are said to be semantically\nequivalent if any state in any model which satisﬁes one of them also satisﬁes\nthe other; we denote this by φ ≡ψ.\n216\n3 Verification by model checking\nWe have already noticed that A is a universal quantiﬁer on paths and E\nis the corresponding existential quantiﬁer. Moreover, G and F are also uni-\nversal and existential quantiﬁers, ranging over the states along a particular\npath. In view of these facts, it is not surprising to ﬁnd that de Morgan rules\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the all paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nenabled is inﬁnitely often taken.\nr A certain process is enabled inﬁnitely often on every computation path:\nAG (AF enabled).\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nAF (AG deadlock).\nr From any state it is possible to get to a restart state:\nAG (EF restart).\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nAG (floor2 ∧directionup ∧ButtonPressed5 →A[directionup U floor5])\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nr The lift can remain idle on the third ﬂoor with its doors closed:\nAG (floor3 ∧idle ∧doorclosed →EG (floor3 ∧idle ∧doorclosed)).\nr A process can always request to enter its critical section. Recall that this was\nnot expressible in LTL. Using the propositions of Figure 3.8, this may be written\nAG (n1 →EX t1) in CTL.\nr Processes need not enter their critical section in strict sequence. This was also\nnot expressible in LTL, though we expressed its negation. CTL allows us to\nexpress it directly: EF (c1 ∧E[c1 U (¬c1 ∧E[¬c2 U c1])]).\n3.4.4 Important equivalences between CTL formulas\nDeﬁnition 3.16 Two CTL formulas φ and ψ are said to be semantically\nequivalent if any state in any model which satisﬁes one of them also satisﬁes\nthe other; we denote this by φ ≡ψ.\n216\n3 Verification by model checking\nWe have already noticed that A is a universal quantiﬁer on paths and E\nis the corresponding existential quantiﬁer. Moreover, G and F are also uni-\nversal and existential quantiﬁers, ranging over the states along a particular\npath. In view of these facts, it is not surprising to ﬁnd that de Morgan rules\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nmeets a q, but that is still not capturing the meaning of F p →F q.\nCTL* is a logic which combines the expressive powers of LTL and CTL,\nby dropping the CTL constraint that every temporal operator (X, U, F, G)\nhas to be associated with a unique path quantiﬁer (A, E). It allows us to\nwrite formulas such as\nr A[(p U r) ∨(q U r)]: along all paths, either p is true until r, or q is true until r.\nr A[X p ∨X X p]: along all paths, p is true in the next state, or the next but one.\nr E[G F p]: there is a path along which p is inﬁnitely often true.\nThese formulas are not equivalent to, respectively, A[(p ∨q) U r)], AX p ∨\nAX AX p and EG EF p. It turns out that the ﬁrst of them can be written\nas a (rather long) CTL formula. The second and third do not have a CTL\nequivalent.\nThe syntax of CTL* involves two classes of formulas:\nr state formulas, which are evaluated in states:\nφ ::= ⊤| p | (¬φ) | (φ ∧φ) | A[α] | E[α]\nwhere p is any atomic formula and α any path formula; and\nr path formulas, which are evaluated along paths:\nα ::= φ | (¬α) | (α ∧α) | (α U α) | (G α) | (F α) | (X α)\nwhere φ is any state formula. This is an example of an inductive deﬁnition\nwhich is mutually recursive: the deﬁnition of each class depends upon the\ndeﬁnition of the other, with base cases p and ⊤.\nLTL and CTL as subsets of CTL*\nAlthough the syntax of LTL does\nnot include A and E, the semantic viewpoint of LTL is that we consider\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually resolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\ntime-consuming and local ‘ﬁxes’ often introduce new bugs at other places. Ex-\nperience has shown that verifying programs with respect to formal speciﬁcations\ncan signiﬁcantly cut down the duration of software development and maintenance\nby eliminating most errors in the planning phase and helping in the clariﬁcation\nof the roles and structural aspects of system components.\nr Refactoring: Properly speciﬁed and veriﬁed software is easier to reuse, since\nwe have a clear speciﬁcation of what it is meant to do.\nr Certiﬁcation audits: Safety-critical computer systems – such as the control\nof cooling systems in nuclear power stations, or cockpits of modern aircrafts –\ndemand that their software be speciﬁed and veriﬁed with as much rigour and\nformality as possible. Other programs may be commercially critical, such as ac-\ncountancy software used by banks, and they should be delivered with a warranty:\na guarantee for correct performance within proper use. The proof that a program\nmeets its speciﬁcations is indeed such a warranty.\n258\n4 Program verification\nThe degree to which the software industry accepts the beneﬁts of proper\nveriﬁcation of code depends on the perceived extra cost of producing it and\nthe perceived beneﬁts of having it. As veriﬁcation technology improves, the\ncosts are declining; and as the complexity of software and the extent to which\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nmically by a computer. As we will see, there are often good heuristics\nto help the programmer complete these tasks. This contrasts with the\nsituation of the last chapter, which was fully automatic.\nProperty-oriented. Just like in the previous chapter, we verify proper-\nties of a program rather than a full speciﬁcation of its behaviour.\n256\n4.1 Why should we specify and verify code?\n257\nApplication domain. The domain of application in this chapter is se-\nquential transformational programs. ‘Sequential’ means that we assume\nthe program runs on a single processor and that there are no concur-\nrency issues. ‘Transformational’ means that the program takes an input\nand, after some computation, is expected to terminate with an output.\nFor example, methods of objects in Java are often programmed in this\nstyle. This contrasts with the previous chapter which focuses on reactive\nsystems that are not intended to terminate and that react continually\nwith their environment.\nPre/post-development. The techniques of this chapter should be used\nduring the coding process for small fragments of program that perform\nan identiﬁable (and hence, speciﬁable) task and hence should be used\nduring the development process in order to avoid functional bugs.\n4.1 Why should we specify and verify code?\nThe task of specifying and verifying code is often perceived as an unwel-\ncome addition to the programmer’s job and a dispensable one. Arguments\nin favour of veriﬁcation include the following:\nr Documentation: The speciﬁcation of a program is an important component\nin its documentation and the process of documenting a program may raise or\nresolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\ninto an ‘equivalent’ formula φR of some symbolic logic;\nr Write a program P which is meant to realise φR in the programming environment\nsupplied by your company, or wanted by the particular customer;\nr Prove that the program P satisﬁes the formula φR.\nThis scheme is quite crude – for example, constraints may be actual design\ndecisions for interfaces and data types, or the speciﬁcation may ‘evolve’\n4.2 A framework for software verification\n259\nand may partly be ‘unknown’ in big projects – but it serves well as a ﬁrst\napproximation to trying to deﬁne good programming methodology. Several\nvariations of such a sequence of activities are conceivable. For example,\nyou, as a programmer, might have been given only the formula φR, so you\nmight have little if any insight into the real-world problem which you are\nsupposed to solve. Technically, this poses no problem, but often it is handy\nto have both informal and formal descriptions available. Moreover, crafting\nthe informal requirements R is often a mutual process between the client\nand the programmer, whereby the attempt at formalising R can uncover\nambiguities or undesired consequences and hence lead to revisions of R.\nThis ‘going back and forth’ between the realms of informal and formal\nspeciﬁcations is necessary since it is impossible to ‘verify’ whether an infor-\nmal requirement R is equivalent to a formal description φR. The meaning\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nin an integrated in-house development environment.\nCurrently, many companies struggle with a legacy of ancient code with-\nout proper documentation which has to be adapted to new hardware and\nnetwork environments, as well as ever-changing requirements. Often, the\noriginal programmers who might still remember what certain pieces of code\nare for have moved, or died. Software systems now often have a longer\nlife-expectancy than humans, which necessitates a durable, transparent and\nportable design and implementation process; the year-2000 problem was just\none such example. Software veriﬁcation provides some of this.\n4.2 A framework for software verification\nSuppose you are working for a software company and your task is to write\nprograms which are meant to solve sophisticated problems, or computations.\nTypically, such a project involves an outside customer – a utility company,\nfor example – who has written up an informal description, in plain English,\nof the real-world task that is at hand. In this case, it could be the devel-\nopment and maintenance of a database of electricity accounts with all the\npossible applications of that – automated billing, customer service etc. Since\nthe informality of such descriptions may cause ambiguities which eventually\ncould result in serious and expensive design ﬂaws, it is desirable to condense\nall the requirements of such a project into formal speciﬁcations. These formal\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\n1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically, r A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nmeets a q, but that is still not capturing the meaning of F p →F q.\nCTL* is a logic which combines the expressive powers of LTL and CTL,\nby dropping the CTL constraint that every temporal operator (X, U, F, G)\nhas to be associated with a unique path quantiﬁer (A, E). It allows us to\nwrite formulas such as\nr A[(p U r) ∨(q U r)]: along all paths, either p is true until r, or q is true until r.\nr A[X p ∨X X p]: along all paths, p is true in the next state, or the next but one.\nr E[G F p]: there is a path along which p is inﬁnitely often true.\nThese formulas are not equivalent to, respectively, A[(p ∨q) U r)], AX p ∨\nAX AX p and EG EF p. It turns out that the ﬁrst of them can be written\nas a (rather long) CTL formula. The second and third do not have a CTL\nequivalent.\nThe syntax of CTL* involves two classes of formulas:\nr state formulas, which are evaluated in states:\nφ ::= ⊤| p | (¬φ) | (φ ∧φ) | A[α] | E[α]\nwhere p is any atomic formula and α any path formula; and\nr path formulas, which are evaluated along paths:\nα ::= φ | (¬α) | (α ∧α) | (α U α) | (G α) | (F α) | (X α)\nwhere φ is any state formula. This is an example of an inductive deﬁnition\nwhich is mutually recursive: the deﬁnition of each class depends upon the\ndeﬁnition of the other, with base cases p and ⊤.\nLTL and CTL as subsets of CTL*\nAlthough the syntax of LTL does\nnot include A and E, the semantic viewpoint of LTL is that we consider\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above. exist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\nWriting W in terms of U is also possible: W is like U but also allows the\npossibility of the eventuality never occurring:\nφ W ψ ≡φ U ψ ∨G φ.\n(3.3)\nInspection of clauses 12 and 13 reveals that R and W are rather similar. The\ndiﬀerences are that they swap the roles of their arguments φ and ψ; and the\nclause for W has an i −1 where R has i. Therefore, it is not surprising that\nthey are expressible in terms of each other, as follows:\nφ W ψ ≡ψ R (φ ∨ψ)\n(3.4)\nφ R ψ ≡ψ W (φ ∧ψ).\n(3.5)\n3.2.5 Adequate sets of connectives for LTL\nRecall that φ ≡ψ holds iﬀany path in any transition system which sat-\nisﬁes φ also satisﬁes ψ, and vice versa. As in propositional logic, there is\nsome redundancy among the connectives. For example, in Chapter 1 we saw\nthat the set {⊥, ∧, ¬} forms an adequate set of connectives, since the other\nconnectives ∨, →, ⊤, etc., can be written in terms of those three.\nSmall adequate sets of connectives also exist in LTL. Here is a summary\nof the situation.\nr X is completely orthogonal to the other connectives. That is to say, its presence\ndoesn’t help in deﬁning any of the other ones in terms of each other. Moreover,\nX cannot be derived from any combination of the others.\nr Each of the sets {U, X}, {R, X}, {W, X} is adequate. To see this, we note that\n– R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and\nequivalence (3.4) followed by the duality, respectively.\n– U and W may be deﬁned from R, by the duality φ U ψ ≡¬(¬φ R ¬ψ) and\nequivalence (3.4), respectively.\n– R and U may be deﬁned from W, by equivalence (3.5) and the duality φ U\nψ ≡¬(¬φ R ¬ψ) followed by equivalence (3.5).\nSometimes it is useful to look at adequate sets of connectives which do not\nrely on the availability of negation. That’s because it is often convenient to\nassume formulas are written in negation-normal form, where all the negation\nsymbols are applied to propositional atoms (i.e., they are near the leaves\n3.3 Model checking: systems, tools, properties\n187",
                    "summary": "Every A or E must have one of X, F, G and U to accompany it. U cannot occur without being preceded by an A or an E. Weak-until (W) and release (R) are not included in CTL, but they are derivable (see Section 3.4.5). We assume similar binding priorities for the CTL con-                nectives to what we did for propositional and predicate logic. Let us see some examples of well-formed CTL formulas and some examples                which are not well- formed, in order to understand the syntax. The unary                connectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF It is worth spending some time seeing how the syntax rules allow us toconstruct each of these. The following are well-formed CTLformulas: AG (q →EG r), EF (r U q) and EF G (r G r) The problem with this string is that U can occur only when paired with an A or an E. To make this into a well- formed CTL formula, we would have to write EF E[r Uq] or EF A[r R q] The formula for EF G r is not well-formatted because G can only be written with an F or an A, not with an E or a U. The formula is also not well formed because the E we Notice that we use square brackets after the A or E. When the pairedLTL we also have quantiﬁers A and E which express ‘all paths’ and Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. The symbols weak-until (W) and release (R) are not included in CTL, but they are derivable. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.   The CTL formula AG (p →AF) expresses in terms of the order of occurrence of events p, s and t. Explain what exactly exactly the CTL Formula AG ( p →AF (s ∧AX (AF t) does.   See Section 3.4.5 for more information on CTL. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any CTL model) Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment intosemantically equivalent formulas in that fragment and deﬁne f φ to be f ψ. Prove that the evaluation of φ depends only on the values ρ(xi) and that it does not matter what ρ assigns Exercises 6.16 and 6.17 are based on the CTL model M = (S, →, L) Given a model M, we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. The former deﬁnes fair in terms of f ECG for general φ. Why is this unproblem-phthalatic, i.e. non-circular? Exercises (6.16) and (7) consider the coding without consideration of simple fairness constraints. The last exercise is based on f E[x1∨¬x2Ux1]. All subformulas of f φ are formally monotone. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write it in an equivalent form in terms of the adequate set of connectives. Figure 3.24. The iteration step of the procedure for labelling states with subsections of the form AF ψ1. The model-checking algorithm would then repeat the iteration step until no change is made to the formula. The algorithm is called the model-checker algorithm and is described in more detail in the next section of the book. The book is published by Oxford University Press, London, in the US and in the UK by request of the author. The algorithm uses a CTL model M and a formula φ. It labels states of M with the subformulas of φ that are satisﬁed there, starting with the smallest subformula and working outwards. Here is the algorithm:INPUT: a model M = (S, →, L)OUTPUT: the set ofStates of M which satisfy φ, i.e., the output of TRANSLATE ( φ) The algorithm is based on the CTL algorithm. The LTL formula is equivalent to the CTL* formula. If ψ is ⊥, then no states are labelled with ≥. If p is p, then label s with p if p ∈L(s). If ω is ω, then the state is labelled with ω1 or ω2. This step is illustrated in Figure 3.24. The next step is to label all successor states with AF ψ1, until there is no change. The final step is called E[ψ1 U ψ2] and is the same as the previous step. It is the first step in the next section of the LTL algorithm. Figure 3.23 shows the relationship among the expressive powers of CTL, LTL, CTL* and CTL*. Here are some examples of formulas in each of the subsets. The proof that AG EF p is not expressible in LTL is as follows. Let φ be an LTL formula such that A[φ] is allegedly equivalent to AG EF. p. In CTL but not in L TL: ψ1defreprehensive=AG EF p. This expresses: wherever we have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof that this is not expressible in CTL is quite complex. It may be found in the papers co-authored by E. A. Emerson with others, given                in the references. (Why is it not expressable in LTL?) It is not the case that M′, s ⊨AG EF p; a contradiction. Yet, it is not a contradiction that there is a path with inﬁnitely many p along the path, then there is an occurrence of q. The algorithm SAT takes as input a CTL formula. The program SAT expects a parse tree of some LTL formula constructed by means of the grammar in Deﬁnition 3.12.18 We just saw that some (but not all) LTL formulas can be or must pass through such a state to reach a labelled state. This expectation reﬂects an important precondition on thecorrectness of the algorithm SAT. The pseudo-code of the CTL model-checking algorithm can be found at: http://www.satis.org/satis-algorithm/ctl-model-checking.html. The pseudo-code we write for SAT looks a bit like fragments of C orJava code. We use functions with a keyword return that indicates which result the function should return. We will also use natural language toindicate the case analysis over the root node of the parse tree of φ. For example, the program simply would not know what to do with an input of the form X (⊤∧EF p3), since this is not a CTL formula. We repeat until executes thecommand which follows it repeatedly, until the condition becomes true. The code is shown in the figure 3.27 section of the book. The book can be downloaded from: http://www.academia.edu/s We assume that SAT has access to all the relevant parts of the model: S, →and L. Ad-ditionally, we employ suggestive notation for the operations on sets, like intersection, set complement and so forth. In reality we would need an ab-                 abstract data type, together with implementations of these operations, but for now we are interested only in the mechanism in principle of the algorithm. A certain process is enabled inﬁnitely often on every computation path. Whatever happens, a certain process will eventually be permanently deadlocked. Processes need not enter their critical section in strict sequence. An upwards travelling lift at the second ﬂoor does not change its direction when passengers wish to go to the ﬁfth. The lift can remain idle on the third ﬀoor with its doors closed. A process can always request to enter its critical section. Using the propositions of Figure 3.8, this may be written as CTLAG (n1 →EX t1) in CTL. The atomic descriptions are boolean expressions built from system vari-ables, e.g., floor2 Two CTL formulas φ and ψ are said to be semanticallyequivalent if any state in any model which satisﬁes one of them also satis ﬁed the other. This was also not expressible in LTL, though we expressed its negation. CTL allows us to directly express it directly: EF (c1 ∧E[c1 U (¬c1  U c1) )   3.4.4 Important equivalences between CTL and LTL formulas. 3.5 Adequate sets of CTL connectives. 4. Verification by model checking. 5. An explanation of de Morgan rules. LTL can be viewed as a subset of CTL*. CTL* is the fragment in which we restrict the form of path formulas. LTL formula α is equivalent to the C TL* formula                A[α]. Figure 3.23 shows the relationship among the expressive powers of LTL, CTL, and CTL*, as well as CTL and LTL* The expressive powers are shown in terms of formulas in each of the three subsets. For example, in CTL but not in LTL: ψ1 defends= AG EF p. This expresses: wherever we get to, we can always get to a state in which p is true. This is also useful, e.g., in deadlocks In CTL*, but neither in CTL nor in LTL: ψ4defdef= E[G F p],                saying that there is a path with inﬁnitely many p. The paths from s in M′ are a subset of those in M, so we have M′, s ⊨A[φ]. Yet, it is not the case that M′,. s ⋅AG EF p; a contradiction. The proof that this is not expressible in C TL is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given given the references. (Why is it not expressable in L TL?) Theorem 6.19 is valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment into equivalent formulas in that fragment. Prove that the evaluation of f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to X or Z. Recall the way the two labelling algorithms operate in Chapter 3. Does oursymbolic coding mimic either or both of them, or neither? Exercises 6.16-16: Consider the equations in (6.22-6.27) and 6.27-7. Proving that f AF (¬x1-1) holds for the model in Figure 6.32( Given a CTL model M = (S, →, L), we saw how to code formulas f φ. The former deﬁnes fair in terms of f ECG for general φ, whereas the latter is unproblematic, i.e. non-circular. We now want to modify the model so that the resulting output is not a set, or an OBDD, but a formula                LTL. We also have quanti ﬁers A and E which express ‘all paths’ and ‘exists a path’, respectively. We show that the free variables of f. φ are among ˆx, and that all subformulas of Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. The symbols weak-until (W) and release (R) are not included in CTL, but they are derivable. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.   The CTL formula AG (p →AF) expresses in terms of the order of occurrence of events p, s and t. Explain what exactly exactly the CTL Formula AG ( p →AF (s ∧AX (AF t) does.   See Section 3.4.5 for more information on CTL. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any model) using de Morgan rules and the LTL equivalence. Here, our atomic descriptions are boolean expressions built from systemvari-ables, e.g., floor2. For example, a lift can remain idle on the third ﬂoor with its doors closed. A process can always request to enter its critical section. A certain process is enabled inﬁnitely often on Using the propositions of Figure 3.8, this may be written asAG (n1 →EX t1) in CTL. Processes need not enter their critical section in strict sequence. This was also not expressible in LTL, though we expressed its negation. Two CTL formulas φ and ψ are said to be semanticallyequivalent if any state in any model which satisﬁes one of them also satis ﬁed the other. We denote this by φ ≡ ψ. We have already noticed that A is a universal quanti-versal on paths and E is the corresponding existential quanti versal. In CTL, every A or E must have one of X, F, G and U to accompany it. The unary connectives AG, EG, AF, EF,AX and EX bind most tightly. Weak-until (W) and release (R) are not included in CTL. But they are derivable (see Section 3.4.5).Convention 3.13 We assume similar binding priorities for the CTL con-                nectives to what we did for propositional and predicate logic. Next in the order come  ‘’; and after that come ’’, ‘ ’ and ‘–’. Let us see some examples of well-formed CTL formulas and some examples which are not well- formed. Let us see how the syntax rules allow us toconstruct each of these. For example, take EF (r U q). The problem with this string is that U can occur only when paired with an A or an E. The E we have is                paired with the F. We can also see why we can’t use EF (p U r) or EF EG (p →AF r) to construct these. We will also see how we can use EF G (r G r) and EF E (r E r) in the next section of this article. CTL is a logic which combines the expressive powers of LTL and CTL, by dropping the CTL constraint that every temporal operator (X, U, F, G) has to be associated with a unique path. To make this into a well-formed CTL formula, we would have to write EF E[r U q] or EF A[ r U q]. The parse tree of a CTL Formula without infix notation can be seen in the figure 3.18 of the model checking section of this article. The model checking process can be carried out by using the following code: EUAX¬¬                 ‘EX’, ‘X,’ ‘G’ The syntax of CTL* involves two classes of formulas: state formulas, which are evaluated in states, and path formulas, evaluated along paths. It turns out that the ﬁrst of them can be written as a (rather long) CTL formula. It allows us to write formulas such as A[(p U r) ∨(q U r), where either p is true until r, or q istrue until r. These formulas are not equivalent to, respectively, A[ (p ∨q) U r, AX p, EG EF p and AX p. The second and third do not have a CTL formulas that are equivalent to them. LTL can be viewed as a subset of CTL*.CTL is also a subset. LTL does not include A and E, but the semantic viewpoint of LTL is that we consider all paths. Therefore, the LTL formula α is equivalent to the CTL* formula autoimmuneA[α]. This is an example of an inductive deﬁnition which is mutually recursive. The de�arynition of each class depends upon the de�aries of the other, with base cases p and ⊤. For example, we restrict the form of path formulas to (φ U φ) | (G φ), and then use the second one. For example, the intuition for the third one is the following: in order to have AF φ in a particular state, φ must be true at some point along each path                from that state. Notice how this equivalence appears to deﬁne AF in terms of AX and AF itself, an apparently circular de nition. In fact, these equivalences can be used to de ﬁnition the six connectives on the left in a non-circular way, in a way that is not circular at all. For example, in the equivalence between AF and AX, we can say that AF is true now, but not in the future. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. The logical structure of the formal speciﬁcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The formula AF p →AF q means2182182183 Verification by model checking                something quite diﬀerent: it says ‘if all paths have a p along them, then                allpaths have a q along them’ One might write AG (p →AFq), which is closer, since it says that every way of extending Properly speciﬁed software is easier to reuse, since it has a clear speci ﬁcation of what it is meant to do. Safety-critical computer systems – such as the control of cooling systems in nuclear power stations, or cockpits of modern aircrafts – demand that their software be speci credible. Other programs may be commercially critical, such as ac countancy software used by banks, and they should be delivered with a warranty: a guarantee for correct performance within proper use. Ex-perience has shown that verifying programs with respect to formal specians can cut down the duration of software development and maintenance. The degree to which the software industry accepts the beneﬁts of proper Verification depends on the perceived extra cost of producing it. Microsoft’s emergent technology. # combines program veri ﬁcation, testing, and model-checking techniques. As we will see, there are often good heuristics to help the programmer complete these tasks. This contrasts with the.situation of the last chapter, which was fully automatic. The importance of Verification to industry will.continue to increase over the next decades. The proof that a program.meets its speciﬅcations is indeed such a warranty. The domain of application in this chapter is se-quential transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems that are not intended to terminate and that react continually with their environment.Pre/post-development. Pre- and post-development of programs. Pre/post development of programs that are intended to run on a single processor and that have no concur-rency issues. Pre and post development of a program that is intended The techniques of this chapter should be used.during the coding process for small fragments of program that perform. an identiﬁable task. The techniques should also be used during the development process in order to avoid functional bugs. 4.1 Why should we specify and verify code? The task of specifying and verifying code is often perceived as an unwel-                come addition to the programmer’s job and a dispensable one. The logical structure of the formal speciﬃcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The process of documenting a program may raise or alleviate important issues. A framework for producing the software could be: Convert the informal description R of requirements for an application domain into an ‘equivalent’ formula φR of some symbolic logic. Write a program P which is meant to realise that formula. Prove that the program P satisﬁes the formula. This scheme is quite crude – for example, constraints may be actual design decisions for interfaces and data types, or the speci ﬁcation may ‘evolve’4.2 A framework for software verification may partly be ‘unknown’ in big projects – but it serves well as a approximation to good programming methodology. For example, as a programmer, might have been given only the The meaning of R as a piece of natural language is grounded in common sense. The attempt at formalising R can uncoverambiguities or undesired consequences and hence lead to revisions of R. It is impossible to ‘verify’ whether an infor-cular requirement R is equivalent to a formal description φR. The meaningof R is based on heuristics or quantitative reasoning and often based on real-world knowledge about the domain. The ‘going back and forth’ between the realms of informal and formalspeciﬁcations Microsoft’s emergent technology seamlessly combines program veriﬁcation, testing, and model-checking techniques in an integrated in-house development environment. Software systems now often have a longer life-expectancy than humans, which necessitates a durable, transparent and                portable design and implementation process. The meaning of a logic formula φR, on the other hand, is de ﬁned in a precise mathematical, qualitative and compositional way. As society depends on it more and more, the beneﬃts are becoming more important. We can expect that the importance of veri-cation to industry will continue to increase over the next decades. Software veriﬁcation provides some of this framework for software verification. It is a way of condensing the requirements of such a project into formal speci ﬁcations. These formalspeciﬀcations are usually symbolic encodings of real-world constraints into some sort of logic. For example, it could be the devel-                opment and maintenance of a database of electricity accounts with all the possible applications of that – automated billing, customer service etc. It could also be the creation of an online bank account database. For more information on software verification, see the Software Verification Handbook. The book, published by Oxford University Press, is available in English and French. Convert the informal description R of requirements for an application domain into a logical formula R. R is grounded in common sense and gen-                eral knowledge about the real-world domain. The meaning of a logic formula φR is deﬁned in a precise mathematical, qualitative and compositional way by structural induction on the parse tree of R. To make matters worse, the requirements R are often inconsistent; customers usually have a fairly vagueception of what exactly a program should do for them. Thus, a framework for producing the software could be: Convert R into a formalisation of the formalisation R of the application domain R as a piece of natural language. The process of formalising R requires the utmost care. Producing a clear and coherent description R of the requirements for an application do-                main is already a crucial step in successful programming. We address this ﬁrst item only implicitly in this text, but you should certainly be aware of its importance in practice. The programming language which we set out to study here is the typicalcore language of most imperative programming languages. The next phase of the software development framework involves construct-                ing the program P and after that the last task is to verify that P satisﬁes φR. The correspondence between proving and program-                ming can be stated quite precisely, but that is beyond the scope of this book. The book includes a core programming language for imperative languages Program verification is a subset of Pascal, C, C++ and Java. Our lan-guage consists of assignments to integer- and boolean-valued variables. If-and refer to a method’s object. Upon validation, this contract.establishes that all calls to withdraw leave (the ‘object. invariant’) 0 <= 0 <= balance invariant 4.7 Bibliographic notes. Backhouse’S book [Bac86] describes program logic and weakest precondi-tions and also contains numerous examples and exercises. Other books [AO91, Fra92] extend the basic core language to in-clude features such as procedures and parallelism. In propositional or predicate logic, formulas are either true, or false, in any model. Propositional logic and predicate logic do not allow for any further possibilities. The issue of writing to.                arrays and the problem of array cell. aliasing are described in [Fra92]. The. article describing the minimal-sum section problem is [Gri82]. A text on functional programming on the freely available. Standard ML of New Jersey is [Pau91].8 www.opensource.org                9 www.sims.berkeley.edu/~pam/papers.html676.5. Modal logics and agents                5.1 Modes of truth The tool was developed by D. Jackson at the Massachusetts Institute of Technology. The tool has a dedicated repository website at                alloy.mit.edu. More information on typed higher-order logics and their use in the.modelling and verifying of programming frameworks can be found on F.Pfenning’s course homepage7 on Computation and. Deduction. The book, The Typed Higher-order Logics of Programming, is published by Oxford University Press, priced £16.99, is available in hard copy and soft copy for £12.99. Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The veriﬁcation method consists of trying to prove that a formula is a formula. This typically requires guidance and expertise from the user. We will model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to see if prerequisites in the form of libraries or other packages are present. The formal models attached to software products can be seen as aiability contract; a promise that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬁed therein. We will use a formula that captures formally static and dynamic system structure and behaviour. This formula can be used to verify consistency of the constrained design space and to test the correctness of claims about static andynamic aspects of all its compliant implementations. It can also boost our conﬀdence into the Software package dependency systems are used in several computer systems. Users often have to guess how technical questions get resolved within the system. To the best of our knowledge, there is no publicly available model of any particular dependency system to which application programmers could turn if they had non-trivial technicalquestions about its inner workings. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things, such as a database or a file system, for example. The requirements on a software package dependency system are not straightfor-                ward. The upgrading process can go wrong in various ways. For example, upgrading a package can involve replacing older versions of shared These deﬁnitions are justi�ken by LTL equivalences in Sections 3.2.4 and 3.5. In order to have AF φ in a particular state, φ must be true at some point along each path from that state to that state. These equivalences can be used to de�ir�ne the six connectives on the left in terms of AX and EX, in a non-circular way. The equivalence for the third one is the following: In order for AF to be true now, we must have it true in each of the next three states we go through, or we must postpone one of them. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. The formula AF p →AF q means ‘if all paths have a p along them, then                allpaths have a q along them’ Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas φ which are not in the adequate fragment intosemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ. Prove that the evaluation of φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ worrisomei or Z′ horrifyingi. Proving that ρ does not depend on the value of x′. Exercises 6.16 and 6.17 are based on the CTL model M = (S, →, L) Given a model M, we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. The former deﬁnes fair in terms of f ECG for general φ. Why is this unproblem-phthalatic, i.e. non-circular? Exercises (6.16) and (7) consider the coding without consideration of simple fairness constraints. The last exercise is based on f E[x1∨¬x2Ux1]. Consider the pseudo-code for the function SAT on page 227. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.  Explain what exactly the CTL formula AG expresses in terms of the order of occurrence of events p, s and t. Explain what the formula AG (p →AF (s ∧AX (AF t)) does in plain English. Find a model in which no formula of F holds. Show these two assertions if f φ also encodes simple fairness constraints. Show that all the subformulas of f χ are formally monotone. Find the only formula in F that is not a set, or an OBDD. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� Figure 3.23 shows the relationship among the expressive powers of CTL, LTL and CTL*. The LTL formula α is equivalent to the CTL* formula A[α]. LTL can be viewed as a subset of C TL*. CTL is also a subset of CTL*, since it is the fragment of Ctl* in which we restrict the form of path formulas to α. Here are some examples of formulas in each of the subsets3.5 C TL* and LTL* and the expressive power of LTL, CTL andCTL* shown in Figure 3.22. The expressive powers are shown in Figures 3.3 and 3.4. The proof that AG EF p is not expressible in LTL is as follows. Let M′ be as shown in the right-hand diagram. The paths from sin M′ are a subset of those from s in M. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. This expresses: wherever we                have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given in the references. CTL* is a logic that combines the expressive powers of LTL and CTL. It does this by dropping the CTL constraint that every temporal operator (X, U, F, G) has to be associated with a unique path quantiﬁer (A, E) It is based on the fact that LTL formulas can be verified by model checking. For example, in CTL, AG (p →AF q) can be written as F p →F q. In LTL, it can be rewritten as G (p ·F q) or G p ·Fq in LTL. The result is that any p is eventually followed by a q. The syntax of CTL* involves two classes of formulas: state formulas, which are evaluated in states, and path formulas, evaluated along paths. It turns out that the ﬁrst of them can be written as a (rather long) CTL formula. It allows us to write formulas such as A[(p U r) ∨(q U r), where either p is true until r, or q istrue until r. These formulas are not equivalent to, respectively, A[ (p ∨q) U r, AX p, EG EF p and AX p. The second and third do not have a CTL formulas that are equivalent to them. LTL and CTL as subsets of CTL* are mutually recursive. The deﬁnition of each class depends upon the de ﬁNition of the other. LTL does not include A and E, but the semantic viewpoint of LTL is that we consider all paths. Therefore, the LTL CTL is a subset of CTL* in which we restrict the form of path formulas to (φ U φ) | (G φ), (F φ, (X X) LTL can be viewed as a subset to CTL*. If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective begins with E, then Satisfaction holds if some path from s satisfies the LTL formula. The result of removing A or E is not strictly an LTLformula, for it The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path There Exists a path beginning in s such that φ holds Globally along the path. The equivalencesAF and EF are similar to the corresponding equivalences in LTL. For example, the connective AX can be written ¬EX ¬;. AG, AF, EG and EF can bewritten in terms of AU and EU as follows:. write AG φ as ¬EF ¬φ and EG φ. as ¼AF ¬ φ, using (3.6), and then use. (2.6) to write EF and EF as ¹AF and ¹EF, using. (1) and (2) respectively. Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX, AF, AU, EG, EU, and EX. Theorem is proved in a paper referenced in the bibliographic notes at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it is valid in the logic CTL* introduced in the next section. For example, we have the equivalence: A[φ U ψ] ≡¬(E[¬ φ U (¬φ ∧¬hy),  “EG” U ( Neither weak-until W nor release R are primitive in CTL. The connective EU plays a special role in that theorems. The temporal connectives AR, ER, AW and EW are all deﬁnable in C TL. LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For a positive example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p ·AF q) in LTL. Some other noteworthy equivalences are the following:AG φ  ‘in’ and ‘out’ are of the form ‘in. often requested implies eventuallyacknowledged’ In fact, AF AG p is strictly stronger than F G p. While the LTL formulas X F p and F X p are equivalent, they are not equivalent to AF AX p. CTL* is more expressive than either of them, but is computationally more expensive. The choice between LTL and CTL depends on the application at hand, and on personal prefer-iness. LTL lacks CTL’s ability to quantify over paths, and C TL lacks LTL”s ability. to describe individual paths. We have seen that they have incomparable expressivepowers. We discuss two more negative examples: F G and AF AG. The latter has quite a strange meaning (try working it out). CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn't allow nest-ing of path modalities X, F and G. To many people, LTL ap-                pears to be more straightforward to use; as noted above, CTL formulas like                AF AX p seem hard to understand. The equivalences between CTL and LTL are similar to the corresponding equivalences in LTL. As in propositional logic, there is some redundancy among the CTL connectives, but the equivalences are equivalent to those for LTL and CTL in the same way. In LTL, the equivalence between the two sets of connectives is similar to that for CTL AU, EU and EX form an adequate set of temporal connectives. AG, AF, EG and EF can be written in terms of AU and EU as follows. For example, the connective AX can bewritten ¬EX ¬;. And AG, EF, EG, EF and AF can be. written interms of AU, EU, and EX as follows:. write AG φ as ¬EF ¬φ;. write EG υ as EG;. Write AF and EF using (3.6);. Use EF and EF as AU;. Use AU as EU; and so on. Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX,EG, AF, AU } and EU. The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in C TL. The temporal connective AR, ER, AW and EW are all deﬁnable in the logic CTL* and the expressive powers of LTL and CTL. Theorem is proved in a paper referenced in the bibliographic notes referenced at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it The algorithm for labelling states with subformulas of the form AF is called the model-checking algorithm. Here is the algorithm:. A CTL model M = (S, →, L) and a CTL formula φ: the set of states of M. which satisfy φ. First, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms of the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given earlier in the chapter. Figure 3.24. The iteration step of the procedure for labelled states withsubformulas is the ‘model- checking algorithm’ Label the states of M with the subformulas of φ that are satisﬁed there, starting with the smallest subformula and working outwards towards φ. We determine by a case analysis which states to label with ψ. This step is illustrated in Figure 3.24. If a state is labelled with ⊥ and no states are labelled with p, then label s with p if p ∈L(s). If ψ is a subformulum of ω, label it with ω if it is already labelled with φ and with ρ if it isn't. If ω is not a sub formula of ψ, label the state with a different subform Theorem 6.19 remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment into equivalent formulas in that fragment. Prove that the evaluation of f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ or Z. Theorem is illustrated in Figure 3.25 in the next section of the paper. The next step is to prove that the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407 is equivalent to f E[x1 Ux1] (x1, x2, x3) (0, 1 Exercises 6.16 and 6.27. Recall the way the two labelling algorithms operate in Chapter 3. Given a CTL model M = (S, →, L), we saw how to code formulas f φ. The former deﬁnes fair in terms of                f ECG⊤, whereas the latter deﰁnes f ECG φ for general φ, i.e. non-circular. Does our Symbolic coding mimic either or both of them, or neither? The answers to these questions can be found in (6.22) and (6,27) in the appendix to the book. The final chapter of the book is available on Amazon. If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective begins with E, then Satisfaction holds if some path from s satisfies the LTL formula. In the last two cases, the result of removing A or E is not strictly an LTLformula, for it may contain further As or Es below. We now want to modify it so that the resulting output is not a set, or an OBDD, but a formula                roughly understood as follows. The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path An adequate set of connectives for propositional logic is a set such that for every formula of logic there is an equivalent formula with only connectives from that set. For example, the set {¬, ∨} is adequate for logic, because any occurrence of  and  can be removed by using the equivalences. The set C is adequate because it is a nullary con-nective, and we are treating ⊥ as a Nullary Connective in this case. We show that C ⊆{¬,.    ,    ”, “C’s” is adequate. We also show that if C is an adequate set, Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that the relation ≡ is reﬂexive, symmetric, transitive, commutative, associative, distributive, and absorptive. Prove your answer to the question Is {↔, ¬} adequate? Proving your answer will help you understand the de Morgan rules. Proving the truth value of a formula φ, formed by using only the connectives in C, can be done by using the word \"proving\" in the form C = C + T.  construct a formula in CNF based on each of the following truth tables. Exercises include the following:. Construct a model in which no formula of F holds. Explain what exactly the CTL formula AG expresses in terms of the order of occurrence of events p, s and t. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.  The final exercise is to find a model of F in which all formulas hold in it. For example, consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →apologeticAF q)}. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any                model): A[p U q] (¬p  G p) ( G  P) (P U q) (G  P) (Q U Q) (U U Q (G P) U (Q Q) Q (U Q) U  Q (Q q) G (Q p) U(Q Q q) Q( Let us see some examples of well-formed CTL formulas and some examples which are not well- formed. Let us see how the syntax rules allow us toconstruct each of these. For example, take EF (r U q). The problem with this string is that U can occur only when paired with an A or an E. The E we have is                paired with the F. We can also see why we can’t use EF (p U r) or EF EG (p →AF r) to construct these. We will also see how we can use EF G (r G r) and EF E (r E r) in the next section of this article. Inspection of clauses 12 and 13 reveals that R and W are rather similar. They swap the roles of their arguments φ and ψ; and the clause for W has an i where R has i. Therefore, it is not surprising that they are expressible in terms of each other. As in propositional logic, there is some redundancy among the connectives in the CTL formula. For example, W is like U but also allows the eventuality of never occurring: W ψ U ψ  G φ (3.3) W is also possible to write W  U  (3.4) W   U    (4.5) W (5) U  Small adequate sets of connectives also exist in LTL. The set X is completely orthogonal to the other connectives. X cannot be derived from any combination of the others. Each of the sets {U, X}. {R, X}, {W, X} is adequate.  The set {⊥, ∧, ¬} forms an adequate set of connective. For example, in Chapter 1 we saw that the set { ≹, ≳, Sometimes it is useful to look at adequate sets of connectives which do notrely on the availability of negation. That’s because it is often convenient to assume formulas are written in negation-normal form, where all the negationsymbols are applied to propositional atoms. To see this, we note that R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) andequivalence (3.4) followed by theDuality, respectively. We also note that U and W can be de-de-de",
                    "children": [
                        {
                            "id": "chapter-3-section-4-subsection-1",
                            "title": "Syntax of CTL",
                            "content": "U cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nc2, or must pass through such a state to reach a labelled state.\nThe pseudo-code of the CTL model-checking algorithm\nWe\npresent the pseudo-code for the basic labelling algorithm. The main function\nSAT (for ‘satisﬁes’) takes as input a CTL formula. The program SAT expects\na parse tree of some CTL formula constructed by means of the grammar in\nDeﬁnition 3.12. This expectation reﬂects an important precondition on the\ncorrectness of the algorithm SAT. For example, the program simply would\nnot know what to do with an input of the form X (⊤∧EF p3), since this is\nnot a CTL formula.\n226\n3 Verification by model checking\ns5\ns0\n0: t1n2\n0: c1n2\n0: t1t2\n0: c1t2\n2: E[¬c2 U c1]\ns3\ns1\ns2\ns6\ns9\ns4\ns7\n1: E[¬c2 U c1]\n1: E[¬c2 U c1]\n2: E[¬c2 U c1]\n3: E[¬c2 U c1]\n0: n1n2\n0: n1t2\n0: t1t2\n0: t1c2\n0: n1c2\nFigure 3.27. An example run of the labelling algorithm in our second\nmodel of mutual exclusion applied to the formula E[¬c2 U c1].\nThe pseudo-code we write for SAT looks a bit like fragments of C or\nJava code; we use functions with a keyword return that indicates which\nresult the function should return. We will also use natural language to\nindicate the case analysis over the root node of the parse tree of φ. The\ndeclaration local var declares some fresh variables local to the current in-\nstance of the procedure in question, whereas repeat until executes the\ncommand which follows it repeatedly, until the condition becomes true. Ad-\nditionally, we employ suggestive notation for the operations on sets, like\nintersection, set complement and so forth. In reality we would need an ab-\nstract data type, together with implementations of these operations, but for\nnow we are interested only in the mechanism in principle of the algorithm\nfor SAT; any (correct and eﬃcient) implementation of sets would do and\nwe study such an implementation in Chapter 6. We assume that SAT has\naccess to all the relevant parts of the model: S, →and L. In particular,\nenabled is inﬁnitely often taken.\nr A certain process is enabled inﬁnitely often on every computation path:\nAG (AF enabled).\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nAF (AG deadlock).\nr From any state it is possible to get to a restart state:\nAG (EF restart).\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nAG (floor2 ∧directionup ∧ButtonPressed5 →A[directionup U floor5])\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nr The lift can remain idle on the third ﬂoor with its doors closed:\nAG (floor3 ∧idle ∧doorclosed →EG (floor3 ∧idle ∧doorclosed)).\nr A process can always request to enter its critical section. Recall that this was\nnot expressible in LTL. Using the propositions of Figure 3.8, this may be written\nAG (n1 →EX t1) in CTL.\nr Processes need not enter their critical section in strict sequence. This was also\nnot expressible in LTL, though we expressed its negation. CTL allows us to\nexpress it directly: EF (c1 ∧E[c1 U (¬c1 ∧E[¬c2 U c1])]).\n3.4.4 Important equivalences between CTL formulas\nDeﬁnition 3.16 Two CTL formulas φ and ψ are said to be semantically\nequivalent if any state in any model which satisﬁes one of them also satisﬁes\nthe other; we denote this by φ ≡ψ.\n216\n3 Verification by model checking\nWe have already noticed that A is a universal quantiﬁer on paths and E\nis the corresponding existential quantiﬁer. Moreover, G and F are also uni-\nversal and existential quantiﬁers, ranging over the states along a particular\npath. In view of these facts, it is not surprising to ﬁnd that de Morgan rules\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the",
                            "summary": "Every A or E must have one of X, F, G and U to accompany it. U cannot occur without being preceded by an A or an E. Weak-until (W) and release (R) are not included in CTL, but they are derivable (see Section 3.4.5). We assume similar binding priorities for the CTL con-                nectives to what we did for propositional and predicate logic. Let us see some examples of well-formed CTL formulas and some examples                which are not well- formed, in order to understand the syntax. The unary                connectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF It is worth spending some time seeing how the syntax rules allow us toconstruct each of these. The following are well-formed CTLformulas: AG (q →EG r), EF (r U q) and EF G (r G r) The problem with this string is that U can occur only when paired with an A or an E. To make this into a well- formed CTL formula, we would have to write EF E[r Uq] or EF A[r R q] The formula for EF G r is not well-formatted because G can only be written with an F or an A, not with an E or a U. The formula is also not well formed because the E we Notice that we use square brackets after the A or E. When the pairedLTL we also have quantiﬁers A and E which express ‘all paths’ and Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. The symbols weak-until (W) and release (R) are not included in CTL, but they are derivable. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.   The CTL formula AG (p →AF) expresses in terms of the order of occurrence of events p, s and t. Explain what exactly exactly the CTL Formula AG ( p →AF (s ∧AX (AF t) does.   See Section 3.4.5 for more information on CTL. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any CTL model) Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment intosemantically equivalent formulas in that fragment and deﬁne f φ to be f ψ. Prove that the evaluation of φ depends only on the values ρ(xi) and that it does not matter what ρ assigns Exercises 6.16 and 6.17 are based on the CTL model M = (S, →, L) Given a model M, we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. The former deﬁnes fair in terms of f ECG for general φ. Why is this unproblem-phthalatic, i.e. non-circular? Exercises (6.16) and (7) consider the coding without consideration of simple fairness constraints. The last exercise is based on f E[x1∨¬x2Ux1]. All subformulas of f φ are formally monotone. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write it in an equivalent form in terms of the adequate set of connectives. Figure 3.24. The iteration step of the procedure for labelling states with subsections of the form AF ψ1. The model-checking algorithm would then repeat the iteration step until no change is made to the formula. The algorithm is called the model-checker algorithm and is described in more detail in the next section of the book. The book is published by Oxford University Press, London, in the US and in the UK by request of the author. The algorithm uses a CTL model M and a formula φ. It labels states of M with the subformulas of φ that are satisﬁed there, starting with the smallest subformula and working outwards. Here is the algorithm:INPUT: a model M = (S, →, L)OUTPUT: the set ofStates of M which satisfy φ, i.e., the output of TRANSLATE ( φ) The algorithm is based on the CTL algorithm. The LTL formula is equivalent to the CTL* formula. If ψ is ⊥, then no states are labelled with ≥. If p is p, then label s with p if p ∈L(s). If ω is ω, then the state is labelled with ω1 or ω2. This step is illustrated in Figure 3.24. The next step is to label all successor states with AF ψ1, until there is no change. The final step is called E[ψ1 U ψ2] and is the same as the previous step. It is the first step in the next section of the LTL algorithm. Figure 3.23 shows the relationship among the expressive powers of CTL, LTL, CTL* and CTL*. Here are some examples of formulas in each of the subsets. The proof that AG EF p is not expressible in LTL is as follows. Let φ be an LTL formula such that A[φ] is allegedly equivalent to AG EF. p. In CTL but not in L TL: ψ1defreprehensive=AG EF p. This expresses: wherever we have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof that this is not expressible in CTL is quite complex. It may be found in the papers co-authored by E. A. Emerson with others, given                in the references. (Why is it not expressable in LTL?) It is not the case that M′, s ⊨AG EF p; a contradiction. Yet, it is not a contradiction that there is a path with inﬁnitely many p along the path, then there is an occurrence of q. The algorithm SAT takes as input a CTL formula. The program SAT expects a parse tree of some LTL formula constructed by means of the grammar in Deﬁnition 3.12.18 We just saw that some (but not all) LTL formulas can be or must pass through such a state to reach a labelled state. This expectation reﬂects an important precondition on thecorrectness of the algorithm SAT. The pseudo-code of the CTL model-checking algorithm can be found at: http://www.satis.org/satis-algorithm/ctl-model-checking.html. The pseudo-code we write for SAT looks a bit like fragments of C orJava code. We use functions with a keyword return that indicates which result the function should return. We will also use natural language toindicate the case analysis over the root node of the parse tree of φ. For example, the program simply would not know what to do with an input of the form X (⊤∧EF p3), since this is not a CTL formula. We repeat until executes thecommand which follows it repeatedly, until the condition becomes true. The code is shown in the figure 3.27 section of the book. The book can be downloaded from: http://www.academia.edu/s We assume that SAT has access to all the relevant parts of the model: S, →and L. Ad-ditionally, we employ suggestive notation for the operations on sets, like intersection, set complement and so forth. In reality we would need an ab-                 abstract data type, together with implementations of these operations, but for now we are interested only in the mechanism in principle of the algorithm. A certain process is enabled inﬁnitely often on every computation path. Whatever happens, a certain process will eventually be permanently deadlocked. Processes need not enter their critical section in strict sequence. An upwards travelling lift at the second ﬂoor does not change its direction when passengers wish to go to the ﬁfth. The lift can remain idle on the third ﬀoor with its doors closed. A process can always request to enter its critical section. Using the propositions of Figure 3.8, this may be written as CTLAG (n1 →EX t1) in CTL. The atomic descriptions are boolean expressions built from system vari-ables, e.g., floor2 Two CTL formulas φ and ψ are said to be semanticallyequivalent if any state in any model which satisﬁes one of them also satis ﬁed the other. This was also not expressible in LTL, though we expressed its negation. CTL allows us to directly express it directly: EF (c1 ∧E[c1 U (¬c1  U c1) )   3.4.4 Important equivalences between CTL and LTL formulas. 3.5 Adequate sets of CTL connectives. 4. Verification by model checking. 5. An explanation of de Morgan rules.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-4-subsection-2",
                            "title": "Semantics of CTL",
                            "content": "all paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nenabled is inﬁnitely often taken.\nr A certain process is enabled inﬁnitely often on every computation path:\nAG (AF enabled).\nr Whatever happens, a certain process will eventually be permanently deadlocked:\nAF (AG deadlock).\nr From any state it is possible to get to a restart state:\nAG (EF restart).\nr An upwards travelling lift at the second ﬂoor does not change its direction when\nit has passengers wishing to go to the ﬁfth ﬂoor:\nAG (floor2 ∧directionup ∧ButtonPressed5 →A[directionup U floor5])\nHere, our atomic descriptions are boolean expressions built from system vari-\nables, e.g., floor2.\nr The lift can remain idle on the third ﬂoor with its doors closed:\nAG (floor3 ∧idle ∧doorclosed →EG (floor3 ∧idle ∧doorclosed)).\nr A process can always request to enter its critical section. Recall that this was\nnot expressible in LTL. Using the propositions of Figure 3.8, this may be written\nAG (n1 →EX t1) in CTL.\nr Processes need not enter their critical section in strict sequence. This was also\nnot expressible in LTL, though we expressed its negation. CTL allows us to\nexpress it directly: EF (c1 ∧E[c1 U (¬c1 ∧E[¬c2 U c1])]).\n3.4.4 Important equivalences between CTL formulas\nDeﬁnition 3.16 Two CTL formulas φ and ψ are said to be semantically\nequivalent if any state in any model which satisﬁes one of them also satisﬁes\nthe other; we denote this by φ ≡ψ.\n216\n3 Verification by model checking\nWe have already noticed that A is a universal quantiﬁer on paths and E\nis the corresponding existential quantiﬁer. Moreover, G and F are also uni-\nversal and existential quantiﬁers, ranging over the states along a particular\npath. In view of these facts, it is not surprising to ﬁnd that de Morgan rules\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nmeets a q, but that is still not capturing the meaning of F p →F q.\nCTL* is a logic which combines the expressive powers of LTL and CTL,\nby dropping the CTL constraint that every temporal operator (X, U, F, G)\nhas to be associated with a unique path quantiﬁer (A, E). It allows us to\nwrite formulas such as\nr A[(p U r) ∨(q U r)]: along all paths, either p is true until r, or q is true until r.\nr A[X p ∨X X p]: along all paths, p is true in the next state, or the next but one.\nr E[G F p]: there is a path along which p is inﬁnitely often true.\nThese formulas are not equivalent to, respectively, A[(p ∨q) U r)], AX p ∨\nAX AX p and EG EF p. It turns out that the ﬁrst of them can be written\nas a (rather long) CTL formula. The second and third do not have a CTL\nequivalent.\nThe syntax of CTL* involves two classes of formulas:\nr state formulas, which are evaluated in states:\nφ ::= ⊤| p | (¬φ) | (φ ∧φ) | A[α] | E[α]\nwhere p is any atomic formula and α any path formula; and\nr path formulas, which are evaluated along paths:\nα ::= φ | (¬α) | (α ∧α) | (α U α) | (G α) | (F α) | (X α)\nwhere φ is any state formula. This is an example of an inductive deﬁnition\nwhich is mutually recursive: the deﬁnition of each class depends upon the\ndeﬁnition of the other, with base cases p and ⊤.\nLTL and CTL as subsets of CTL*\nAlthough the syntax of LTL does\nnot include A and E, the semantic viewpoint of LTL is that we consider\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually",
                            "summary": "LTL can be viewed as a subset of CTL*. CTL* is the fragment in which we restrict the form of path formulas. LTL formula α is equivalent to the C TL* formula A[α]. Figure 3.23 shows the relationship among the expressive powers of LTL, CTL and CTL*, as well as the subsets CTL, LTL andCTL* The expressive powers are shown in terms of formulas in each of the three subsets. For example, in CTL we can always get to a state in which p is true. This is also useful, e.g., in deadlocks in protocols. The proof that AG EF p is not expressible in LTL is as follows In CTL*, but neither in CTL nor in LTL: ψ4defdef= E[G F p],                saying that there is a path with inﬁnitely many p. The paths from s in M′ are a subset of those in M, so we have M′, s ⊨A[φ]. Yet, it is not the case that M′,. s ⋅AG EF p; a contradiction. The proof that this is not expressible in C TL is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given given the references. (Why is it not expressable in L TL?) Theorem 6.19 is valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment into equivalent formulas in that fragment. Prove that the evaluation of f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to X or Z. Recall the way the two labelling algorithms operate in Chapter 3. Does oursymbolic coding mimic either or both of them, or neither? Exercises 6.16-16: Consider the equations in (6.22-6.27) and 6.27-7. Proving that f AF (¬x1-1) holds for the model in Figure 6.32( Given a CTL model M = (S, →, L), we saw how to code formulas f φ. The former deﬁnes fair in terms of f ECG for general φ, whereas the latter is unproblematic, i.e. non-circular. We now want to modify the model so that the resulting output is not a set, or an OBDD, but a formula                LTL. We also have quanti ﬁers A and E which express ‘all paths’ and ‘exists a path’, respectively. We show that the free variables of f. φ are among ˆx, and that all subformulas of Computation Tree Logic is a branching-time logic. Its model of time is a tree-like structure in which the future is not determined. There are diﬀerent paths in the future, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas/descriptions (such as p, q, r, . . . , or p1, p2, .. . .    ) for each state. We can write: EF q, AG (p →E[p U q), EF AG p, EF AG q, EF p p,EF AG p. We use the following syntax: EF p, AG We deﬁne CTL formulas inductively via a Backus Naurform as done for LTL. Each of the CTL temporal connectives is a pair of symbols. A means ‘along All paths’ (inevitably) E means “along at least (there Exists) one path” (possibly) X, F, G, or U, meaning ‘neXt state,’ ‘some Future state’ or ‘all future states (Globally)’ and Until, respectively. In CTL, pairs of symbols like EU are binary. Notice that AU and EU arebinary. In LTL, the symbols are not binary. The symbols X, F, G and U cannot occur without being preceded by an A or an E. The symbols weak-until (W) and release (R) are not included in CTL, but they are derivable. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.   The CTL formula AG (p →AF) expresses in terms of the order of occurrence of events p, s and t. Explain what exactly exactly the CTL Formula AG ( p →AF (s ∧AX (AF t) does.   See Section 3.4.5 for more information on CTL. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any model) using de Morgan rules and the LTL equivalence. Here, our atomic descriptions are boolean expressions built from systemvari-ables, e.g., floor2. For example, a lift can remain idle on the third ﬂoor with its doors closed. A process can always request to enter its critical section. A certain process is enabled inﬁnitely often on Using the propositions of Figure 3.8, this may be written asAG (n1 →EX t1) in CTL. Processes need not enter their critical section in strict sequence. This was also not expressible in LTL, though we expressed its negation. Two CTL formulas φ and ψ are said to be semanticallyequivalent if any state in any model which satisﬁes one of them also satis ﬁed the other. We denote this by φ ≡ ψ. We have already noticed that A is a universal quanti-versal on paths and E is the corresponding existential quanti versal. In CTL, every A or E must have one of X, F, G and U to accompany it. The unary connectives AG, EG, AF, EF,AX and EX bind most tightly. Weak-until (W) and release (R) are not included in CTL. But they are derivable (see Section 3.4.5).Convention 3.13 We assume similar binding priorities for the CTL con-                nectives to what we did for propositional and predicate logic. Next in the order come  ‘’; and after that come ’’, ‘ ’ and ‘–’. Let us see some examples of well-formed CTL formulas and some examples which are not well- formed. Let us see how the syntax rules allow us toconstruct each of these. For example, take EF (r U q). The problem with this string is that U can occur only when paired with an A or an E. The E we have is                paired with the F. We can also see why we can’t use EF (p U r) or EF EG (p →AF r) to construct these. We will also see how we can use EF G (r G r) and EF E (r E r) in the next section of this article. CTL is a logic which combines the expressive powers of LTL and CTL, by dropping the CTL constraint that every temporal operator (X, U, F, G) has to be associated with a unique path. To make this into a well-formed CTL formula, we would have to write EF E[r U q] or EF A[ r U q]. The parse tree of a CTL Formula without infix notation can be seen in the figure 3.18 of the model checking section of this article. The model checking process can be carried out by using the following code: EUAX¬¬                 ‘EX’, ‘X,’ ‘G’ The syntax of CTL* involves two classes of formulas: state formulas, which are evaluated in states, and path formulas, evaluated along paths. It turns out that the ﬁrst of them can be written as a (rather long) CTL formula. It allows us to write formulas such as A[(p U r) ∨(q U r), where either p is true until r, or q istrue until r. These formulas are not equivalent to, respectively, A[ (p ∨q) U r, AX p, EG EF p and AX p. The second and third do not have a CTL formulas that are equivalent to them. LTL can be viewed as a subset of CTL*.CTL is also a subset. LTL does not include A and E, but the semantic viewpoint of LTL is that we consider all paths. Therefore, the LTL formula α is equivalent to the CTL* formula autoimmuneA[α]. This is an example of an inductive deﬁnition which is mutually recursive. The de�arynition of each class depends upon the de�aries of the other, with base cases p and ⊤. For example, we restrict the form of path formulas to (φ U φ) | (G φ), and then use the second one. For example, the intuition for the third one is the following: in order to have AF φ in a particular state, φ must be true at some point along each path                from that state. Notice how this equivalence appears to deﬁne AF in terms of AX and AF itself, an apparently circular de nition. In fact, these equivalences can be used to de ﬁnition the six connectives on the left in a non-circular way, in a way that is not circular at all. For example, in the equivalence between AF and AX, we can say that AF is true now, but not in the future. CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one to select a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation ofCTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL. Verification by model checking algorithm. The formula AF p →AF q means ‘if all paths have a p along them, then                all paths",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-4-subsection-3",
                            "title": "Practical Patterns of Specifications",
                            "content": "resolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\ntime-consuming and local ‘ﬁxes’ often introduce new bugs at other places. Ex-\nperience has shown that verifying programs with respect to formal speciﬁcations\ncan signiﬁcantly cut down the duration of software development and maintenance\nby eliminating most errors in the planning phase and helping in the clariﬁcation\nof the roles and structural aspects of system components.\nr Refactoring: Properly speciﬁed and veriﬁed software is easier to reuse, since\nwe have a clear speciﬁcation of what it is meant to do.\nr Certiﬁcation audits: Safety-critical computer systems – such as the control\nof cooling systems in nuclear power stations, or cockpits of modern aircrafts –\ndemand that their software be speciﬁed and veriﬁed with as much rigour and\nformality as possible. Other programs may be commercially critical, such as ac-\ncountancy software used by banks, and they should be delivered with a warranty:\na guarantee for correct performance within proper use. The proof that a program\nmeets its speciﬁcations is indeed such a warranty.\n258\n4 Program verification\nThe degree to which the software industry accepts the beneﬁts of proper\nveriﬁcation of code depends on the perceived extra cost of producing it and\nthe perceived beneﬁts of having it. As veriﬁcation technology improves, the\ncosts are declining; and as the complexity of software and the extent to which\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nmically by a computer. As we will see, there are often good heuristics\nto help the programmer complete these tasks. This contrasts with the\nsituation of the last chapter, which was fully automatic.\nProperty-oriented. Just like in the previous chapter, we verify proper-\nties of a program rather than a full speciﬁcation of its behaviour.\n256\n4.1 Why should we specify and verify code?\n257\nApplication domain. The domain of application in this chapter is se-\nquential transformational programs. ‘Sequential’ means that we assume\nthe program runs on a single processor and that there are no concur-\nrency issues. ‘Transformational’ means that the program takes an input\nand, after some computation, is expected to terminate with an output.\nFor example, methods of objects in Java are often programmed in this\nstyle. This contrasts with the previous chapter which focuses on reactive\nsystems that are not intended to terminate and that react continually\nwith their environment.\nPre/post-development. The techniques of this chapter should be used\nduring the coding process for small fragments of program that perform\nan identiﬁable (and hence, speciﬁable) task and hence should be used\nduring the development process in order to avoid functional bugs.\n4.1 Why should we specify and verify code?\nThe task of specifying and verifying code is often perceived as an unwel-\ncome addition to the programmer’s job and a dispensable one. Arguments\nin favour of veriﬁcation include the following:\nr Documentation: The speciﬁcation of a program is an important component\nin its documentation and the process of documenting a program may raise or\nresolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\ninto an ‘equivalent’ formula φR of some symbolic logic;\nr Write a program P which is meant to realise φR in the programming environment\nsupplied by your company, or wanted by the particular customer;\nr Prove that the program P satisﬁes the formula φR.\nThis scheme is quite crude – for example, constraints may be actual design\ndecisions for interfaces and data types, or the speciﬁcation may ‘evolve’\n4.2 A framework for software verification\n259\nand may partly be ‘unknown’ in big projects – but it serves well as a ﬁrst\napproximation to trying to deﬁne good programming methodology. Several\nvariations of such a sequence of activities are conceivable. For example,\nyou, as a programmer, might have been given only the formula φR, so you\nmight have little if any insight into the real-world problem which you are\nsupposed to solve. Technically, this poses no problem, but often it is handy\nto have both informal and formal descriptions available. Moreover, crafting\nthe informal requirements R is often a mutual process between the client\nand the programmer, whereby the attempt at formalising R can uncover\nambiguities or undesired consequences and hence lead to revisions of R.\nThis ‘going back and forth’ between the realms of informal and formal\nspeciﬁcations is necessary since it is impossible to ‘verify’ whether an infor-\nmal requirement R is equivalent to a formal description φR. The meaning\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nsociety depends on it increase, the beneﬁts are becoming more important.\nThus, we can expect that the importance of veriﬁcation to industry will\ncontinue to increase over the next decades. Microsoft’s emergent technology\nA# combines program veriﬁcation, testing, and model-checking techniques\nin an integrated in-house development environment.\nCurrently, many companies struggle with a legacy of ancient code with-\nout proper documentation which has to be adapted to new hardware and\nnetwork environments, as well as ever-changing requirements. Often, the\noriginal programmers who might still remember what certain pieces of code\nare for have moved, or died. Software systems now often have a longer\nlife-expectancy than humans, which necessitates a durable, transparent and\nportable design and implementation process; the year-2000 problem was just\none such example. Software veriﬁcation provides some of this.\n4.2 A framework for software verification\nSuppose you are working for a software company and your task is to write\nprograms which are meant to solve sophisticated problems, or computations.\nTypically, such a project involves an outside customer – a utility company,\nfor example – who has written up an informal description, in plain English,\nof the real-world task that is at hand. In this case, it could be the devel-\nopment and maintenance of a database of electricity accounts with all the\npossible applications of that – automated billing, customer service etc. Since\nthe informality of such descriptions may cause ambiguities which eventually\ncould result in serious and expensive design ﬂaws, it is desirable to condense\nall the requirements of such a project into formal speciﬁcations. These formal\nspeciﬁcations are usually symbolic encodings of real-world constraints into\nsome sort of logic. Thus, a framework for producing the software could be:\nr Convert the informal description R of requirements for an application domain\nof R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\n1.\nit captures formally static and dynamic system structure and behaviour;\n2.\nit can verify consistency of the constrained design space;\n2.7 Micromodels of software\n149\n3.\nit is executable, so it allows guided simulations through a potentially very com-\nplex design space; and\n4.\nit can boost our conﬁdence into the correctness of claims about static and\ndynamic aspects of all its compliant implementations.\nMoreover, formal models attached to software products can be seen as a\nreliability contract; a promise that the software implements the structure and\nbehaviour of the model and is expected to meet all of the assertions certiﬁed\ntherein. (However, this may not be very useful for extremely under-speciﬁed\nmodels.)\nWe will model a software package dependency system. This system is used\nwhen software packages are installed or upgraded. The system checks to see\nif prerequisites in the form of libraries or other packages are present. The\nrequirements on a software package dependency system are not straightfor-\nward. As most computer users know, the upgrading process can go wrong\nin various ways. For example, upgrading a package can involve replacing\nshared libraries with newer versions. But other packages which rely on the\nolder versions of the shared libraries may then cease to work.\nSoftware package dependency systems are used in several computer sys-\ntems, such as Red Hat Linux, .NET’s Global Assembly Cache and others.\nUsers often have to guess how technical questions get resolved within the de-\npendency system. To the best of our knowledge, there is no publicly available\nformal and executable model of any particular dependency system to which\napplication programmers could turn if they had such non-trivial technical\nquestions about its inner workings.\nIn our model, applications are built out of components. Components oﬀer\nservices to other components. A service can be a number of things. Typically,",
                            "summary": "The logical structure of the formal speciﬁcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. resolve important issues. Debugging big systems during the testing phase is costly and Properly speciﬁed software is easier to reuse, since it has a clear speci ﬁcation of what it is meant to do. Safety-critical computer systems – such as the control of cooling systems in nuclear power stations, or cockpits of modern aircrafts – demand that their software be speci credible. Other programs may be commercially critical, such as ac countancy software used by banks, and they should be delivered with a warranty: a guarantee for correct performance within proper use. Ex-perience has shown that verifying programs with respect to formal specians can cut down the duration of software development and maintenance. The degree to which the software industry accepts the beneﬁts of proper Verification depends on the perceived extra cost of producing it. Microsoft’s emergent technology. # combines program veri ﬁcation, testing, and model-checking techniques. As we will see, there are often good heuristics to help the programmer complete these tasks. This contrasts with the.situation of the last chapter, which was fully automatic. The importance of Verification to industry will.continue to increase over the next decades. The proof that a program.meets its speciﬅcations is indeed such a warranty. The domain of application in this chapter is se-quential transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems that are not intended to terminate and that react continually with their environment.Pre/post-development. Pre- and post-development of programs. Pre/post development of programs that are intended to run on a single processor and that have no concur-rency issues. Pre and post development of a program that is intended The techniques of this chapter should be used.during the coding process for small fragments of program that perform. an identiﬁable task. The techniques should also be used during the development process in order to avoid functional bugs. 4.1 Why should we specify and verify code? The task of specifying and verifying code is often perceived as an unwel-                come addition to the programmer’s job and a dispensable one. The logical structure of the formal speciﬃcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. The process of documenting a program may raise or alleviate important issues. A framework for producing the software could be: Convert the informal description R of requirements for an application domain into an ‘equivalent’ formula φR of some symbolic logic. Write a program P which is meant to realise that formula. Prove that the program P satisﬁes the formula. This scheme is quite crude – for example, constraints may be actual design decisions for interfaces and data types, or the speci ﬁcation may ‘evolve’4.2 A framework for software verification may partly be ‘unknown’ in big projects – but it serves well as a approximation to good programming methodology. For example, as a programmer, might have been given only the The meaning of R as a piece of natural language is grounded in common sense. The attempt at formalising R can uncoverambiguities or undesired consequences and hence lead to revisions of R. It is impossible to ‘verify’ whether an infor-cular requirement R is equivalent to a formal description φR. The meaningof R is based on heuristics or quantitative reasoning and often based on real-world knowledge about the domain. The ‘going back and forth’ between the realms of informal and formalspeciﬁcations Microsoft’s emergent technology seamlessly combines program veriﬁcation, testing, and model-checking techniques in an integrated in-house development environment. Software systems now often have a longer life-expectancy than humans, which necessitates a durable, transparent and                portable design and implementation process. The meaning of a logic formula φR, on the other hand, is de ﬁned in a precise mathematical, qualitative and compositional way. As society depends on it more and more, the beneﬃts are becoming more important. We can expect that the importance of veri-cation to industry will continue to increase over the next decades. Software veriﬁcation provides some of this framework for software verification. It is a way of condensing the requirements of such a project into formal speci ﬁcations. These formalspeciﬀcations are usually symbolic encodings of real-world constraints into some sort of logic. For example, it could be the devel-                opment and maintenance of a database of electricity accounts with all the possible applications of that – automated billing, customer service etc. It could also be the creation of an online bank account database. For more information on software verification, see the Software Verification Handbook. The book, published by Oxford University Press, is available in English and French. Convert the informal description R of requirements for an application domain into a logical formula R. R is grounded in common sense and gen-                eral knowledge about the real-world domain. The meaning of a logic formula φR is deﬁned in a precise mathematical, qualitative and compositional way by structural induction on the parse tree of R. To make matters worse, the requirements R are often inconsistent; customers usually have a fairly vagueception of what exactly a program should do for them. Thus, a framework for producing the software could be: Convert R into a formalisation of the formalisation R of the application domain R as a piece of natural language. The process of formalising R requires the utmost care. Producing a clear and coherent description R of the requirements for an application do-                main is already a crucial step in successful programming. We address this ﬁrst item only implicitly in this text, but you should certainly be aware of its importance in practice. The programming language which we set out to study here is the typicalcore language of most imperative programming languages. The next phase of the software development framework involves construct-                ing the program P and after that the last task is to verify that P satisﬁes φR. The correspondence between proving and program-                ming can be stated quite precisely, but that is beyond the scope of this book. The book includes a core programming language for imperative languages Program verification is a subset of Pascal, C, C++ and Java. Our lan-guage consists of assignments to integer- and boolean-valued variables. If-and refer to a method’s object. Upon validation, this contract.establishes that all calls to withdraw leave (the ‘object. invariant’) 0 <= 0 <= balance invariant 4.7 Bibliographic notes. Backhouse’S book [Bac86] describes program logic and weakest precondi-tions and also contains numerous examples and exercises. Other books [AO91, Fra92] extend the basic core language to in-clude features such as procedures and parallelism. In propositional or predicate logic, formulas are either true, or false, in any model. Propositional logic and predicate logic do not allow for any further possibilities. The issue of writing to.                arrays and the problem of array cell. aliasing are described in [Fra92]. The. article describing the minimal-sum section problem is [Gri82]. A text on functional programming on the freely available. Standard ML of New Jersey is [Pau91].8 www.opensource.org                9 www.sims.berkeley.edu/~pam/papers.html676.5. Modal logics and agents                5.1 Modes of truth The tool was developed by D. Jackson at the Massachusetts Institute of Technology. The tool has a dedicated repository website at                alloy.mit.edu. More information on typed higher-order logics and their use in the.modelling and verifying of programming frameworks can be found on F.Pfenning’s course homepage7 on Computation and. Deduction. The book, The Typed Higher-order Logics of Programming, is published by Oxford University Press, priced £16.99, is available in hard copy and soft copy for £12.99. Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The veriﬁcation method consists of trying to prove that a formula is a formula. This typically requires guidance and expertise from the user. We will model a software package dependency system. This system is used when software packages are installed or upgraded. The system checks to see if prerequisites in the form of libraries or other packages are present. The formal models attached to software products can be seen as aiability contract; a promise that the software implements the structure andbehaviour of the model and is expected to meet all of the assertions certiﬁed therein. We will use a formula that captures formally static and dynamic system structure and behaviour. This formula can be used to verify consistency of the constrained design space and to test the correctness of claims about static andynamic aspects of all its compliant implementations. It can also boost our conﬀdence into the Software package dependency systems are used in several computer systems. Users often have to guess how technical questions get resolved within the system. To the best of our knowledge, there is no publicly available model of any particular dependency system to which application programmers could turn if they had non-trivial technicalquestions about its inner workings. In our model, applications are built out of components. Components oﬀerservices to other components. A service can be a number of things. Typically,.  Typically,. a service is a combination of these components, such as a database, a file system, or a web browser. For more information on how to use dependency systems, visit the Software Package Dependency System (SPDS) website.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-4-subsection-4",
                            "title": "Important Equivalences Between CTL Formulas",
                            "content": "r A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nEG φ ≡φ ∧EX EG φ\nAF φ ≡φ ∨AX AF φ\nEF φ ≡φ ∨EX EF φ\nA[φ U ψ] ≡ψ ∨(φ ∧AX A[φ U ψ])\nE[φ U ψ] ≡ψ ∨(φ ∧EX E[φ U ψ]).\nFor example, the intuition for the third one is the following: in order to have\nAF φ in a particular state, φ must be true at some point along each path\nfrom that state. To achieve this, we either have φ true now, in the current\nstate; or we postpone it, in which case we must have AF φ in each of the next\nstates. Notice how this equivalence appears to deﬁne AF in terms of AX\nand AF itself, an apparently circular deﬁnition. In fact, these equivalences\ncan be used to deﬁne the six connectives on the left in terms of AX and\nEX , in a non-circular way. This is called the ﬁxed-point characterisation of\nCTL; it is the mathematical foundation for the model-checking algorithm\ndeveloped in Section 3.6.1; and we return to it later (Section 3.7).\n3.5 CTL* and the expressive powers of LTL and CTL\nCTL allows explicit quantiﬁcation over paths, and in this respect it is more\nexpressive than LTL, as we have seen. However, it does not allow one to\nselect a range of paths by describing them with a formula, as LTL does.\nIn that respect, LTL is more expressive. For example, in LTL we can say\n‘all paths which have a p along them also have a q along them,’ by writing\nF p →F q. It is not possible to write this in CTL because of the constraint\nthat every F has an associated A or E. The formula AF p →AF q means\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nFigure 3.23 shows the relationship among the expressive powers of CTL,\nLTL and CTL*. Here are some examples of formulas in each of the subsets\n3.5 CTL* and the expressive powers of LTL and CTL\n219\nLTL\nψ1\nψ2\nψ3\nψ4\nCTL\nCTL*\nFigure 3.23. The expressive powers of CTL, LTL and CTL*.\nshown:\nIn CTL but not in LTL: ψ1\ndef\n= AG EF p. This expresses: wherever we\nhave got to, we can always get to a state in which p is true. This is\nalso useful, e.g., in ﬁnding deadlocks in protocols.\nThe proof that AG EF p is not expressible in LTL is as follows. Let φ be\nan LTL formula such that A[φ] is allegedly equivalent to AG EF p. Since\nM, s ⊨AG EF p in the left-hand diagram below, we have M, s ⊨A[φ].\nNow let M′ be as shown in the right-hand diagram. The paths from s\nin M′ are a subset of those from s in M, so we have M′, s ⊨A[φ]. Yet,\nit is not the case that M′, s ⊨AG EF p; a contradiction.\n¬p\n¬p\np\ns\ns\nt\nIn CTL*, but neither in CTL nor in LTL: ψ4\ndef\n= E[G F p],\nsaying\nthat\nthere is a path with inﬁnitely many p.\nThe proof that this is not expressible in CTL is quite complex and may\nbe found in the papers co-authored by E. A. Emerson with others, given\nin the references. (Why is it not expressible in LTL?)\nIn LTL but not in CTL: ψ3\ndef\n= A[G F p →F q], saying that if there are in-\nﬁnitely many p along the path, then there is an occurrence of q. This\nis an interesting thing to be able to say; for example, many fairness\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\n218\n3 Verification by model checking\nsomething quite diﬀerent: it says ‘if all paths have a p along them, then\nall paths have a q along them.’ One might write AG (p →AF q), which is\ncloser, since it says that every way of extending every path to a p eventually\nmeets a q, but that is still not capturing the meaning of F p →F q.\nCTL* is a logic which combines the expressive powers of LTL and CTL,\nby dropping the CTL constraint that every temporal operator (X, U, F, G)\nhas to be associated with a unique path quantiﬁer (A, E). It allows us to\nwrite formulas such as\nr A[(p U r) ∨(q U r)]: along all paths, either p is true until r, or q is true until r.\nr A[X p ∨X X p]: along all paths, p is true in the next state, or the next but one.\nr E[G F p]: there is a path along which p is inﬁnitely often true.\nThese formulas are not equivalent to, respectively, A[(p ∨q) U r)], AX p ∨\nAX AX p and EG EF p. It turns out that the ﬁrst of them can be written\nas a (rather long) CTL formula. The second and third do not have a CTL\nequivalent.\nThe syntax of CTL* involves two classes of formulas:\nr state formulas, which are evaluated in states:\nφ ::= ⊤| p | (¬φ) | (φ ∧φ) | A[α] | E[α]\nwhere p is any atomic formula and α any path formula; and\nr path formulas, which are evaluated along paths:\nα ::= φ | (¬α) | (α ∧α) | (α U α) | (G α) | (F α) | (X α)\nwhere φ is any state formula. This is an example of an inductive deﬁnition\nwhich is mutually recursive: the deﬁnition of each class depends upon the\ndeﬁnition of the other, with base cases p and ⊤.\nLTL and CTL as subsets of CTL*\nAlthough the syntax of LTL does\nnot include A and E, the semantic viewpoint of LTL is that we consider\nall paths. Therefore, the LTL formula α is equivalent to the CTL* formula\nA[α]. Thus, LTL can be viewed as a subset of CTL*.\nCTL is also a subset of CTL*, since it is the fragment of CTL* in which\nwe restrict the form of path formulas to\nα ::= (φ U φ) | (G φ) | (F φ) | (X φ)\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\nexist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\nconstraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.",
                            "summary": "These deﬁnitions are justiﬃed by LTL equivalences in Sections 3.2.4 and 3.5. Some other noteworthy equivalences are the following:. r A[ φ W ψ] = A[ψ R ( φ ∨ψ)], and then use the ﬁrst equation above. r E[ ω W ω] = E[ω R (φ    ( ω   ω)]. R A[   A [ ω U ω ] = E [  E[  E [ φ U   ]]. r A [  A[   A CTL allows explicit quantiﬁcation over paths, and in this respect it is moreexpressive than LTL. However, it does not allow one toselect a range of paths by describing them with a formula, as LTL does. This is called the ﬁxed-point characterisation of CTL. It is the mathematical foundation for the model-checking algorithm developed in Section 3.6.1; and we return to it later (Section 3.7).3.5 CTL* and the expressive powers of LTL and CTL grotesqueCTL. LTL is more expressive. The formula AF p →AF q means ‘if all paths have a p along them, then                allpaths have a q along them’ Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas φ which are not in the adequate fragment intosemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ. Prove that the evaluation of φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ worrisomei or Z′ horrifyingi. Proving that ρ does not depend on the value of x′. Exercises 6.16 and 6.17 are based on the CTL model M = (S, →, L) Given a model M, we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. The former deﬁnes fair in terms of f ECG for general φ. Why is this unproblem-phthalatic, i.e. non-circular? Exercises (6.16) and (7) consider the coding without consideration of simple fairness constraints. The last exercise is based on f E[x1∨¬x2Ux1]. Consider the pseudo-code for the function SAT on page 227. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.  Explain what exactly the CTL formula AG expresses in terms of the order of occurrence of events p, s and t. Explain what the formula AG (p →AF (s ∧AX (AF t)) does in plain English. Find a model in which no formula of F holds. Show these two assertions if f φ also encodes simple fairness constraints. Show that all the subformulas of f χ are formally monotone. Find the only formula in F that is not a set, or an OBDD. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� Figure 3.23 shows the relationship among the expressive powers of CTL, LTL and CTL*. The LTL formula α is equivalent to the CTL* formula A[α]. LTL can be viewed as a subset of C TL*. CTL is also a subset of CTL*, since it is the fragment of Ctl* in which we restrict the form of path formulas to α. Here are some examples of formulas in each of the subsets3.5 C TL* and LTL* and the expressive power of LTL, CTL andCTL* shown in Figure 3.22. The expressive powers are shown in Figures 3.3 and 3.4. The proof that AG EF p is not expressible in LTL is as follows. Let M′ be as shown in the right-hand diagram. The paths from sin M′ are a subset of those from s in M. Yet, it is not the case that M′, s ⊨AG EF p; a contradiction. This expresses: wherever we                have got to, we can always get to a state in which p is true. This is also useful, e.g., in ﬁnding deadlocks in protocols. The proof is quite complex and may be found in the papers co-authored by E. A. Emerson with others, given in the references. CTL* is a logic that combines the expressive powers of LTL and CTL. It does this by dropping the CTL constraint that every temporal operator (X, U, F, G) has to be associated with a unique path quantiﬁer (A, E) It is based on the fact that LTL formulas can be verified by model checking. For example, in CTL, AG (p →AF q) can be written as F p →F q. In LTL, it can be rewritten as G (p ·F q) or G p ·Fq in LTL. The result is that any p is eventually followed by a q. The syntax of CTL* involves two classes of formulas: state formulas, which are evaluated in states, and path formulas, evaluated along paths. It turns out that the ﬁrst of them can be written as a (rather long) CTL formula. It allows us to write formulas such as A[(p U r) ∨(q U r), where either p is true until r, or q istrue until r. These formulas are not equivalent to, respectively, A[ (p ∨q) U r, AX p, EG EF p and AX p. The second and third do not have a CTL formulas that are equivalent to them. LTL and CTL as subsets of CTL* are mutually recursive. The deﬁnition of each class depends upon the de ﬁNition of the other. LTL does not include A and E, but the semantic viewpoint of LTL is that we consider all paths. Therefore, the LTL CTL is a subset of CTL* in which we restrict the form of path formulas to (φ U φ) | (G φ), (F φ, (X X) LTL can be viewed as a subset to CTL*. If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective begins with E, then Satisfaction holds if some path from s satisfies the LTL formula. The result of removing A or E is not strictly an LTLformula, for it The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path There Exists a path beginning in s such that φ holds Globally along the path. The equivalencesAF and EF are similar to the corresponding equivalences in LTL. For example, the connective AX can be written ¬EX ¬;. AG, AF, EG and EF can bewritten in terms of AU and EU as follows:. write AG φ as ¬EF ¬φ and EG φ. as ¼AF ¬ φ, using (3.6), and then use. (2.6) to write EF and EF as ¹AF and ¹EF, using. (1) and (2) respectively. Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX, AF, AU, EG, EU, and EX. Theorem is proved in a paper referenced in the bibliographic notes at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it is valid in the logic CTL* introduced in the next section. For example, we have the equivalence: A[φ U ψ] ≡¬(E[¬ φ U (¬φ ∧¬hy),  “EG” U ( Neither weak-until W nor release R are primitive in CTL. The connective EU plays a special role in that theorems. The temporal connectives AR, ER, AW and EW are all deﬁnable in C TL. LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For a positive example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p ·AF q) in LTL. Some other noteworthy equivalences are the following:AG φ  ‘in’ and ‘out’ are of the form ‘in. often requested implies eventuallyacknowledged’ In fact, AF AG p is strictly stronger than F G p. While the LTL formulas X F p and F X p are equivalent, they are not equivalent to AF AX p. CTL* is more expressive than either of them, but is computationally more expensive. The choice between LTL and CTL depends on the application at hand, and on personal prefer-iness. LTL lacks CTL’s ability to quantify over paths, and C TL lacks LTL”s ability. to describe individual paths. We have seen that they have incomparable expressivepowers. We discuss two more negative examples: F G and AF AG. The latter has quite a strange meaning (try working it out). The syntax of CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn't allow nesting of path modalities X, F and G. To many people, LTL ap-                pears to be more straightforward to use; as noted above, CTL formulas like AX p seem hard to understand. The syntax of LTL is more general than CTL.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-4-subsection-5",
                            "title": "Adequate Sets of CTL Connectives",
                            "content": "exist:\n¬AF φ ≡EG ¬φ\n¬EF φ ≡AG ¬φ\n(3.6)\n¬AX φ ≡EX ¬φ.\nWe also have the equivalences\nAF φ ≡A[⊤U φ]\nEF φ ≡E[⊤U φ]\nwhich are similar to the corresponding equivalences in LTL.\n3.4.5 Adequate sets of CTL connectives\nAs in propositional logic and in LTL, there is some redundancy among the\nCTL connectives. For example, the connective AX can be written ¬EX ¬;\nand AG, AF, EG and EF can be written in terms of AU and EU as follows:\nﬁrst, write AG φ as ¬EF ¬φ and EG φ as ¬AF ¬φ, using (3.6), and then use\nAF φ ≡A[⊤U φ] and EF φ ≡E[⊤U φ]. Therefore AU, EU and EX form\nan adequate set of temporal connectives.\nAlso EG, EU, and EX form an adequate set, for we have the equivalence\nA[φ U ψ] ≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ)\n(3.7)\nwhich can be proved as follows:\nA[φ U ψ] ≡A[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E¬[¬(¬ψ U (¬φ ∧¬ψ)) ∧F ψ]\n≡¬E[(¬ψ U (¬φ ∧¬ψ)) ∨G ¬ψ]\n≡¬(E[¬ψ U (¬φ ∧¬ψ)] ∨EG ¬ψ).\nThe ﬁrst line is by Theorem 3.10, and the remainder by elementary manipu-\nlation. (This proof involves intermediate formulas which violate the syntactic\nformation rules of CTL; however, it is valid in the logic CTL* introduced in\nthe next section.) More generally, we have:\nTheorem 3.17 A set of temporal connectives in CTL is adequate if, and\nonly if, it contains at least one of {AX , EX }, at least one of {EG , AF , AU }\nand EU .\n3.5 CTL* and the expressive powers of LTL and CTL\n217\nThis theorem is proved in a paper referenced in the bibliographic notes\nat the end of the chapter. The connective EU plays a special role in that\ntheorem because neither weak-until W nor release R are primitive in CTL\n(Deﬁnition 3.12). The temporal connectives AR, ER, AW and EW are all\ndeﬁnable in CTL:\nr A[φ R ψ] = ¬E[¬φ U ¬ψ]\nr E[φ R ψ] = ¬A[¬φ U ¬ψ]\nr A[φ W ψ] = A[ψ R (φ ∨ψ)], and then use the ﬁrst equation above\nr E[φ W ψ] = E[ψ R (φ ∨ψ)], and then use the second one.\nThese deﬁnitions are justiﬁed by LTL equivalences in Sections 3.2.4\nand 3.2.5. Some other noteworthy equivalences in CTL are the following:\nAG φ ≡φ ∧AX AG φ\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nit in an equivalent form in terms of the adequate set of connectives, and then\n3.6 Model-checking algorithms\n223\nRepeat. . .\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\nAFψ1\n. . . until no change.\nFigure 3.24. The iteration step of the procedure for labelling states with\nsubformulas of the form AF ψ1.\ncall the model-checking algorithm. Here is the algorithm:\nINPUT: a CTL model M = (S, →, L) and a CTL formula φ.\nOUTPUT: the set of states of M which satisfy φ.\nFirst, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms\nof the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given\nearlier in the chapter. Next, label the states of M with the subformulas of φ\nthat are satisﬁed there, starting with the smallest subformulas and working\noutwards towards φ.\nSuppose ψ is a subformula of φ and states satisfying all the immediate\nsubformulas of ψ have already been labelled. We determine by a case analysis\nwhich states to label with ψ. If ψ is\nr ⊥: then no states are labelled with ⊥.\nr p: then label s with p if p ∈L(s).\nr ψ1 ∧ψ2: label s with ψ1 ∧ψ2 if s is already labelled both with ψ1 and with ψ2.\nr ¬ψ1: label s with ¬ψ1 if s is not already labelled with ψ1.\nr AF ψ1:\n– If any state s is labelled with ψ1, label it with AF ψ1.\n– Repeat: label any state with AF ψ1 if all successor states are labelled with\nAF ψ1, until there is no change. This step is illustrated in Figure 3.24.\nr E[ψ1 U ψ2]:\n– If any state s is labelled with ψ2, label it with E[ψ1 U ψ2].\n– Repeat: label any state with E[ψ1 U ψ2] if it is labelled with ψ1 and at least\none of its successors is labelled with E[ψ1 U ψ2], until there is no change. This\nstep is illustrated in Figure 3.25.\nr EX ψ1: label any state with EX ψ1 if one of its successors is labelled with ψ1.\n224\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\nquestion is answered by the usual truth-table deﬁnition and further recursion\ndown φ.\nr If the top level connective is an operator beginning A, then satisfaction holds if\nall paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol.\nr Similarly, if the top level connective begins with E, then satisfaction holds if\nsome path from s satisfy the ‘LTL formula’ resulting from removing the E.\nIn the last two cases, the result of removing A or E is not strictly an LTL\nformula, for it may contain further As or Es below. However, these will be\ndealt with by the recursion.\nThe formal deﬁnition of M, s ⊨φ is a bit more verbose:\nDeﬁnition 3.15 Let M = (S, →, L) be a model for CTL, s in S, φ a CTL\nformula. The relation M, s ⊨φ is deﬁned by structural induction on φ:\n1.\nM, s ⊨⊤and M, s ̸⊨⊥\n2.\nM, s ⊨p iﬀp ∈L(s)\n3.\nM, s ⊨¬φ iﬀM, s ̸⊨φ\n4.\nM, s ⊨φ1 ∧φ2 iﬀM, s ⊨φ1 and M, s ⊨φ2\n5.\nM, s ⊨φ1 ∨φ2 iﬀM, s ⊨φ1 or M, s ⊨φ2\n6.\nM, s ⊨φ1 →φ2 iﬀM, s ̸⊨φ1 or M, s ⊨φ2.\n7.\nM, s ⊨AX φ iﬀfor all s1 such that s →s1 we have M, s1 ⊨φ. Thus, AX says:\n‘in every next state.’\n8.\nM, s ⊨EX φ iﬀfor some s1 such that s →s1 we have M, s1 ⊨φ. Thus, EX\nsays: ‘in some next state.’ E is dual to A – in exactly the same way that ∃is\ndual to ∀in predicate logic.\n9.\nM, s ⊨AG φ holds iﬀfor all paths s1 →s2 →s3 →. . ., where s1 equals s, and\nall si along the path, we have M, si ⊨φ. Mnemonically: for All computation\npaths beginning in s the property φ holds Globally. Note that ‘along the path’\nincludes the path’s initial state s.\n10.\nM, s ⊨EG φ holds iﬀthere is a path s1 →s2 →s3 →. . ., where s1 equals s,\nand for all si along the path, we have M, si ⊨φ. Mnemonically: there Exists\na path beginning in s such that φ holds Globally along the path.\n212\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\nbecause any occurrence of ∧and →can be removed by using the equivalences\nφ →ψ ≡¬φ ∨ψ and φ ∧ψ ≡¬(¬φ ∨¬ψ).\n(a) Show that {¬, ∧}, {¬, →} and {→, ⊥} are adequate sets of connectives for\npropositional logic. (In the latter case, we are treating ⊥as a nullary con-\nnective.)\n(b) Show that, if C ⊆{¬, ∧, ∨, →, ⊥} is adequate for propositional logic, then\n¬ ∈C or ⊥∈C. (Hint: suppose C contains neither ¬ nor ⊥and consider\nthe truth value of a formula φ, formed by using only the connectives in C,\nfor a valuation in which every atom is assigned T.)\n(c) Is {↔, ¬} adequate? Prove your answer.\n4. Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ψ has a\nproof iﬀφ1 →φ2 →. . . φn →ψ is a tautology.\n88\n1 Propositional logic\n5. Show that the relation ≡is\n(a) reﬂexive: φ ≡φ holds for all φ\n(b) symmetric: φ ≡ψ implies ψ ≡φ and\n(c) transitive: φ ≡ψ and ψ ≡η imply φ ≡η.\n6. Show that, with respect to ≡,\n(a) ∧and ∨are idempotent:\ni. φ ∧φ ≡φ\nii. φ ∨φ ≡φ\n(b) ∧and ∨are commutative:\ni. φ ∧ψ ≡ψ ∧φ\nii. φ ∨ψ ≡ψ ∨φ\n(c) ∧and ∨are associative:\ni. φ ∧(ψ ∧η) ≡(φ ∧ψ) ∧η\nii. φ ∨(ψ ∨η) ≡(φ ∨ψ) ∨η\n(d) ∧and ∨are absorptive:\ni.\n*\nφ ∧(φ ∨η) ≡φ\nii. φ ∨(φ ∧η) ≡φ\n(e) ∧and ∨are distributive:\ni. φ ∧(ψ ∨η) ≡(φ ∧ψ) ∨(φ ∧η)\nii.\n*\nφ ∨(ψ ∧η) ≡(φ ∨ψ) ∧(φ ∨η)\n(f) ≡allows for double negation: φ ≡¬¬φ and\n(g) ∧and ∨satisﬁes the de Morgan rules:\ni. ¬(φ ∧ψ) ≡¬φ ∨¬ψ\nii.\n*\n¬(φ ∨ψ) ≡¬φ ∧¬ψ.\n7. Construct a formula in CNF based on each of the following truth tables:\n(a)\n*\np\nq\nφ1\nT\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\n(b)\n*\np\nq\nr\nφ2\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\n1.7 Exercises\n89\n(c)\nr\ns\nq\nφ3\nT\nT\nT\nF\nT\nT\nF\nT\nT\nF\nT\nF\nF\nT\nT\nF\nT\nF\nF\nT\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\n8.\n*\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nConvention 3.13 We assume similar binding priorities for the CTL con-\nnectives to what we did for propositional and predicate logic. The unary\nconnectives (consisting of ¬ and the temporal connectives AG, EG, AF, EF,\nAX and EX) bind most tightly. Next in the order come ∧and ∨; and after\nthat come →, AU and EU .\nNaturally, we can use brackets in order to override these priorities. Let\nus see some examples of well-formed CTL formulas and some examples\nwhich are not well-formed, in order to understand the syntax. Suppose\nthat p, q and r are atomic formulas. The following are well-formed CTL\nformulas:\nr AG (q →EG r), note that this is not the same as AG q →EG r, for according to\nConvention 3.13, the latter formula means (AG q) →(EG r)\nr EF E[r U q]\nr A[p U EF r]\nr EF EG p →AF r, again, note that this binds as (EF EG p) →AF r, not\nEF (EG p →AF r) or EF EG (p →AF r)\nr A[p1 U A[p2 U p3]]\nr E[A[p1 U p2] U p3]\nr AG (p →A[p U (¬p ∧A[¬p U q])]).\nIt is worth spending some time seeing how the syntax rules allow us to\nconstruct each of these. The following are not well-formed formulas:\nr EF G r\nr A¬G ¬p\nr F [r U q]\nr EF (r U q)\nr AEF r\nr A[(r U q) ∧(p U r)].\nIt is especially worth understanding why the syntax rules don’t allow us to\nconstruct these. For example, take EF (r U q). The problem with this string\nis that U can occur only when paired with an A or an E. The E we have is\npaired with the F. To make this into a well-formed CTL formula, we would\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\nWriting W in terms of U is also possible: W is like U but also allows the\npossibility of the eventuality never occurring:\nφ W ψ ≡φ U ψ ∨G φ.\n(3.3)\nInspection of clauses 12 and 13 reveals that R and W are rather similar. The\ndiﬀerences are that they swap the roles of their arguments φ and ψ; and the\nclause for W has an i −1 where R has i. Therefore, it is not surprising that\nthey are expressible in terms of each other, as follows:\nφ W ψ ≡ψ R (φ ∨ψ)\n(3.4)\nφ R ψ ≡ψ W (φ ∧ψ).\n(3.5)\n3.2.5 Adequate sets of connectives for LTL\nRecall that φ ≡ψ holds iﬀany path in any transition system which sat-\nisﬁes φ also satisﬁes ψ, and vice versa. As in propositional logic, there is\nsome redundancy among the connectives. For example, in Chapter 1 we saw\nthat the set {⊥, ∧, ¬} forms an adequate set of connectives, since the other\nconnectives ∨, →, ⊤, etc., can be written in terms of those three.\nSmall adequate sets of connectives also exist in LTL. Here is a summary\nof the situation.\nr X is completely orthogonal to the other connectives. That is to say, its presence\ndoesn’t help in deﬁning any of the other ones in terms of each other. Moreover,\nX cannot be derived from any combination of the others.\nr Each of the sets {U, X}, {R, X}, {W, X} is adequate. To see this, we note that\n– R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) and\nequivalence (3.4) followed by the duality, respectively.\n– U and W may be deﬁned from R, by the duality φ U ψ ≡¬(¬φ R ¬ψ) and\nequivalence (3.4), respectively.\n– R and U may be deﬁned from W, by equivalence (3.5) and the duality φ U\nψ ≡¬(¬φ R ¬ψ) followed by equivalence (3.5).\nSometimes it is useful to look at adequate sets of connectives which do not\nrely on the availability of negation. That’s because it is often convenient to\nassume formulas are written in negation-normal form, where all the negation\nsymbols are applied to propositional atoms (i.e., they are near the leaves\n3.3 Model checking: systems, tools, properties\n187",
                            "summary": "In propositional logic and in LTL, there is some redundancy among theCTL connectives. AU, EU and EX form an adequate set of temporal connectives, and AG, AF, EG and EF can be written in terms of AU and EU as follows: write AG φ as ¬EF ¬φ. Theorem 3.10 can be proved by elementary manipu-walletlation. For example, the connective AX can bewritten ¬EX ¬;. And the equivalencesAF φ and EF φ are similar to the corresponding equivalences for AG and LTL in 3.4.5 and 3.6 respectively, and are proved as follows. Theorem 3.17: A set of temporal connectives in CTL is adequate if, and only if, it contains at least one of {AX, EX,EG, AF, AU } and EU. The connective EU plays a special role in that theorem because neither weak-until W nor release R are primitive in C TL. The temporal connective AR, ER, AW and EW are all deﬁnable in the logic CTL* and the expressive powers of LTL and CTL. Theorem is proved in a paper referenced in the bibliographic notes referenced at the end of the chapter. The proof involves intermediate formulas which violate the syntacticformation rules of CTL; however, it The algorithm for labelling states with subformulas of the form AF is called the model-checking algorithm. Here is the algorithm:. A CTL model M = (S, →, L) and a CTL formula φ: the set of states of M. which satisfy φ. First, change φ to the output of TRANSLATE (φ), i.e., we write φ in terms of the connectives AF, EU, EX, ∧, ¬ and ⊥using the equivalences given earlier in the chapter. Figure 3.24. The iteration step of the procedure for labelled states withsubformulas is the ‘model- checking algorithm’ Label the states of M with the subformulas of φ that are satisﬁed there, starting with the smallest subformula and working outwards towards φ. We determine by a case analysis which states to label with ψ. This step is illustrated in Figure 3.24. If a state is labelled with ⊥ and no states are labelled with p, then label s with p if p ∈L(s). If ψ is a subformulum of ω, label it with ω if it is already labelled with φ and with ρ if it isn't. If ω is not a sub formula of ψ, label the state with a different subform Theorem 6.19 remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment into equivalent formulas in that fragment. Prove that the evaluation of f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ or Z. Theorem is illustrated in Figure 3.25 in the next section of the paper. The next step is to prove that the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407 is equivalent to f E[x1 Ux1] (x1, x2, x3) (0, 1 Exercises 6.16 and 6.27. Recall the way the two labelling algorithms operate in Chapter 3. Given a CTL model M = (S, →, L), we saw how to code formulas f φ. The former deﬁnes fair in terms of                f ECG⊤, whereas the latter deﰁnes f ECG φ for general φ, i.e. non-circular. Does our Symbolic coding mimic either or both of them, or neither? The answers to these questions can be found in (6.22) and (6,27) in the appendix to the book. The final chapter of the book is available on Amazon. If φ is atomic, satisfaction is determined by L. If the top level connective is an operator beginning A, then satisfaction holds if all paths from s satisfy the ‘LTL formula’ resulting from removing the A symbol. Similarly, if the top-level connective begins with E, then Satisfaction holds if some path from s satisfies the LTL formula. In the last two cases, the result of removing A or E is not strictly an LTLformula, for it may contain further As or Es below. We now want to modify it so that the resulting output is not a set, or an OBDD, but a formula                roughly understood as follows. The formal deﬁnition of M, s ⊨φ is a bit more verbose. Let M = (S, →, L) be a model for CTL, s in S, φ a CTL                formula. The relation M,  s is de-energised by structural induction on φ. However, these will bedealt with by the recursion. For All computation.paths beginning in s the property φ holds Globally. For all paths s1, s2, s3, we have M, si ≹. For S1, S2, S3, where s1 equals s, and. si along the path An adequate set of connectives for propositional logic is a set such that for every formula of logic there is an equivalent formula with only connectives from that set. For example, the set {¬, ∨} is adequate for logic, because any occurrence of  and  can be removed by using the equivalences. The set C is adequate because it is a nullary con-nective, and we are treating ⊥ as a Nullary Connective in this case. We show that C ⊆{¬,.    ,    ”, “C’s” is adequate. We also show that if C is an adequate set, Use soundness or completeness to show that a sequent φ1, φ2, . . . , φn ⊢ ω is a tautology. Show that the relation ≡ is reﬂexive, symmetric, transitive, commutative, associative, distributive, and absorptive. Prove your answer to the question Is {↔, ¬} adequate? Proving your answer will help you understand the de Morgan rules. Proving the truth value of a formula φ, formed by using only the connectives in C, can be done by using the word \"proving\" in the form C = C + T.  construct a formula in CNF based on each of the following truth tables. Exercises include the following:. Construct a model in which no formula of F holds. Explain what exactly the CTL formula AG expresses in terms of the order of occurrence of events p, s and t. Extend the algorithm NNF from page 62 which computes the negation normalform of propositional logic formulas to CTL*.  The final exercise is to find a model of F in which all formulas hold in it. For example, consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →apologeticAF q)}. CTL* is deﬁned in terms of two syntactic categories (state formulas and path formulas) This requires two separate versions of NNF which call each other in a way that is reﬂected by the syntax of CTL* given on page 218. Find a transition system which distinguishes the following pairs of C TL* formu-                las, i.e., show that they are not equivalent. Invent CTL equivalents for:. The translation from CTL with boolean combinations of path formulas to plain.CTL introduced in Section 3.5.1 is not complete. For example, the form E[ φ] can be rewritten as E[φ]  E[� The aim of this exercise is to demonstrate the expansion given for AW at the end of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)]. Show that the following LTL formulas are valid (i.e. true in any state of any                model): A[p U q] (¬p  G p) ( G  P) (P U q) (G  P) (Q U Q) (U U Q (G P) U (Q Q) Q (U Q) U  Q (Q q) G (Q p) U(Q Q q) Q( Let us see some examples of well-formed CTL formulas and some examples which are not well- formed. Let us see how the syntax rules allow us toconstruct each of these. For example, take EF (r U q). The problem with this string is that U can occur only when paired with an A or an E. The E we have is                paired with the F. We can also see why we can’t use EF (p U r) or EF EG (p →AF r) to construct these. We will also see how we can use EF G (r G r) and EF E (r E r) in the next section of this article. Inspection of clauses 12 and 13 reveals that R and W are rather similar. They swap the roles of their arguments φ and ψ; and the clause for W has an i where R has i. Therefore, it is not surprising that they are expressible in terms of each other. As in propositional logic, there is some redundancy among the connectives in the CTL formula. For example, W is like U but also allows the eventuality of never occurring: W ψ U ψ  G φ (3.3) W is also possible to write W  U  (3.4) W   U    (4.5) W (5) U  Small adequate sets of connectives also exist in LTL. The set X is completely orthogonal to the other connectives. X cannot be derived from any combination of the others. Each of the sets {U, X}. {R, X}, {W, X} is adequate.  The set {⊥, ∧, ¬} forms an adequate set of connective. For example, in Chapter 1 we saw that the set { ≹, ≳, Sometimes it is useful to look at adequate sets of connectives which do notrely on the availability of negation. That’s because it is often convenient to assume formulas are written in negation-normal form, where all the negationsymbols are applied to propositional atoms. To see this, we note that R and W may be deﬁned from U, by the duality φ R ψ ≡¬(¬φ U ¬ψ) andequivalence (3.4) followed by theDuality, respectively. We also note that U and W can be de-de-de",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-3-section-5",
                    "title": "CTL* and the Expressive Powers of LTL and CTL",
                    "content": "constraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLiveness: Messages get through eventually. Thus, for any state there is\ninevitably a future state in which the current message has got through. In\nthe module sender, we speciﬁed G F st=sent. (This speciﬁcation could\nequivalently have been written in the main module, as G F S.st=sent.)\nSimilarly, acknowledgements get through eventually. In the module\nreceiver, we write G F st=received.\n3.4 Branching-time logic\nIn our analysis of LTL (linear-time temporal logic) in the preceding sections,\nwe noted that LTL formulas are evaluated on paths. We deﬁned that a state\nof a system satisﬁes an LTL formula if all paths from the given state satisfy\nit. Thus, LTL implicitly quantiﬁes universally over paths. Therefore, prop-\nerties which assert the existence of a path cannot be expressed in LTL. This\nproblem can partly be alleviated by considering the negation of the property\nin question, and interpreting the result accordingly. To check whether there\n208\n3 Verification by model checking\nexists a path from s satisfying the LTL formula φ, we check whether all paths\nsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-\ntion, and vice versa. We used this approach when analysing the ferryman\npuzzle in the previous section. However, as already noted, properties which\nmix universal and existential path quantiﬁers cannot in general be model\nchecked using this approach, because the complement formula still has a mix.\nBranching-time logics solve this problem by allowing us to quantify ex-\nplicitly over paths. We will examine a logic known as Computation Tree\nLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X of\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.\nMar01. A. Martin. Adequate sets of temporal connectives in CTL. Electronic\nNotes in Theoretical Computer Science 52(1), 2001.\nMcM93. K. L. McMillan. Symbolic Model Checking. Kluwer Academic\nPublishers, 1993.\nMP91. Z. Manna and A. Pnueli. The Temporal Logic of Reactive and\nConcurrent Systems: Speciﬁcation. Springer-Verlag, 1991.\nMP95. Z. Manna and A. Pnueli. Temporal Veriﬁcation of Reactive Systems:\nSafety. Springer-Verlag, 1995.\nMvdH95. J.-J. Ch. Meyer and W. van der Hoek. Epistemic Logic for AI and\nComputer Science, volume 41 of Cambridge Tracts in Theoretical\nComputer Science. Cambridge University Press, 1995.\nPap94. C. H. Papadimitriou. Computational Complexity. Addison Wesley,\n1994.\nPau91. L.C. Paulson. ML for the Working Programmer. Cambridge University\nPress, 1991.\nPnu81. A. Pnueli. A temporal logic of programs. Theoretical Computer\nScience, 13:45–60, 1981.\nPop94. S. Popkorn. First Steps in Modal Logic. Cambridge University Press,\n1994.\nPra65. D. Prawitz. Natural Deduction: A Proof-Theoretical Study. Almqvist &\nWiksell, 1965.\nQS81. J. P. Quielle and J. Sifakis. Speciﬁcation and veriﬁcation of concurrent\nsystems in CESAR. In Proceedings of the Fifth International\nSymposium on Programming, 1981.\nRos97. A. W. Roscoe. The Theory and Practice of Concurrency. Prentice\nHall, 1997.\nSA91. V. Sperschneider and G. Antoniou. Logic, A Foundation for Computer\nScience. Addison Wesley, 1991.\nSch92. U. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag, 1992.\nSch94. D. A. Schmidt. The Structure of Typed Programming Languages.\nFoundations of Computing. The MIT Press, 1994.\nSim94. A. K. Simpson. The Proof Theory and Semantics of Intuitionistic\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nIn this section, we see that the ﬁrst of these restrictions is only apparent;\nwe can ﬁnd equivalents in CTL for formulas having boolean combinations\nof path formulas. The idea is to translate any CTL formula having boolean\ncombinations of path formulas into a CTL formula that doesn’t. For exam-\nple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q ∧EF p] since, if\nwe have F p ∧F q along any path, then either the p must come before the q,\nor the other way around, corresponding to the two disjuncts on the right.\n(If the p and q occur simultaneously, then both disjuncts are true.)\n3.6 Model-checking algorithms\n221\nSince U is like F (only with the extra complication of its ﬁrst argument),\nwe ﬁnd the following equivalence:\nE[(p1 U q1) ∧(p2 U q2)] ≡E[(p1 ∧p2) U (q1 ∧E[p2 U q2])]\n∨E[(p1 ∧p2) U (q2 ∧E[p1 U q1])].\nAnd from the CTL equivalence A[p U q] ≡¬(E[¬q U (¬p ∧¬q)] ∨EG ¬q)\n(see Theorem 3.10) we can obtain E[¬(p U q)]\n≡\nE[¬q U (¬p ∧¬q)] ∨\nEG ¬q. Other identities we need in this translation include E[¬X p]\n≡\nEX ¬p.\n3.5.2 Past operators in LTL\nThe temporal operators X, U, F, etc. which we have seen so far refer to the\nfuture. Sometimes we want to encode properties that refer to the past, such\nas: ‘whenever q occurs, then there was some p in the past.’ To do this, we\nmay add the operators Y, S, O, H. They stand for yesterday, since, once, and\nhistorically, and are the past analogues of X, U, F, G, respectively. Thus,\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker the example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))",
                    "summary": "Some LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) We discuss two more negative examples: F G p and AF AG p are not equivalent. The latter is strictly stronger, and has quite a strange meaning (try working it out). There is a considerable literature comparing linear-time and branching-time logics. For more information, see the book ‘LTL and Branching-Time Logics’, published by Oxford University Press, priced £16.99, and the book’s online version is £19. CTL* is more expressive than either of them, but is computationallymuch more expensive. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL's ability to describe individual paths. To many people, LTL ap- grotesquepears to be more straightforward to use; as noted above, CTL formulas likeAF AX p seem hard to understand. CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn’t allow nest-inducing of path modalities X, F and G. The choice between CTL and LTL depends on the application at hand, and on personal prefer-                ence. A model as a whole satisﬁes an LTL formula. The future shall include the present. The formulas G p →p, p →q U p and p →F p are true in every state of every model. We write M, s ⊨φ if, for every execution path π of M starting at                s, we have π ≹ ≿. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M,  s ≳ holds. We call this the ‘pro-                cynical’ version of CTL. Let us now look at some example checks for the system in Figures 3.1, 3.3, and 3.5. Later we will examine algorithms which implement this calcula-                tion. Let us first look at the checks for Linear-time temporal logic (LTL) LTL holds since the atomic symbol r is not contained in node s0. It also holds since all paths from s0 have either s1 or s2 as their next state, and each of those states satisﬁes r. It holds since we have the rightmost computation paths0 →s2, but not the leftmost path s2. We can also check that the atomic symbols p and q are contained Linear-time temporal logic is a temporal logic, with con-nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or p1, p2, .. . . ).    We work with an atomic formula, such as P1, P2, P3, P Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. For any state there is inevitably a future state in which the current message has got through. Messages get through eventually. In the module sender, we speciﬁed G F st=sent. The next three, U,R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives in the next section; for now, we concentrate on their syntax. We de-analysed LTL (linear-time temporal logic) in the preceding sections. We noted that LTL formulas are evaluated on paths. A state is an LTL formula if all paths from the given state satisfy the formula. We will examine a logic known as Computation TreeLogic, or CTL. LTL implicitly quantiﬁes universally over paths. Therefore, prop-phthalerties which assert the existence of a path cannot be expressed in LTL. Thisproblem can partly be alleviated by considering the negation of the property in question, and interpreting the result accordingly. We used this approach when analysing the ferrymanpuzzle in the previous section. However, properties which seamlesslymix universal and existential path quanti ﬁers cannot in general be modelchecked using this approach, because the complement formula still has a mix. We will examine this problem by allowing us to quantify ex-oplicitly over paths in CTL In CTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists The NuSMV model checker is used to test the correctness of software programs. The CTL model-checking algorithm is also used to check correctness of CTL connectives. The programming language is called a core programming language. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255 or visit www.suicidepreventionlifeline.org. C. Y. Lee. Representation of switching circuits by binary-decisionprograms. Bell System Technical Journal, 38:985–999, 1959. D. E. Long. Model Checking, Abstraction, and CompositionalVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon University, July 1983. C. H. Papadimitriou. Computational Complexity. Addison Wesley, November 1994. L.C. Paulson. Epistemic Logic for AI and Computer Science. Cambridge University Press, 1995. Z. Manna and A. Pnueli. The Temporal Logic of Reactive and A temporal logic of programs. Theoretical ComputerScience, 13:45–60, 1981. First Steps in Modal Logic. The Structure of Typed Programming Languages. The MIT Press, 1994. The Theory and Practice of Concurrency. ML for the Working Programmer. Cambridge University Press, 1991. A. Pnueli. Theory of Programming. A Foundation for Computer.Science. Addison Wesley, 1992. P. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag,. 1992. D. Prawitz. Natural Deduction: The Proof Theory and Semantics of Intuitionistic Proof does not allow nesting of path modalities X, F and G. The idea is to translate any CTL formula having booleancombinations of path formulas into a CTL form that doesn’t. We see that the ﬁrst of these restrictions is only apparent; we can find equivalents in CTL for formulas having boolean combinations of path formula. We also see that CTL does not let us nest path mod The temporal operators X, U, F, etc. which we have seen so far refer to the future. For exam-ple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q  EF p] since, if we have F p  along any path, then either the p must come before the q, or the other way around. Other identities we need in this translation include E[¬X p] and E [¬P p] Theorem 3.10: If the p and q occur simultaneously, then both disjuncts are true. Theorems 3.5.2 and 3.6: The Sometimes we want to encode properties that refer to the past, such as ‘whenever q occurs, then there was some p in the past’ To do this, we add the operators Y, S, O, H. They stand for yesterday, since, once, and are the past analogues of X, U, F, G, respectively. Thus, the example formula may be written G (q →O p). NuSMV supports past operators in LTL. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. That is to say, every LTL formula with past operators can be written equivalently without them The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In contrast, adding past operators to CTL does increase its expressive power. This is because they can let us examine states not forward-reachable from the present one. The results are surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. For more details on the model-checking algorithms used in this article, please visit: http://www.npr.org/2013/01 NuSMV supports past operators in LTL. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. Every LTL formula with past operators can be written equivalently without them. LTL is generally preferred by speciﬁers, as already noted, but we start with CTL model checking because its algorithm is simpler. In general, inter-                esting transition systems will have a huge number of states. Verification by model checking may be quite long. It is therefore well worth trying to ﬁnd eﬃcient algorithms. For example, if we think of implementing a model checker the example formula may The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 provide a basic model-checking question. The example formula above can                be written ¬p W q, or equivalently ¬(¬q U (p ∧¬Q) if one wants to avoid W. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. In contrast, adding past operators to CTL does increase its expressive power, because they can allow us to examine states not forward-reachable from the present one. For example, the past operators let us to travel backwards In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long. It is therefore well worth trying to ﬁnd eﬃcient algorithms. Although LTL is generally preferred by speciﬁers, as already noted, we start with CTL model checking because its algorithm is simpler. The CTL algorithm is based on the following formula: G p →p, p →q U p and p →F p. The formulas are true in every state of every model. We call the algorithm CTL because the future shall include the present, and LTL because it excludes the present. We conclude that CTL is a better algorithm than L A model as a whole is an LTL formula. This is deﬁned to hold whenever every possible execution path of the model sits on the formula. Later in this chapter, we will examine algorithms which implement this calcula-                cyntion. We write M, s ⊨φ if, for every execution path π of M starting at the beginning of the formula, we have π ⋅. If M is clear from the context, we may abbreviate M,  by s ⋉. We have outlined the formal foundations of a pro-                cure that can check whether Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. Linear-time temporal logic is a temporal logic with con-                nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or                p1, p2, .. . . ). Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. X means ‘neXt state,’ F mean ‘someFuture state, and G means � ‘all future states (Globally).’ The next three, U,R and W are called ‘Until,” ‘Release’ and ‘Weak-until�",
                    "children": [
                        {
                            "id": "chapter-3-section-5-subsection-1",
                            "title": "Boolean Combinations of Temporal Formulas in CTL",
                            "content": "constraints are of the form ‘inﬁnitely often requested implies eventually\nacknowledged’.\nIn LTL and CTL: ψ2\ndef\n= AG (p →AF q) in CTL, or G (p →F q) in LTL:\nany p is eventually followed by a q.\nRemark 3.18 We just saw that some (but not all) LTL formulas can be\nconverted into CTL formulas by adding an A to each temporal operator. For\n220\n3 Verification by model checking\na positive example, the LTL formula G (p →F q) is equivalent to the CTL\nformula AG (p →AF q). We discuss two more negative examples:\nr F G p and AF AG p are not equivalent, since F G p is satisﬁed, whereas AF AG p\nis not satisﬁed, in the model\np\n¬p\np\nIn fact, AF AG p is strictly stronger than F G p.\nr While the LTL formulas X F p and F X p are equivalent, and they are equivalent\nto the CTL formula AX AF p, they are not equivalent to AF AX p. The latter\nis strictly stronger, and has quite a strange meaning (try working it out).\nRemark 3.19 There is a considerable literature comparing linear-time and\nbranching-time logics. The question of which one is ‘better’ has been debated\nfor about 20 years. We have seen that they have incomparable expressive\npowers. CTL* is more expressive than either of them, but is computationally\nmuch more expensive (as will be seen in Section 3.6). The choice between\nLTL and CTL depends on the application at hand, and on personal prefer-\nence. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL’s\nﬁner-grained ability to describe individual paths. To many people, LTL ap-\npears to be more straightforward to use; as noted above, CTL formulas like\nAF AX p seem hard to understand.\n3.5.1 Boolean combinations of temporal formulas in CTL\nCompared with CTL*, the syntax of CTL is restricted in two ways: it does\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLiveness: Messages get through eventually. Thus, for any state there is\ninevitably a future state in which the current message has got through. In\nthe module sender, we speciﬁed G F st=sent. (This speciﬁcation could\nequivalently have been written in the main module, as G F S.st=sent.)\nSimilarly, acknowledgements get through eventually. In the module\nreceiver, we write G F st=received.\n3.4 Branching-time logic\nIn our analysis of LTL (linear-time temporal logic) in the preceding sections,\nwe noted that LTL formulas are evaluated on paths. We deﬁned that a state\nof a system satisﬁes an LTL formula if all paths from the given state satisfy\nit. Thus, LTL implicitly quantiﬁes universally over paths. Therefore, prop-\nerties which assert the existence of a path cannot be expressed in LTL. This\nproblem can partly be alleviated by considering the negation of the property\nin question, and interpreting the result accordingly. To check whether there\n208\n3 Verification by model checking\nexists a path from s satisfying the LTL formula φ, we check whether all paths\nsatisfy ¬φ; a positive answer to this is a negative answer to our original ques-\ntion, and vice versa. We used this approach when analysing the ferryman\npuzzle in the previous section. However, as already noted, properties which\nmix universal and existential path quantiﬁers cannot in general be model\nchecked using this approach, because the complement formula still has a mix.\nBranching-time logics solve this problem by allowing us to quantify ex-\nplicitly over paths. We will examine a logic known as Computation Tree\nLogic, or CTL. In CTL, as well as the temporal operators U, F, G and X of\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.\nMar01. A. Martin. Adequate sets of temporal connectives in CTL. Electronic\nNotes in Theoretical Computer Science 52(1), 2001.\nMcM93. K. L. McMillan. Symbolic Model Checking. Kluwer Academic\nPublishers, 1993.\nMP91. Z. Manna and A. Pnueli. The Temporal Logic of Reactive and\nConcurrent Systems: Speciﬁcation. Springer-Verlag, 1991.\nMP95. Z. Manna and A. Pnueli. Temporal Veriﬁcation of Reactive Systems:\nSafety. Springer-Verlag, 1995.\nMvdH95. J.-J. Ch. Meyer and W. van der Hoek. Epistemic Logic for AI and\nComputer Science, volume 41 of Cambridge Tracts in Theoretical\nComputer Science. Cambridge University Press, 1995.\nPap94. C. H. Papadimitriou. Computational Complexity. Addison Wesley,\n1994.\nPau91. L.C. Paulson. ML for the Working Programmer. Cambridge University\nPress, 1991.\nPnu81. A. Pnueli. A temporal logic of programs. Theoretical Computer\nScience, 13:45–60, 1981.\nPop94. S. Popkorn. First Steps in Modal Logic. Cambridge University Press,\n1994.\nPra65. D. Prawitz. Natural Deduction: A Proof-Theoretical Study. Almqvist &\nWiksell, 1965.\nQS81. J. P. Quielle and J. Sifakis. Speciﬁcation and veriﬁcation of concurrent\nsystems in CESAR. In Proceedings of the Fifth International\nSymposium on Programming, 1981.\nRos97. A. W. Roscoe. The Theory and Practice of Concurrency. Prentice\nHall, 1997.\nSA91. V. Sperschneider and G. Antoniou. Logic, A Foundation for Computer\nScience. Addison Wesley, 1991.\nSch92. U. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag, 1992.\nSch94. D. A. Schmidt. The Structure of Typed Programming Languages.\nFoundations of Computing. The MIT Press, 1994.\nSim94. A. K. Simpson. The Proof Theory and Semantics of Intuitionistic\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nIn this section, we see that the ﬁrst of these restrictions is only apparent;\nwe can ﬁnd equivalents in CTL for formulas having boolean combinations\nof path formulas. The idea is to translate any CTL formula having boolean\ncombinations of path formulas into a CTL formula that doesn’t. For exam-\nple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q ∧EF p] since, if\nwe have F p ∧F q along any path, then either the p must come before the q,\nor the other way around, corresponding to the two disjuncts on the right.\n(If the p and q occur simultaneously, then both disjuncts are true.)\n3.6 Model-checking algorithms\n221\nSince U is like F (only with the extra complication of its ﬁrst argument),\nwe ﬁnd the following equivalence:\nE[(p1 U q1) ∧(p2 U q2)] ≡E[(p1 ∧p2) U (q1 ∧E[p2 U q2])]\n∨E[(p1 ∧p2) U (q2 ∧E[p1 U q1])].\nAnd from the CTL equivalence A[p U q] ≡¬(E[¬q U (¬p ∧¬q)] ∨EG ¬q)\n(see Theorem 3.10) we can obtain E[¬(p U q)]\n≡\nE[¬q U (¬p ∧¬q)] ∨\nEG ¬q. Other identities we need in this translation include E[¬X p]\n≡\nEX ¬p.\n3.5.2 Past operators in LTL\nThe temporal operators X, U, F, etc. which we have seen so far refer to the\nfuture. Sometimes we want to encode properties that refer to the past, such\nas: ‘whenever q occurs, then there was some p in the past.’ To do this, we\nmay add the operators Y, S, O, H. They stand for yesterday, since, once, and\nhistorically, and are the past analogues of X, U, F, G, respectively. Thus,\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker",
                            "summary": "Some LTL formulas can be converted into CTL formulas by adding an A to each temporal operator. For example, the LTL formula G (p →F q) is equivalent to the CTLformula AG (p→AF q) We discuss two more negative examples: F G p and AF AG p are not equivalent. The latter is strictly stronger, and has quite a strange meaning (try working it out). There is a considerable literature comparing linear-time and branching-time logics. For more information, see the book ‘LTL and Branching-Time Logics’, published by Oxford University Press, priced £16.99, and the book’s online version is £19. CTL* is more expressive than either of them, but is computationallymuch more expensive. LTL lacks CTL’s ability to quantify over paths, and CTL lacks LTL's ability to describe individual paths. To many people, LTL ap- grotesquepears to be more straightforward to use; as noted above, CTL formulas likeAF AX p seem hard to understand. CTL is restricted in two ways: it does not allow boolean combinations of path formulas and it doesn’t allow nest-inducing of path modalities X, F and G. The choice between CTL and LTL depends on the application at hand, and on personal prefer-                ence. A model as a whole satisﬁes an LTL formula. The future shall include the present. The formulas G p →p, p →q U p and p →F p are true in every state of every model. We write M, s ⊨φ if, for every execution path π of M starting at                s, we have π ≹ ≿. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M,  s ≳ holds. We call this the ‘pro-                cynical’ version of CTL. Let us now look at some example checks for the system in Figures 3.1, 3.3, and 3.5. Later we will examine algorithms which implement this calcula-                tion. Let us first look at the checks for Linear-time temporal logic (LTL) LTL holds since the atomic symbol r is not contained in node s0. It also holds since all paths from s0 have either s1 or s2 as their next state, and each of those states satisﬁes r. It holds since we have the rightmost computation paths0 →s2, but not the leftmost path s2. We can also check that the atomic symbols p and q are contained Linear-time temporal logic is a temporal logic, with con-nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures, any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or p1, p2, .. . . ).    We work with an atomic formula, such as P1, P2, P3, P Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. For any state there is inevitably a future state in which the current message has got through. Messages get through eventually. In the module sender, we speciﬁed G F st=sent. The next three, U,R and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will look at the precise meaning of all these connectives in the next section; for now, we concentrate on their syntax. We de-analysed LTL (linear-time temporal logic) in the preceding sections. We noted that LTL formulas are evaluated on paths. A state is an LTL formula if all paths from the given state satisfy the formula. We will examine a logic known as Computation TreeLogic, or CTL. LTL implicitly quantiﬁes universally over paths. Therefore, prop-phthalerties which assert the existence of a path cannot be expressed in LTL. Thisproblem can partly be alleviated by considering the negation of the property in question, and interpreting the result accordingly. We used this approach when analysing the ferrymanpuzzle in the previous section. However, properties which seamlesslymix universal and existential path quanti ﬁers cannot in general be modelchecked using this approach, because the complement formula still has a mix. We will examine this problem by allowing us to quantify ex-oplicitly over paths in CTL In CTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists The NuSMV model checker is used to test the correctness of software programs. The CTL model-checking algorithm is also used to check correctness of CTL connectives. The programming language is called a core programming language. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255 or visit www.suicidepreventionlifeline.org. C. Y. Lee. Representation of switching circuits by binary-decisionprograms. Bell System Technical Journal, 38:985–999, 1959. D. E. Long. Model Checking, Abstraction, and CompositionalVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon University, July 1983. C. H. Papadimitriou. Computational Complexity. Addison Wesley, November 1994. L.C. Paulson. Epistemic Logic for AI and Computer Science. Cambridge University Press, 1995. Z. Manna and A. Pnueli. The Temporal Logic of Reactive and A temporal logic of programs. Theoretical ComputerScience, 13:45–60, 1981. First Steps in Modal Logic. The Structure of Typed Programming Languages. The MIT Press, 1994. The Theory and Practice of Concurrency. ML for the Working Programmer. Cambridge University Press, 1991. A. Pnueli. Theory of Programming. A Foundation for Computer.Science. Addison Wesley, 1992. P. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag,. 1992. D. Prawitz. Natural Deduction: The Proof Theory and Semantics of Intuitionistic Proof does not allow nesting of path modalities X, F and G. The idea is to translate any CTL formula having booleancombinations of path formulas into a CTL form that doesn’t. We see that the ﬁrst of these restrictions is only apparent; we can find equivalents in CTL for formulas having boolean combinations of path formula. We also see that CTL does not let us nest path mod The temporal operators X, U, F, etc. which we have seen so far refer to the future. For exam-ple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q  EF p] since, if we have F p  along any path, then either the p must come before the q, or the other way around. Other identities we need in this translation include E[¬X p] and E [¬P p] Theorem 3.10: If the p and q occur simultaneously, then both disjuncts are true. Theorems 3.5.2 and 3.6: The Sometimes we want to encode properties that refer to the past, such as ‘whenever q occurs, then there was some p in the past’ To do this, we add the operators Y, S, O, H. They stand for yesterday, since, once, and are the past analogues of X, U, F, G, respectively. Thus, the example formula may be written G (q →O p). NuSMV supports past operators in LTL. One could also add past opera-                tors to CTL (AY, ES, etc.) but NuSMV does not support them. That is to say, every LTL formula with past operators can be written equivalently without them The semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4 allow us to test whether the initial states of a given system satisfy an LTL orCTL formula. In contrast, adding past operators to CTL does increase its expressive power. This is because they can let us examine states not forward-reachable from the present one. The results are surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. For more details on the model-checking algorithms used in this article, please visit: http://www.npr.org/2013/01 In general, inter-esting transition systems will have a huge number of states. Verification by model checking may be quite long. LTL is generally preferred by speciﬁers, as already noted. CTL model checking is simpler than LTL because its algorithm is simpler. The CTL algorithm can be used to build a model checker for inﬃnite trees, given a designated initial state, for then all possible paths are plainly visible.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-5-subsection-2",
                            "title": "Past Operators in LTL",
                            "content": "the example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-\nsive power of LTL. That is to say, every LTL formula with past operators\ncan be written equivalently without them. The example formula above can\nbe written ¬p W q, or equivalently ¬(¬q U (p ∧¬q)) if one wants to avoid\nW. This result is surprising, because it seems that being able to talk about\nthe past as well as the future allows more expressivity than talking about\nthe future alone. However, recall that LTL equivalence is quite crude: it says\nthat the two formulas are satisﬁed by exactly the same set of paths. The\npast operators allow us to travel backwards along the path, but only to reach\npoints we could have reached by travelling forwards from its beginning. In\ncontrast, adding past operators to CTL does increase its expressive power,\nbecause they can allow us to examine states not forward-reachable from the\npresent one.\n3.6 Model-checking algorithms\nThe semantic deﬁnitions for LTL and CTL presented in Sections 3.2 and 3.4\nallow us to test whether the initial states of a given system satisfy an LTL or\nCTL formula. This is the basic model-checking question. In general, inter-\nesting transition systems will have a huge number of states and the formula\n222\n3 Verification by model checking\nwe are interested in checking may be quite long. It is therefore well worth\ntrying to ﬁnd eﬃcient algorithms.\nAlthough LTL is generally preferred by speciﬁers, as already noted, we\nstart with CTL model checking because its algorithm is simpler.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))",
                            "summary": "NuSMV supports past operators in LTL. One could also add past opera-tors to CTL (AY, ES, etc.) but NuSMV does not support them. This result is surprising, because it seems that being able to talk about the past as well as the future allows more expressivity than talking about the future alone. However, recall that LTL equivalence is quite crude: it saysthat the two formulas are satisﬁed by exactly the same set of paths. The past operators allow us to travel backwards along the path, but only to reach points we could have reached by travelling forwards from its beginning. The example formula above can be written ¬p W q, or equival The semantic deﬁnitions for LTL and CTL are presented in Sections 3.2 and 3.4. We start with CTL model checking because its algorithm is simpler. In general, inter-esting transition systems will have a huge number of states. Verification by model checking can take a long time, so it is well worth trying to develop an eﬃcient algorithm. We conclude by looking at the results of our model-checking algorithm for CTL and LTL. The results are published in the book CTL: A Model-checking Algorithm for Inter-esting Transition Systems, published by Oxford University Press, priced £16.99, with a print run of 1,000 copies. The future shall include the present if the formulas G p →p, p →q U p and p →F p are true in every state of every model. A model is a whole if every possible execution path of the model satisﬁes the formula. Later in this chapter, we will examine algorithms which implement this calcula-                tion. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s ⊨φ holds. It should be clear that we have outlining the formal foundation of aproposals that can be used to verify systems. We will examine the algorithms that implement thisproposure later in this Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. Linear-time temporal logic is a temporal logic with con-                nectives that allow us to refer to the future. It models time as a sequence of states, extending inﬁnitely into the future, called a computation path. In general, the future is not determined, so we consider several paths, representing diﬀerent possible futures. Any one of which might be the ‘actual’ path that is realised. We work with a set of atomic formulas (such as p, q, r, . . . , or                p1, p2, .. . . ). Linear-time temporal logic (LTL) has the following syntax given in Backus Naur form. The choice of atomic descriptions depends on our particular interest in a system at hand. The connectives X, F, G, U, R, and W are called temporal connectives. The parse tree of LTL is (F (p →G r) (¬q) U p), where p is any propositional atom from some set Atoms. The symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;and ¬φ is an LTL formula if φ is one, etc. The model checking process is called model checking. X means ‘neXt state,’ F mean ‘someFuture state, and G means � ‘all future states (Globally).’ The next three, U,R and W are called ‘Until,” ‘Release’ and ‘Weak-until�",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-3-section-6",
                    "title": "Model-Checking Algorithms",
                    "content": "that φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\n‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ndoes the combined system have a path. The acceptance conditions of A¬φ\nare represented as implicit fairness conditions for the CTL model-checking\nprocedure. Explicitly, this amounts to asserting ‘FAIRNESS ¬(χ U ψ) ∨ψ’\nfor each formula χ U ψ occurring in C(φ).\n3.7 The fixed-point characterisation of CTL\nOn page 227, we presented an algorithm which, given a CTL formula φ and\na model M = (S, →, L), computes the set of states s ∈S satisfying φ. We\nwrite this set as [[φ]]. The algorithm works recursively on the structure of\nφ. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. Other\n3.7 The fixed-point characterisation of CTL\n239\nformulas are composed of smaller subformulas combined by a connective of\nCTL. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets\n[[ψ1]] and [[ψ2]] and combines them in a certain way (in this case, by taking\nthe union) in order to obtain [[ψ1 ∨ψ2]].\nThe more interesting cases arise when we deal with a formula such as\nEX ψ, involving a temporal operator. The algorithm computes the set [[ψ]]\nand then computes the set of all states which have a transition to a state in\n[[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is\na state s′ with s →s′ and M, s′ ⊨ψ.\nFor most of these logical operators, we may easily continue this discussion\nto see that the algorithms work just as expected. However, the cases EU,\nAF and EG (where we needed to iterate a certain labelling policy until it\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula call such paths fair computation paths. The presence of fairness constraints\nmeans that, when evaluating the truth of CTL formulas in speciﬁcations,\nthe connectives A and E range only over fair paths.\n3.6 Model-checking algorithms\n231\nWe therefore impose the fairness constraint that !st=c be true inﬁnitely\noften. This means that, whatever state the process is in, there will be a\nstate in the future in which it is not in its critical section. Similar fairness\nconstraints were used for the Alternating Bit Protocol.\nFairness constraints of the form (where φ is a state formula)\nProperty φ is true inﬁnitely often\nare known as simple fairness constraints. Other types include those of the\nform\nIf φ is true inﬁnitely often, then ψ is also true inﬁnitely often.\nSMV can deal only with simple fairness constraints; but how does it do\nthat? To answer that, we now explain how we may adapt our model-checking\nalgorithm so that A and E are assumed to range only over fair computation\npaths.\nDeﬁnition 3.21 Let C\ndef\n= {ψ1, ψ2, . . . , ψn} be a set of n fairness constraints.\nA computation path s0 →s1 →. . . is fair with respect to these fairness\nconstraints iﬀfor each i there are inﬁnitely many j such that sj ⊨ψi, that\nis, each ψi is true inﬁnitely often along the path. Let us write AC and EC\nfor the operators A and E restricted to fair paths.\nFor example, M, s0 ⊨ACG φ iﬀφ is true in every state along all fair paths;\nand similarly for ACF, ACU, etc. Notice that these operators explicitly de-\npend on the chosen set C of fairness constraints. We already know that ECU,\nECG and ECX form an adequate set; this can be shown in the same man-\nner as was done for the temporal connectives without fairness constraints\n(Section 3.4.4). We also have that\nEC[φ U ψ] ≡E[φ U (ψ ∧ECG ⊤)]\nECX φ ≡EX (φ ∧ECG ⊤).\nTo see this, observe that a computation path is fair iﬀany suﬃx of it is\nfair. Therefore, we need only provide an algorithm for ECG φ. It is similar\ntion problems.\nThe last four issues are beyond the scope of this book, but references may\nbe found at the end of this chapter.\n3.6.2 CTL model checking with fairness\nThe veriﬁcation of M, s0 ⊨φ might fail because the model M may contain\nbehaviour which is unrealistic, or guaranteed not to occur in the actual sys-\ntem being analysed. For example, in the mutual exclusion case, we expressed\nthat the process prc can stay in its critical section (st=c) as long as it needs.\nWe modelled this by the non-deterministic assignment\nnext(st) :=\ncase\n...\n(st = c)\n: {c,n};\n...\nesac;\nHowever, if we really allow process 2 to stay in its critical section as\nlong as it likes, then we have a path which violates the liveness constraint\nAG (t1 →AF c1), since, if process 2 stays forever in its critical section, t1\ncan be true without c1 ever becoming true.\nWe would like to ignore this path, i.e., we would like to assume that the\nprocess can stay in its critical section as long as it needs, but will eventually\nexit from its critical section after some ﬁnite time.\nIn LTL, we could handle this by verifying a formula like FG¬c2 →φ,\nwhere φ is the formula we actually want to verify. This whole formula asserts\nthat all paths which satisfy inﬁnitely often ¬c2 also satisfy φ. However,\nwe cannot do this in CTL because we cannot write formulas of the form\nFG¬c2 →φ in CTL. The logic CTL is not expressive enough to allow us\nto pick out the ‘fair’ paths, i.e., those in which process 2 always eventually\nleaves its critical section.\nIt is for that reason that SMV allows us to impose fairness constraints\non top of the transition system it describes. These assumptions state that\na given formula is true inﬁnitely often along every computation path. We\ncall such paths fair computation paths. The presence of fairness constraints\nmeans that, when evaluating the truth of CTL formulas in speciﬁcations,\nthe connectives A and E range only over fair paths.\n3.6 Model-checking algorithms\n231\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ndoes the combined system have a path. The acceptance conditions of A¬φ\nare represented as implicit fairness conditions for the CTL model-checking\nprocedure. Explicitly, this amounts to asserting ‘FAIRNESS ¬(χ U ψ) ∨ψ’\nfor each formula χ U ψ occurring in C(φ).\n3.7 The fixed-point characterisation of CTL\nOn page 227, we presented an algorithm which, given a CTL formula φ and\na model M = (S, →, L), computes the set of states s ∈S satisfying φ. We\nwrite this set as [[φ]]. The algorithm works recursively on the structure of\nφ. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. Other\n3.7 The fixed-point characterisation of CTL\n239\nformulas are composed of smaller subformulas combined by a connective of\nCTL. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets\n[[ψ1]] and [[ψ2]] and combines them in a certain way (in this case, by taking\nthe union) in order to obtain [[ψ1 ∨ψ2]].\nThe more interesting cases arise when we deal with a formula such as\nEX ψ, involving a temporal operator. The algorithm computes the set [[ψ]]\nand then computes the set of all states which have a transition to a state in\n[[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is\na state s′ with s →s′ and M, s′ ⊨ψ.\nFor most of these logical operators, we may easily continue this discussion\nto see that the algorithms work just as expected. However, the cases EU,\nAF and EG (where we needed to iterate a certain labelling policy until it\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\nhow SMV could use fairness assumptions which were not expressible entirely\n5 Since we have added the variable u, there are actually six states; they all satisfy the formula.\n6.4 A relational mu-calculus\n397\nwithin CTL and its semantics. The addition of fairness could be achieved\nby restricting the ordinary CTL semantics to fair computation paths, or fair\nstates. Formally, we were given a set C = {ψ1, ψ2, . . . , ψk} of CTL formulas,\ncalled the fairness constraints, and we wanted to check whether s ⊨φ holds\nfor a CTL formula φ and all initial states s, with the additional fairness\nconstraints in C. Since ⊥, ¬, ∧, EX, EU and EG form an adequate set of\nconnectives for CTL, we may restrict this discussion to only these operators.\nClearly, the propositional connectives won’t change their meaning with the\naddition of fairness constraints. Therefore, it suﬃces to provide symbolic\ncodings for the fair connectives ECX, ECU and ECG from Chapter 3. The\nkey is to represent the set of fair states symbolically as a boolean formula\nfair deﬁned as\nfair\ndef\n= fECG⊤\n(6.22)\nwhich uses the (yet to be deﬁned) function fECG φ with ⊤as an instance.\nAssuming that the coding of fECG φ is correct, we see that fair computes 1\nin a state s if, and only if, there is a fair path with respect to C that begins\nin s. We say that such an s is a fair state.\nAs for ECX, note that s ⊨ECXφ if, and only if, there is some next state s′\nwith s →s′ and s′ ⊨φ such that s′ is a fair state. This immediately renders\nfECXφ def\n= ∃ˆx′.(f→· (fφ · fair)[ˆx := ˆx′]).\n(6.23)\nSimilarly, we obtain\nfEC[φ1Uφ2] def\n= µZ. (fφ2 · fair + fφ1 · ∃ˆx′. (f→· Z[ˆx := ˆx′])).\n(6.24)\nThis leaves us with the task of coding fECG φ. It is this last connective\nwhich reveals the complexity of fairness checks at work. Because the coding\nof fECG φ is rather complex, we proceed in steps. It is convenient to have the\nEX and EU functionality also at the level of boolean formulas directly. For\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nIn this section, we see that the ﬁrst of these restrictions is only apparent;\nwe can ﬁnd equivalents in CTL for formulas having boolean combinations\nof path formulas. The idea is to translate any CTL formula having boolean\ncombinations of path formulas into a CTL formula that doesn’t. For exam-\nple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q ∧EF p] since, if\nwe have F p ∧F q along any path, then either the p must come before the q,\nor the other way around, corresponding to the two disjuncts on the right.\n(If the p and q occur simultaneously, then both disjuncts are true.)\n3.6 Model-checking algorithms\n221\nSince U is like F (only with the extra complication of its ﬁrst argument),\nwe ﬁnd the following equivalence:\nE[(p1 U q1) ∧(p2 U q2)] ≡E[(p1 ∧p2) U (q1 ∧E[p2 U q2])]\n∨E[(p1 ∧p2) U (q2 ∧E[p1 U q1])].\nAnd from the CTL equivalence A[p U q] ≡¬(E[¬q U (¬p ∧¬q)] ∨EG ¬q)\n(see Theorem 3.10) we can obtain E[¬(p U q)]\n≡\nE[¬q U (¬p ∧¬q)] ∨\nEG ¬q. Other identities we need in this translation include E[¬X p]\n≡\nEX ¬p.\n3.5.2 Past operators in LTL\nThe temporal operators X, U, F, etc. which we have seen so far refer to the\nfuture. Sometimes we want to encode properties that refer to the past, such\nas: ‘whenever q occurs, then there was some p in the past.’ To do this, we\nmay add the operators Y, S, O, H. They stand for yesterday, since, once, and\nhistorically, and are the past analogues of X, U, F, G, respectively. Thus,\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres- that φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\n‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\n4 www.cs.indiana.edu/formal-methods-education/\n246\n3 Verification by model checking\nq3\nq1\nq2\nab\nq4\nab\nab\nab\nFigure 3.39. A model M.\n2. Consider the system of Figure 3.39. For each of the formulas φ:\n(a) G a\n(b) a U b\n(c) a U X (a ∧¬b)\n(d) X ¬b ∧G (¬a ∨¬b)\n(e) X (a ∧b) ∧F (¬a ∧¬b)\n(i) Find a path from the initial state q3 which satisﬁes φ.\n(ii) Determine whether M, q3 ⊨φ.\n3. Working from the clauses of Deﬁnition 3.1 (page 175), prove the equivalences:\nφ U ψ ≡φ W ψ ∧F ψ\nφ W ψ ≡φ U ψ ∨G φ\nφ W ψ ≡ψ R (φ ∨ψ)\nφ R ψ ≡ψ W (φ ∧ψ) .\n4. Prove that φ U ψ ≡ψ R (φ ∨ψ) ∧F ψ.\n5. List all subformulas of the LTL formula ¬p U (F r ∨G ¬q →q W ¬r).\n6. ‘Morally’ there ought to be a dual for W. Work out what it might mean, and\nthen pick a symbol based on the ﬁrst letter of the meaning.\n7. Prove that for all paths π of all models, π ⊨φ W ψ ∧F ψ implies π ⊨φ U ψ.\nThat is, prove the remaining half of equivalence (3.2) on page 185.\n8. Recall the algorithm NNF on page 62 which computes the negation normal form\nof propositional logic formulas. Extend this algorithm to LTL: you need to add\nprogram clauses for the additional connectives X, F, G and U, R and W; these\nclauses have to animate the semantic equivalences that we presented in this\nsection.\n3.8 Exercises\n247\nExercises 3.3\n1. Consider the model in Figure 3.9 (page 193).\n(a)\n*\nVerify that G(req -> F busy) holds in all initial states.\n(b) Does ¬(req U ¬busy) hold in all initial states of that model?\n(c) NuSMV has the capability of referring to the next value of a declared vari-\nable v by writing next(v). Consider the model obtained from Figure 3.9\nby removing the self-loop on state !req & busy. Use the NuSMV feature\nnext(...) to code that modiﬁed model as an NuSMV program with the\nspeciﬁcation G(req -> F busy). Then run it.\n2. Verify Remark 3.11 from page 190.\n3.\n*\nDraw the transition system described by the ABP program.\nRemarks: There are 28 reachable states of the ABP program. (Looking at the\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;",
                    "summary": "The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. This is not the case for LTL, which must be evaluated not in states but alongpaths of thesystem. For example, G F φ → ψ means that if all paths are fair then ψ holds, rather than what was intended: ω holds along all paths which are fair. It is not possible to express this in CTL in the same way as in LTL. In particular, any way of adding As or Es to the formula will result in a There are several algorithms for LTL model checking described in the literature. Although they diﬀer in detail, nearly all of them adopt the same strategy. We explain that strategy ﬁrst; then, we describe some algo-                rithms in more detail. The basic strategy is: Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. This strategy is called the basic strategy of model-checking algorithms. Humans may ﬁnd it easier to do model checks on the unwindings of models                into inﬁnite trees, given a designated initial state. However, if we think of implementing a model checker. on a computer, we certainly cannot unwind transition systems into in-                . trees. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. Such a deeper understanding will provide the basis for an eﬃcient algorithm which, given M, s ∈S and φ, computes whether M holds. In other words, the automaton Aψ encodes precisely the traces which satisfy ψ We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. NuSMV is an Open Source product, is ac-tively supported and has a substantial user community. SMV takes as input a text describing a model and some speciﬁca-tions (temporal logic formulas) It produces as output either the word ‘true’ if the speci ﬁcations hold, or a trace showing why the speiﬃcation is false for the model represented by our program. For details on how to obtain SMV, see the bibliographic notes at the end of the chapter. For more information on SMV and how to use it, visit the NuSMV website or read the book’s bibliography. Assignments usually give the initialvalue of a variable and its next value as an expression. This expression can be non-deterministic (denoted by several expressions in braces, or no assignment at all) Non-determinism is used to model the environment and for abstraction. The following input to SMV:. mainVAR request : boolean;. status : {ready,busy;. next: {ready,. busy;. request : The program has two variables, request of type boolean and status of enumeration type {ready, busy]: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent valuesof variable request are not determined within this program; this conserva-                tively models that these values are determined by an external environment. This under-speciﬁcation of request implies that the value of variable status. is partially determined: initially, it is ready; and it becomes busy whenever. The NuSMV model checker is used to test the correctness of the CTL model-checking algorithm. The program is written in a programming language called ‘Guideline’. The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.3. Representing OBDDs.6.4. The system description language as CMU SMV, but it has an improved user in-terface and a greater variety of algorithms. The term                emphasises that individual states are not represented; rather, sets of states are represented symbolically, namely, those which satisfy the formula beingchecked. The way to do this in general is to assign to each element of S aunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, werepresent a subset T by the boolean function fT which maps ( Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction as ways of addressing the state explosion problem. NuSMV supports LTL and CTL. Spin is geared towards asynchronous systems and is based on the temporal logic LTL, can be found at the Spin website10. Current research in model checking includes attempts to exploit abstrac-aryl symmetries and compositionality in order to reduce the impact of the state Explosion problem. For example, whereas CMU SMVchecks only CTL speciﬁcation, Nu SMV supports CTL and LTL. For more information on model checking, visit the CTL/LTL/C A model checker called FDR2 based on the process algebra CSP is available. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. The Edinburgh Concurrency Workbench12 and the Concurity Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The algorithm works recursively on the structure of CTL φ. The acceptance conditions of A¬φ are represented as implicit fairness conditions for the CTL model-checking procedure. The code for NuSMV can be found at: http://www.dcs.ed.edu/~cwb/, http://bogor.projects.cis.ksu.org/774/NuSMV-CTL-Model-Checking-Algorithm-Code-1-2-3-4-5-6. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. The algorithm computes the set of all states which have a transition to a state in                [[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is a state s′ with s →s′. The more interesting cases arise when we deal with a formula such as EX ω involving a temporal operator. For example, if φ is ψ1 ∨ψ2, then the algorithm compute the sets                [[ ω1] and [[ ω2] and combines them. Inspecting the pseudo-analyzer [JSS01] has been developed by D. Jackson at the Laboratory for Computer Science at the Massachusetts Institute of Technology. More information on typed higher-order logics and their use in the modelling and verifying of programming frameworks can be found on F. Pfenning’s course homepage7 on Computation and Deduction. The tool has a dedicated repository website at                alloy.mit.edu/repositories/jss01. The topic of this section is to provide semantic insights into these operators that allow us to provide acomplete proof for their termination Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The speciﬁcation is again representation by a formula call such paths fair computation paths. The presence of fairness constraints means that, when evaluating the truth of CTL formulas in speci ﬁcations, connectives A and E range only over fair paths. We therefore impose the fairness constraint that !st=c be true inﬃnitely often. This means that whatever state the process is in, there will be a state in the future in which it is not in its critical section.    In a Proof-based Approach, the process consists of trying to Constraints of the form (where φ is a state formula) are known as simple fairness constraints. Similar fairness constraints were used for the Alternating Bit Protocol. We now explain how we may adapt our model-checking algorithm so that A and E are assumed to range only over fair computation paths. For example, M, s0 ⊨ACG φ iﬀφ is true in every state along all fair paths; similarly for ACF, ACU, etc.    The algorithm can deal only with simple fairness constraint; but how does it do that? We show how to make the algorithm work with other types of constraints, such as those of theform. The last four issues are beyond the scope of this book, but references may                be found at the end of this chapter. The veriﬁcation of M, s0 ⊨φ might fail because the model M may contain unrealisticbehaviour which is unrealistic, or guaranteed not to occur in the actualsys- tumultuous being analysed. The algorithm for ECG φ is similar to the one for temporal connectives without fairness constraints. We already know that ECU, ECG and ECX form an adequate set; this can be shown in the same man-                ner as was done in Section 3.4.4 (Section 3.6.2 CTL model checking with fairness) We modelled this by the non-deterministic assignment assignment. For example, in the mutual exclusion case, we expressedthat the process prc can stay in its critical section (st=c) as long as it needs. However, if we really allow process 2 to stay in the critical section aslong as it likes, then we have a path which violates the liveness constraint (t1 →AF c1) We would like to ignore this path, i.e., we would like. to assume that the process canStay in itscritical section as longas it needs, but will eventuallyexit from its critical. section after some ﬁnite time. In LTL, we could handle this by verifying CTL is not expressive enough to pick out the ‘fair’ paths, i.e., those in which process 2 always eventually eventuallyleaves its critical section. SMV allows us to impose fairness constraints on top of the transition system it describes. These assumptions state that a given formula is true inﬁnitely often along every computation path. The presence of fairness constraintsmeans that, when evaluating the truth of CTL formulas, only connectives A and E range only over fair paths. 3.6 Model-checking algorithms for CTL and SMV. 4.7 Model- checking algorithms for SMV and CTL. 5. A model-checking algorithm for the CTL, SMV, and The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-reprehensiblemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the                literature. Nearly all of them adopt the same basic strategy. Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. Almost all LTL model checking algorithms proceed along the following three steps. Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton has a notion of accepting a trace. A trace is a sequence of valuations of the proposi-                tional atoms. NuSMV encodes precisely the traces which satisfy ψ. In otherwords, the automaton A ω encodes exactly the traces that satisfy ω. It is possible to implement the check for such a path in terms of CTL. model checking, and this is in fact what NuSMV does. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255. The acceptance conditions of A¬φare represented as implicit fairness conditions for the CTL model-checking procedure. The algorithm works recursively on the structure of CTL formula φ. For formulas φ of height 1 (⊥, ⊤or p), [[φ] is computed directly. Other CTL formulas are composed of smaller subformulas combined by a connective of                CTL. The combined system is represented as the system to be model checked in NuSMV, and the formula to be checked is simply EG ⊥. We ask the question:does the combined system have a path? The answer is ‘yes’. For most of these logical operators, we may easily continue this discussion. However, the cases EU, EUAF and EG are not so obvious to reason about. The topic of this section is todevelop the semantic insights into these operators that allow us to provide acomplete proof for their termination and correctness. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets[[ψ1] and [[ ω2] and combines them in a certain way. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is a state s′ with s →s′ and M, S, s′ � The addition of fairness could be achieved by restricting the ordinary CTL semantics to fair computation paths. The propositional connectives won’t change their meaning with theaddition of fairness constraints. Therefore, it suﬃces to provide symboliccodings for the fair connectives ECX, ECU and ECG from Chapter 3 of the CTL textbook, CTL: An Introduction to the Theory of Relational Computation. The book is published by Oxford University Press, London, UK, and is available in paperback and Kindle editions, with prices starting at £9.99 (US) and £14.99 ($19.99) for the paperback version and £16.99 for the Kindle edition. The set of fair states symbolically is represented as a boolean formula. We say that there is a fair path with respect to C that begins with s and ends with s. The coding of fECG φ is rather complex, we proceed in steps. It is convenient to have the functionality of ECX and EU functionality also at the level of boolean formulas directly. For ECX, note that s ⊨ECXφ if, and only if, there is some next state s′with s →s′ and s′ ≳ such that s′ is aFair state. For EU, we obtainfEC[φ1Uφ2] def= µZ. This immediately rendersfEC We need to develop new insights into the semantics of CTL. Such adeeper understanding will provide the basis for an eﬃcient algorithm. In the case that M is not satisﬁed, such an algorithm can be augmented to produce an ac-                tual path (= run) of the system demonstrating that M cannot satisfy φ. That way, we may debug a system by trying to ﬁx what enables runs which                refute φ, for example. For                3.6.1 The CTL model-checking algorithm. The algorithm is based on a model-checker that looks at the unwindings of models into in-                nite trees. We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. In this section, we see that the ﬁrst of these restrictions is only apparent in CTL. The idea is to translate any CTL formula having boolean combinations of path formulas into a CTL form that doesn’t. For example, we can write the formula φ in order to write the CTLformula φ. We can also use the formula F in the same way, but with a different CTLFormula, such as F-F-G. The temporal operators X, U, F, etc. which we have seen so far refer to the future. For exam-ple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q  EF p] since, if we have F p  along any path, then either the p must come before the q, or the other way around. Other identities we need in this translation include E[¬X p] and E [¬P p] Theorem 3.10: If the p and q occur simultaneously, then both disjuncts are true. Theorems 3.5.2 and 3.6: The NuSMV supports past operators in LTL. One could also add past opera-tors to CTL (AY, ES, etc.) but NuSMV does not support them. Past operators do not increase the expres- that φ is inﬁnitely often true, we check G F φ → ψ. It is not possible to express past operators as operands in CTL. In particular, any way of adding As or Es to G F will result in a formula with a diﬀerent meaning from the intended one. The result is that the formula may be written G (q →O p) rather than G F (q) The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-reprehensiblemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the                literature. Nearly all of them adopt the same basic strategy. Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. Almost all LTL model checking algorithms proceed along the following three steps.Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton has a                notion of accepting a trace. A trace is a sequence of valuations of the proposi-                tional atoms. From a path, we can abstract its trace. The construction has theproperty that for all paths SMV provides a language for describing the models we have been drawing as diagrams. It directly checks thevalidity of LTL (and also CTL) formulas on those models. SMV programs consist of one or more modules. As in the programminglanguage C, or Java, one of the modules must be called main. Modules can declare variables and assign to them. Assignments usually give the initialvalue of a variable and its next value as an expression in terms of the current values of variables. For details on how to obtain it, see the bibliographic notes at the end of the chapter.                NuSMV (sometimes called simply SMV) is a programming language. Non-determinism is used to model the environment and for abstraction. The program has two variables, request of type boolean and status of enumeration type {ready, busy}. The initial and subsequent values of variable request are not determined within this program. The value of variable status is partially determined: initially, it is ready; and it becomes busy whenever it is not ready. The system was developed in the early 1990s, because they have allowed systems with much larger state spaces to be veriﬁed. It is based on an early version of SMV, which was written in the 1980s and 1990s. The current version is written in C and has a more modern version of the SMV The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.3. Representing OBDDs.6.4 Representing sets of states in the form of a set of boolean values. 6,5. The term ‘state’ is used to emphasise that individual states are not represented; rather, sets are represented symbolically, namely, those which satisfy the formula beingchecked. 6,.5. A set is called a ‘set of states’ if it contains all the states that satisfy the condition ‘s’ = ‘S’ and ‘t’ means ‘to be’. 7. The concept of an OBDD is called ‘O A model as a whole satisﬁes an LTL formula. The formulas G p →p, p →q U p and p →F p are true in every state of every model. We will examine algorithms which implement this calcula-tion later in this chapter. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later in the chapter, we will examine an algorithm which implements this pro-                             cedure. We conclude with the conclusion that the future shall include the present and that the formula G p is true in all states of the system. Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. Humans may ﬁnd it easier to do model checks on the unwindings of models                into inﬁnite trees, given a designated initial state. However, if we think of implementing a model checker on a computer, we certainly cannot unwind transition systems. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. Such adeeper understanding will provide the basis for an eﬃcient algorithm which, given M, s ∈S and φ, computes whether M,  ⊨φ holds. This says that if                3.6.1 The CTL model-checking algorithm is We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write                4 www.cs.indiana.edu/formal-methods-education/246246.3 Verification by model checking. Figure 3.39. A model M. For each of the formulas φ: G, U, X, Q, F, G, X (a, b, c, d, e, f, g, h, j, k, l, m, n, p, q, r, t, w, y, z, s, w,. For each path π of all models, π ⊨φ W ψ implies π The ABP program has 28 reachable states. The LTL program has the additional connectives X, F, G and U, R and W. The program has to animate the semantic equivalences that we presented in this section. It has the capability of referring to the next value of a declared vari-able v by writing next(v) The program is written as an NuSMV program with the G(req -> F busy) clause. It also has the ability to draw the transition system described by the ABPProgram program. It can be used to test the correctness of the LTL Program. The code can be downloaded from the following website: http://www.lttl.org/programs/program NuSMV im-plements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely new model checker focused on compositional systems. It was also developed by K. McMillan and its description language resembles but much extends the original SMV. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. D Current research in model checking includes attempts to exploit abstrac-                tions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to reduce the impact of the state explosion problem. The model checker Spin, which is geared towards asynchronous systems, can be found at the Spin website. The Edinburgh Concurity Workbench12 and the Concurrency Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The kinds of systems we are interested in verifying using LTL may be modelled as transition systems. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The following are not well-formed formulas: U r – since U is binary, not unary. p G q – since G is unary, not binary. p W (q U r), e.g., are p, q, r, q U r and p W   (q W U r). Transition systems are also simply called models in this chapter. A model has a collection of states S, a relation →, saying how the system can move from state to state, and, associated with each state s, one has the set ofatomic propositions L(s) which are true at that particular state. A good way of thinking about L is that it is just an assignment of truth values to all the atoms in a system. We write P(Atoms) for the power set of Atoms, a collection. of atomic descriptions. We call a system a transition system by means of states (static structure) and transitions (dynamic structure). More                formally:                Deﬁnition 3.4 We may conveniently express all the information about a (ﬁnite) tran-                sition system M using directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. For example, if a system has only three states s0, s1 and s2, we can say that the only possible transi-tions between states are s0 →s1, s0 — s1 — s2.",
                    "children": [
                        {
                            "id": "chapter-3-section-6-subsection-1",
                            "title": "The CTL Model-Checking Algorithm",
                            "content": "that φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\n‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ndoes the combined system have a path. The acceptance conditions of A¬φ\nare represented as implicit fairness conditions for the CTL model-checking\nprocedure. Explicitly, this amounts to asserting ‘FAIRNESS ¬(χ U ψ) ∨ψ’\nfor each formula χ U ψ occurring in C(φ).\n3.7 The fixed-point characterisation of CTL\nOn page 227, we presented an algorithm which, given a CTL formula φ and\na model M = (S, →, L), computes the set of states s ∈S satisfying φ. We\nwrite this set as [[φ]]. The algorithm works recursively on the structure of\nφ. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. Other\n3.7 The fixed-point characterisation of CTL\n239\nformulas are composed of smaller subformulas combined by a connective of\nCTL. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets\n[[ψ1]] and [[ψ2]] and combines them in a certain way (in this case, by taking\nthe union) in order to obtain [[ψ1 ∨ψ2]].\nThe more interesting cases arise when we deal with a formula such as\nEX ψ, involving a temporal operator. The algorithm computes the set [[ψ]]\nand then computes the set of all states which have a transition to a state in\n[[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is\na state s′ with s →s′ and M, s′ ⊨ψ.\nFor most of these logical operators, we may easily continue this discussion\nto see that the algorithms work just as expected. However, the cases EU,\nAF and EG (where we needed to iterate a certain labelling policy until it\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\nanalyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula",
                            "summary": "The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. This is not the case for LTL, which must be evaluated not in states but alongpaths of thesystem. For example, G F φ → ψ means that if all paths are fair then ψ holds, rather than what was intended: ω holds along all paths which are fair. It is not possible to express this in CTL in the same way as in LTL. In particular, any way of adding As or Es to the formula will result in a There are several algorithms for LTL model checking described in the literature. Although they diﬀer in detail, nearly all of them adopt the same strategy. We explain that strategy ﬁrst; then, we describe some algo-                rithms in more detail. The basic strategy is: Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. This strategy is called the basic strategy of model-checking algorithms. Humans may ﬁnd it easier to do model checks on the unwindings of models                into inﬁnite trees, given a designated initial state. However, if we think of implementing a model checker. on a computer, we certainly cannot unwind transition systems into in-                . trees. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. Such a deeper understanding will provide the basis for an eﬃcient algorithm which, given M, s ∈S and φ, computes whether M holds. In other words, the automaton Aψ encodes precisely the traces which satisfy ψ We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. NuSMV is an Open Source product, is ac-tively supported and has a substantial user community. SMV takes as input a text describing a model and some speciﬁca-tions (temporal logic formulas) It produces as output either the word ‘true’ if the speci ﬁcations hold, or a trace showing why the speiﬃcation is false for the model represented by our program. For details on how to obtain SMV, see the bibliographic notes at the end of the chapter. For more information on SMV and how to use it, visit the NuSMV website or read the book’s bibliography. Assignments usually give the initialvalue of a variable and its next value as an expression. This expression can be non-deterministic (denoted by several expressions in braces, or no assignment at all) Non-determinism is used to model the environment and for abstraction. The following input to SMV:. mainVAR request : boolean;. status : {ready,busy;. next: {ready,. busy;. request : The program has two variables, request of type boolean and status of enumeration type {ready, busy]: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent valuesof variable request are not determined within this program; this conserva-                tively models that these values are determined by an external environment. This under-speciﬁcation of request implies that the value of variable status. is partially determined: initially, it is ready; and it becomes busy whenever. The NuSMV model checker is used to test the correctness of the CTL model-checking algorithm. The program is written in a programming language called ‘Guideline’. The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. We show in this section how the model and the intermediate sets can be stored as OBDDs. We extend that to the representation of the transition system; and we show how theremainder of the required operations is implemented.6.3 Symbolic model checking using O BDDs is called symbolic model checking. We describe in detail how                the model-checking algorithm presented in Chapter 3 can be implemented                using ObdDs as the basic data structure. 6.1 Representing subsets of the set of states. 6.3. Representing OBDDs.6.4. The system description language as CMU SMV, but it has an improved user in-terface and a greater variety of algorithms. The term                emphasises that individual states are not represented; rather, sets of states are represented symbolically, namely, those which satisfy the formula beingchecked. The way to do this in general is to assign to each element of S aunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, werepresent a subset T by the boolean function fT which maps ( Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction as ways of addressing the state explosion problem. NuSMV supports LTL and CTL. Spin is geared towards asynchronous systems and is based on the temporal logic LTL, can be found at the Spin website10. Current research in model checking includes attempts to exploit abstrac-aryl symmetries and compositionality in order to reduce the impact of the state Explosion problem. For example, whereas CMU SMVchecks only CTL speciﬁcation, Nu SMV supports CTL and LTL. For more information on model checking, visit the CTL/LTL/C A model checker called FDR2 based on the process algebra CSP is available. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. The Edinburgh Concurrency Workbench12 and the Concurity Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The algorithm works recursively on the structure of CTL φ. The acceptance conditions of A¬φ are represented as implicit fairness conditions for the CTL model-checking procedure. The code for NuSMV can be found at: http://www.dcs.ed.edu/~cwb/, http://bogor.projects.cis.ksu.org/774/NuSMV-CTL-Model-Checking-Algorithm-Code-1-2-3-4-5-6. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. The algorithm computes the set of all states which have a transition to a state in                [[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is a state s′ with s →s′. The more interesting cases arise when we deal with a formula such as EX ω involving a temporal operator. For example, if φ is ψ1 ∨ψ2, then the algorithm compute the sets                [[ ω1] and [[ ω2] and combines them. Inspecting the pseudo-analyzer [JSS01] has been developed by D. Jackson at the Laboratory for Computer Science at the Massachusetts Institute of Technology. More information on typed higher-order logics and their use in the modelling and verifying of programming frameworks can be found on F. Pfenning’s course homepage7 on Computation and Deduction. The tool has a dedicated repository website at                alloy.mit.edu/repositories/jss01. The topic of this section is to provide semantic insights into these operators that allow us to provide acomplete proof for their termination Formal veriﬁcation methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. We examine two applications of logics to the question of verifying the correctness of computer systems, or programs. We also look at the difference between proof-based vs. model-based approaches to veri ﬁcations. We conclude with a look at how we can use these techniques to test computer systems for correctness in a variety of situations, such as the production of microchips, or the testing of computer programs for security reasons. We end with a discussion of how to apply these techniques in the real world. In a model-based approach, the system is represented by a model M for an appropriate logic. The speciﬁcation is again represented by another formula. The veriﬃcation method consists of trying to prove that a formula is true. This typically requires guidance and expertise from the user.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-6-subsection-2",
                            "title": "CTL Model Checking with Fairness",
                            "content": "call such paths fair computation paths. The presence of fairness constraints\nmeans that, when evaluating the truth of CTL formulas in speciﬁcations,\nthe connectives A and E range only over fair paths.\n3.6 Model-checking algorithms\n231\nWe therefore impose the fairness constraint that !st=c be true inﬁnitely\noften. This means that, whatever state the process is in, there will be a\nstate in the future in which it is not in its critical section. Similar fairness\nconstraints were used for the Alternating Bit Protocol.\nFairness constraints of the form (where φ is a state formula)\nProperty φ is true inﬁnitely often\nare known as simple fairness constraints. Other types include those of the\nform\nIf φ is true inﬁnitely often, then ψ is also true inﬁnitely often.\nSMV can deal only with simple fairness constraints; but how does it do\nthat? To answer that, we now explain how we may adapt our model-checking\nalgorithm so that A and E are assumed to range only over fair computation\npaths.\nDeﬁnition 3.21 Let C\ndef\n= {ψ1, ψ2, . . . , ψn} be a set of n fairness constraints.\nA computation path s0 →s1 →. . . is fair with respect to these fairness\nconstraints iﬀfor each i there are inﬁnitely many j such that sj ⊨ψi, that\nis, each ψi is true inﬁnitely often along the path. Let us write AC and EC\nfor the operators A and E restricted to fair paths.\nFor example, M, s0 ⊨ACG φ iﬀφ is true in every state along all fair paths;\nand similarly for ACF, ACU, etc. Notice that these operators explicitly de-\npend on the chosen set C of fairness constraints. We already know that ECU,\nECG and ECX form an adequate set; this can be shown in the same man-\nner as was done for the temporal connectives without fairness constraints\n(Section 3.4.4). We also have that\nEC[φ U ψ] ≡E[φ U (ψ ∧ECG ⊤)]\nECX φ ≡EX (φ ∧ECG ⊤).\nTo see this, observe that a computation path is fair iﬀany suﬃx of it is\nfair. Therefore, we need only provide an algorithm for ECG φ. It is similar\ntion problems.\nThe last four issues are beyond the scope of this book, but references may\nbe found at the end of this chapter.\n3.6.2 CTL model checking with fairness\nThe veriﬁcation of M, s0 ⊨φ might fail because the model M may contain\nbehaviour which is unrealistic, or guaranteed not to occur in the actual sys-\ntem being analysed. For example, in the mutual exclusion case, we expressed\nthat the process prc can stay in its critical section (st=c) as long as it needs.\nWe modelled this by the non-deterministic assignment\nnext(st) :=\ncase\n...\n(st = c)\n: {c,n};\n...\nesac;\nHowever, if we really allow process 2 to stay in its critical section as\nlong as it likes, then we have a path which violates the liveness constraint\nAG (t1 →AF c1), since, if process 2 stays forever in its critical section, t1\ncan be true without c1 ever becoming true.\nWe would like to ignore this path, i.e., we would like to assume that the\nprocess can stay in its critical section as long as it needs, but will eventually\nexit from its critical section after some ﬁnite time.\nIn LTL, we could handle this by verifying a formula like FG¬c2 →φ,\nwhere φ is the formula we actually want to verify. This whole formula asserts\nthat all paths which satisfy inﬁnitely often ¬c2 also satisfy φ. However,\nwe cannot do this in CTL because we cannot write formulas of the form\nFG¬c2 →φ in CTL. The logic CTL is not expressive enough to allow us\nto pick out the ‘fair’ paths, i.e., those in which process 2 always eventually\nleaves its critical section.\nIt is for that reason that SMV allows us to impose fairness constraints\non top of the transition system it describes. These assumptions state that\na given formula is true inﬁnitely often along every computation path. We\ncall such paths fair computation paths. The presence of fairness constraints\nmeans that, when evaluating the truth of CTL formulas in speciﬁcations,\nthe connectives A and E range only over fair paths.\n3.6 Model-checking algorithms\n231\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nIt is possible to implement the check for such a path in terms of CTL\nmodel checking, and this is in fact what NuSMV does. The combined system\nM × A¬φ is represented as the system to be model checked in NuSMV,\nand the formula to be checked is simply EG ⊤. Thus, we ask the question:\ndoes the combined system have a path. The acceptance conditions of A¬φ\nare represented as implicit fairness conditions for the CTL model-checking\nprocedure. Explicitly, this amounts to asserting ‘FAIRNESS ¬(χ U ψ) ∨ψ’\nfor each formula χ U ψ occurring in C(φ).\n3.7 The fixed-point characterisation of CTL\nOn page 227, we presented an algorithm which, given a CTL formula φ and\na model M = (S, →, L), computes the set of states s ∈S satisfying φ. We\nwrite this set as [[φ]]. The algorithm works recursively on the structure of\nφ. For formulas φ of height 1 (⊥, ⊤or p), [[φ]] is computed directly. Other\n3.7 The fixed-point characterisation of CTL\n239\nformulas are composed of smaller subformulas combined by a connective of\nCTL. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets\n[[ψ1]] and [[ψ2]] and combines them in a certain way (in this case, by taking\nthe union) in order to obtain [[ψ1 ∨ψ2]].\nThe more interesting cases arise when we deal with a formula such as\nEX ψ, involving a temporal operator. The algorithm computes the set [[ψ]]\nand then computes the set of all states which have a transition to a state in\n[[ψ]]. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is\na state s′ with s →s′ and M, s′ ⊨ψ.\nFor most of these logical operators, we may easily continue this discussion\nto see that the algorithms work just as expected. However, the cases EU,\nAF and EG (where we needed to iterate a certain labelling policy until it\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\nhow SMV could use fairness assumptions which were not expressible entirely\n5 Since we have added the variable u, there are actually six states; they all satisfy the formula.\n6.4 A relational mu-calculus\n397\nwithin CTL and its semantics. The addition of fairness could be achieved\nby restricting the ordinary CTL semantics to fair computation paths, or fair\nstates. Formally, we were given a set C = {ψ1, ψ2, . . . , ψk} of CTL formulas,\ncalled the fairness constraints, and we wanted to check whether s ⊨φ holds\nfor a CTL formula φ and all initial states s, with the additional fairness\nconstraints in C. Since ⊥, ¬, ∧, EX, EU and EG form an adequate set of\nconnectives for CTL, we may restrict this discussion to only these operators.\nClearly, the propositional connectives won’t change their meaning with the\naddition of fairness constraints. Therefore, it suﬃces to provide symbolic\ncodings for the fair connectives ECX, ECU and ECG from Chapter 3. The\nkey is to represent the set of fair states symbolically as a boolean formula\nfair deﬁned as\nfair\ndef\n= fECG⊤\n(6.22)\nwhich uses the (yet to be deﬁned) function fECG φ with ⊤as an instance.\nAssuming that the coding of fECG φ is correct, we see that fair computes 1\nin a state s if, and only if, there is a fair path with respect to C that begins\nin s. We say that such an s is a fair state.\nAs for ECX, note that s ⊨ECXφ if, and only if, there is some next state s′\nwith s →s′ and s′ ⊨φ such that s′ is a fair state. This immediately renders\nfECXφ def\n= ∃ˆx′.(f→· (fφ · fair)[ˆx := ˆx′]).\n(6.23)\nSimilarly, we obtain\nfEC[φ1Uφ2] def\n= µZ. (fφ2 · fair + fφ1 · ∃ˆx′. (f→· Z[ˆx := ˆx′])).\n(6.24)\nThis leaves us with the task of coding fECG φ. It is this last connective\nwhich reveals the complexity of fairness checks at work. Because the coding\nof fECG φ is rather complex, we proceed in steps. It is convenient to have the\nEX and EU functionality also at the level of boolean formulas directly. For\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nnot allow boolean combinations of path formulas and it does not allow nest-\ning of the path modalities X, F and G. Indeed, we have already seen exam-\nples of the inexpressibility in CTL of nesting of path modalities, namely the\nformulas ψ3 and ψ4 above.\nIn this section, we see that the ﬁrst of these restrictions is only apparent;\nwe can ﬁnd equivalents in CTL for formulas having boolean combinations\nof path formulas. The idea is to translate any CTL formula having boolean\ncombinations of path formulas into a CTL formula that doesn’t. For exam-\nple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q ∧EF p] since, if\nwe have F p ∧F q along any path, then either the p must come before the q,\nor the other way around, corresponding to the two disjuncts on the right.\n(If the p and q occur simultaneously, then both disjuncts are true.)\n3.6 Model-checking algorithms\n221\nSince U is like F (only with the extra complication of its ﬁrst argument),\nwe ﬁnd the following equivalence:\nE[(p1 U q1) ∧(p2 U q2)] ≡E[(p1 ∧p2) U (q1 ∧E[p2 U q2])]\n∨E[(p1 ∧p2) U (q2 ∧E[p1 U q1])].\nAnd from the CTL equivalence A[p U q] ≡¬(E[¬q U (¬p ∧¬q)] ∨EG ¬q)\n(see Theorem 3.10) we can obtain E[¬(p U q)]\n≡\nE[¬q U (¬p ∧¬q)] ∨\nEG ¬q. Other identities we need in this translation include E[¬X p]\n≡\nEX ¬p.\n3.5.2 Past operators in LTL\nThe temporal operators X, U, F, etc. which we have seen so far refer to the\nfuture. Sometimes we want to encode properties that refer to the past, such\nas: ‘whenever q occurs, then there was some p in the past.’ To do this, we\nmay add the operators Y, S, O, H. They stand for yesterday, since, once, and\nhistorically, and are the past analogues of X, U, F, G, respectively. Thus,\nthe example formula may be written G (q →O p).\nNuSMV supports past operators in LTL. One could also add past opera-\ntors to CTL (AY, ES, etc.) but NuSMV does not support them.\nSomewhat counter-intuitively, past operators do not increase the expres-",
                            "summary": "We impose the fairness constraint that !st=c be true inﬁnitely often. This means that, whatever state the process is in, there will be a state in the future in which it is not in its critical section. Similar fairness constraints were used for the Alternating Bit Protocol. The presence of fairness constraintsmeans that, when evaluating the truth of CTL formulas, the connectives A and E range only over fair paths. call such paths fair computation paths. SMV can deal only with simple fairness constraints; but how does it do that? To answer that, we now explain how we may adapt our model-checking algorithm so that A and E are assumed to range only over fair computation paths. Let us write AC and ECfor the operators A andE restricted to fair paths. For example, M, s0 ⊨ACG φ iﬀφ is true in every state along all fair paths; and similarly for ACF, ACU, etc.  Notice that these operators explicitly de-pend on the chosen set C of fairness constraints.    Theorem: For each i there are inﬁnitely many j such that sj The last four issues are beyond the scope of this book, but references may be found at the end of this chapter. We already know that ECU, ECG and ECX form an adequate set; this can be shown in the same man-                ner as was done for the temporal connectives without fairness constraints. The veriﬁcation of M, s0 ⊨φ might fail because the model M may contain unrealisticbehaviour which is unrealistic, or guaranteed not to occur in the actualsys-��tem being analysed. It is similar to the problems with ECG φ. We need only provide an algorithm for ECG. We modelled this by the non-deterministic assignment assignment. For example, in the mutual exclusion case, we expressedthat the process prc can stay in its critical section (st=c) as long as it needs. However, if we really allow process 2 to stay in the critical section aslong as it likes, then we have a path which violates the liveness constraint (t1 →AF c1) We would like to ignore this path, i.e., we would like. to assume that the process canStay in itscritical section as longas it needs, but will eventuallyexit from its critical. section after some ﬁnite time. In LTL, we could handle this by verifying CTL is not expressive enough to pick out the ‘fair’ paths, i.e., those in which process 2 always eventually eventuallyleaves its critical section. SMV allows us to impose fairness constraints on top of the transition system it describes. These assumptions state that a given formula is true inﬁnitely often along every computation path. The presence of fairness constraintsmeans that, when evaluating the truth of CTL formulas, only connectives A and E range only over fair paths. 3.6 Model-checking algorithms for CTL and SMV. 4.7 Model- checking algorithms for SMV and CTL. 5. A model-checking algorithm for the CTL, SMV, and The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-reprehensiblemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the                literature. Nearly all of them adopt the same basic strategy. Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. Almost all LTL model checking algorithms proceed along the following three steps. Construct an automaton, also known as a tableau, for the formula ¬φ. The automaton has a notion of accepting a trace. A trace is a sequence of valuations of the proposi-                tional atoms. NuSMV encodes precisely the traces which satisfy ψ. In otherwords, the automaton A ω encodes exactly the traces that satisfy ω. It is possible to implement the check for such a path in terms of CTL. model checking, and this is in fact what NuSMV does. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org for details. In the U.S. call the National Suicide Prevention Line on 1-800-273-8255. The acceptance conditions of A¬φare represented as implicit fairness conditions for the CTL model-checking procedure. The algorithm works recursively on the structure of CTL formula φ. For formulas φ of height 1 (⊥, ⊤or p), [[φ] is computed directly. Other CTL formulas are composed of smaller subformulas combined by a connective of                CTL. The combined system is represented as the system to be model checked in NuSMV, and the formula to be checked is simply EG ⊥. We ask the question:does the combined system have a path? The answer is ‘yes’. For most of these logical operators, we may easily continue this discussion. However, the cases EU, EUAF and EG are not so obvious to reason about. The topic of this section is todevelop the semantic insights into these operators that allow us to provide acomplete proof for their termination and correctness. For example, if φ is ψ1 ∨ψ2, then the algorithm computes the sets[[ψ1] and [[ ω2] and combines them in a certain way. This is in accord with the semantics of EX ψ: M, s ⊨EX ψ iﬀthere is a state s′ with s →s′ and M, S, s′ � The addition of fairness could be achieved by restricting the ordinary CTL semantics to fair computation paths. The propositional connectives won’t change their meaning with theaddition of fairness constraints. Therefore, it suﬃces to provide symboliccodings for the fair connectives ECX, ECU and ECG from Chapter 3 of the CTL textbook, CTL: An Introduction to the Theory of Relational Computation. The book is published by Oxford University Press, London, UK, and is available in paperback and Kindle editions, with prices starting at £9.99 (US) and £14.99 ($19.99) for the paperback version and £16.99 for the Kindle edition. The set of fair states symbolically is represented as a boolean formula. We say that there is a fair path with respect to C that begins with s and ends with s. The coding of fECG φ is rather complex, we proceed in steps. It is convenient to have the functionality of ECX and EU functionality also at the level of boolean formulas directly. For ECX, note that s ⊨ECXφ if, and only if, there is some next state s′with s →s′ and s′ ≳ such that s′ is aFair state. For EU, we obtainfEC[φ1Uφ2] def= µZ. This immediately rendersfEC We need to develop new insights into the semantics of CTL. Such adeeper understanding will provide the basis for an eﬃcient algorithm. In the case that M is not satisﬁed, such an algorithm can be augmented to produce an ac-                tual path (= run) of the system demonstrating that M cannot satisfy φ. That way, we may debug a system by trying to ﬁx what enables runs which                refute φ, for example. For                3.6.1 The CTL model-checking algorithm. The algorithm is based on a model-checker that looks at the unwindings of models into in-                nite trees. We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. In this section, we see that the ﬁrst of these restrictions is only apparent in CTL. The idea is to translate any CTL formula having boolean combinations of path formulas into a CTL form that doesn’t. For example, we can write the formula φ in order to write the CTLformula φ. We can also use the formula F in the same way, but with a different CTLFormula, such as F-F-G. The temporal operators X, U, F, etc. which we have seen so far refer to the future. For exam-ple, we may see that E[F p ∧F q] ≡EF [p ∧EF q] ∨EF [q  EF p] since, if we have F p  along any path, then either the p must come before the q, or the other way around. Other identities we need in this translation include E[¬X p] and E [¬P p] Theorem 3.10: If the p and q occur simultaneously, then both disjuncts are true. Theorems 3.5.2 and 3.6: The NuSMV supports past operators in LTL. One could also add past opera-tors to CTL (AY, ES, etc.) but NuSMV does not support them. Past operators do not increase the expres-. S, S, O, H are the past analogues of X, U, F, G, respectively. The example formula may be written G (q →O p) for past operators.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-6-subsection-3",
                            "title": "The LTL Model-Checking Algorithm",
                            "content": "that φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\n‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nLTL in which the future excludes the present. A consequence of adopting\nthe convention that the future shall include the present is that the formulas\nG p →p, p →q U p and p →F p are true in every state of every model.\nSo far we have deﬁned a satisfaction relation between paths and LTL for-\nmulas. However, to verify systems, we would like to say that a model as\na whole satisﬁes an LTL formula. This is deﬁned to hold whenever every\npossible execution path of the model satisﬁes the formula.\nDeﬁnition 3.8 Suppose M = (S, →, L) is a model, s ∈S, and φ an LTL\nformula. We write M, s ⊨φ if, for every execution path π of M starting at\ns, we have π ⊨φ.\nIf M is clear from the context, we may abbreviate M, s ⊨φ by s ⊨φ.\nIt should be clear that we have outlined the formal foundations of a pro-\ncedure that, given φ, M and s, can check whether M, s ⊨φ holds. Later\nin this chapter, we will examine algorithms which implement this calcula-\ntion. Let us now look at some example checks for the system in Figures 3.3\nand 3.5.\n1.\nM, s0 ⊨p ∧q holds since the atomic symbols p and q are contained in the node\nof s0: π ⊨p ∧q for every path π beginning in s0.\n3.2 Linear-time temporal logic\n183\n2.\nM, s0 ⊨¬r holds since the atomic symbol r is not contained in node s0.\n3.\nM, s0 ⊨⊤holds by deﬁnition.\n4.\nM, s0 ⊨X r holds since all paths from s0 have either s1 or s2 as their next\nstate, and each of those states satisﬁes r.\n5.\nM, s0 ⊨X (q ∧r) does not hold since we have the rightmost computation path\ns0 →s2 →s2 →s2 →. . . in Figure 3.5, whose second node s2 contains r, but\nnot q.\n6.\nM, s0 ⊨G ¬(p ∧r) holds since all computation paths beginning in s0 satisfy\nG ¬(p ∧r), i.e. they satisfy ¬(p ∧r) in each state along the path. Notice that\nG φ holds in a state if, and only if, φ holds in all states reachable from the\ngiven state.\n7.\nFor similar reasons, M, s2 ⊨G r holds (note the s2 instead of s0).\n8.\nFor any state s of M, we have M, s ⊨F (¬q ∧r) →F G r. This says that if\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\n4 www.cs.indiana.edu/formal-methods-education/\n246\n3 Verification by model checking\nq3\nq1\nq2\nab\nq4\nab\nab\nab\nFigure 3.39. A model M.\n2. Consider the system of Figure 3.39. For each of the formulas φ:\n(a) G a\n(b) a U b\n(c) a U X (a ∧¬b)\n(d) X ¬b ∧G (¬a ∨¬b)\n(e) X (a ∧b) ∧F (¬a ∧¬b)\n(i) Find a path from the initial state q3 which satisﬁes φ.\n(ii) Determine whether M, q3 ⊨φ.\n3. Working from the clauses of Deﬁnition 3.1 (page 175), prove the equivalences:\nφ U ψ ≡φ W ψ ∧F ψ\nφ W ψ ≡φ U ψ ∨G φ\nφ W ψ ≡ψ R (φ ∨ψ)\nφ R ψ ≡ψ W (φ ∧ψ) .\n4. Prove that φ U ψ ≡ψ R (φ ∨ψ) ∧F ψ.\n5. List all subformulas of the LTL formula ¬p U (F r ∨G ¬q →q W ¬r).\n6. ‘Morally’ there ought to be a dual for W. Work out what it might mean, and\nthen pick a symbol based on the ﬁrst letter of the meaning.\n7. Prove that for all paths π of all models, π ⊨φ W ψ ∧F ψ implies π ⊨φ U ψ.\nThat is, prove the remaining half of equivalence (3.2) on page 185.\n8. Recall the algorithm NNF on page 62 which computes the negation normal form\nof propositional logic formulas. Extend this algorithm to LTL: you need to add\nprogram clauses for the additional connectives X, F, G and U, R and W; these\nclauses have to animate the semantic equivalences that we presented in this\nsection.\n3.8 Exercises\n247\nExercises 3.3\n1. Consider the model in Figure 3.9 (page 193).\n(a)\n*\nVerify that G(req -> F busy) holds in all initial states.\n(b) Does ¬(req U ¬busy) hold in all initial states of that model?\n(c) NuSMV has the capability of referring to the next value of a declared vari-\nable v by writing next(v). Consider the model obtained from Figure 3.9\nby removing the self-loop on state !req & busy. Use the NuSMV feature\nnext(...) to code that modiﬁed model as an NuSMV program with the\nspeciﬁcation G(req -> F busy). Then run it.\n2. Verify Remark 3.11 from page 190.\n3.\n*\nDraw the transition system described by the ABP program.\nRemarks: There are 28 reachable states of the ABP program. (Looking at the\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;",
                            "summary": "The algorithm presented in the sections above for CTL model checking is quite intuitive. Given a system and a CTL formula, it labels states of the system with the subformulas of the formula which are satisﬁed there. This is not the case for LTL, which must be evaluated not in states but alongpaths of thesystem. For example, G F φ → ψ means that if all paths are fair then ψ holds, rather than what was intended: ω holds along all paths which are fair. It is not possible to express this in CTL in the same way as in LTL. In particular, any way of adding As or Es to the formula will result in a There are several algorithms for LTL model checking described in the literature. Although they diﬀer in detail, nearly all of them adopt the same strategy. We explain that strategy ﬁrst; then, we describe some algo-                rithms in more detail. The basic strategy is: Let M = (S, →, L) be a model, s ∈S, and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along all paths of M starting at s. This strategy is called the basic strategy of model-checking algorithms. NuSMV is an Open Source product, is ac-tively supported and has a substantial user community. SMV takes as input a text describing a model and some speciﬁca-tions (temporal logic formulas) It produces as output either the word ‘true’if the speci ﬁcations hold, or a trace showing why the speiﬃcation is false for the model represented by our program. As in the programminglanguage C, or Java, one of the modules must be called main. Modules can also declare variables and assign to them. For details on how to obtain SMV, see the bibliographic notes at the end of the chapter. Assignments usually give the initialvalue of a variable and its next value as an expression. This expression can be non-deterministic (denoted by several expressions in braces, or no assignment at all) Non-determinism is used to model the environment and for abstraction. The following input to SMV:. mainVAR request : boolean;. status : {ready,busy;. next: {ready,. busy;. request : The pseudo-code presented in Figure 3.28 on page 227 takes as input a formula φ and returns the set of states of the given model which satisfy the formula. Inspection of the code shows that the algorithm consists of manipulating intermediate sets of states. In this section, we describe in detail how the model-checking algorithm presented in Chapter 3 can be implemented using OBDDs as the basic data structure. The program has two variables, request of type boolean and status of enumeration type {ready, busy}: ‘false’ and 1 represents ‘true’ The initial and subsequent valuesof variable request are not determined within this program; this conserva-tively models that these values are determined by an external environment Model checking using OBDDs is called symbolic model checking. The term purposefullyemphasises that individual states are not represented. Instead, sets of states are represented symbolically, namely, those which satisfy the formula beingchecked. We show in this section how the model and the intermediate sets ofStates can be stored as OBDD. We also show how the operations required in that pseudo-code can be implemented in terms of the operations on OBDDS which we have seen in this chapter. We conclude with a discussion of the implications of the model checking scheme for computer science. We hope that this will help you to understand the theory of computer science more fully. Back to the page you came from. Since OBDDs encodeolean functions, we need somehow to code the elements of S as boolean values. The way to do this in general is to assign to each element s aunique vector of boolean values (v1, v2, . . . , vn) Each element T is represented by a subset T by the function fT. fT maps a subset of T onto 1 if s is 1, and onto 0 otherwise. There are 2n boolean vectors (v 1, v 2, .. . . ). Therefore, n should be chosen such that 2n−1 < |S| ≤2n. A consequence of adopting the convention that the future shall include the present is that the formulas G p → M, s ⊨φ is a formula that holds whenever every possible execution path of the model is found. Later in this chapter, we will examine algorithms which implement this calcula-                tion. We have outlined the formal foundations of a pro-                cedure that, given φ, M and s, can check whether M, s  holds. We will then examine the algorithms that implement this pro-reprehensibility. Back to Mail Online home. back to the page you came from. Let us now look at some example checks for the system in Figures 3.3 and 3.5. For each state s of M, we have M, s ⊨F (¬q ∧r) →F G r. Notice that G holds in a state if, and only if, φ holds in all states reachable from the given state. For example, the rightmost computation path s0 does not hold since its second node s2 contains r, but not q. For any state s in M, the state F holds if F holds in each state along the path, and F r holds if G r holds in every state in the path. Humans may ﬁnd it easier to do model checks on the unwindings of models                into inﬁnite trees, given a designated initial state. However, if we think of implementing a model checker on a computer, we certainly cannot unwind transition systems. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. Such adeeper understanding will provide the basis for an eﬃcient algorithm which, given M, s ∈S and φ, computes whether M,  ⊨φ holds. This says that if                3.6.1 The CTL model-checking algorithm is We present an algorithm which, given a model M and a CTL formula, outputs the set of states of the model that satisfy the φ. The algorithm does not need to be able to handle every CTL con-                nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. The labelling algorithm is based on the following model: M, φ, s0, AF, EU, EX, E, F, R, S, T, B, C, D, G, H, I, J, K, L, M, M. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write                4 www.cs.indiana.edu/formal-methods-education/246246.3 Verification by model checking. Figure 3.39. A model M. For each of the formulas φ: G, U, X, Q, F, G, X (a, b, c, d, e, f, g, h, j, k, l, m, n, p, q, r, t, w, y, z, s, w,. For each path π of all models, π ⊨φ W ψ implies π The ABP program has 28 reachable states. The LTL program has the additional connectives X, F, G and U, R and W. The program has to animate the semantic equivalences that we presented in this section. It has the capability of referring to the next value of a declared vari-able v by writing next(v) The program is written as an NuSMV program with the G(req -> F busy) clause. It also has the ability to draw the transition system described by the ABPProgram program. It can be used to test the correctness of the LTL Program. The code can be downloaded from the following website: http://www.lttl.org/programs/program NuSMV im-plements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely new model checker focused on compositional systems. It was also developed by K. McMillan and its description language resembles but much extends the original SMV. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. D Current research in model checking includes attempts to exploit abstrac-                tions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to reduce the impact of the state explosion problem. The model checker Spin, which is geared towards asynchronous systems, can be found at the Spin website. The Edinburgh Concurity Workbench12 and the Concurrency Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The kinds of systems we are interested in verifying using LTL may be modelled as transition systems. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. The following are not well-formed formulas: U r – since U is binary, not unary. p G q – since G is unary, not binary. p W (q U r), e.g., are p, q, r, q U r and p W   (q W U r). Transition systems are also simply called models in this chapter. A model has a collection of states S, a relation →, saying how the system can move from state to state, and, associated with each state s, one has the set ofatomic propositions L(s) which are true at that particular state. A good way of thinking about L is that it is just an assignment of truth values to all the atoms in a system. We write P(Atoms) for the power set of Atoms, a collection. of atomic descriptions. We call a system a transition system by means of states (static structure) and transitions (dynamic structure). More                formally:                Deﬁnition 3.4 We may conveniently express all the information about a (ﬁnite) tran-                sition system M using directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. For example, if a system has only three states s0, s1 and s2, we can say that the only possible transi-tions between states are s0 →s1, s0 — s1 — s2.",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-3-section-7",
                    "title": "The Fixed-Point Characterisation of CTL",
                    "content": "for all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\ncode in Figure 3.28, we see that most of these clauses just do the obvious\nand correct thing according to the semantics of CTL. For example, try out\nwhat SAT does when you call it with φ1 →φ2.\nOur aim in this section is to prove the termination and correctness\nof SATAF and SATEU. In fact, we will also write a procedure SATEG and\nprove its termination and correctness1. The procedure SATEG is given in\nFigure 3.37 and is based on the intuitions given in Section 3.6.1: note how\ndeleting the label if none of the successor states is labelled is coded as\nintersecting the labelled set with the set of states which have a labelled\nsuccessor.\nThe semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-\nputation path s0 →s1 →s2 →. . . such that si ⊨φ holds for all i ≥0. We\ncould instead express it as follows: EG φ holds if φ holds and EG φ holds\nin one of the successor states to the current state. This suggests the equiv-\nalence EG φ ≡φ ∧EX EG φ which can easily be proved from the semantic\ndeﬁnitions of the connectives.\nObserving that [[EX ψ]] = pre∃([[ψ]]) we see that the equivalence above\ncan be written as [[EG φ]] = [[φ]] ∩pre∃([[EG φ]]). This does not look like a\nvery promising way of calculating EG φ, because we need to know EG φ in\norder to work out the right-hand side. Fortunately, there is a way around\nthis apparent circularity, known as computing ﬁxed points, and that is the\nsubject of this section.\n1 Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted in Section 3.6.1\nthat EG could be handled directly.\n240\n3 Verification by model checking\nfunction SATEG (φ)\n/* determines the set of states satisfying EG φ */\nlocal var X, Y\nbegin\nY := SAT (φ);\nX := ∅;\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∩pre∃(Y )\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\ntions compute a pre-image of a set of states. The function pre∃(instrumental\nin SATEX and SATEU) takes a subset Y of states and returns the set of states\nwhich can make a transition into Y . The function pre∀, used in SATAF, takes\n228\n3 Verification by model checking\nfunction SATEX (φ)\n/* determines the set of states satisfying EX φ */\nlocal var X, Y\nbegin\nX := SAT (φ);\nY := pre∃(X);\nreturn Y\nend\nFigure 3.29. The function SATEX. It computes the states satisfying φ by\ncalling SAT. Then, it looks backwards along →to find the states satisfying\nEX φ.\nfunction SATAF (φ)\n/* determines the set of states satisfying AF φ */\nlocal var X, Y\nbegin\nX := S;\nY := SAT (φ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪pre∀(Y )\nend\nreturn Y\nend\nFigure 3.30. The function SATAF. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying AF φ in the manner\ndescribed in the labelling algorithm.\na set Y and returns the set of states which make transitions only into Y .\nObserve that pre∀can be expressed in terms of complementation and pre∃,\nas follows:\npre∀(Y ) = S −pre∃(S −Y )\n(3.8)\nwhere we write S −Y for the set of all s ∈S which are not in Y .\nThe correctness of this pseudocode and the model checking algorithm is\ndiscussed in Section 3.7.\n3.6 Model-checking algorithms\n229\nfunction SATEU (φ, ψ)\n/* determines the set of states satisfying E[φ U ψ] */\nlocal var W, X, Y\nbegin\nW := SAT (φ);\nX := S;\nY := SAT (ψ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪(W ∩pre∃(Y ))\nend\nreturn Y\nend\nFigure 3.31. The function SATEU. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying E[φ U ψ] in the manner\ndescribed in the labelling algorithm.\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nlaws to it, and extract a witness to the DAG’s satisﬁability. Explain in what\nsense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is\nnot valid.\n5. Explain in what sense the SAT solving technique, as presented in this chapter,\ncan be used to check whether formulas are tautologies.\n6. For φ from (1.10), can one reverse engineer φ from the DAG of T(φ)?\n7. Consider a modiﬁcation of our method which initially tags a DAG’s root node\nwith ‘1: F.’ In that case,\n(a) are the forcing laws still sound? If so, state the invariant.\n(b) what can we say about the formula(s) a DAG represents if\ni. we detect contradictory constraints?\nii. we compute consistent forced constraints for each node?\n8. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied\nto T(φ) –\nto the marking algorithm – applied to φ. Discuss similarities and\ndiﬀerences of these approaches.\n1.8 Bibliographic notes\n91\n9. Consider Figure 1.20 on page 77. Verify that\n(a) its test produces contradictory constraints\n(b) its cubic analysis does not decide satisﬁability, regardless of whether the\ntwo optimizations we described are present.\n10. Verify that the DAG of Figure 1.17 (page 74) is indeed the one obtained for\nT(φ), where φ is the formula in (1.11) on page 73.\n11.\n*\nAn implementor may be concerned with the possibility that the answers to the\ncubic SAT solver may depend on a particular order in which we test unmarked\nnodes or use the rules in Figure 1.14. Give a semi-formal argument for why the\nanalysis results don’t depend on such an order.\n12. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability\nof T(φ).\n13. Advanced Project: Write a complete implementation of the cubic SAT solver\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nWhen we applied our linear SAT solver, we saw two possible outcomes:\nwe either detected contradictory constraints, meaning that no formula rep-\nresented by the DAG is satisﬁable (e.g. Fig. 1.16); or we managed to force\nconsistent constraints on all nodes, in which case all formulas represented by\nthis DAG are satisﬁable with those constraints as a witness (e.g. Fig. 1.13).\nUnfortunately, there is a third possibility: all forced constraints are consis-\ntent with each other, but not all nodes are constrained! We already remarked\nthat this occurs for formulas of the form ¬(φ1 ∧φ2).\n1.6 SAT solvers\n73\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n1: T\n2: F\n3: T\n4: T\n4: T\n5: F\n6: T\n5: F\n7: T\n8: F\n9: T\n11: F\n10: T\n10: T\n7: T\nits conjunction parent\n– a contradiction\nand ∧frr force F\nits children and\n∧ti force T\nFigure 1.16. The forcing rules, applied to the DAG of Figure 1.15,\ndetect contradictory constraints at the indicated node – implying that\nthe initial constraint ‘1:T’ cannot be realized. Thus, formulas represented\nby this DAG are not satisfiable.\nRecall that checking validity of formulas in CNF is very easy. We already\nhinted at the fact that checking satisﬁability of formulas in CNF is hard. To\nillustrate, consider the formula\n((p ∨(q ∨r)) ∧((p ∨¬q) ∧((q ∨¬r) ∧((r ∨¬p) ∧(¬p ∨(¬q ∨¬r))))))\n(1.11)\nin CNF – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula\nshould not be satisﬁable. The ﬁrst and last clause in (1.11) ‘say’ that at least\none of p, q, and r are false and true (respectively). The remaining three\nclauses, in their conjunction, ‘say’ that p, q, and r all have the same truth\nvalue. This cannot be satisﬁable, and a good SAT solver should discover\nnow we are interested only in the mechanism in principle of the algorithm\nfor SAT; any (correct and eﬃcient) implementation of sets would do and\nwe study such an implementation in Chapter 6. We assume that SAT has\naccess to all the relevant parts of the model: S, →and L. In particular,\nwe ignore the fact that SAT would require a description of M as input as\nwell. We simply assume that SAT operates directly on any such given model.\nNote how SAT translates φ into an equivalent formula of the adequate set\nchosen.\n3.6 Model-checking algorithms\n227\nfunction SAT (φ)\n/* determines the set of states satisfying φ */\nbegin\ncase\nφ is ⊤: return S\nφ is ⊥: return ∅\nφ is atomic: return {s ∈S | φ ∈L(s)}\nφ is ¬φ1 : return S −SAT (φ1)\nφ is φ1 ∧φ2 : return SAT (φ1) ∩SAT (φ2)\nφ is φ1 ∨φ2 : return SAT (φ1) ∪SAT (φ2)\nφ is φ1 →φ2 : return SAT (¬φ1 ∨φ2)\nφ is AX φ1 : return SAT (¬EX ¬φ1)\nφ is EX φ1 : return SATEX(φ1)\nφ is A[φ1 U φ2] : return SAT(¬(E[¬φ2 U (¬φ1 ∧¬φ2)] ∨EG ¬φ2))\nφ is E[φ1 U φ2] : return SATEU(φ1, φ2)\nφ is EF φ1 : return SAT (E(⊤U φ1))\nφ is EG φ1 : return SAT(¬AF ¬φ1)\nφ is AF φ1 : return SATAF (φ1)\nφ is AG φ1 : return SAT (¬EF ¬φ1)\nend case\nend function\nFigure 3.28. The function SAT. It takes a CTL formula as input and\nreturns the set of states satisfying the formula. It calls the functions\nSATEX, SATEU and SATAF, respectively, if EX , EU or AF is the root of the\ninput’s parse tree.\nThe algorithm is presented in Figure 3.28 and its subfunctions in Fig-\nures 3.29–3.31. They use program variables X, Y , V and W which are sets\nof states. The program for SAT handles the easy cases directly and passes\nmore complicated cases on to special procedures, which in turn might call\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\nto write a procedure SATAU. Can you use that routine to handle all calls of the\nform AF φ as well?\n7. Prove that [[A[φ1 U φ2]]] = [[φ2 ∨(φ1 ∧AX (A[φ1 U φ2]))]].\n8. Prove that [[AG φ]] = [[φ ∧AX (AG φ)]].\n9. Show that the repeat-statements in the code for SATEU and SATEG always termi-\nnate. Use this fact to reason informally that the main program SAT terminates\nfor all valid CTL formulas φ. Note that some subclauses, like the one for AU,\ncall SAT recursively and with a more complex formula. Why does this not aﬀect\ntermination?\n254\n3 Verification by model checking\n3.9 Bibliographic notes\nTemporal logic was invented by the philosopher A. Prior in the 1960s; his\nlogic was similar to what we now call LTL. The ﬁrst use of temporal logic for\nreasoning about concurrent programs was by A. Pnueli [Pnu81]. The logic\nCTL was invented by E. Clarke and E. A. Emerson (during the early 1980s);\nand CTL* was invented by E. A. Emerson and J. Halpern (in 1986) to unify\nCTL and LTL.\nCTL model checking was invented by E. Clarke and E. A. Emerson [CE81]\nand by J. Quielle and J. Sifakis [QS81]. The technique we described for LTL\nmodel checking was invented by M. Vardi and P. Wolper [VW84]. Surveys\nof some of these ideas can be found in [CGL93] and [CGP99]. The theorem\nabout adequate sets of CTL connectives is proved in [Mar01].\nThe original SMV system was written by K. McMillan [McM93] and is\navailable with source code from Carnegie Mellon University6. NuSMV7 is a\nreimplementation, developed in Trento by A. Cimatti, and M. Roveri and is\naimed at being customisable and extensible. Extensive documentation about\nNuSMV can be found at that site. NuSMV supports essentially the same\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely We conclude this case study by pointing out limitations of Alloy and its\nanalyzer. In order to be able to use a SAT solver for propositional logic\nas an analysis engine, we can only check or run formulas of existential or\nuniversal second-order logic in the bodies of assertions or in the bodies of\nfun-statements (if they are wrapped in existential quantiﬁers for all param-\neters). For example, we cannot even check whether there is an instance of\nAddComponent such that for the resulting PDS a certain scheduling policy is\nimpossible. For less explicit reasons it also seems unlikely that we can check\nin Alloy that every coherent set of components is realizable as P.components\nfor some PDS P. This deﬁciency is due to the inherent complexity of such\nproblems and theorem provers may have to be used if such properties need\nto be guaranteed. On the other hand, the expressiveness of Alloy allows for\nthe rapid prototyping of models and the exploration of simulations and pos-\nsible counterexamples which should enhance once understanding of a design\nand so improve that design’s reliability.\n2.8 Exercises\n157\n2.8 Exercises\nExercises 2.1\n1.\n*\nUse the predicates\nA(x, y) :\nx admires y\nB(x, y) :\nx attended y\nP(x) :\nx is a professor\nS(x) :\nx is a student\nL(x) :\nx is a lecture\nand the nullary function symbol (constant)\nm :\nMary\nto translate the following into predicate logic:\n(a) Mary admires every professor.\n(The answer is not ∀x A(m, P(x)).)\n(b) Some professor admires Mary.\n(c) Mary admires herself.\n(d) No student attended every lecture.\n(e) No lecture was attended by every student.\n(f) No lecture was attended by any student.\n2. Use the predicate speciﬁcations\nB(x, y) :\nx beats y\nF(x) :\nx is an (American) football team\nQ(x, y) :\nx is quarterback of y\nL(x, y) :\nx loses to y\nand the constant symbols\nc :\nWildcats\nj :\nJayhawks\nto translate the following into predicate logic.\n(a) Every football team has a quarterback.\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\ntions compute a pre-image of a set of states. The function pre∃(instrumental\nin SATEX and SATEU) takes a subset Y of states and returns the set of states\nwhich can make a transition into Y . The function pre∀, used in SATAF, takes\n228\n3 Verification by model checking\nfunction SATEX (φ)\n/* determines the set of states satisfying EX φ */\nlocal var X, Y\nbegin\nX := SAT (φ);\nY := pre∃(X);\nreturn Y\nend\nFigure 3.29. The function SATEX. It computes the states satisfying φ by\ncalling SAT. Then, it looks backwards along →to find the states satisfying\nEX φ.\nfunction SATAF (φ)\n/* determines the set of states satisfying AF φ */\nlocal var X, Y\nbegin\nX := S;\nY := SAT (φ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪pre∀(Y )\nend\nreturn Y\nend\nFigure 3.30. The function SATAF. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying AF φ in the manner\ndescribed in the labelling algorithm.\na set Y and returns the set of states which make transitions only into Y .\nObserve that pre∀can be expressed in terms of complementation and pre∃,\nas follows:\npre∀(Y ) = S −pre∃(S −Y )\n(3.8)\nwhere we write S −Y for the set of all s ∈S which are not in Y .\nThe correctness of this pseudocode and the model checking algorithm is\ndiscussed in Section 3.7.\n3.6 Model-checking algorithms\n229\nfunction SATEU (φ, ψ)\n/* determines the set of states satisfying E[φ U ψ] */\nlocal var W, X, Y\nbegin\nW := SAT (φ);\nX := S;\nY := SAT (ψ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪(W ∩pre∃(Y ))\nend\nreturn Y\nend\nFigure 3.31. The function SATEU. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying E[φ U ψ] in the manner\ndescribed in the labelling algorithm.\n57\nDeﬁnition 1.44 Given a formula φ in propositional logic, we say that φ is\nsatisﬁable if it has a valuation in which is evaluates to T.\nFor example, the formula p ∨q →p is satisﬁable since it computes T if we\nassign T to p. Clearly, p ∨q →p is not valid. Thus, satisﬁability is a weaker\nconcept since every valid formula is by deﬁnition also satisﬁable but not vice\nversa. However, these two notions are just mirror images of each other, the\nmirror being negation.\nProposition 1.45 Let φ be a formula of propositional logic. Then φ is sat-\nisﬁable iﬀ¬φ is not valid.\nProof: First, assume that φ is satisﬁable. By deﬁnition, there exists a\nvaluation of φ in which φ evaluates to T; but that means that ¬φ evaluates\nto F for that same valuation. Thus, ¬φ cannot be valid.\nSecond, assume that ¬φ is not valid. Then there must be a valuation\nof ¬φ in which ¬φ evaluates to F. Thus, φ evaluates to T and is there-\nfore satisﬁable. (Note that the valuations of φ are exactly the valuations of\n¬φ.)\n2\nThis result is extremely useful since it essentially says that we need provide\na decision procedure for only one of these concepts. For example, let’s say\nthat we have a procedure P for deciding whether any φ is valid. We obtain a\ndecision procedure for satisﬁability simply by asking P whether ¬φ is valid.\nIf it is, φ is not satisﬁable; otherwise φ is satisﬁable. Similarly, we may\ntransform any decision procedure for satisﬁability into one for validity. We\nwill encounter both kinds of procedures in this text.\nThere is one scenario in which computing an equivalent formula in CNF\nis really easy; namely, when someone else has already done the work of\nwriting down a full truth table for φ. For example, take the truth table\nof (p →¬q) →(q ∨¬p) in Figure 1.8 (page 40). For each line where (p →\n¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. Since\nthere is only one such line, we have only one conjunct ψ1. That conjunct\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\ncode in Figure 3.28, we see that most of these clauses just do the obvious\nand correct thing according to the semantics of CTL. For example, try out\nwhat SAT does when you call it with φ1 →φ2.\nOur aim in this section is to prove the termination and correctness\nof SATAF and SATEU. In fact, we will also write a procedure SATEG and\nprove its termination and correctness1. The procedure SATEG is given in\nFigure 3.37 and is based on the intuitions given in Section 3.6.1: note how\ndeleting the label if none of the successor states is labelled is coded as\nintersecting the labelled set with the set of states which have a labelled\nsuccessor.\nThe semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-\nputation path s0 →s1 →s2 →. . . such that si ⊨φ holds for all i ≥0. We\ncould instead express it as follows: EG φ holds if φ holds and EG φ holds\nin one of the successor states to the current state. This suggests the equiv-\nalence EG φ ≡φ ∧EX EG φ which can easily be proved from the semantic\ndeﬁnitions of the connectives.\nObserving that [[EX ψ]] = pre∃([[ψ]]) we see that the equivalence above\ncan be written as [[EG φ]] = [[φ]] ∩pre∃([[EG φ]]). This does not look like a\nvery promising way of calculating EG φ, because we need to know EG φ in\norder to work out the right-hand side. Fortunately, there is a way around\nthis apparent circularity, known as computing ﬁxed points, and that is the\nsubject of this section.\n1 Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted in Section 3.6.1\nthat EG could be handled directly.\n240\n3 Verification by model checking\nfunction SATEG (φ)\n/* determines the set of states satisfying EG φ */\nlocal var X, Y\nbegin\nY := SAT (φ);\nX := ∅;\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∩pre∃(Y )\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver",
                    "summary": "We will execute this marking algorithm on the parse tree of formulas, except that we will translate formulas into the adequate fragment. ‘true’ marks generalize into ‘ true’ and ‘false’ mark. The inductively deﬁned transla-handedly translates T(p) = p to T(¬φ) = ¬T( φ) and vice versa. We then share common subformulas of the resulting parse tree, making the tree into a directed, acyclic graph (DAG) The DAG can be used to test the correctness of a linear solver, such as (1.6.6) For the formula φ being p ∧¬(q ∨¬p) we compute T(�) = p  ¬ (¬q ¬¬ p) The latter ensures that the diagnostics of a SAT solver, applied to T(φ), is meaningful for the original formula. Therefore, φ is satisﬁable iﬀT( φ) is sati﬉able. The formal set of rules for forcing new constraints from old ones is depicted in Figures 1.12 and 1.14. A small circle indicates any node (ª,  ‘or atom’) In Figure 3.28, we see that most of these clauses just do the obvious and correct thing according to the semantics of CTL. The force stabilised clauses are not so obvious to reason about. The aim in this section is to prove the termination and correctness of SATAF and SATEU. In fact, we will also write a procedure SATEG and use it to prove its termination and. correctness1. The procedure is given inFigure 3.37 and is based on the intuitions given in Section 3.6.1: note howdeleting the label if none of the successor states is labelled is coded as. ‘intersecting the labelled set with the set of states which have a labelledsuccess In Section 3.6.1 we show that the equivalence above can be written as [[EG φ] = [[φ]  pre∃([[EG χ]]. This does not look like a very promising way of calculating EG φ, because we need to know EG χ in order to work out the right-hand side. Fortunately, there is a way around this apparent circularity, known as computing ﬁxed points, and that is the subject of this section. We show how this can be done using the function SATEG (φ) which determines the set of states satisfying EG υ. We also show how the function can be used to prove that a state The DAG of T(φ) is depicted in Figure 1.15. Rules for flow of constraints in a formula’s DAG indicate arbitrary nodes. A post-processing phase takes the marks for all                atoms and re-computes marks of all other nodes in a bottom-up manner, as done in Section 1.4 on parse trees. Only if the resulting marks match the                ones we computed have we found a witness. Please verify that this is the case in the comments section of this article. The annotations “1” etc.indicate which nodes represent which sub-formulas. We can apply SAT solvers to checking whether sequents are valid. For example, the sequent The SAT solver can be seen in Figure 1.16. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T(φ)whose DAG equals that of this ﬁgure are not satisﬁable. In particular, all propositions T( φ) whose DAG is less than this DAG are unsatisﬅable. This SAT solaver has a linear running time in the size of the DAG for T(phi) T( Phi) T (T(phi), T (phi, T (t(phi, t(t(t (t ( A cubic solver recursively on subexpressions. The function SATEX. computes the states satisfying φ by calling SAT. This linearity came with a price: our linear solver fails for all formulas of the form ¬( φ1 ∧φ2). Figure 3.29.6. A model checking procedure for the solver SATAF. The model checking procedures for SATAF and SATEU are shown in figure 3.28. The solver SATEF takes the form SATAF (SAT) and SATU (SATEU) and works on the same set of states as SATAF, but with a different formula. The function SATAF. (φ) determines the set of states satisfying AF φ. It computes the states satisfying φ by calling SAT. Then, it looks backwards along →to find the statesatisfying φ in the sequence X, Y, S, Y. Figure 3.30 shows how the function works. The correctness of this pseudocode and the model checking algorithm is discussed in Section 3.7. The function SATEU computes the states satisfying φ by calling it SAT. Then, it accumulates states satisfying AF φ in the manner described in the labelling algorithm. The linear SAT solver does not employ any case analysis. The correctness of the model-checking algorithm is also discussed in section 3.6 of the book. The book is published by Oxford University Press, London, UK, priced £16.99 (US) and £19.99 UK (Europe, UK), with a print run of 1,000,000 copies. For confidential support, call the Samaritans on 08457 90 90 90 The SAT solving technique, as presented in this chapter, can be used to check whether formulas are tautologies. Tag the DAG’s root node with ‘1: T,’ apply the forcing laws to it, and extract a witness to its satisﬁability. Explain in what sense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is not valid. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied to T(φ) – to the marking algorithm – applied. to φ. For φ from (1.10), can one reverse engineer χ from the D AG of T( 9. Consider Figure 1.20 on page 77. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability of T(φ) 10. Consider the similarities and disparities of these approaches. 11. Write a complete implementation of the cubic SATsolver of φ – the translation T causes only a linear blow-up – our SAT Solver has a linear running time in the length of the formula. 12. Discuss similarities and discrepancies between the two approaches. 13. Consider whether the answers to the questions we are trying to answer depend on a particular order in which we test unmarkednodes or use the rules in Figures 1.17 and 1.14. When we applied our linear SAT solver, we saw two possible outcomes. We either detected contradictory constraints, meaning that no formula rep-resented by the DAG is satisﬁable (e.g. Fig. 1.16) or we managed to forceconsistent constraints on all nodes.Unfortunately, there is a third possibility: all forced constraints are consis-                tent with each other, but not all nodes are constrained. We already remarked that this occurs for formulas of the form ¬(φ1    2). We now show that our linear solver fails for all formulas of that form. We conclude that our solver can be used to build a cubic solver. The forcing rules, applied to the DAG of Figure 1.15,detect contradictory constraints at the indicated node. This implies that the initial constraint ‘1:T’ cannot be realized. Thus, formulas represented by this DAG are not satisfiable. Checking validity of formulas in CNF is very easy. We already highlighted that checking satisﬁability of formulas is hard. To demonstrate this, consider the formula (1.11) – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula should not be satis ﬁable. We assume that SAT has access to all the relevant parts of the model: S, →and L. We ignore the fact that SAT would require a description of M as input. This cannot be satisﬁable, and a good SAT solver should discover it. We are interested only in the mechanism in principle of the algorithm for SAT. The function SAT takes a CTL formula as input and returns the set of states satisfying the formula. We simply assume that SAT operates directly on any such given model. Figure 3.28 shows how SAT translates φ into an equivalent formula of the adequate set.3.6 Model-checking algorithms for SAT (φ) and other CTL-like algorithms. The model-checking algorithm for SAT is called SATEX(φ1, φ2) and the algorithm for SATEU( φ1) is known as the SATE algorithm. It is based on the model- checking algorithm for the CTL algorithm, which is called SAT ( φ, SAT). The algorithm is presented in Figure 3.28 and its subfunctions in Fig-                ures 3.29–3.31. It calls the functions                SATEX, SATEU and SATAF, respectively, if EX , EU or AF is the root of the parse tree. The program for SAT handles the easy cases directly and passes the more complicated cases on to special procedures, which in turn might call SAT recursively on subexpressions. These special procedures rely on imple-                mentations of the functions pre, pre and pre-. The code for SATEG always termi-                nate, and the repeat-statements in the code are always correct. Temporal logic was invented by the philosopher A. Prior in the 1960s. CTL* was invented in 1986 to unifyCTL and LTL. The technique we described for LTL is used to verify model checking for CTL. Use this fact to reason informally that the main program SAT terminates for all valid CTL formulas φ. Some subclauses, like the one for AU, call SAT recursively and with a more complex formula. Why does this not aﬀect terminating? Why does SAT not terminate with a complex formula, but not with a simple one? Why is SAT not terminated with a simpler formula? Why isn't SAT terminated with the more complex one? The original SMV system was written by K. McMillan [McM93] and is available with source code from Carnegie Mellon University6. NuSMV7 is a                reimplementation, developed in Trento by A. Cimatti, and M. Roveri and is aimed at being customisable and extensible. We conclude this case study by pointing out limitations of Alloy and its Analyzer analyzer. The theorem about adequate sets of CTL connectives is proved in [Mar01] and can be found at [NuSMV] The Cadence SMV8 is an entirely In order to be able to use a SAT solver for propositional logic as an analysis engine, we can only check or run formulas of existential oruniversal second-order logic. For example, we cannot even check whether there is an instance of AddComponent such that for the resulting PDS a certain scheduling policy is impossible. For less explicit reasons it also seems unlikely that we can check that every coherent set of components is realizable as P.components for some PDS. This deﬁciency is due to the inherent complexity of such problems and theorem provers may have to be used if such properties need to be guaranteed The expressiveness of Alloy allows for rapid prototyping of models and the exploration of simulations. It should enhance once understanding of a design and so improve that design’s reliability. Use the predicates A(x, y) and L(x) to translate the following into predicate logic: Mary admires every professor. Some professor admires Mary. No student attended every lecture. No lecture was attended by any student. The answer is not A(m, P(x).) But it is the answer to the question ‘What is the number of people in the world who attended the most recent lecture?’ And the answer is ‘Mary’. Use the predicate speciﬁcations B(x, y) and F(x) to translate the following into predicate logic. ‘True’ marks generalize into ‘true’ and ‘false’ Marks generalize to subformu-las; and “true” generalizes to “false” marks. We will execute this marking algorithm on the parse tree of formulas, except that we will translate formulas into the adequate fragment p. We then share common subformulas of the resulting parse tree, making the resulting tree into a directed, acyclic graph (DAG) The algorithm can be used to design an algorithm and to prove correctness. The inductively deﬁned transla-tion T(p) = pT(¬φ) = ¬T( φ)transforms formulas generated by (1.3) into formulas. The parse tree and DAG of T( ω) are depicted in Fig-                ure 1.12. The set of valuations for which φ is true equals the set of values for which T(ω) is true. The latter ensures that the diagnostics of a SAT solver, applied to T(phi) is meaningful for the original formula φ. In the exercises, you are asked to prove these claims. For example, in Figure 1.48 we compute T( The formal set of rules for forcing new constraints from old ones is depicted in Figure 1.14. A small circle indicates any node (¬, � or atom) The forcenectives such as →and ¬. are hard to use in practice. Gentzenimproved the situation by inventing the idea of working with assumptions. The linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the U.S. of America. Propositional and predicate logic can be found in the bibliographic remarks at the end of Chapter 2, and in other contemporary books. In the ﬁrst chapter, we developed propositional logic by examining it from three angles: its proof theory, its syntax and its semantics. We begin this second chapter by pointing out the limitations of propo-centric logic with respect to encoding declarative sentences. What can we do with modiﬁers like not, and, or                and if . . . then, then, and so on? And how can we create a richer language for these modi-propositional-logic terms? We conclude this chapter by asking: What do we want to say in a language that is richer than propositional-proprietary-logics? In propositional logic, we could identify this assertion with a propositionalSAT recursively on subexpressions. The desire to express more subtle declarative sentences led to the design of predicate logic, which is also called ﬁrst-order logic. The function pre∃(Y) takes a subset Y of states and returns the set of states which can make a transition into Y. Pre’ denotes travelling backwards along the transition relation. Both func-                tions compute a pre-image of a set ofStates. The ‘pre’ part of the function is used to denote a transition from one state to the next. function SATEX determines the set of states satisfying EX φ. The function SATAF computes the states satisfying φ by looking backwards along the line. The pre∀, used in SATAF, takes the number of states and is called pre∃. Verification by model checking can be carried out by using the model checker. The model checkers can be used to test the correctness of the model. For example, the model can be checked by checking whether the state is a positive or negative positive. For more information on the model checking technique, see: http://www.f The correctness of this pseudocode and the model checking algorithm is discussed in Section 3.7. The function SATEU computes the states satisfying φ by calling SAT. Then, it accumulates states satisfying AF φ in the manner described in the labelling algorithm. The model-checking algorithm can be expressed in terms of complementation and pre∃, as follows: pre∀(Y ) = S −pre∃(S −Y ) (3.8) (2.4) (1) ( 2) (3) ( 3) (4) 4) (5) (6) (7) (9) (10) (11) (12) (13) (14 Given a formula φ in propositional logic, we say that φ is                satisﬁable if it has a valuation in which is evaluates to T. For example, the formula p ∨q →p is satis﬋able since it computes T if we assigning T to p. However, this is a weaker concept since every valid formula is by de ﬁnition also satis ﬉able but not vice versa. The two notions are just mirror images of each other, the mirror being negation. The proof is given in the next section of the book. The book is published by Oxford University Press, London, UK, priced £16.99. We obtain a decision procedure for satisﬁability simply by asking P whether ¬φ is valid. If it is not, φ is not satis ﬁable; otherwise, it is. We may transform any decision procedure into one for validity. For each line where (p →¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. The result is extremely useful since it essentially says that we need provide only one procedure for each of these concepts. We will encounter both kinds of procedures in this text. For example, take the truth table autoimmuneof (p ) in Figure 1.8 (page 40) In Figure 3.28, we see that most of these clauses just do the obvious and correct thing according to the semantics of CTL. Since there is only one such line, we have only one conjunct ψ1. That conjuncts are not so obvious to reason about. The topic of this section is todevelop the semantic insights into these operators that allow us to provide acomplete proof for their termination and correctness. In fact, we will also write a procedure SATEG and SATEU to prove its termination and. correctness1. The procedure SATEG is given in Figure 3.37 and is based on the intuitions given in Section 3.6.1. The semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-putation path s0 →s1 →s2 →. . . such that si ≹ holds for all i ≥0. We could instead express it as follows: EG υ holds if φ hold and EG ω holds if the state is in one of the successor states to the current state. The equivalence above can be written as [[EG υ] = pre∃ [[EG ω]]. Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted that EG could be handled directly. Fortunately, there is a way around this apparent circularity, known as computing ﬁxed points, and that is the subject of this section. Section 3. 6.3 Verification by model checking is the final section of the book. The book is published by Oxford University Press. This foreword is re-printed in the second edition with its author’s permis-                sion. We developed this theme for propositional, temporal, modal, and program logics. At the heart of this set-up is that one can often specify and implement algorithms for computing. I recommend it to the reader                with greatest enthusiasm and predict that the book will be an enormous                success. The book is published by Oxford University Press, London, priced £16.99. For more information on the book, visit the publisher's website or visit the book's website at: http://www.oxford-uk.com/books/computer-science- The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. We can apply SAT solvers to checking whether sequents are valid. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc.indicate which nodes represent which sub-formulas. A post-processing phase takes the marks for all grotesqueatoms and re-computes marks of all other nodes in a bottom-up manner, as done in Section 1.4 on parse trees. Only if the resulting marks match the ones we computed have we found a witness. It now begins with a discus-                Figure 1.14. Rules for flow of constraints in a formula’s DAG. Small Carbunclecircles indicate arbitrary nodes (¬ The SAT solver can be seen in Figure 1.16. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T(φ)whose DAG equals that of this ﬁgure are not satisﬁable. In particular, all propositions T( φ) whose DAG is less than this DAG are unsatisﬅable. This SAT solaver has a linear running time in the size of the DAG for T(phi) T( Phi) T (T(phi), T (phi, T (t(phi, t(t(t (t ( 6.2 A cubic solver. This linearity came with a price: our linear sol",
                    "children": [
                        {
                            "id": "chapter-3-section-7-subsection-1",
                            "title": "Monotone Functions",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-7-subsection-2",
                            "title": "The Correctness of SATEG",
                            "content": "for all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\ncode in Figure 3.28, we see that most of these clauses just do the obvious\nand correct thing according to the semantics of CTL. For example, try out\nwhat SAT does when you call it with φ1 →φ2.\nOur aim in this section is to prove the termination and correctness\nof SATAF and SATEU. In fact, we will also write a procedure SATEG and\nprove its termination and correctness1. The procedure SATEG is given in\nFigure 3.37 and is based on the intuitions given in Section 3.6.1: note how\ndeleting the label if none of the successor states is labelled is coded as\nintersecting the labelled set with the set of states which have a labelled\nsuccessor.\nThe semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-\nputation path s0 →s1 →s2 →. . . such that si ⊨φ holds for all i ≥0. We\ncould instead express it as follows: EG φ holds if φ holds and EG φ holds\nin one of the successor states to the current state. This suggests the equiv-\nalence EG φ ≡φ ∧EX EG φ which can easily be proved from the semantic\ndeﬁnitions of the connectives.\nObserving that [[EX ψ]] = pre∃([[ψ]]) we see that the equivalence above\ncan be written as [[EG φ]] = [[φ]] ∩pre∃([[EG φ]]). This does not look like a\nvery promising way of calculating EG φ, because we need to know EG φ in\norder to work out the right-hand side. Fortunately, there is a way around\nthis apparent circularity, known as computing ﬁxed points, and that is the\nsubject of this section.\n1 Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted in Section 3.6.1\nthat EG could be handled directly.\n240\n3 Verification by model checking\nfunction SATEG (φ)\n/* determines the set of states satisfying EG φ */\nlocal var X, Y\nbegin\nY := SAT (φ);\nX := ∅;\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∩pre∃(Y )\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\ntions compute a pre-image of a set of states. The function pre∃(instrumental\nin SATEX and SATEU) takes a subset Y of states and returns the set of states\nwhich can make a transition into Y . The function pre∀, used in SATAF, takes\n228\n3 Verification by model checking\nfunction SATEX (φ)\n/* determines the set of states satisfying EX φ */\nlocal var X, Y\nbegin\nX := SAT (φ);\nY := pre∃(X);\nreturn Y\nend\nFigure 3.29. The function SATEX. It computes the states satisfying φ by\ncalling SAT. Then, it looks backwards along →to find the states satisfying\nEX φ.\nfunction SATAF (φ)\n/* determines the set of states satisfying AF φ */\nlocal var X, Y\nbegin\nX := S;\nY := SAT (φ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪pre∀(Y )\nend\nreturn Y\nend\nFigure 3.30. The function SATAF. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying AF φ in the manner\ndescribed in the labelling algorithm.\na set Y and returns the set of states which make transitions only into Y .\nObserve that pre∀can be expressed in terms of complementation and pre∃,\nas follows:\npre∀(Y ) = S −pre∃(S −Y )\n(3.8)\nwhere we write S −Y for the set of all s ∈S which are not in Y .\nThe correctness of this pseudocode and the model checking algorithm is\ndiscussed in Section 3.7.\n3.6 Model-checking algorithms\n229\nfunction SATEU (φ, ψ)\n/* determines the set of states satisfying E[φ U ψ] */\nlocal var W, X, Y\nbegin\nW := SAT (φ);\nX := S;\nY := SAT (ψ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪(W ∩pre∃(Y ))\nend\nreturn Y\nend\nFigure 3.31. The function SATEU. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying E[φ U ψ] in the manner\ndescribed in the labelling algorithm.\nof the proof rule LEM; and the linear SAT solver does not employ any case\nanalysis.)\n4.\n*\nConsider the sequent p ∨q, p →r ⊢r. Determine a DAG which is not satisﬁable\niﬀthis sequent is valid. Tag the DAG’s root node with ‘1: T,’ apply the forcing\nlaws to it, and extract a witness to the DAG’s satisﬁability. Explain in what\nsense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is\nnot valid.\n5. Explain in what sense the SAT solving technique, as presented in this chapter,\ncan be used to check whether formulas are tautologies.\n6. For φ from (1.10), can one reverse engineer φ from the DAG of T(φ)?\n7. Consider a modiﬁcation of our method which initially tags a DAG’s root node\nwith ‘1: F.’ In that case,\n(a) are the forcing laws still sound? If so, state the invariant.\n(b) what can we say about the formula(s) a DAG represents if\ni. we detect contradictory constraints?\nii. we compute consistent forced constraints for each node?\n8. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied\nto T(φ) –\nto the marking algorithm – applied to φ. Discuss similarities and\ndiﬀerences of these approaches.\n1.8 Bibliographic notes\n91\n9. Consider Figure 1.20 on page 77. Verify that\n(a) its test produces contradictory constraints\n(b) its cubic analysis does not decide satisﬁability, regardless of whether the\ntwo optimizations we described are present.\n10. Verify that the DAG of Figure 1.17 (page 74) is indeed the one obtained for\nT(φ), where φ is the formula in (1.11) on page 73.\n11.\n*\nAn implementor may be concerned with the possibility that the answers to the\ncubic SAT solver may depend on a particular order in which we test unmarked\nnodes or use the rules in Figure 1.14. Give a semi-formal argument for why the\nanalysis results don’t depend on such an order.\n12. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability\nof T(φ).\n13. Advanced Project: Write a complete implementation of the cubic SAT solver\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver\nWhen we applied our linear SAT solver, we saw two possible outcomes:\nwe either detected contradictory constraints, meaning that no formula rep-\nresented by the DAG is satisﬁable (e.g. Fig. 1.16); or we managed to force\nconsistent constraints on all nodes, in which case all formulas represented by\nthis DAG are satisﬁable with those constraints as a witness (e.g. Fig. 1.13).\nUnfortunately, there is a third possibility: all forced constraints are consis-\ntent with each other, but not all nodes are constrained! We already remarked\nthat this occurs for formulas of the form ¬(φ1 ∧φ2).\n1.6 SAT solvers\n73\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n1: T\n2: F\n3: T\n4: T\n4: T\n5: F\n6: T\n5: F\n7: T\n8: F\n9: T\n11: F\n10: T\n10: T\n7: T\nits conjunction parent\n– a contradiction\nand ∧frr force F\nits children and\n∧ti force T\nFigure 1.16. The forcing rules, applied to the DAG of Figure 1.15,\ndetect contradictory constraints at the indicated node – implying that\nthe initial constraint ‘1:T’ cannot be realized. Thus, formulas represented\nby this DAG are not satisfiable.\nRecall that checking validity of formulas in CNF is very easy. We already\nhinted at the fact that checking satisﬁability of formulas in CNF is hard. To\nillustrate, consider the formula\n((p ∨(q ∨r)) ∧((p ∨¬q) ∧((q ∨¬r) ∧((r ∨¬p) ∧(¬p ∨(¬q ∨¬r))))))\n(1.11)\nin CNF – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula\nshould not be satisﬁable. The ﬁrst and last clause in (1.11) ‘say’ that at least\none of p, q, and r are false and true (respectively). The remaining three\nclauses, in their conjunction, ‘say’ that p, q, and r all have the same truth\nvalue. This cannot be satisﬁable, and a good SAT solver should discover\nnow we are interested only in the mechanism in principle of the algorithm\nfor SAT; any (correct and eﬃcient) implementation of sets would do and\nwe study such an implementation in Chapter 6. We assume that SAT has\naccess to all the relevant parts of the model: S, →and L. In particular,\nwe ignore the fact that SAT would require a description of M as input as\nwell. We simply assume that SAT operates directly on any such given model.\nNote how SAT translates φ into an equivalent formula of the adequate set\nchosen.\n3.6 Model-checking algorithms\n227\nfunction SAT (φ)\n/* determines the set of states satisfying φ */\nbegin\ncase\nφ is ⊤: return S\nφ is ⊥: return ∅\nφ is atomic: return {s ∈S | φ ∈L(s)}\nφ is ¬φ1 : return S −SAT (φ1)\nφ is φ1 ∧φ2 : return SAT (φ1) ∩SAT (φ2)\nφ is φ1 ∨φ2 : return SAT (φ1) ∪SAT (φ2)\nφ is φ1 →φ2 : return SAT (¬φ1 ∨φ2)\nφ is AX φ1 : return SAT (¬EX ¬φ1)\nφ is EX φ1 : return SATEX(φ1)\nφ is A[φ1 U φ2] : return SAT(¬(E[¬φ2 U (¬φ1 ∧¬φ2)] ∨EG ¬φ2))\nφ is E[φ1 U φ2] : return SATEU(φ1, φ2)\nφ is EF φ1 : return SAT (E(⊤U φ1))\nφ is EG φ1 : return SAT(¬AF ¬φ1)\nφ is AF φ1 : return SATAF (φ1)\nφ is AG φ1 : return SAT (¬EF ¬φ1)\nend case\nend function\nFigure 3.28. The function SAT. It takes a CTL formula as input and\nreturns the set of states satisfying the formula. It calls the functions\nSATEX, SATEU and SATAF, respectively, if EX , EU or AF is the root of the\ninput’s parse tree.\nThe algorithm is presented in Figure 3.28 and its subfunctions in Fig-\nures 3.29–3.31. They use program variables X, Y , V and W which are sets\nof states. The program for SAT handles the easy cases directly and passes\nmore complicated cases on to special procedures, which in turn might call\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\nto write a procedure SATAU. Can you use that routine to handle all calls of the\nform AF φ as well?\n7. Prove that [[A[φ1 U φ2]]] = [[φ2 ∨(φ1 ∧AX (A[φ1 U φ2]))]].\n8. Prove that [[AG φ]] = [[φ ∧AX (AG φ)]].\n9. Show that the repeat-statements in the code for SATEU and SATEG always termi-\nnate. Use this fact to reason informally that the main program SAT terminates\nfor all valid CTL formulas φ. Note that some subclauses, like the one for AU,\ncall SAT recursively and with a more complex formula. Why does this not aﬀect\ntermination?\n254\n3 Verification by model checking\n3.9 Bibliographic notes\nTemporal logic was invented by the philosopher A. Prior in the 1960s; his\nlogic was similar to what we now call LTL. The ﬁrst use of temporal logic for\nreasoning about concurrent programs was by A. Pnueli [Pnu81]. The logic\nCTL was invented by E. Clarke and E. A. Emerson (during the early 1980s);\nand CTL* was invented by E. A. Emerson and J. Halpern (in 1986) to unify\nCTL and LTL.\nCTL model checking was invented by E. Clarke and E. A. Emerson [CE81]\nand by J. Quielle and J. Sifakis [QS81]. The technique we described for LTL\nmodel checking was invented by M. Vardi and P. Wolper [VW84]. Surveys\nof some of these ideas can be found in [CGL93] and [CGP99]. The theorem\nabout adequate sets of CTL connectives is proved in [Mar01].\nThe original SMV system was written by K. McMillan [McM93] and is\navailable with source code from Carnegie Mellon University6. NuSMV7 is a\nreimplementation, developed in Trento by A. Cimatti, and M. Roveri and is\naimed at being customisable and extensible. Extensive documentation about\nNuSMV can be found at that site. NuSMV supports essentially the same\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely",
                            "summary": "We will execute this marking algorithm on the parse tree of formulas, except that we will translate formulas into the adequate fragment. ‘true’ marks generalize into ‘ true’ and ‘false’ mark. The inductively deﬁned transla-handedly translates T(p) = p to T(¬φ) = ¬T( φ) and vice versa. We then share common subformulas of the resulting parse tree, making the tree into a directed, acyclic graph (DAG) The DAG can be used to test the correctness of a linear solver, such as (1.6.6) For the formula φ being p ∧¬(q ∨¬p) we compute T(�) = p  ¬ (¬q ¬¬ p) The latter ensures that the diagnostics of a SAT solver, applied to T(φ), is meaningful for the original formula. Therefore, φ is satisﬁable iﬀT( φ) is sati﬉able. The formal set of rules for forcing new constraints from old ones is depicted in Figures 1.12 and 1.14. A small circle indicates any node (ª,  ‘or atom’) In Figure 3.28, we see that most of these clauses just do the obvious and correct thing according to the semantics of CTL. The force stabilised clauses are not so obvious to reason about. The aim in this section is to prove the termination and correctness of SATAF and SATEU. In fact, we will also write a procedure SATEG and use it to prove its termination and. correctness1. The procedure is given inFigure 3.37 and is based on the intuitions given in Section 3.6.1: note howdeleting the label if none of the successor states is labelled is coded as. ‘intersecting the labelled set with the set of states which have a labelledsuccess In Section 3.6.1 we show that the equivalence above can be written as [[EG φ] = [[φ]  pre∃([[EG χ]]. This does not look like a very promising way of calculating EG φ, because we need to know EG χ in order to work out the right-hand side. Fortunately, there is a way around this apparent circularity, known as computing ﬁxed points, and that is the subject of this section. We show how this can be done using the function SATEG (φ) which determines the set of states satisfying EG υ. We also show how the function can be used to prove that a state The DAG of T(φ) is depicted in Figure 1.15. Rules for flow of constraints in a formula’s DAG indicate arbitrary nodes. A post-processing phase takes the marks for all                atoms and re-computes marks of all other nodes in a bottom-up manner, as done in Section 1.4 on parse trees. Only if the resulting marks match the                ones we computed have we found a witness. Please verify that this is the case in the comments section of this article. The annotations “1” etc.indicate which nodes represent which sub-formulas. We can apply SAT solvers to checking whether sequents are valid. For example, the sequent The SAT solver can be seen in Figure 1.16. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T(φ)whose DAG equals that of this ﬁgure are not satisﬁable. In particular, all propositions T( φ) whose DAG is less than this DAG are unsatisﬅable. This SAT solaver has a linear running time in the size of the DAG for T(phi) T( Phi) T (T(phi), T (phi, T (t(phi, t(t(t (t ( A cubic solver recursively on subexpressions. The function SATEX. computes the states satisfying φ by calling SAT. This linearity came with a price: our linear solver fails for all formulas of the form ¬( φ1 ∧φ2). Figure 3.29.6. A model checking procedure for the solver SATAF. The model checking procedures for SATAF and SATEU are shown in figure 3.28. The solver SATEF takes the form SATAF (SAT) and SATU (SATEU) and works on the same set of states as SATAF, but with a different formula. The function SATAF. (φ) determines the set of states satisfying AF φ. It computes the states satisfying φ by calling SAT. Then, it looks backwards along →to find the statesatisfying φ in the sequence X, Y, S, Y. Figure 3.30 shows how the function works. The correctness of this pseudocode and the model checking algorithm is discussed in Section 3.7. The function SATEU computes the states satisfying φ by calling it SAT. Then, it accumulates states satisfying AF φ in the manner described in the labelling algorithm. The linear SAT solver does not employ any case analysis. The correctness of the model-checking algorithm is also discussed in section 3.6 of the book. The book is published by Oxford University Press, London, UK, priced £16.99 (US) and £19.99 UK (Europe, UK), with a print run of 1,000,000 copies. For confidential support, call the Samaritans on 08457 90 90 90 The SAT solving technique, as presented in this chapter, can be used to check whether formulas are tautologies. Tag the DAG’s root node with ‘1: T,’ apply the forcing laws to it, and extract a witness to its satisﬁability. Explain in what sense this witness serves as an explanation for the fact that p ∨q, p →r ⊢r is not valid. Given an arbitrary Horn formula φ, compare our linear SAT solver – applied to T(φ) – to the marking algorithm – applied. to φ. For φ from (1.10), can one reverse engineer χ from the D AG of T( 9. Consider Figure 1.20 on page 77. Find a formula φ such that our cubic SAT solver cannot decide the satisﬁability of T(φ) 10. Consider the similarities and disparities of these approaches. 11. Write a complete implementation of the cubic SATsolver of φ – the translation T causes only a linear blow-up – our SAT Solver has a linear running time in the length of the formula. 12. Discuss similarities and discrepancies between the two approaches. 13. Consider whether the answers to the questions we are trying to answer depend on a particular order in which we test unmarkednodes or use the rules in Figures 1.17 and 1.14. When we applied our linear SAT solver, we saw two possible outcomes. We either detected contradictory constraints, meaning that no formula rep-resented by the DAG is satisﬁable (e.g. Fig. 1.16) or we managed to forceconsistent constraints on all nodes.Unfortunately, there is a third possibility: all forced constraints are consis-                tent with each other, but not all nodes are constrained. We already remarked that this occurs for formulas of the form ¬(φ1    2). We now show that our linear solver fails for all formulas of that form. We conclude that our solver can be used to build a cubic solver. The forcing rules, applied to the DAG of Figure 1.15,detect contradictory constraints at the indicated node. This implies that the initial constraint ‘1:T’ cannot be realized. Thus, formulas represented by this DAG are not satisfiable. Checking validity of formulas in CNF is very easy. We already highlighted that checking satisﬁability of formulas is hard. To demonstrate this, consider the formula (1.11) – based on Example 4.2, page 77, in [Pap94]. Intuitively, this formula should not be satis ﬁable. We assume that SAT has access to all the relevant parts of the model: S, →and L. We ignore the fact that SAT would require a description of M as input. This cannot be satisﬁable, and a good SAT solver should discover it. We are interested only in the mechanism in principle of the algorithm for SAT. The function SAT takes a CTL formula as input and returns the set of states satisfying the formula. We simply assume that SAT operates directly on any such given model. Figure 3.28 shows how SAT translates φ into an equivalent formula of the adequate set.3.6 Model-checking algorithms for SAT (φ) and other CTL-like algorithms. The model-checking algorithm for SAT is called SATEX(φ1, φ2) and the algorithm for SATEU( φ1) is known as the SATE algorithm. It is based on the model- checking algorithm for the CTL algorithm, which is called SAT ( φ, SAT). The algorithm is presented in Figure 3.28 and its subfunctions in Fig-                ures 3.29–3.31. It calls the functions                SATEX, SATEU and SATAF, respectively, if EX , EU or AF is the root of the parse tree. The program for SAT handles the easy cases directly and passes the more complicated cases on to special procedures, which in turn might call SAT recursively on subexpressions. These special procedures rely on imple-                mentations of the functions pre, pre and pre-. The code for SATEG always termi-                nate, and the repeat-statements in the code are always correct. Temporal logic was invented by the philosopher A. Prior in the 1960s. CTL* was invented in 1986 to unifyCTL and LTL. The technique we described for LTL is used to verify model checking for CTL. Use this fact to reason informally that the main program SAT terminates for all valid CTL formulas φ. Some subclauses, like the one for AU, call SAT recursively and with a more complex formula. Why does this not aﬀect terminating? Why does SAT not terminate with a complex formula, but not with a simple one? Why is SAT not terminated with a simpler formula? Why isn't SAT terminated with the more complex one? The original SMV system was written by K. McMillan [McM93] and is available with source code from Carnegie Mellon University6. NuSMV7 is a                reimplementation, developed in Trento by A. Cimatti, and M. Roveri and is aimed at being customisable and extensible. The theorem about adequate sets of CTL connectives is proved in [Mar01] and can be found at that site. Cadence SMV8 is an entirely. entirely. different system.",
                            "children": []
                        },
                        {
                            "id": "chapter-3-section-7-subsection-3",
                            "title": "The Correctness of SATEU",
                            "content": "We conclude this case study by pointing out limitations of Alloy and its\nanalyzer. In order to be able to use a SAT solver for propositional logic\nas an analysis engine, we can only check or run formulas of existential or\nuniversal second-order logic in the bodies of assertions or in the bodies of\nfun-statements (if they are wrapped in existential quantiﬁers for all param-\neters). For example, we cannot even check whether there is an instance of\nAddComponent such that for the resulting PDS a certain scheduling policy is\nimpossible. For less explicit reasons it also seems unlikely that we can check\nin Alloy that every coherent set of components is realizable as P.components\nfor some PDS P. This deﬁciency is due to the inherent complexity of such\nproblems and theorem provers may have to be used if such properties need\nto be guaranteed. On the other hand, the expressiveness of Alloy allows for\nthe rapid prototyping of models and the exploration of simulations and pos-\nsible counterexamples which should enhance once understanding of a design\nand so improve that design’s reliability.\n2.8 Exercises\n157\n2.8 Exercises\nExercises 2.1\n1.\n*\nUse the predicates\nA(x, y) :\nx admires y\nB(x, y) :\nx attended y\nP(x) :\nx is a professor\nS(x) :\nx is a student\nL(x) :\nx is a lecture\nand the nullary function symbol (constant)\nm :\nMary\nto translate the following into predicate logic:\n(a) Mary admires every professor.\n(The answer is not ∀x A(m, P(x)).)\n(b) Some professor admires Mary.\n(c) Mary admires herself.\n(d) No student attended every lecture.\n(e) No lecture was attended by every student.\n(f) No lecture was attended by any student.\n2. Use the predicate speciﬁcations\nB(x, y) :\nx beats y\nF(x) :\nx is an (American) football team\nQ(x, y) :\nx is quarterback of y\nL(x, y) :\nx loses to y\nand the constant symbols\nc :\nWildcats\nj :\nJayhawks\nto translate the following into predicate logic.\n(a) Every football team has a quarterback.\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional\nSAT recursively on subexpressions. These special procedures rely on imple-\nmentations of the functions\npre∃(Y ) = {s ∈S | exists s′, (s →s′ and s′ ∈Y )}\npre∀(Y ) = {s ∈S | for all s′, (s →s′ implies s′ ∈Y )}.\n‘Pre’ denotes travelling backwards along the transition relation. Both func-\ntions compute a pre-image of a set of states. The function pre∃(instrumental\nin SATEX and SATEU) takes a subset Y of states and returns the set of states\nwhich can make a transition into Y . The function pre∀, used in SATAF, takes\n228\n3 Verification by model checking\nfunction SATEX (φ)\n/* determines the set of states satisfying EX φ */\nlocal var X, Y\nbegin\nX := SAT (φ);\nY := pre∃(X);\nreturn Y\nend\nFigure 3.29. The function SATEX. It computes the states satisfying φ by\ncalling SAT. Then, it looks backwards along →to find the states satisfying\nEX φ.\nfunction SATAF (φ)\n/* determines the set of states satisfying AF φ */\nlocal var X, Y\nbegin\nX := S;\nY := SAT (φ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪pre∀(Y )\nend\nreturn Y\nend\nFigure 3.30. The function SATAF. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying AF φ in the manner\ndescribed in the labelling algorithm.\na set Y and returns the set of states which make transitions only into Y .\nObserve that pre∀can be expressed in terms of complementation and pre∃,\nas follows:\npre∀(Y ) = S −pre∃(S −Y )\n(3.8)\nwhere we write S −Y for the set of all s ∈S which are not in Y .\nThe correctness of this pseudocode and the model checking algorithm is\ndiscussed in Section 3.7.\n3.6 Model-checking algorithms\n229\nfunction SATEU (φ, ψ)\n/* determines the set of states satisfying E[φ U ψ] */\nlocal var W, X, Y\nbegin\nW := SAT (φ);\nX := S;\nY := SAT (ψ);\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∪(W ∩pre∃(Y ))\nend\nreturn Y\nend\nFigure 3.31. The function SATEU. It computes the states satisfying φ by\ncalling SAT. Then, it accumulates states satisfying E[φ U ψ] in the manner\ndescribed in the labelling algorithm.\n57\nDeﬁnition 1.44 Given a formula φ in propositional logic, we say that φ is\nsatisﬁable if it has a valuation in which is evaluates to T.\nFor example, the formula p ∨q →p is satisﬁable since it computes T if we\nassign T to p. Clearly, p ∨q →p is not valid. Thus, satisﬁability is a weaker\nconcept since every valid formula is by deﬁnition also satisﬁable but not vice\nversa. However, these two notions are just mirror images of each other, the\nmirror being negation.\nProposition 1.45 Let φ be a formula of propositional logic. Then φ is sat-\nisﬁable iﬀ¬φ is not valid.\nProof: First, assume that φ is satisﬁable. By deﬁnition, there exists a\nvaluation of φ in which φ evaluates to T; but that means that ¬φ evaluates\nto F for that same valuation. Thus, ¬φ cannot be valid.\nSecond, assume that ¬φ is not valid. Then there must be a valuation\nof ¬φ in which ¬φ evaluates to F. Thus, φ evaluates to T and is there-\nfore satisﬁable. (Note that the valuations of φ are exactly the valuations of\n¬φ.)\n2\nThis result is extremely useful since it essentially says that we need provide\na decision procedure for only one of these concepts. For example, let’s say\nthat we have a procedure P for deciding whether any φ is valid. We obtain a\ndecision procedure for satisﬁability simply by asking P whether ¬φ is valid.\nIf it is, φ is not satisﬁable; otherwise φ is satisﬁable. Similarly, we may\ntransform any decision procedure for satisﬁability into one for validity. We\nwill encounter both kinds of procedures in this text.\nThere is one scenario in which computing an equivalent formula in CNF\nis really easy; namely, when someone else has already done the work of\nwriting down a full truth table for φ. For example, take the truth table\nof (p →¬q) →(q ∨¬p) in Figure 1.8 (page 40). For each line where (p →\n¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. Since\nthere is only one such line, we have only one conjunct ψ1. That conjunct\nstabilised) are not so obvious to reason about. The topic of this section is to\ndevelop the semantic insights into these operators that allow us to provide a\ncomplete proof for their termination and correctness. Inspecting the pseudo-\ncode in Figure 3.28, we see that most of these clauses just do the obvious\nand correct thing according to the semantics of CTL. For example, try out\nwhat SAT does when you call it with φ1 →φ2.\nOur aim in this section is to prove the termination and correctness\nof SATAF and SATEU. In fact, we will also write a procedure SATEG and\nprove its termination and correctness1. The procedure SATEG is given in\nFigure 3.37 and is based on the intuitions given in Section 3.6.1: note how\ndeleting the label if none of the successor states is labelled is coded as\nintersecting the labelled set with the set of states which have a labelled\nsuccessor.\nThe semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-\nputation path s0 →s1 →s2 →. . . such that si ⊨φ holds for all i ≥0. We\ncould instead express it as follows: EG φ holds if φ holds and EG φ holds\nin one of the successor states to the current state. This suggests the equiv-\nalence EG φ ≡φ ∧EX EG φ which can easily be proved from the semantic\ndeﬁnitions of the connectives.\nObserving that [[EX ψ]] = pre∃([[ψ]]) we see that the equivalence above\ncan be written as [[EG φ]] = [[φ]] ∩pre∃([[EG φ]]). This does not look like a\nvery promising way of calculating EG φ, because we need to know EG φ in\norder to work out the right-hand side. Fortunately, there is a way around\nthis apparent circularity, known as computing ﬁxed points, and that is the\nsubject of this section.\n1 Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted in Section 3.6.1\nthat EG could be handled directly.\n240\n3 Verification by model checking\nfunction SATEG (φ)\n/* determines the set of states satisfying EG φ */\nlocal var X, Y\nbegin\nY := SAT (φ);\nX := ∅;\nrepeat until X = Y\nbegin\nX := Y ;\nY := Y ∩pre∃(Y )\non logic for computer science should be like. I recommend it to the reader\nwith greatest enthusiasm and predict that the book will be an enormous\nsuccess.\n(This foreword is re-printed in the second edition with its author’s permis-\nsion.)\nPreface to the second edition\nOur motivation for (re)writing this book\nOne of the leitmotifs of writing the ﬁrst edition of our book was the obser-\nvation that most logics used in the design, speciﬁcation and veriﬁcation of\ncomputer systems fundamentally deal with a satisfaction relation\nM ⊨φ\nwhere M is some sort of situation or model of a system, and φ is a speciﬁ-\ncation, a formula of that logic, expressing what should be true in situation\nM. At the heart of this set-up is that one can often specify and implement\nalgorithms for computing ⊨. We developed this theme for propositional,\nﬁrst-order, temporal, modal, and program logics. Based on the encourag-\ning feedback received from ﬁve continents we are pleased to hereby present\nthe second edition of this text which means to preserve and improve on the\noriginal intent of the ﬁrst edition.\nWhat’s new and what’s gone\nChapter 1 now discusses the design, correctness, and complexity of a SAT\nsolver (a marking algorithm similar to St˚almarck’s method [SS90]) for full\npropositional logic.\nChapter 2 now contains basic results from model theory (Compactness\nTheorem and L¨owenheim–Skolem Theorem); a section on the transitive clo-\nsure and the expressiveness of existential and universal second-order logic;\nand a section on the use of the object modelling language Alloy and its anal-\nyser for specifying and exploring under-speciﬁed ﬁrst-order logic models with\nrespect to properties written in ﬁrst-order logic with transitive closure. The\nAlloy language is executable which makes such exploration interactive and\nformal.\nxi\nxii\nPreface to the second edition\nChapter 3 has been completely restructured. It now begins with a discus-\nFigure 1.14. Rules for flow of constraints in a formula’s DAG. Small\ncircles indicate arbitrary nodes (¬, ∧or atom). Note that the rules ∧ﬂl,\n∧frr and ∧ti require that the source constraints of both =⇒are present.\nrepresented by this DAG. A post-processing phase takes the marks for all\natoms and re-computes marks of all other nodes in a bottom-up manner, as\ndone in Section 1.4 on parse trees. Only if the resulting marks match the\nones we computed have we found a witness. Please verify that this is the\ncase in Figure 1.13.\nWe can apply SAT solvers to checking whether sequents are valid. For\nexample, the sequent p ∧q →r ⊢p →q →r is valid iﬀ(p ∧q →r) →p →\nq →r is a theorem (why?) iﬀφ = ¬((p ∧q →r) →p →q →r) is not satis-\nﬁable. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc\nindicate which nodes represent which sub-formulas. Notice that such DAGs\nmay be constructed by applying the translation clauses for T to sub-formulas\nin a bottom-up manner – sharing equal subgraphs were applicable.\nThe ﬁndings of our SAT solver can be seen in Figure 1.16. The solver\nconcludes that the indicated node requires the marks T and F for (1.9) to be\nmet. Such contradictory constraints therefore imply that all formulas T(φ)\nwhose DAG equals that of this ﬁgure are not satisﬁable. In particular, all\n72\n1 Propositional logic\np\nq\nr\n¬\n∧\n∧\n∧\n¬\n¬\n¬\n∧\n¬\n¬\n∧\n¬\n¬\n= ”3” →”2”\n“5” = entire formula\n“4”\n“3” = p ∧q →r\n“2” = p →”1”\n“1” = q →r\n“2”\n“3”\n“1”\n“4”\n“5”\nFigure 1.15. The DAG for the translation of ¬((p ∧q →r) →p →q →\nr). Labels ‘‘1’’ etc indicate which nodes represent what subformulas.\nsuch φ are unsatisﬁable. This SAT solver has a linear running time in the\nsize of the DAG for T(φ). Since that size is a linear function of the length\nof φ – the translation T causes only a linear blow-up – our SAT solver has\na linear running time in the length of the formula. This linearity came with\na price: our linear solver fails for all formulas of the form ¬(φ1 ∧φ2).\n1.6.2 A cubic solver",
                            "summary": "We conclude this case study by pointing out limitations of Alloy and itsanalyzer. In order to be able to use a SAT solver for propositional logic as an analysis engine, we can only check or run formulas of existential oruniversal second-order logic. For example, we cannot even check whether there is an instance of AddComponent such that for the resulting PDS a certain scheduling policy is impossible. For less explicit reasons it also seems unlikely that we can check in Alloy that every coherent set of components is realizable as P.components for some PDS. This deﬁciency is due to the inherent complexity of such problems and theorem provers. The expressiveness of Alloy allows for rapid prototyping of models and the exploration of simulations. It should enhance once understanding of a design and so improve that design’s reliability. Use the predicates A(x, y) and L(x) to translate the following into predicate logic: Mary admires every professor. Some professor admires Mary. No student attended every lecture. No lecture was attended by any student. The answer is not A(m, P(x).) But it is the answer to the question ‘What is the number of people in the world who attended the most recent lecture?’ And the answer is ‘Mary’. Use the predicate speciﬁcations B(x, y) and F(x) to translate the following into predicate logic. ‘True’ marks generalize into ‘true’ and ‘false’ Marks generalize to subformu-las; and “true” generalizes to “false” marks. We will execute this marking algorithm on the parse tree of formulas, except that we will translate formulas into the adequate fragment p. We then share common subformulas of the resulting parse tree, making the resulting tree into a directed, acyclic graph (DAG) The algorithm can be used to design an algorithm and to prove correctness. The inductively deﬁned transla-tion T(p) = pT(¬φ) = ¬T( φ)transforms formulas generated by (1.3) into formulas. The parse tree and DAG of T( ω) are depicted in Fig-                ure 1.12. The set of valuations for which φ is true equals the set of values for which T(ω) is true. The latter ensures that the diagnostics of a SAT solver, applied to T(phi) is meaningful for the original formula φ. In the exercises, you are asked to prove these claims. For example, in Figure 1.48 we compute T( The formal set of rules for forcing new constraints from old ones is depicted in Figure 1.14. A small circle indicates any node (¬, � or atom) The forcenectives such as →and ¬. are hard to use in practice. Gentzenimproved the situation by inventing the idea of working with assumptions. The linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the U.S. of America. Propositional and predicate logic can be found in the bibliographic remarks at the end of Chapter 2, and in other contemporary books. In the ﬁrst chapter, we developed propositional logic by examining it from three angles: its proof theory, its syntax and its semantics. We begin this second chapter by pointing out the limitations of propo-centric logic with respect to encoding declarative sentences. What can we do with modiﬁers like not, and, or                and if . . . then, then, and so on? And how can we create a richer language for these modi-propositional-logic terms? We conclude this chapter by asking: What do we want to say in a language that is richer than propositional-proprietary-logics? In propositional logic, we could identify this assertion with a propositionalSAT recursively on subexpressions. The desire to express more subtle declarative sentences led to the design of predicate logic, which is also called ﬁrst-order logic. The function pre∃(Y) takes a subset Y of states and returns the set of states which can make a transition into Y. Pre’ denotes travelling backwards along the transition relation. Both func-                tions compute a pre-image of a set ofStates. The ‘pre’ part of the function is used to denote a transition from one state to the next. function SATEX determines the set of states satisfying EX φ. The function SATAF computes the states satisfying φ by looking backwards along the line. The pre∀, used in SATAF, takes the number of states and is called pre∃. Verification by model checking can be carried out by using the model checker. The model checkers can be used to test the correctness of the model. For example, the model can be checked by checking whether the state is a positive or negative positive. For more information on the model checking technique, see: http://www.f The correctness of this pseudocode and the model checking algorithm is discussed in Section 3.7. The function SATEU computes the states satisfying φ by calling SAT. Then, it accumulates states satisfying AF φ in the manner described in the labelling algorithm. The model-checking algorithm can be expressed in terms of complementation and pre∃, as follows: pre∀(Y ) = S −pre∃(S −Y ) (3.8) (2.4) (1) ( 2) (3) ( 3) (4) 4) (5) (6) (7) (9) (10) (11) (12) (13) (14 Given a formula φ in propositional logic, we say that φ is                satisﬁable if it has a valuation in which is evaluates to T. For example, the formula p ∨q →p is satis﬋able since it computes T if we assigning T to p. However, this is a weaker concept since every valid formula is by de ﬁnition also satis ﬉able but not vice versa. The two notions are just mirror images of each other, the mirror being negation. The proof is given in the next section of the book. The book is published by Oxford University Press, London, UK, priced £16.99. We obtain a decision procedure for satisﬁability simply by asking P whether ¬φ is valid. If it is not, φ is not satis ﬁable; otherwise, it is. We may transform any decision procedure into one for validity. For each line where (p →¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. The result is extremely useful since it essentially says that we need provide only one procedure for each of these concepts. We will encounter both kinds of procedures in this text. For example, take the truth table autoimmuneof (p ) in Figure 1.8 (page 40) In Figure 3.28, we see that most of these clauses just do the obvious and correct thing according to the semantics of CTL. Since there is only one such line, we have only one conjunct ψ1. That conjuncts are not so obvious to reason about. The topic of this section is todevelop the semantic insights into these operators that allow us to provide acomplete proof for their termination and correctness. In fact, we will also write a procedure SATEG and SATEU to prove its termination and. correctness1. The procedure SATEG is given in Figure 3.37 and is based on the intuitions given in Section 3.6.1. The semantics of EG φ says that s0 ⊨EG φ holds iﬀthere exists a com-putation path s0 →s1 →s2 →. . . such that si ≹ holds for all i ≥0. We could instead express it as follows: EG υ holds if φ hold and EG ω holds if the state is in one of the successor states to the current state. The equivalence above can be written as [[EG υ] = pre∃ [[EG ω]]. Section 3.6.1 handles EG φ by translating it into ¬AF ¬φ, but we already noted that EG could be handled directly. Fortunately, there is a way around this apparent circularity, known as computing ﬁxed points, and that is the subject of this section. Section 3. 6.3 Verification by model checking is the final section of the book. The book is published by Oxford University Press. This foreword is re-printed in the second edition with its author’s permis-                sion. We developed this theme for propositional, temporal, modal, and program logics. At the heart of this set-up is that one can often specify and implement algorithms for computing. I recommend it to the reader                with greatest enthusiasm and predict that the book will be an enormous                success. The book is published by Oxford University Press, London, priced £16.99. For more information on the book, visit the publisher's website or visit the book's website at: http://www.oxford-uk.com/books/computer-science- The second edition of this text means to preserve and improve on the                original intent of the ﬁrst edition. It now discusses the design, correctness, and complexity of a SATsolver (a marking algorithm similar to St˚almarck’s method [SS90] for full Propositional logic. The preface to the second edition has been completely restructured. The object modelling language Alloy is now executable which makes such exploration interactive andformal. It also contains a section on the expressiveness of existential and universal second-order logic. It is based on the first edition of the book, which was published in 2007 and is available in English, German, and French. We can apply SAT solvers to checking whether sequents are valid. The DAG of T(φ) is depicted in Figure 1.15. The annotations “1” etc.indicate which nodes represent which sub-formulas. A post-processing phase takes the marks for all grotesqueatoms and re-computes marks of all other nodes in a bottom-up manner, as done in Section 1.4 on parse trees. Only if the resulting marks match the ones we computed have we found a witness. It now begins with a discus-                Figure 1.14. Rules for flow of constraints in a formula’s DAG. Small Carbunclecircles indicate arbitrary nodes (¬ The SAT solver can be seen in Figure 1.16. The solver concludes that the indicated node requires the marks T and F for (1.9) to be met. Such contradictory constraints therefore imply that all formulas T(φ)whose DAG equals that of this ﬁgure are not satisﬁable. In particular, all propositions T( φ) whose DAG is less than this DAG are unsatisﬅable. This SAT solaver has a linear running time in the size of the DAG for T(phi) T( Phi) T (T(phi), T (phi, T (t(phi, t(t(t (t ( 6.2 A cubic solver. This linearity came with a price: our linear sol",
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-4",
            "title": "Program Verification",
            "content": "of R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nstatements, while-statements and sequential compositions. Everything that\ncan be computed by large languages like C and Java can also be computed\nby our language, though perhaps not as conveniently, because it does not\nhave any objects, procedures, threads or recursive data structures. While\nthis makes it seem unrealistic compared with fully blown commercial lan-\nguages, it allows us to focus our discussion on the process of formal program\nveriﬁcation. The features missing from our language could be implemented\non top of it; that is the justiﬁcation for saying that they do not add to the\npower of the language, but only to the convenience of using it. Verifying\nprograms using those features would require non-trivial extensions of the\nproof calculus we present here. In particular, dynamic scoping of variables\npresents hard problems for program-veriﬁcation methods, but this is beyond\nthe scope of this book.\nOur core language has three syntactic domains: integer expressions,\nboolean expressions and commands – the latter we consider to be our\nprograms. Integer expressions are built in the familiar way from variables\nx, y, z, . . . , numerals 0, 1, 2, . . . , −1, −2, . . . and basic operations like addition\n(+) and multiplication (∗). For example,\n5\nx\n4 + (x −3)\nx + (x ∗(y −(5 + z)))\nare all valid integer expressions. Our grammar for generating integer expres-\nsions is\nE ::=\nn | x | (−E) | (E + E) | (E −E) | (E ∗E)\n(4.1)\nwhere n is any numeral in {. . . , −2, −1, 0, 1, 2, . . . } and x is any variable.\nNote that we write multiplication in ‘mathematics’ as 2 · 3, whereas our\ncore language writes 2 ∗3 instead.\nConvention 4.1 In the grammar above, negation −binds more tightly\ngramming language you used a list of features of its software development envi-\nronment (compiler, editor, linker, run-time environment etc) that may improve\nthe likelihood that your programs work correctly. Try to rate the eﬀectiveness of\neach such feature.\n2. Repeat the previous exercise by listing and rating features that may decrease\nthe likelihood of procuding correct and reliable programs.\nExercises 4.2\n1.\n*\nIn what circumstances would if (B) {C1} else {C2} fail to terminate?\n2.\n*\nA familiar command missing from our language is the for-statement. It may be\nused to sum the elements in an array, for example, by programming as follows:\ns = 0;\nfor (i = 0; i <= max; i = i+1) {\ns = s + a[i];\n}\nAfter performing the initial assignment s = 0, this executes i = 0 ﬁrst, then\nexecutes the body s = s + a[i] and the incrementation i = i + 1 continually\nuntil i <= max becomes false. Explain how for (C1; B; C2) {C3} can be deﬁned\nas a derived program in our core language.\n3. Suppose that you need a language construct repeat {C} until (B) which re-\npeats C until B becomes true, i.e.\ni. executes C in the current state of the store;\nii. evaluates B in the resulting state of the store;\niii. if B is false, the program resumes with (i); otherwise, the program\nrepeat {C} until (B) terminates.\nThis construct sometimes allows more elegant code than a corresponding while-\nstatement.\n300\n4 Program verification\n(a) Deﬁne repeat C until B as a derived expression using our core language.\n(b) Can one deﬁne every repeat expression in our core language extended with\nfor-statements? (You might need the empty command skip which does noth-\ning.)\nExercises 4.3\n1. For any store l as in Example 4.4 (page 264), determine which of the relations\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\nalone must take responsibility for those.\nAdded for second edition\nMany people have helped improve this text by pointing out typos and\nmaking other useful comments after the publication date. Among them,\nxiii\nxiv\nAcknowledgements\nwe mention Wolfgang Ahrendt, Yasuhiro Ajiro, Torben Amtoft, Stephan\nAndrei, Bernhard Beckert, Jonathan Brown, James Caldwell, Ruchira Datta,\nAmy Felty, Dimitar Guelev, Hirotsugu Kakugawa, Kamran Kashef, Markus\nKr¨otzsch, Jagun Kwon, Ranko Lazic, David Makinson, Alexander Miczo,\nAart Middeldorp, Robert Morelli, Prakash Panangaden, Aileen Paraguya,\nFrank Pfenning, Shekhar Pradhan, Koichi Takahashi, Kazunori Ueda,\nHiroshi Watanabe, Fuzhi Wang and Reinhard Wilhelm.\n1\nPropositional logic\nThe aim of logic in computer science is to develop languages to model the\nsituations we encounter as computer science professionals, in such a way\nthat we can reason about them formally. Reasoning about situations means\nconstructing arguments about them; we want to do this formally, so that\nthe arguments are valid and can be defended rigorously, or executed on a\nmachine.\nConsider the following argument:\nExample 1.1 If the train arrives late and there are no taxis at the station,\nthen John is late for his meeting. John is not late for his meeting. The train\ndid arrive late. Therefore, there were taxis at the station.\nIntuitively, the argument is valid, since if we put the ﬁrst sentence and\nthe third sentence together, they tell us that if there are no taxis, then John\nwill be late. The second sentence tells us that he was not late, so it must be\nthe case that there were taxis.\nMuch of this book will be concerned with arguments that have this struc-\nture, namely, that consist of a number of sentences followed by the word\n‘therefore’ and then another sentence. The argument is valid if the sentence\nafter the ‘therefore’ logically follows from the sentences before it. Exactly\nwhat we mean by ‘follows from’ is the subject of this chapter and the next\none.\naxiomatic, 91\ncommercially critical, 172, 257\ncomponent, 206\nconcurrent, 173\ndebugging, 174\ndescription, 193\ndesign, 174\ndevelopment, 173\nelevator, 184, 215\nﬁnite-state, 256\nhybrid, 277\ninﬁnite-state, 256\nmission-critical, 172\nmulti-agent, 331\nphysical, 175\nreactive, 173, 257, 358\nsafety-critical, 172, 257\ntransition, 174\nveriﬁcation, 256\ntautology, 50\ntemporal connective\nAF, 212\nAG, 211\nAU, 212\nAX, 211\nEF, 212\nEG, 211\nEU, 212\nEX, 211\ntemporal connectives, 176\ntemporal logic, 174, 306\nterm, 99\ninterpretation, 128\nterm-rewriting system, 170\ntermination\nCollatz 3n + 1, 295\nproof, 266\ntertium non datur, 25\ntheorem, 13\nprover, 106, 136\nproving, 170\ntime\ncontinuous, 174\ndiscrete, 174\ntop\nmarking, 66\ntotal correctness, 265, 266\ntransition relation, 178\nfor SMV programs, 388\ntransition system, 174\nof ABP program, 247\nof Mutex code, 198\nof SMV program, 192\nunwinding, 180, 212, 222\nIndex\n427\ntranslation\nEnglish into predicate logic, 95, 101\ntree\ninﬁnite, 180, 212\ntruth\ndynamic, 174\nmode, 306, 308\nof knowledge, 326\nstatic, 174\nvalue\nfor predicate logic, 127\nfor propositional logic, 3\ntruth table\nfor conjunction, 37\ntruth tables, 38\ntype, 12, 327\nchecking, 12\ntheory, 170\nunary connective, 307\nundecidability\nof provability, 136\nof satisﬁability, 135\nof validity in predicate logic, 133\nuniversal quantiﬁcation, 268\nuniversal quantiﬁer, 216\nuniversal second-order logic, 140, 156\nuniverse of concrete values, 124\nunreachability, 140\nunsound sequent, 164\nUntil\nin natural language, 182\nnegating, 187\nupdated valuation, 391\nvalid sequent\nof modal logic, 330\npartial correctness, 267\ntotal correctness, 267\nvalidity\nin basic modal logic, 314\nin KT45n, 339\nin propositional logic, 85\nundecidability in predicate logic, 133\nvaluation\nfor propositional logic, 37\nin predicate logic, 123\nin relational mu-calculus, 391\nvalue\ninitial, 206, 268, 269\nVardi, M., 254\nvariable, 94, 260\nboolean, 229, 247, 358\nbound, 103\ncapture, 106\ndummy, 110\nfree, 103\nlocal, 263\nlogical, 268, 290\nvariable ordering\nsmall scope hypothesis, 143\nSMV, 254\nmain program for ABP, 207\nmodule, 193\nreceiver, 205\nsender, 204\nfor channel, 206\ninstantiation, 193\nprocess, 389\nprogram\nexample, 192\nfor Mutex, 195\nspeciﬁcation, 192\nsoftware\nlife-cycle, 142\nmicromodel, 142\nreliability, 149\nrequirements, 142\nspeciﬁcation, 142\nvalidation, 142\nsoundness\nof forall-elimination, 109\nof natural deduction\nbasic modal logic, 354\npredicate logic, 96, 122\npropositional logic, 45\nof program logics, 267\nof proof rule for while-statements,\n282\nof the substitution principle, 108\n426\nIndex\nspeciﬁcation\nfor ABP, 207\nformal, 259\ninformal, 259\nlanguage, 172\nof a predicate, 157\npatterns, 254\npractical pattern, 183, 215\ntruth table, 58\nspeciﬁcations, 191\nSpin, 254\nstate\ncritical, 188\nexplosion, 229\nexplosion problem, 254\nfair, 397\nﬁnal, 142\nformula, 218\nglobal, 188\ngraph, 180\ninitial, 142, 189, 222, 247, 252, 264\nnon-critical, 188\nof a system, 269\nof core program, 264\nreachable, 247\nresulting, 263, 299\nspace, 229\nsplitting states, 190\ntransition, 142\ntrying, 188\nstate machine, 142\nstorage\nlocation, 288\nstate, 261\nstore\nof core program, 264\nstring, 247, 307\nbinary, 126, 132\nempty, 126\nstrongly connected component, 225\nstructural equality, 153\nstructural induction, 44, 51\nsubformula, 178\nsubstitution\nin predicate logic, 105\ninstance, 323\ninstance of tautology, 314\nprinciple, 108\nsymbolic model checking, 383\nsyntactic\ndomain, 260, 261\nsyntax\nof basic modal logic, 307\nof boolean expressions, 261\nof boolean formulas, 398\nof CTL, 208\nof CTL*, 218\nof KT45n, 335\nof LTL, 175\nof predicate logic, 100\nof propositional logic, 33\nof relational mu-calculus, 390\nof terms, 99\nsystem\nasynchronous, 254\ninterleaving model, 389\nsimultaneous model, 389\naxiomatic, 91\ncommercially critical, 172, 257\ncomponent, 206\nconcurrent, 173\ndebugging, 174\ndescription, 193\ndesign, 174\ndevelopment, 173\nelevator, 184, 215\nﬁnite-state, 256\nhybrid, 277\ninﬁnite-state, 256\nmission-critical, 172\nmulti-agent, 331\nphysical, 175\nreactive, 173, 257, 358\nLogic Programming, volume 1. Oxford University Press, 1993.\nFit96. M. Fitting. First-Order Logic and Automated Theorem Proving.\nSpringer, 2nd edition, 1996.\nFra92. N. Francez. Program Veriﬁcation. Addison-Wesley, 1992.\nFre03. G. Frege. Grundgesetze der Arithmetik, begriﬀsschriftlich abgeleitet.\n1903. Volumes I and II (Jena).\nGal87. J. H. Gallier. Logic for Computer Science. John Wiley, 1987.\nGen69. G. Gentzen. Investigations into logical deduction. In M. E. Szabo,\neditor, The Collected Papers of Gerhard Gentzen, chapter 3, pages\n68–129. North-Holland Publishing Company, 1969.\nGol87. R. Goldblatt. Logics of Time and Computation. CSLI Lecture Notes,\n1987.\nGri82. D. Gries. A note on a standard strategy for developing loop invariants\nand loops. Science of Computer Programming, 2:207–214, 1982.\nHam78. A. G. Hamilton. Logic for Mathematicians. Cambridge University\nPress, 1978.\nHoa69. C. A. R. Hoare. An axiomatic basis for computer programming.\nCommunications of the ACM, 12:576–580, 1969.\nHod77. W. Hodges. Logic. Penguin Books, 1977.\nHod83. W. Hodges. Elementary predicate logic. In D. Gabbay and\nF. Guenthner, editors, Handbook of Philosophical Logic, volume 1.\nDordrecht: D. Reidel, 1983.\n416\nBibliography\nHol90. G. Holzmann. Design and Validation of Computer Protocols. Prentice\nHall, 1990.\nJSS01. D. Jackson, I. Shlyakhter, and M. Sridharan. A Micromodularity\nMechanism. In Proceedings of the ACM SIGSOFT Conference on the\nFoundations of Software Engineering/European Software Engineering\nConference (FSE/ESEC’01), September 2001.\nKoz83. D. Kozen. Results on the propositional mu-calculus. Theoretical\nComputer Science, 27:333–354, 1983.\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983. \u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis satisﬁed under partial correctness if, for all states which satisfy φ, the\nstate resulting from P’s execution satisﬁes the postcondition ψ, provided\nthat P actually terminates. In this case, the relation ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\nWe call ⊨par the satisfaction relation for partial correctness.\nThus, we insist on ψ being true of the resulting state only if the program P\nhas terminated on an input satisfying φ. Partial correctness is rather a weak\nrequirement, since any program which does not terminate at all satisﬁes its\n266\n4 Program verification\nspeciﬁcation. In particular, the program\nwhile true { x = 0; }\n– which endlessly ‘loops’ and never terminates – satisﬁes all speciﬁcations,\nsince partial correctness only says what must happen if the program termi-\nnates.\nTotal correctness, on the other hand, requires that the program terminates\nin order for it to satisfy a speciﬁcation.\nDeﬁnition 4.6 (Total correctness) We say that the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis\nsatisﬁed under total correctness if, for all states in which P is executed which\nsatisfy the precondition φ, P is guaranteed to terminate and the resulting\nstate satisﬁes the postcondition ψ. In this case, we say that ⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds and call ⊨tot the satisfaction relation of total correctness.\nA program which ‘loops’ forever on all input does not satisfy any spec-\niﬁcation under total correctness. Clearly, total correctness is more useful\nthan partial correctness, so the reader may wonder why partial correctness\nis introduced at all. Proving total correctness usually beneﬁts from prov-\ning partial correctness ﬁrst and then proving termination. So, although our\nprimary interest is in proving total correctness, it often happens that we\nhave to or may wish to split this into separate proofs of partial correctness\nand of termination. Most of this chapter is devoted to the proof of partial\ncorrectness, though we return to the issue of termination in Section 4.4.\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\n3. Let the relation P ⊢l ; l′ hold iﬀP’s execution in store l terminates, resulting\nin store l′. Use this formal judgment P ⊢l ; l′ along with the relation l ⊨φ to\ndeﬁne ⊨par and ⊨tot symbolically.\n4. Another reason for proving partial correctness in isolation is that some program\nfragments have the form while (true) {C}. Give useful examples of such pro-\ngram fragments in application programming.\n5.\n*\nUse the proof rule for assignment and logical implication as appropriate to show\nthe validity of\n(a) ⊢par\n\u0001\nx > 0\n\u0002\ny = x + 1\n\u0001\ny > 1\n\u0002\n(b) ⊢par\n\u0001\n⊤\n\u0002\ny = x; y = x + x + y\n\u0001\ny = 3 · x\n\u0002\n(c) ⊢par\n\u0001\nx > 1\n\u0002\na = 1; y = x; y = y - a\n\u0001\ny > 0 ∧x > y\n\u0002\n.\n6.\n*\nWrite down a program P such that\n(a)\n\u0001\n⊤\n\u0002\nP\n\u0001\ny = x + 2\n\u0002\n(b)\n\u0001\n⊤\n\u0002\nP\n\u0001\nz > x + y + 4\n\u0002\nholds under partial correctness; then prove that this is so.\n7. For all instances of Implied in the proof on page 274, specify their corresponding\n⊢AR sequents.\n8. There is a safe way of relaxing the format of the proof rule for assignment: as\nlong as no variable occurring in E gets updated in between the assertion ψ[E/x]\nand the assignment x = E we may conclude ψ right after this assignment. Ex-\nplain why such a proof rule is sound.\n9. (a) Show, by means of an example, that the ‘reversed’ version of the rule Implied\n⊢AR φ →φ′\n\u0001\nφ\n\u0002\nC\n\u0001\nψ\n\u0002\n⊢AR ψ′ →ψ\n\u0001\nφ′\u0002\nC\n\u0001\nψ′\u0002\nImplied Reversed\nis unsound for partial correctness.\n(b) Explain why the modiﬁed rule If-Statement in (4.7) is sound with respect\nto the partial and total satisfaction relation.\n4.6 Exercises\n301\n(c)\n*\nShow that any instance of the modiﬁed rule If-Statement in a proof can\nbe replaced by an instance of the original If-statement and instances of the\nrule Implied. Is the converse true as well?\n10.\n*\nProve the validity of the sequent ⊢par\n\u0001\nBefore a discussion of how to ﬁnd invariants for while-statement, we now\nlook at the assignment and the if-statement to see how the weakest precon-\ndition is calculated for each one.\nAssignment.\nThe assignment axiom is easily adapted to work for proof\ntableaux. We write it thus:\n4 φ is weaker than ψ means that φ is implied by ψ in predicate logic enlarged with the basic\nfacts about arithmetic: the sequent ⊢AR ψ →φ is valid. We want the weakest formula, because\nwe want to impose as few constraints as possible on the preceding code. In some cases, espe-\ncially those involving while-statements, it might not be possible to extract the logically weakest\nformula. We just need one which is suﬃciently weak to allow us to complete the proof at hand.\n4.3 Proof calculus for partial correctness\n277\n\u0001\nψ[E/x]\n\u0002\nx = E\n\u0001\nψ\n\u0002\nAssignment\nThe justiﬁcation is written against the ψ, since, once the proof has been con-\nstructed, we want to read it in a forwards direction. The construction itself\nproceeds in a backwards direction, because that is the way the assignment\naxiom facilitates.\nImplied.\nIn tableau form, the Implied rule allows us to write one formula φ2\ndirectly underneath another one φ1 with no code in between, provided that\nφ1 implies φ2 in that the sequent ⊢AR φ1 →φ2 is valid. Thus, the Implied\nrule acts as an interface between predicate logic with arithmetic and program\nlogic. This is a surprising and crucial insight. Our proof calculus for partial\ncorrectness is a hybrid system which interfaces with another proof calculus\nvia the Implied proof rule only.\nWhen we appeal to the Implied rule, we will usually not explicitly write\nout the proof of the implication in predicate logic, for this chapter focuses\non the program logic. Mostly, the implications we typically encounter will\nbe easy to verify.\nThe Implied rule is often used to simplify formulas that are generated by\napplications of the other rules. It is also used when the weakest precondition\nφ and a postcondition ψ in (4.5). Recall that we developed proof calculi\nfor propositional and predicate logic where such proofs could be accom-\nplished by investigating the structure of the formula one wanted to prove.\nFor example, for proving an implication φ →ψ one had to assume φ and\nmanage to show ψ; then the proof could be ﬁnished with the proof rule for\nimplies-introduction. The proof calculi which we are about to develop follow\nsimilar lines. Yet, they are diﬀerent from the logics we previously studied\nsince they prove triples which are built from two diﬀerent sorts of things:\nlogical formulas φ and ψ versus a piece of code P. Our proof calculi have to\naddress each of these appropriately. Nonetheless, we retain proof strategies\nwhich are compositional, but now in the structure of P. Note that this is\nan important advantage in the veriﬁcation of big projects, where code is\nbuilt from a multitude of modules such that the correctness of certain parts\nwill depend on the correctness of certain others. Thus, your code might\ncall subroutines which other members of your project are about to code,\nbut you can already check the correctness of your code by assuming that\nthe subroutines meet their own speciﬁcations. We will explore this topic in\nSection 4.5.\n4.2.3 Partial and total correctness\nOur explanation of when the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds was rather informal. In\nparticular, it did not say what we should conclude if P does not terminate.\nIn fact there are two ways of handling this situation. Partial correctness\nmeans that we do not require the program to terminate, whereas in total\ncorrectness we insist upon its termination.\nDeﬁnition 4.5 (Partial correctness) We say that the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis satisﬁed under partial correctness if, for all states which satisfy φ, the\nstate resulting from P’s execution satisﬁes the postcondition ψ, provided\nthat P actually terminates. In this case, the relation ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\n, i.e. triples in which the postcon-\ndition is the same as the precondition conjoined with ¬B. Suppose that we\nare required to prove\n\u0001\nφ\n\u0002\nwhile (B) {C}\n\u0001\nψ\n\u0002\n(4.10)\nfor some φ and ψ which are not related in that way. How can we use\nPartial-while in a situation like this?\nThe answer is that we must discover a suitable η, such that\n1.\n⊢AR φ →η,\n2.\n⊢AR η ∧¬B →ψ and\n3.\n⊢par\n\u0001\nη\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\nare all valid, where the latter is shown by means of Partial-while. Then,\nImplied infers that (4.10) is a valid partial-correctness triple.\nThe crucial thing, then, is the discovery of a suitable invariant η. It is a\nnecessary step in order to use the proof rule Partial-while and in general it\nrequires intelligence and ingenuity. This contrasts markedly with the case of\nthe proof rules for if-statements and assignments, which are purely mechan-\nical in nature: their usage is just a matter of symbol-pushing and does not\nrequire any deeper insight.\nDiscovery of a suitable invariant requires careful thought about what the\nwhile-statement is really doing. Indeed the eminent computer scientist, the\nlate E. Dijkstra, said that to understand a while-statement is tantamount\nto knowing what its invariant is with respect to given preconditions and\npostconditions for that while-statement.\nThis is because a suitable invariant can be interpreted as saying that the\nintended computation performed by the while-statement is correct up to\nthe current step of the execution. It then follows that, when the execution\n284\n4 Program verification\nterminates, the entire computation is correct. Let us formalize invariants\nand then study how to discover them.\nDeﬁnition 4.15 An invariant of the while-statement while (B) {C} is a\nformula η such that ⊨par\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\nholds; i.e. for all states l, if η and B\nare true in l and C is executed from state l and terminates, then η is again\ntrue in the resulting state.\nwhile-statements was presented in the following form in Figure 4.1 – here\nwe have written η instead of ψ:\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\n\u0001\nη\n\u0002\nwhile B {C}\n\u0001\nη ∧¬B\n\u0002 Partial-while.\n(4.9)\nBefore we look at how Partial-while will be represented in proof tableaux,\nlet us look in more detail at the ideas behind this proof rule. The formula η is\nchosen to be an invariant of the body C of the while-statement: provided the\nboolean guard B is true, if η is true before we start C, and C terminates,\nthen it is also true at the end. This is what the premise\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\nexpresses.\nNow suppose the while-statement executes a terminating run from a state\nthat satisﬁes η; and that the premise of (4.9) holds.\nr If B is false as soon as we embark on the while-statement, then we do not execute\nC at all. Nothing has happened to change the truth value of η, so we end the\nwhile-statement with η ∧¬B.\n4.3 Proof calculus for partial correctness\n283\nr If B is true when we embark on the while-statement, we execute C. By the\npremise of the rule in (4.9), we know η is true at the end of C.\n– if B is now false, we stop with η ∧¬B.\n– if B is true, we execute C again; η is again re-established. No matter how\nmany times we execute C in this way, η is re-established at the end of each\nexecution of C. The while-statement terminates if, and only if, B is false after\nsome ﬁnite (zero including) number of executions of C, in which case we have\nη ∧¬B.\nThis argument shows that Partial-while is sound with respect to the sat-\nisfaction relation for partial correctness, in the sense that anything we prove\nusing it is indeed true. However, as it stands it allows us to prove only things\nof the form\n\u0001\nη\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\n, i.e. triples in which the postcon-\ndition is the same as the precondition conjoined with ¬B. Suppose that we\nare required to prove\n\u0001\nφ\n\u0002\nwhile (B) {C}\n\u0001\nψ\n\u0002\n(4.10)\nfor some φ and ψ which are not related in that way. How can we use\nPartial-while in a situation like this?\nthing if P ‘loops’ indeﬁnitely. In this section, we extend our proof calculus\nfor partial correctness so that it also proves that programs terminate. In the\nprevious section, we already pointed out that only the syntactic construct\nwhile B {C} could be responsible for non-termination.\n4.4 Proof calculus for total correctness\n293\nTherefore, the proof calculus for total correctness is the same as\nfor partial correctness for all the rules except the rule for while-\nstatements.\nA proof of total correctness for a while-statement will consist of two parts:\nthe proof of partial correctness and a proof that the given while-statement\nterminates. Usually, it is a good idea to prove partial correctness ﬁrst since\nthis often provides helpful insights for a termination proof. However, some\nprograms require termination proofs as premises for establishing partial cor-\nrectness, as can be seen in exercise 1(d) on page 303.\nThe proof of termination usually has the following form. We identify an\ninteger expression whose value can be shown to decrease every time we\nexecute the body of the while-statement in question, but which is always\nnon-negative. If we can ﬁnd an expression with these properties, it follows\nthat the while-statement must terminate; because the expression can only\nbe decremented a ﬁnite number of times before it becomes 0. That is because\nthere is only a ﬁnite number of integer values between 0 and the initial value\nof the expression.\nSuch integer expressions are called variants. As an example, for the pro-\ngram Fac1 of Example 4.2, a suitable variant is x −z. The value of this\nexpression is decremented every time the body of the while-statement is\nexecuted. When it is 0, the while-statement terminates.\nWe can codify this intuition in the following rule for total correctness\nwhich replaces the rule for the while statement:\n\u0001\nη ∧B ∧0 ≤E = E0\n\u0002\nC\n\u0001\nη ∧0 ≤E < E0\n\u0002\n\u0001\nη ∧0 ≤E\n\u0002\nwhile B {C}\n\u0001\nη ∧¬B\n\u0002\nTotal-while.\n(4.15) and refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nif-statement and the while-statement, as in languages such as C and Java.\nThey can be omitted if the blocks consist of a single statement. The intuitive\nmeaning of the programming constructs is the following:\n1.\nThe atomic command x = E is the usual assignment statement; it evaluates\nthe integer expression E in the current state of the store and then overwrites\nthe current value stored in x with the result of that evaluation.\n2.\nThe compound command C1; C2 is the sequential composition of the commands\nC1 and C2. It begins by executing C1 in the current state of the store. If that\nexecution terminates, then it executes C2 in the storage state resulting from the\nexecution of C1. Otherwise – if the execution of C1 does not terminate – the\nrun of C1; C2 also does not terminate. Sequential composition is an example of\na control structure since it implements a certain policy of ﬂow of control in a\ncomputation.\n1 In common with languages like C and Java, we use a single equals sign = to mean assignment\nand a double sign == to mean equality. Earlier languages like Pascal used := for assignment and\nsimple = for equality; it is a great pity that C and its successors did not keep this convention.\nThe reason that = is a bad symbol for assignment is that assignment is not symmetric: if we\ninterpret x = y as the assignment, then x becomes y which is not the same thing as y becoming\nx; yet, x = y and y = x are the same thing if we mean equality. The two dots in := helped\nremind the reader that this is an asymmetric assignment operation rather than a symmetric\nassertion of equality. However, the notation = for assignment is now commonplace, so we will\nuse it.\n262\n4 Program verification\n3.\nAnother control structure is if B {C1} else {C2}. It ﬁrst evaluates the boolean\nexpression B in the current state of the store; if that result is true, then C1 is\nexecuted; if B evaluated to false, then C2 is executed.\n4.\nThe third control construct while B {C} allows us to write statements which\n(4) will do. Et alors, qu’est-ce qu’on pense des phrases (5) et (6)? Sentences\n(5) and (6) are ﬁne if you happen to read French and German a bit. Thus,\ndeclarative statements can be made in any natural, or artiﬁcial, language.\nThe kind of sentences we won’t consider here are non-declarative ones,\nlike\nr Could you please pass me the salt?\nr Ready, steady, go!\nr May fortune come your way.\nPrimarily, we are interested in precise declarative sentences, or statements\nabout the behaviour of computer systems, or programs. Not only do we\nwant to specify such statements but we also want to check whether a given\nprogram, or system, fulﬁls a speciﬁcation at hand. Thus, we need to develop\na calculus of reasoning which allows us to draw conclusions from given as-\nsumptions, like initialised variables, which are reliable in the sense that they\npreserve truth: if all our assumptions are true, then our conclusion ought to\nbe true as well. A much more diﬃcult question is whether, given any true\nproperty of a computer program, we can ﬁnd an argument in our calculus\nthat has this property as its conclusion. The declarative sentence (3) above\nmight illuminate the problematic aspect of such questions in the context of\nnumber theory.\nThe logics we intend to design are symbolic in nature. We translate a cer-\ntain suﬃciently large subset of all English declarative sentences into strings\nof symbols. This gives us a compressed but still complete encoding of declar-\native sentences and allows us to concentrate on the mere mechanics of our\nargumentation. This is important since speciﬁcations of systems or software\nare sequences of such declarative sentences. It further opens up the possibil-\nity of automatic manipulation of such speciﬁcations, a job that computers\njust love to do1. Our strategy is to consider certain declarative sentences as\n1 There is a certain, slightly bitter, circularity in such endeavours: in proving that a certain\nz = z + x;\nx = x - 1;\n}\nThis program adds up the ﬁrst x integers and stores the result in z.\nThus,\n\u0001\nx = 3\n\u0002\nSum\n\u0001\nz = 6\n\u0002\n,\n\u0001\nx = 8\n\u0002\nSum\n\u0001\nz = 36\n\u0002\netc. We know from The-\norem 1.31 on page 41 that 1 + 2 + · · · + x = x(x + 1)/2 for all x ≥0, so\n4.3 Proof calculus for partial correctness\n269\nwe would like to express, as a Hoare triple, that the value of z upon\ntermination is x0(x0 + 1)/2 where x0 is the initial value of x. Thus, we write\n\u0001\nx = x0 ∧x ≥0\n\u0002\nSum\n\u0001\nz = x0(x0 + 1)/2\n\u0002\n.\nVariables like x0 in these examples are called logical variables, because they\noccur only in the logical formulas that constitute the precondition and post-\ncondition; they do not occur in the code to be veriﬁed. The state of the\nsystem gives a value to each program variable, but not for the logical vari-\nables. Logical variables take a similar role to the dummy variables of the\nrules for ∀i and ∃e in Chapter 2.\nDeﬁnition 4.10 For a Hoare triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\n, its set of logical variables\nare those variables that are free in φ or ψ; and don’t occur in P.\n4.3 Proof calculus for partial correctness\nThe proof calculus which we now present goes back to R. Floyd and C.\nA. R. Hoare. In the next subsection, we specify proof rules for each of the\ngrammar clauses for commands. We could go on to use these proof rules\ndirectly, but it turns out to be more convenient to present them in a diﬀerent\nform, suitable for the construction of proofs known as proof tableaux. This\nis what we do in the subsection following the next one.\n4.3.1 Proof rules\nThe proof rules for our calculus are given in Figure 4.1. They should be\ninterpreted as rules that allow us to pass from simple assertions of the form\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nto more complex ones. The rule for assignment is an axiom as\nit has no premises. This allows us to construct some triples out of noth-\ning, to get the proof going. Complete proofs are trees, see page 274 for an\nexample.\nComposition.\nGiven speciﬁcations for the program fragments C1 and C2,\nsay\n\u0001\nφ\nLogic Programming, volume 1. Oxford University Press, 1993.\nFit96. M. Fitting. First-Order Logic and Automated Theorem Proving.\nSpringer, 2nd edition, 1996.\nFra92. N. Francez. Program Veriﬁcation. Addison-Wesley, 1992.\nFre03. G. Frege. Grundgesetze der Arithmetik, begriﬀsschriftlich abgeleitet.\n1903. Volumes I and II (Jena).\nGal87. J. H. Gallier. Logic for Computer Science. John Wiley, 1987.\nGen69. G. Gentzen. Investigations into logical deduction. In M. E. Szabo,\neditor, The Collected Papers of Gerhard Gentzen, chapter 3, pages\n68–129. North-Holland Publishing Company, 1969.\nGol87. R. Goldblatt. Logics of Time and Computation. CSLI Lecture Notes,\n1987.\nGri82. D. Gries. A note on a standard strategy for developing loop invariants\nand loops. Science of Computer Programming, 2:207–214, 1982.\nHam78. A. G. Hamilton. Logic for Mathematicians. Cambridge University\nPress, 1978.\nHoa69. C. A. R. Hoare. An axiomatic basis for computer programming.\nCommunications of the ACM, 12:576–580, 1969.\nHod77. W. Hodges. Logic. Penguin Books, 1977.\nHod83. W. Hodges. Elementary predicate logic. In D. Gabbay and\nF. Guenthner, editors, Handbook of Philosophical Logic, volume 1.\nDordrecht: D. Reidel, 1983.\n416\nBibliography\nHol90. G. Holzmann. Design and Validation of Computer Protocols. Prentice\nHall, 1990.\nJSS01. D. Jackson, I. Shlyakhter, and M. Sridharan. A Micromodularity\nMechanism. In Proceedings of the ACM SIGSOFT Conference on the\nFoundations of Software Engineering/European Software Engineering\nConference (FSE/ESEC’01), September 2001.\nKoz83. D. Kozen. Results on the propositional mu-calculus. Theoretical\nComputer Science, 27:333–354, 1983.\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nstatements, while-statements and sequential compositions. Everything that\ncan be computed by large languages like C and Java can also be computed\nby our language, though perhaps not as conveniently, because it does not\nhave any objects, procedures, threads or recursive data structures. While\nthis makes it seem unrealistic compared with fully blown commercial lan-\nguages, it allows us to focus our discussion on the process of formal program\nveriﬁcation. The features missing from our language could be implemented\non top of it; that is the justiﬁcation for saying that they do not add to the\npower of the language, but only to the convenience of using it. Verifying\nprograms using those features would require non-trivial extensions of the\nproof calculus we present here. In particular, dynamic scoping of variables\npresents hard problems for program-veriﬁcation methods, but this is beyond\nthe scope of this book.\nOur core language has three syntactic domains: integer expressions,\nboolean expressions and commands – the latter we consider to be our\nprograms. Integer expressions are built in the familiar way from variables\nx, y, z, . . . , numerals 0, 1, 2, . . . , −1, −2, . . . and basic operations like addition\n(+) and multiplication (∗). For example,\n5\nx\n4 + (x −3)\nx + (x ∗(y −(5 + z)))\nare all valid integer expressions. Our grammar for generating integer expres-\nsions is\nE ::=\nn | x | (−E) | (E + E) | (E −E) | (E ∗E)\n(4.1)\nwhere n is any numeral in {. . . , −2, −1, 0, 1, 2, . . . } and x is any variable.\nNote that we write multiplication in ‘mathematics’ as 2 · 3, whereas our\ncore language writes 2 ∗3 instead.\nConvention 4.1 In the grammar above, negation −binds more tightly\nvariable, 227, 268\nveriﬁcation, 270\nformal, 260\nprogram execution, 316, 319\nprogramming by contract, 296\nEiﬀel, 296\nprogramming language\nimperative, 259\nproof\nbox\nfor →i, 11\nfor forall-introduction, 110\nfor modal logic, 329\nopening, 28\nside by side, 22\nby contradiction, 24\ncalculus, 256, 260\nconstruction, 269\nconstructive, 120\ndashed box, 329, 340\nfragment, 278\nindirect, 29\nof correctness, 239\nof termination, 266\npartial, 281\npartial correctness, 269, 300\nsearch, 49\nsolid box, 329\nstrategy, 115, 265\nsubproof, 272\ntableaux, 269\ntheory, 93, 122, 174\ntotal correctness, 292\nproof rules, 5\nfor implication, 273\nfor assignment, 269\nfor conjunction, 6\nfor disjunction, 16\nfor double negation, 8\nfor equality, 108\nfor existential quantiﬁcation, 112\nfor if-statements, 272, 280\nmodiﬁed, 281\nfor implication, 12, 277\nfor KT45n, 339\nfor negation, 20\nfor quantiﬁers, 112\nfor sequential composition, 269, 275\nfor universal quantiﬁcation, 109\nfor while-statements, 272, 282, 287\nschema, 111\nsubformula property, 113\nproof tableaux\ncomplete, 291\nproof-based veriﬁcation, 172, 256\nproposition, 2\npropositional logic, 93\nprotocol, 187, 188\nprovability\nundecidability of predicate logic, 136\nquantiﬁer, 310, 313\nequivalences, 185\nin predicate logic, 94\nbinding priorities, 101\nequivalences, 130\nmeaning, 123\nQuielle, J., 254\nreachability, 136, 137\nreasoning\nabout knowledge, 326, 331\nconstructive, 29\nin an arbitrary accessible world, 329\ninformal, 343\nquantitative, 259\nunsound, 280\nrecord\nﬁeld, 193\nrecursion\nmutual, 218\nrecursive call, 280\nreductio ad absurdum, 24, 119\nreduction to absurdity, 24\nreﬂexive, transitive closure, 167\nIndex\n425\nregular language, 405\nrelation\nbinary, 178\nEuclidean, 321, 327\nfunctional, 321\nlinear, 321\nreﬂexive, 140, 320, 324\nas formula, 109\nserial, 320, 353\nsymmetric, 320\nas formula, 109\ntotal, 321\ntransition, 178\ntransitive, 140, 320, 324\nas formula, 109\nrelational mu-calculus\nﬁxed-point operators, 392\nrequirement\ninformal, 258, 263, 288\nrequirements, 142\ngramming language you used a list of features of its software development envi-\nronment (compiler, editor, linker, run-time environment etc) that may improve\nthe likelihood that your programs work correctly. Try to rate the eﬀectiveness of\neach such feature.\n2. Repeat the previous exercise by listing and rating features that may decrease\nthe likelihood of procuding correct and reliable programs.\nExercises 4.2\n1.\n*\nIn what circumstances would if (B) {C1} else {C2} fail to terminate?\n2.\n*\nA familiar command missing from our language is the for-statement. It may be\nused to sum the elements in an array, for example, by programming as follows:\ns = 0;\nfor (i = 0; i <= max; i = i+1) {\ns = s + a[i];\n}\nAfter performing the initial assignment s = 0, this executes i = 0 ﬁrst, then\nexecutes the body s = s + a[i] and the incrementation i = i + 1 continually\nuntil i <= max becomes false. Explain how for (C1; B; C2) {C3} can be deﬁned\nas a derived program in our core language.\n3. Suppose that you need a language construct repeat {C} until (B) which re-\npeats C until B becomes true, i.e.\ni. executes C in the current state of the store;\nii. evaluates B in the resulting state of the store;\niii. if B is false, the program resumes with (i); otherwise, the program\nrepeat {C} until (B) terminates.\nThis construct sometimes allows more elegant code than a corresponding while-\nstatement.\n300\n4 Program verification\n(a) Deﬁne repeat C until B as a derived expression using our core language.\n(b) Can one deﬁne every repeat expression in our core language extended with\nfor-statements? (You might need the empty command skip which does noth-\ning.)\nExercises 4.3\n1. For any store l as in Example 4.4 (page 264), determine which of the relations\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds. In the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nExample 1.4 Let’s use these rules to prove that p ∧q, r |−q ∧r is valid.\nWe start by writing down the premises; then we leave a gap and write the\n1.2 Natural deduction\n7\nconclusion:\np ∧q\nr\nq ∧r\nThe task of constructing the proof is to ﬁll the gap between the premises\nand the conclusion by applying a suitable sequence of proof rules. In this\ncase, we apply ∧e2 to the ﬁrst premise, giving us q. Then we apply ∧i to this\nq and to the second premise, r, giving us q ∧r. That’s it! We also usually\nnumber all the lines, and write in the justiﬁcation for each line, producing\nthis:\n1\np ∧q\npremise\n2\nr\npremise\n3\nq\n∧e2 1\n4\nq ∧r\n∧i 3, 2\nDemonstrate to yourself that you’ve understood this by trying to show on\nyour own that (p ∧q) ∧r, s ∧t |−q ∧s is valid. Notice that the φ and ψ can\nbe instantiated not just to atomic sentences, like p and q in the example we\njust gave, but also to compound sentences. Thus, from (p ∧q) ∧r we can\ndeduce p ∧q by applying ∧e1, instantiating φ to p ∧q and ψ to r.\nIf we applied these proof rules literally, then the proof above would actu-\nally be a tree with root q ∧r and leaves p ∧q and r, like this:\np ∧q\n∧e2\nq\nr\n∧i\nq ∧r\nHowever, we ﬂattened this tree into a linear presentation which necessitates\nthe use of pointers as seen in lines 3 and 4 above. These pointers allow\nus to recreate the actual proof tree. Throughout this text, we will use the\nﬂattened version of presenting proofs. That way you have to concentrate only\non ﬁnding a proof, not on how to ﬁt a growing tree onto a sheet of paper.\nIf a sequent is valid, there may be many diﬀerent ways of proving it. So if\nyou compare your solution to these exercises with those of others, they need\nnot coincide. The important thing to realise, though, is that any putative\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nof proof, which states rules for transforming valid sequents into valid sequents.\nFor example, if we have already a proof for the sequent Γ, φ ⊢ψ, then we ob-\ntain a proof of the sequent Γ ⊢φ →ψ by augmenting this very proof with one\napplication of the rule →i. The new approach expresses this as an inference rule\nbetween sequents:\nΓ, φ ⊢ψ\nΓ ⊢φ →ψ →i.\nThe rule ‘assumption’ is written as\nφ ⊢φ assumption\ni.e. the premise is empty. Such rules are called axioms.\n(a) Express all remaining proof rules of Figure 1.2 in such a form. (Hint: some\nof your rules may have more than one premise.)\n(b) Explain why proofs of Γ ⊢ψ in this new system have a tree-like structure\nwith Γ ⊢ψ as root.\n(c) Prove p ∨(p ∧q) ⊢p in your new proof system.\n1.7 Exercises\n81\n7. Show that\n√\n2 cannot be a rational number. Proceed by proof by contradiction:\nassume that\n√\n2 is a fraction k/l with integers k and l ̸= 0. On squaring both sides\nwe get 2 = k2/l2, or equivalently 2l2 = k2. We may assume that any common 2\nfactors of k and l have been cancelled. Can you now argue that 2l2 has a diﬀerent\nnumber of 2 factors from k2? Why would that be a contradiction and to what?\n8. There is an alternative approach to treating negation. One could simply ban the\noperator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally,\nsuch a logic cannot rely on the natural deduction rules for negation. Which of\nthe rules ¬i, ¬e, ¬¬e and ¬¬i can you simulate with the remaining proof rules\nby letting ¬φ be φ →⊥?\n9. Let us introduce a new connective φ ↔ψ which should abbreviate (φ →ψ) ∧\n(ψ →φ). Design introduction and elimination rules for ↔and show that they\nare derived rules if φ ↔ψ is interpreted as (φ →ψ) ∧(ψ →φ).\nExercises 1.3\nIn order to facilitate reading these exercises we assume below the usual\nconventions about binding priorities agreed upon in Convention 1.3.\n1. Given the following formulas, draw their corresponding parse tree:\n(a) p\n(b)\n*\np ∧q\n(c) p ∧¬q →¬p\n(d)\n*\np ∧(¬q →¬p)\n(e) p →(¬q ∨(q →p))\n(f)\nassertion can be true about a procedure while that same procedure could\ncompute strange things or crash in the case that the input is not an in-\nteger. Showing p →q using the rule →i is now called type checking, an\nimportant topic in the construction of compilers for typed programming\nlanguages.\nWe thus formulate the rule →i as follows:\nφ\n...\nψ\nφ →ψ\n→i.\nIt says: in order to prove φ →ψ, make a temporary assumption of φ and then\nprove ψ. In your proof of ψ, you can use φ and any of the other formulas\nsuch as premises and provisional conclusions that you have made so far.\nProofs may nest boxes or open new boxes after old ones have been closed.\nThere are rules about which formulas can be used at which points in the\nproof. Generally, we can only use a formula φ in a proof at a given point if\nthat formula occurs prior to that point and if no box which encloses that\noccurrence of φ has been closed already.\nThe line immediately following a closed box has to match the pattern\nof the conclusion of the rule that uses the box. For implies-introduction,\nthis means that we have to continue after the box with φ →ψ, where φ\nwas the ﬁrst and ψ the last formula of that box. We will encounter two\nmore proof rules involving proof boxes and they will require similar pattern\nmatching.\n1.2 Natural deduction\n13\nExample 1.9 Here is another example of a proof using →i:\n1\n¬q →¬p\npremise\n2\np\nassumption\n3\n¬¬p\n¬¬i 2\n4\n¬¬q\nMT 1, 3\n5\np →¬¬q\n→i 2−4\nwhich veriﬁes the validity of the sequent ¬q →¬p ⊢p →¬¬q. Notice that\nwe could apply the rule MT to formulas occurring in or above the box: at\nline 4, no box has been closed that would enclose line 1 or 3.\nAt this point it is instructive to consider the one-line argument\n1\np\npremise\nwhich demonstrates p ⊢p. The rule →i (with conclusion φ →ψ) does not\nprohibit the possibility that φ and ψ coincide. They could both be instanti-\nated to p. Therefore we may extend the proof above to\n1\np\nassumption\n2\np →p\n→i 1 −1\ny + 1 < 3 + 1 = 4.\nWe may use ordinary logical and arithmetic implications to change a certain\ncondition φ to any condition φ′ which is implied by φ for reasons which have\nnothing to do with the given code. In the example above, φ was y < 3 and the\nimplied formula φ′ was then y + 1 < 4. The validity of ⊢AR (y < 3) →(y + 1 <\n4) is rooted in general facts about integers and the relation < deﬁned on them.\nCompletely formal proofs would require separate proofs attached to all instances\nof the rule Implied. As already said, we won’t do that here as this chapter focuses\non aspects of proofs which deal directly with code.\n3.\nFor the sequential composition of assignment statements\nz = x;\nz = z + y;\nu = z;\nour goal is to show that u stores the sum of x and y after this sequence of\nassignments terminates. Let us write P for the code above. Thus, we mean to\nprove ⊢par\n\u0001\n⊤\n\u0002\nP\n\u0001\nu = x + y\n\u0002\n.\nWe construct the proof by starting with the postcondition u = x + y and\npushing it up through the assignments, in reverse order, using the assignment\nrule.\n– Pushing it up through u = z involves replacing all occurrences of u by z,\nresulting in z = x + y. We thus have the proof fragment\n\u0001\nz = x + y\n\u0002\nu = z;\n\u0001\nu = x + y\n\u0002\nAssignment\n– Pushing z = x + y upwards through z = z + y involves replacing z by z + y,\nresulting in z + y = x + y.\n4.3 Proof calculus for partial correctness\n279\n– Pushing that upwards through z = x involves replacing z by x, resulting in\nx + y = x + y. The proof fragment now looks like this:\n\u0001\nx + y = x + y\n\u0002\nz = x;\n\u0001\nz + y = x + y\n\u0002\nAssignment\nz = z + y;\n\u0001\nz = x + y\n\u0002\nAssignment\nu = z;\n\u0001\nu = x + y\n\u0002\nAssignment\nThe weakest precondition that thus emerges is x + y = x + y; we have to check\nthat this follows from the given precondition ⊤. This means checking that any\nstate that satisﬁes ⊤also satisﬁes x + y = x + y. Well, ⊤is satisﬁed in all states,\nbut so is x + y = x + y, so the sequent ⊢AR ⊤→(x + y = x + y) is valid.\nThe ﬁnal completed proof therefore looks like this:\n\u0001\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nThis rule looks rather similar to ¬i, except that the negation is in a diﬀerent\nplace. This is the clue to how to derive PBC from our basic proof rules.\nSuppose we have a proof of ⊥from ¬φ. By →i, we can transform this into\na proof of ¬φ →⊥and proceed as follows:\n1\n¬φ →⊥\ngiven\n2\n¬φ\nassumption\n3\n⊥\n→e 1, 2\n4\n¬¬φ\n¬i 2−3\n5\nφ\n¬¬e 4\nThis shows that PBC can be derived from →i, ¬i, →e and ¬¬e.\nThe ﬁnal derived rule we consider in this section is arguably the most\nuseful to use in proofs, because its derivation is rather long and complicated,\nso its usage often saves time and eﬀort. It also has a Latin name, tertium\nnon datur; the English name is the law of the excluded middle, or LEM for\nshort. It simply says that φ ∨¬φ is true: whatever φ is, it must be either true\nor false; in the latter case, ¬φ is true. There is no third possibility (hence\nexcluded middle): the sequent ⊢φ ∨¬φ is valid. Its validity is implicit, for\nexample, whenever you write an if-statement in a programming language:\n‘if B {C1} else {C2}’ relies on the fact that B ∨¬B is always true (and\nthat B and ¬B can never be true at the same time). Here is a proof in\nnatural deduction that derives the law of the excluded middle from basic\nproof rules:\n1\n¬(φ ∨¬φ)\nassumption\n2\nφ\nassumption\n3\nφ ∨¬φ\n∨i1 2\n4\n⊥\n¬e 3, 1\n5\n¬φ\n¬i 2−4\n6\nφ ∨¬φ\n∨i2 5\n7\n⊥\n¬e 6, 1\n8\n¬¬(φ ∨¬φ)\n¬i 1−7\n9\nφ ∨¬φ\n¬¬e 8\n26\n1 Propositional logic\nExample 1.24 Using LEM, we show that p →q ⊢¬p ∨q is valid:\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\non the program logic. Mostly, the implications we typically encounter will\nbe easy to verify.\nThe Implied rule is often used to simplify formulas that are generated by\napplications of the other rules. It is also used when the weakest precondition\nφ′ emerges by pushing the postcondition upwards through the whole pro-\ngram. We use the Implied rule to show that the given precondition implies\nthe weakest precondition. Let’s look at some examples of this.\nExamples 4.13\n1.\nWe show that ⊢par\n\u0001\ny = 5\n\u0002\nx = y + 1\n\u0001\nx = 6\n\u0002\nis valid:\n\u0001\ny = 5\n\u0002\n\u0001\ny + 1 = 6\n\u0002\nImplied\nx = y + 1\n\u0001\nx = 6\n\u0002\nAssignment\nThe proof is constructed from the bottom upwards. We start with\n\u0001\nx = 6\n\u0002\nand, using the assignment axiom, we push it upwards through x = y + 1. This\nmeans substituting y + 1 for all occurrences of x, resulting in\n\u0001\ny + 1 = 6\n\u0002\n. Now,\nwe compare this with the given precondition\n\u0001\ny = 5\n\u0002\n. The given precondition\nand the arithmetic fact 5 + 1 = 6 imply it, so we have ﬁnished the proof.\n278\n4 Program verification\nAlthough the proof is constructed bottom-up, its justiﬁcations make sense\nwhen read top-down: the second line is implied by the ﬁrst and the fourth\nfollows from the second by the intervening assignment.\n2.\nWe prove the validity of ⊢par\n\u0001\ny < 3\n\u0002\ny = y + 1\n\u0001\ny < 4\n\u0002\n:\n\u0001\ny < 3\n\u0002\n\u0001\ny + 1 < 4\n\u0002\nImplied\ny = y + 1;\n\u0001\ny < 4\n\u0002\nAssignment\nNotice that Implied always refers to the immediately preceding line. As already\nremarked, proofs in program logic generally combine two logical levels: the ﬁrst\nlevel is directly concerned with proof rules for programming constructs such as\nthe assignment statement; the second level is ordinary entailment familiar to\nus from Chapters 1 and 2 plus facts from arithmetic – here that y < 3 implies\ny + 1 < 3 + 1 = 4.\nWe may use ordinary logical and arithmetic implications to change a certain\ncondition φ to any condition φ′ which is implied by φ for reasons which have\nnothing to do with the given code. In the example above, φ was y < 3 and the\n1\np\npremise\nwhich demonstrates p ⊢p. The rule →i (with conclusion φ →ψ) does not\nprohibit the possibility that φ and ψ coincide. They could both be instanti-\nated to p. Therefore we may extend the proof above to\n1\np\nassumption\n2\np →p\n→i 1 −1\nWe write ⊢p →p to express that the argumentation for p →p does not\ndepend on any premises at all.\nDeﬁnition 1.10 Logical formulas φ with valid sequent ⊢φ are theorems.\nExample 1.11 Here is an example of a theorem whose proof utilises most\nof the rules introduced so far:\n1\nq →r\nassumption\n2\n¬q →¬p\nassumption\n3\np\nassumption\n4\n¬¬p\n¬¬i 3\n5\n¬¬q\nMT 2, 4\n6\nq\n¬¬e 5\n7\nr\n→e 1, 6\n8\np →r\n→i 3−7\n9\n(¬q →¬p) →(p →r)\n→i 2−8\n10\n(q →r) →((¬q →¬p) →(p →r))\n→i 1−9\n14\n1 Propositional logic\nq →r\n→\n→\n→\n¬q →¬p\nr\np\nFigure 1.1. Part of the structure of the formula (q →r) →((¬q →¬p) →\n(p →r)) to show how it determines the proof structure.\nTherefore the sequent\n⊢(q →r) →((¬q →¬p) →(p →r)) is valid,\nshowing that (q →r) →((¬q →¬p) →(p →r)) is another theorem.\nRemark 1.12 Indeed, this example indicates that we may transform any\nproof of φ1, φ2, . . . , φn ⊢ψ in such a way into a proof of the theorem\n⊢φ1 →(φ2 →(φ3 →(· · · →(φn →ψ) . . . )))\nby ‘augmenting’ the previous proof with n lines of the rule →i applied to\nφn, φn−1,. . . , φ1 in that order.\nThe nested boxes in the proof of Example 1.11 reveal a pattern of using\nelimination rules ﬁrst, to deconstruct assumptions we have made, and then\nintroduction rules to construct our ﬁnal conclusion. More diﬃcult proofs\nmay involve several such phases.\nLet us dwell on this important topic for a while. How did we come up\nwith the proof above? Parts of it are determined by the structure of the for-\nmulas we have, while other parts require us to be creative. Consider the log-\nical structure of (q →r) →((¬q →¬p) →(p →r)) schematically depicted\nin Figure 1.1. The formula is overall an implication since →is the root of\nthe tree in Figure 1.1. But the only way to build an implication is by means\n1.2 Natural deduction\n15 this has to be taken into account by the calculus.\n288\n4 Program verification\nwrite Si,j for the sum of that section: a[i] + a[i + 1] + · · · + a[j]. A minimal-\nsum section is a section a[i], . . . , a[j] of a such that the sum Si,j is less than\nor equal to the sum Si′,j′ of any other section a[i′], . . . , a[j′] of a.\nExample 4.19 Let us illustrate these concepts on the example integer array\n[−1, 3, 15, −6, 4, −5]. Both [3, 15, −6] and [−6] are sections, but [3, −6, 4]\nisn’t since 15 is missing. A minimal-sum section for this particular array is\n[−6, 4, −5] with sum −7; it is the only minimal-sum section in this case.\nIn general, minimal-sum sections need not be unique. For example, the\narray [1, −1, 3, −1, 1] has two minimal-sum sections [1, −1] and [−1, 1] with\nminimal sum 0.\nThe task at hand is to\nr write a program Min Sum, written in our core programming language extended\nwith integer arrays, which computes the sum of a minimal-sum section of a given\narray;\nr make the informal requirement of this problem, given in the previous item, into\na formal speciﬁcation about the behaviour of Min Sum;\nr use our proof calculus for partial correctness to show that Min Sum satisﬁes those\nformal speciﬁcations provided that it terminates.\nThere is an obvious program to do the job: we could list all the possible\nsections of a given array, then traverse that list to compute the sum of\neach section and keep the recent minimal sum in a storage location. For the\nexample array [−1, 3, −2], this results in the list\n[−1], [−1, 3], [−1, 3, −2], [3], [3, −2], [−2]\nand we see that only the last section [−2] produces the minimal sum −2.\nThis idea can easily be coded in our core programming language, but it\nhas a serious drawback: the number of sections of a given array of size n is\nproportional to the square of n; if we also have to sum all those, then our task\nhas worst-case time complexity of the order n · n2 = n3. Computationally,\nthe range of indexes of the array and t stores the minimal sum of sections\nthat end at a[k] – whenever the control ﬂow of the program is about to\nevaluate the boolean expression of its while-statement. As each new value is\nexamined, we can either add it to the current minimal sum, or decide that a\nlower minimal sum can be obtained by starting a new section. The variable\ns stores the minimal sum seen so far; it is computed as the minimum we\nhave seen so far in the last step, or the minimal sum of sections that end at\nthe current point.\nAs you can see, it not intuitively clear that this program is correct, war-\nranting the use of our partial-correctness calculus to prove its correctness.\nTesting the program with a few examples is not suﬃcient to ﬁnd all mis-\ntakes, however, and the reader would rightly not be convinced that this\nprogram really does compute the minimal-sum section in all cases. So let\nus try to use the partial-correctness calculus introduced in this chapter to\nprove it.\n290\n4 Program verification\nWe formalise our requirement of the program as two speciﬁcations6, writ-\nten as Hoare triples.\nS1.\n\u0001\n⊤\n\u0002\nMin Sum\n\u0001\n∀i, j (0 ≤i ≤j < n →s ≤Si,j)\n\u0002\n.\nIt says that, after the program terminates, s is less than or equal to, the\nsum of any section of the array. Note that i and j are logical variables\nin that they don’t occur as program variables.\nS2.\n\u0001\n⊤\n\u0002\nMin Sum\n\u0001\n∃i, j (0 ≤i ≤j < n ∧s = Si,j)\n\u0002\n,\nwhich says that there is a section whose sum is s.\nIf there is a section whose sum is s and no section has a sum less than s,\nthen s is the sum of a minimal-sum section: the ‘conjunction’ of S1 and S2\ngive us the property we want.\nLet us ﬁrst prove S1. This begins with seeking a suitable invariant. As\nalways, the following characteristics of invariants are a useful guide:\nr Invariants express the fact that the computation performed so far by the while-\nstatement is correct.\nr Invariants typically have the same form as the desired postcondition of the while-\nstatement.\nt = a[0];\n(Inv1(a[0], k) ∧Inv2(t, k))\nAssignment\ns = a[0];\n(Inv1(s, k) ∧Inv2(t, k))\nAssignment\nwhile (k != n) {\n(Inv1(s, k) ∧Inv2(t, k) ∧k ̸= n)\nInvariant Hyp. ∧guard\n(Inv1(min(s, min(t + a[k], a[k])), k + 1)\n∧Inv2(min(t + a[k], a[k]), k + 1))\nImplied (Lemma 4.20)\nt = min(t + a[k], a[k]);\n(Inv1(min(s, t), k + 1) ∧Inv2(t, k + 1))\nAssignment\ns = min(s,t);\n(Inv1(s, k + 1) ∧Inv2(t, k + 1))\nAssignment\nk = k + 1;\n(Inv1(s, k) ∧Inv2(t, k))\nAssignment\n}\n(Inv1(s, k) ∧Inv2(t, k) ∧¬¬(k = n))\nPartial-while\n(Inv1(s, n))\nImplied\nFigure 4.3. Tableau proof for specification S1 of Min Sum.\ncomputation is\nInv2(t, k)\ndef\n= ∀i (0 ≤i < k →t ≤Si,k−1)\n(4.13)\nsaying that t is not greater than the sum of any section ending in a[k −1].\nOur invariant is the conjunction of these formulas, namely\nInv1(s, k) ∧Inv2(t, k).\n(4.14)\nThe completed proof tableau of S1 for Min Sum is given in Figure 4.3. The\ntableau is constructed by\nr Proving that the candidate invariant (4.14) is indeed an invariant. This involves\npushing it upwards through the body of the while-statement and showing that\nwhat emerges follows from the invariant and the boolean guard. This non-trivial\nimplication is shown in the proof of Lemma 4.20.\nr Proving that the invariant, together with the negation of the boolean guard, is\nstrong enough to prove the desired postcondition. This is the last implication of\nthe proof tableau.\n292\n4 Program verification\nr Proving that the invariant is established by the code before the while-statement.\nWe simply push it upwards through the three initial assignments and check that\nthe resulting formula is implied by the precondition of the speciﬁcation, here ⊤.\nAs so often the case, in constructing the tableau, we ﬁnd that two formulas\nmeet; and we have to prove that the ﬁrst one implies the second one. Some-\ntimes this is easy and we can just note the implication in the tableau. For\nexample, we readily see that ⊤implies Inv1(a[0], 1) ∧Inv2(a[0], 1): k being\nhas a serious drawback: the number of sections of a given array of size n is\nproportional to the square of n; if we also have to sum all those, then our task\nhas worst-case time complexity of the order n · n2 = n3. Computationally,\nthis is an expensive price to pay, so we should inspect the problem more\nclosely in order to see whether we can do better.\nCan we compute the minimal sum over all sections in time proportional\nto n, by passing through the array just once? Intuitively, this seems diﬃcult,\nsince if we store just the minimal sum seen so far as we pass through the\narray, we may miss the opportunity of some large negative numbers later on\nbecause of some large positive numbers we encounter en route. For example,\n4.3 Proof calculus for partial correctness\n289\nsuppose the array is\n[−8, 3, −65, 20, 45, −100, −8, 17, −4, −14].\nShould we settle for −8 + 3 −65, or should we try to take advantage of the\n−100 – remembering that we can pass through the array only once? In this\ncase, the whole array is a section that gives us the smallest sum, but it\nis diﬃcult to see how a program which passes through the array just once\ncould detect this.\nThe solution is to store two values during the pass: the minimal sum seen\nso far (s in the program below) and also the minimal sum seen so far of\nall sections which end at the current point in the array (t below). Here is a\nprogram that is intended to do this:\nk = 1;\nt = a[0];\ns = a[0];\nwhile (k != n) {\nt = min(t + a[k], a[k]);\ns = min(s,t);\nk = k + 1;\n}\nwhere min is a function which computes the minimum of its two arguments\nas speciﬁed in exercise 10 on page 301. The variable k proceeds through\nthe range of indexes of the array and t stores the minimal sum of sections\nthat end at a[k] – whenever the control ﬂow of the program is about to\nevaluate the boolean expression of its while-statement. As each new value is\nexamined, we can either add it to the current minimal sum, or decide that a\nwhile (r >= y) {\nr = r - y;\nd = d + 1;\n}\nShow that ⊢par\n\u0001\n¬(y = 0)\n\u0002\nDiv\n\u0001\n(x = d · y + r) ∧(r < y)\n\u0002\nis valid.\n18.\n*\nShow that ⊢par\n\u0001\nx ≥0\n\u0002\nDownfac\n\u0001\ny = x!\n\u0002\nis valid7, where Downfac is:\na = x;\ny = 1;\nwhile (a > 0) {\ny = y * a;\na = a - 1;\n}\n19. Why can, or can’t, you prove the validity of ⊢par\n\u0001\n⊤\n\u0002\nCopy1\n\u0001\nx = y\n\u0002\n?\n20. Let all while-statements while (B) {C} in P be annotated with invariant\ncandidates η at the and of their bodies, and η ∧B at the beginning of their\nbody.\n(a) Explain how a proof of ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\ncan be automatically reduced to show-\ning the validity of some ⊢AR ψ1 ∧· · · ∧ψn.\n(b) Identify such a sequent ⊢AR ψ1 ∧· · · ∧ψn for the proof in Example 4.17 on\npage 287.\n21. Given n = 5 test the correctness of Min Sum on the arrays below:\n(a)\n*\n[−3, 1, −2, 1, −8]\n(b) [1, 45, −1, 23, −1]\n(c)\n*\n[−1, −2, −3, −4, 1097].\n22. If we swap the ﬁrst and second assignment in the while-statement of Min Sum,\nso that it ﬁrst assigns to s and then to t, is the program still correct? Justify\nyour answer.\n23.\n*\nProve the partial correctness of S2 for Min Sum.\n24. The program Min Sum does not reveal where a minimal-sum section may be\nfound in an input array. Adapt Min Sum to achieve that. Can you do this with\na single pass through the array?\n25. Consider the proof rule\n\u0001\nφ\n\u0002\nC\n\u0001\nψ1\n\u0002\n\u0001\nφ\n\u0002\nC\n\u0001\nψ2\n\u0002\n\u0001\nφ\n\u0002\nC\n\u0001\nψ1 ∧ψ2\n\u0002\nConj\n7 You may have to strengthen your invariant.\n4.6 Exercises\n303\nfor Hoare triples.\n(a) Show that this proof rule is sound for ⊨par.\n(b) Derive this proof rule from the ones on page 270.\n(c) Explain how this rule, or its derived version, is used to establish the overall\ncorrectness of Min Sum.\n26. The maximal-sum problem is to compute the maximal sum of all sections on\nan array.\n(a) Adapt the program from page 289 so that it computes the maximal sum of\nthese sections.\n(b) Prove the partial correctess of your modiﬁed program.\n(c) Which aspects of the correctness proof given in Figure 4.3 (page 291) can\nbe ‘re-used?’\nExercises 4.4",
            "summary": "of R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor q",
            "children": [
                {
                    "id": "chapter-4-section-1",
                    "title": "Why Should We Specify and Verify Code?",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-4-section-2",
                    "title": "A Framework for Software Verification",
                    "content": "of R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nstatements, while-statements and sequential compositions. Everything that\ncan be computed by large languages like C and Java can also be computed\nby our language, though perhaps not as conveniently, because it does not\nhave any objects, procedures, threads or recursive data structures. While\nthis makes it seem unrealistic compared with fully blown commercial lan-\nguages, it allows us to focus our discussion on the process of formal program\nveriﬁcation. The features missing from our language could be implemented\non top of it; that is the justiﬁcation for saying that they do not add to the\npower of the language, but only to the convenience of using it. Verifying\nprograms using those features would require non-trivial extensions of the\nproof calculus we present here. In particular, dynamic scoping of variables\npresents hard problems for program-veriﬁcation methods, but this is beyond\nthe scope of this book.\nOur core language has three syntactic domains: integer expressions,\nboolean expressions and commands – the latter we consider to be our\nprograms. Integer expressions are built in the familiar way from variables\nx, y, z, . . . , numerals 0, 1, 2, . . . , −1, −2, . . . and basic operations like addition\n(+) and multiplication (∗). For example,\n5\nx\n4 + (x −3)\nx + (x ∗(y −(5 + z)))\nare all valid integer expressions. Our grammar for generating integer expres-\nsions is\nE ::=\nn | x | (−E) | (E + E) | (E −E) | (E ∗E)\n(4.1)\nwhere n is any numeral in {. . . , −2, −1, 0, 1, 2, . . . } and x is any variable.\nNote that we write multiplication in ‘mathematics’ as 2 · 3, whereas our\ncore language writes 2 ∗3 instead.\nConvention 4.1 In the grammar above, negation −binds more tightly\ngramming language you used a list of features of its software development envi-\nronment (compiler, editor, linker, run-time environment etc) that may improve\nthe likelihood that your programs work correctly. Try to rate the eﬀectiveness of\neach such feature.\n2. Repeat the previous exercise by listing and rating features that may decrease\nthe likelihood of procuding correct and reliable programs.\nExercises 4.2\n1.\n*\nIn what circumstances would if (B) {C1} else {C2} fail to terminate?\n2.\n*\nA familiar command missing from our language is the for-statement. It may be\nused to sum the elements in an array, for example, by programming as follows:\ns = 0;\nfor (i = 0; i <= max; i = i+1) {\ns = s + a[i];\n}\nAfter performing the initial assignment s = 0, this executes i = 0 ﬁrst, then\nexecutes the body s = s + a[i] and the incrementation i = i + 1 continually\nuntil i <= max becomes false. Explain how for (C1; B; C2) {C3} can be deﬁned\nas a derived program in our core language.\n3. Suppose that you need a language construct repeat {C} until (B) which re-\npeats C until B becomes true, i.e.\ni. executes C in the current state of the store;\nii. evaluates B in the resulting state of the store;\niii. if B is false, the program resumes with (i); otherwise, the program\nrepeat {C} until (B) terminates.\nThis construct sometimes allows more elegant code than a corresponding while-\nstatement.\n300\n4 Program verification\n(a) Deﬁne repeat C until B as a derived expression using our core language.\n(b) Can one deﬁne every repeat expression in our core language extended with\nfor-statements? (You might need the empty command skip which does noth-\ning.)\nExercises 4.3\n1. For any store l as in Example 4.4 (page 264), determine which of the relations\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\nalone must take responsibility for those.\nAdded for second edition\nMany people have helped improve this text by pointing out typos and\nmaking other useful comments after the publication date. Among them,\nxiii\nxiv\nAcknowledgements\nwe mention Wolfgang Ahrendt, Yasuhiro Ajiro, Torben Amtoft, Stephan\nAndrei, Bernhard Beckert, Jonathan Brown, James Caldwell, Ruchira Datta,\nAmy Felty, Dimitar Guelev, Hirotsugu Kakugawa, Kamran Kashef, Markus\nKr¨otzsch, Jagun Kwon, Ranko Lazic, David Makinson, Alexander Miczo,\nAart Middeldorp, Robert Morelli, Prakash Panangaden, Aileen Paraguya,\nFrank Pfenning, Shekhar Pradhan, Koichi Takahashi, Kazunori Ueda,\nHiroshi Watanabe, Fuzhi Wang and Reinhard Wilhelm.\n1\nPropositional logic\nThe aim of logic in computer science is to develop languages to model the\nsituations we encounter as computer science professionals, in such a way\nthat we can reason about them formally. Reasoning about situations means\nconstructing arguments about them; we want to do this formally, so that\nthe arguments are valid and can be defended rigorously, or executed on a\nmachine.\nConsider the following argument:\nExample 1.1 If the train arrives late and there are no taxis at the station,\nthen John is late for his meeting. John is not late for his meeting. The train\ndid arrive late. Therefore, there were taxis at the station.\nIntuitively, the argument is valid, since if we put the ﬁrst sentence and\nthe third sentence together, they tell us that if there are no taxis, then John\nwill be late. The second sentence tells us that he was not late, so it must be\nthe case that there were taxis.\nMuch of this book will be concerned with arguments that have this struc-\nture, namely, that consist of a number of sentences followed by the word\n‘therefore’ and then another sentence. The argument is valid if the sentence\nafter the ‘therefore’ logically follows from the sentences before it. Exactly\nwhat we mean by ‘follows from’ is the subject of this chapter and the next\none.\naxiomatic, 91\ncommercially critical, 172, 257\ncomponent, 206\nconcurrent, 173\ndebugging, 174\ndescription, 193\ndesign, 174\ndevelopment, 173\nelevator, 184, 215\nﬁnite-state, 256\nhybrid, 277\ninﬁnite-state, 256\nmission-critical, 172\nmulti-agent, 331\nphysical, 175\nreactive, 173, 257, 358\nsafety-critical, 172, 257\ntransition, 174\nveriﬁcation, 256\ntautology, 50\ntemporal connective\nAF, 212\nAG, 211\nAU, 212\nAX, 211\nEF, 212\nEG, 211\nEU, 212\nEX, 211\ntemporal connectives, 176\ntemporal logic, 174, 306\nterm, 99\ninterpretation, 128\nterm-rewriting system, 170\ntermination\nCollatz 3n + 1, 295\nproof, 266\ntertium non datur, 25\ntheorem, 13\nprover, 106, 136\nproving, 170\ntime\ncontinuous, 174\ndiscrete, 174\ntop\nmarking, 66\ntotal correctness, 265, 266\ntransition relation, 178\nfor SMV programs, 388\ntransition system, 174\nof ABP program, 247\nof Mutex code, 198\nof SMV program, 192\nunwinding, 180, 212, 222\nIndex\n427\ntranslation\nEnglish into predicate logic, 95, 101\ntree\ninﬁnite, 180, 212\ntruth\ndynamic, 174\nmode, 306, 308\nof knowledge, 326\nstatic, 174\nvalue\nfor predicate logic, 127\nfor propositional logic, 3\ntruth table\nfor conjunction, 37\ntruth tables, 38\ntype, 12, 327\nchecking, 12\ntheory, 170\nunary connective, 307\nundecidability\nof provability, 136\nof satisﬁability, 135\nof validity in predicate logic, 133\nuniversal quantiﬁcation, 268\nuniversal quantiﬁer, 216\nuniversal second-order logic, 140, 156\nuniverse of concrete values, 124\nunreachability, 140\nunsound sequent, 164\nUntil\nin natural language, 182\nnegating, 187\nupdated valuation, 391\nvalid sequent\nof modal logic, 330\npartial correctness, 267\ntotal correctness, 267\nvalidity\nin basic modal logic, 314\nin KT45n, 339\nin propositional logic, 85\nundecidability in predicate logic, 133\nvaluation\nfor propositional logic, 37\nin predicate logic, 123\nin relational mu-calculus, 391\nvalue\ninitial, 206, 268, 269\nVardi, M., 254\nvariable, 94, 260\nboolean, 229, 247, 358\nbound, 103\ncapture, 106\ndummy, 110\nfree, 103\nlocal, 263\nlogical, 268, 290\nvariable ordering\nsmall scope hypothesis, 143\nSMV, 254\nmain program for ABP, 207\nmodule, 193\nreceiver, 205\nsender, 204\nfor channel, 206\ninstantiation, 193\nprocess, 389\nprogram\nexample, 192\nfor Mutex, 195\nspeciﬁcation, 192\nsoftware\nlife-cycle, 142\nmicromodel, 142\nreliability, 149\nrequirements, 142\nspeciﬁcation, 142\nvalidation, 142\nsoundness\nof forall-elimination, 109\nof natural deduction\nbasic modal logic, 354\npredicate logic, 96, 122\npropositional logic, 45\nof program logics, 267\nof proof rule for while-statements,\n282\nof the substitution principle, 108\n426\nIndex\nspeciﬁcation\nfor ABP, 207\nformal, 259\ninformal, 259\nlanguage, 172\nof a predicate, 157\npatterns, 254\npractical pattern, 183, 215\ntruth table, 58\nspeciﬁcations, 191\nSpin, 254\nstate\ncritical, 188\nexplosion, 229\nexplosion problem, 254\nfair, 397\nﬁnal, 142\nformula, 218\nglobal, 188\ngraph, 180\ninitial, 142, 189, 222, 247, 252, 264\nnon-critical, 188\nof a system, 269\nof core program, 264\nreachable, 247\nresulting, 263, 299\nspace, 229\nsplitting states, 190\ntransition, 142\ntrying, 188\nstate machine, 142\nstorage\nlocation, 288\nstate, 261\nstore\nof core program, 264\nstring, 247, 307\nbinary, 126, 132\nempty, 126\nstrongly connected component, 225\nstructural equality, 153\nstructural induction, 44, 51\nsubformula, 178\nsubstitution\nin predicate logic, 105\ninstance, 323\ninstance of tautology, 314\nprinciple, 108\nsymbolic model checking, 383\nsyntactic\ndomain, 260, 261\nsyntax\nof basic modal logic, 307\nof boolean expressions, 261\nof boolean formulas, 398\nof CTL, 208\nof CTL*, 218\nof KT45n, 335\nof LTL, 175\nof predicate logic, 100\nof propositional logic, 33\nof relational mu-calculus, 390\nof terms, 99\nsystem\nasynchronous, 254\ninterleaving model, 389\nsimultaneous model, 389\naxiomatic, 91\ncommercially critical, 172, 257\ncomponent, 206\nconcurrent, 173\ndebugging, 174\ndescription, 193\ndesign, 174\ndevelopment, 173\nelevator, 184, 215\nﬁnite-state, 256\nhybrid, 277\ninﬁnite-state, 256\nmission-critical, 172\nmulti-agent, 331\nphysical, 175\nreactive, 173, 257, 358\nLogic Programming, volume 1. Oxford University Press, 1993.\nFit96. M. Fitting. First-Order Logic and Automated Theorem Proving.\nSpringer, 2nd edition, 1996.\nFra92. N. Francez. Program Veriﬁcation. Addison-Wesley, 1992.\nFre03. G. Frege. Grundgesetze der Arithmetik, begriﬀsschriftlich abgeleitet.\n1903. Volumes I and II (Jena).\nGal87. J. H. Gallier. Logic for Computer Science. John Wiley, 1987.\nGen69. G. Gentzen. Investigations into logical deduction. In M. E. Szabo,\neditor, The Collected Papers of Gerhard Gentzen, chapter 3, pages\n68–129. North-Holland Publishing Company, 1969.\nGol87. R. Goldblatt. Logics of Time and Computation. CSLI Lecture Notes,\n1987.\nGri82. D. Gries. A note on a standard strategy for developing loop invariants\nand loops. Science of Computer Programming, 2:207–214, 1982.\nHam78. A. G. Hamilton. Logic for Mathematicians. Cambridge University\nPress, 1978.\nHoa69. C. A. R. Hoare. An axiomatic basis for computer programming.\nCommunications of the ACM, 12:576–580, 1969.\nHod77. W. Hodges. Logic. Penguin Books, 1977.\nHod83. W. Hodges. Elementary predicate logic. In D. Gabbay and\nF. Guenthner, editors, Handbook of Philosophical Logic, volume 1.\nDordrecht: D. Reidel, 1983.\n416\nBibliography\nHol90. G. Holzmann. Design and Validation of Computer Protocols. Prentice\nHall, 1990.\nJSS01. D. Jackson, I. Shlyakhter, and M. Sridharan. A Micromodularity\nMechanism. In Proceedings of the ACM SIGSOFT Conference on the\nFoundations of Software Engineering/European Software Engineering\nConference (FSE/ESEC’01), September 2001.\nKoz83. D. Kozen. Results on the propositional mu-calculus. Theoretical\nComputer Science, 27:333–354, 1983.\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983. \u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis satisﬁed under partial correctness if, for all states which satisfy φ, the\nstate resulting from P’s execution satisﬁes the postcondition ψ, provided\nthat P actually terminates. In this case, the relation ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\nWe call ⊨par the satisfaction relation for partial correctness.\nThus, we insist on ψ being true of the resulting state only if the program P\nhas terminated on an input satisfying φ. Partial correctness is rather a weak\nrequirement, since any program which does not terminate at all satisﬁes its\n266\n4 Program verification\nspeciﬁcation. In particular, the program\nwhile true { x = 0; }\n– which endlessly ‘loops’ and never terminates – satisﬁes all speciﬁcations,\nsince partial correctness only says what must happen if the program termi-\nnates.\nTotal correctness, on the other hand, requires that the program terminates\nin order for it to satisfy a speciﬁcation.\nDeﬁnition 4.6 (Total correctness) We say that the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis\nsatisﬁed under total correctness if, for all states in which P is executed which\nsatisfy the precondition φ, P is guaranteed to terminate and the resulting\nstate satisﬁes the postcondition ψ. In this case, we say that ⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds and call ⊨tot the satisfaction relation of total correctness.\nA program which ‘loops’ forever on all input does not satisfy any spec-\niﬁcation under total correctness. Clearly, total correctness is more useful\nthan partial correctness, so the reader may wonder why partial correctness\nis introduced at all. Proving total correctness usually beneﬁts from prov-\ning partial correctness ﬁrst and then proving termination. So, although our\nprimary interest is in proving total correctness, it often happens that we\nhave to or may wish to split this into separate proofs of partial correctness\nand of termination. Most of this chapter is devoted to the proof of partial\ncorrectness, though we return to the issue of termination in Section 4.4.\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\n3. Let the relation P ⊢l ; l′ hold iﬀP’s execution in store l terminates, resulting\nin store l′. Use this formal judgment P ⊢l ; l′ along with the relation l ⊨φ to\ndeﬁne ⊨par and ⊨tot symbolically.\n4. Another reason for proving partial correctness in isolation is that some program\nfragments have the form while (true) {C}. Give useful examples of such pro-\ngram fragments in application programming.\n5.\n*\nUse the proof rule for assignment and logical implication as appropriate to show\nthe validity of\n(a) ⊢par\n\u0001\nx > 0\n\u0002\ny = x + 1\n\u0001\ny > 1\n\u0002\n(b) ⊢par\n\u0001\n⊤\n\u0002\ny = x; y = x + x + y\n\u0001\ny = 3 · x\n\u0002\n(c) ⊢par\n\u0001\nx > 1\n\u0002\na = 1; y = x; y = y - a\n\u0001\ny > 0 ∧x > y\n\u0002\n.\n6.\n*\nWrite down a program P such that\n(a)\n\u0001\n⊤\n\u0002\nP\n\u0001\ny = x + 2\n\u0002\n(b)\n\u0001\n⊤\n\u0002\nP\n\u0001\nz > x + y + 4\n\u0002\nholds under partial correctness; then prove that this is so.\n7. For all instances of Implied in the proof on page 274, specify their corresponding\n⊢AR sequents.\n8. There is a safe way of relaxing the format of the proof rule for assignment: as\nlong as no variable occurring in E gets updated in between the assertion ψ[E/x]\nand the assignment x = E we may conclude ψ right after this assignment. Ex-\nplain why such a proof rule is sound.\n9. (a) Show, by means of an example, that the ‘reversed’ version of the rule Implied\n⊢AR φ →φ′\n\u0001\nφ\n\u0002\nC\n\u0001\nψ\n\u0002\n⊢AR ψ′ →ψ\n\u0001\nφ′\u0002\nC\n\u0001\nψ′\u0002\nImplied Reversed\nis unsound for partial correctness.\n(b) Explain why the modiﬁed rule If-Statement in (4.7) is sound with respect\nto the partial and total satisfaction relation.\n4.6 Exercises\n301\n(c)\n*\nShow that any instance of the modiﬁed rule If-Statement in a proof can\nbe replaced by an instance of the original If-statement and instances of the\nrule Implied. Is the converse true as well?\n10.\n*\nProve the validity of the sequent ⊢par\n\u0001\nBefore a discussion of how to ﬁnd invariants for while-statement, we now\nlook at the assignment and the if-statement to see how the weakest precon-\ndition is calculated for each one.\nAssignment.\nThe assignment axiom is easily adapted to work for proof\ntableaux. We write it thus:\n4 φ is weaker than ψ means that φ is implied by ψ in predicate logic enlarged with the basic\nfacts about arithmetic: the sequent ⊢AR ψ →φ is valid. We want the weakest formula, because\nwe want to impose as few constraints as possible on the preceding code. In some cases, espe-\ncially those involving while-statements, it might not be possible to extract the logically weakest\nformula. We just need one which is suﬃciently weak to allow us to complete the proof at hand.\n4.3 Proof calculus for partial correctness\n277\n\u0001\nψ[E/x]\n\u0002\nx = E\n\u0001\nψ\n\u0002\nAssignment\nThe justiﬁcation is written against the ψ, since, once the proof has been con-\nstructed, we want to read it in a forwards direction. The construction itself\nproceeds in a backwards direction, because that is the way the assignment\naxiom facilitates.\nImplied.\nIn tableau form, the Implied rule allows us to write one formula φ2\ndirectly underneath another one φ1 with no code in between, provided that\nφ1 implies φ2 in that the sequent ⊢AR φ1 →φ2 is valid. Thus, the Implied\nrule acts as an interface between predicate logic with arithmetic and program\nlogic. This is a surprising and crucial insight. Our proof calculus for partial\ncorrectness is a hybrid system which interfaces with another proof calculus\nvia the Implied proof rule only.\nWhen we appeal to the Implied rule, we will usually not explicitly write\nout the proof of the implication in predicate logic, for this chapter focuses\non the program logic. Mostly, the implications we typically encounter will\nbe easy to verify.\nThe Implied rule is often used to simplify formulas that are generated by\napplications of the other rules. It is also used when the weakest precondition\nφ and a postcondition ψ in (4.5). Recall that we developed proof calculi\nfor propositional and predicate logic where such proofs could be accom-\nplished by investigating the structure of the formula one wanted to prove.\nFor example, for proving an implication φ →ψ one had to assume φ and\nmanage to show ψ; then the proof could be ﬁnished with the proof rule for\nimplies-introduction. The proof calculi which we are about to develop follow\nsimilar lines. Yet, they are diﬀerent from the logics we previously studied\nsince they prove triples which are built from two diﬀerent sorts of things:\nlogical formulas φ and ψ versus a piece of code P. Our proof calculi have to\naddress each of these appropriately. Nonetheless, we retain proof strategies\nwhich are compositional, but now in the structure of P. Note that this is\nan important advantage in the veriﬁcation of big projects, where code is\nbuilt from a multitude of modules such that the correctness of certain parts\nwill depend on the correctness of certain others. Thus, your code might\ncall subroutines which other members of your project are about to code,\nbut you can already check the correctness of your code by assuming that\nthe subroutines meet their own speciﬁcations. We will explore this topic in\nSection 4.5.\n4.2.3 Partial and total correctness\nOur explanation of when the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds was rather informal. In\nparticular, it did not say what we should conclude if P does not terminate.\nIn fact there are two ways of handling this situation. Partial correctness\nmeans that we do not require the program to terminate, whereas in total\ncorrectness we insist upon its termination.\nDeﬁnition 4.5 (Partial correctness) We say that the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis satisﬁed under partial correctness if, for all states which satisfy φ, the\nstate resulting from P’s execution satisﬁes the postcondition ψ, provided\nthat P actually terminates. In this case, the relation ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\n, i.e. triples in which the postcon-\ndition is the same as the precondition conjoined with ¬B. Suppose that we\nare required to prove\n\u0001\nφ\n\u0002\nwhile (B) {C}\n\u0001\nψ\n\u0002\n(4.10)\nfor some φ and ψ which are not related in that way. How can we use\nPartial-while in a situation like this?\nThe answer is that we must discover a suitable η, such that\n1.\n⊢AR φ →η,\n2.\n⊢AR η ∧¬B →ψ and\n3.\n⊢par\n\u0001\nη\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\nare all valid, where the latter is shown by means of Partial-while. Then,\nImplied infers that (4.10) is a valid partial-correctness triple.\nThe crucial thing, then, is the discovery of a suitable invariant η. It is a\nnecessary step in order to use the proof rule Partial-while and in general it\nrequires intelligence and ingenuity. This contrasts markedly with the case of\nthe proof rules for if-statements and assignments, which are purely mechan-\nical in nature: their usage is just a matter of symbol-pushing and does not\nrequire any deeper insight.\nDiscovery of a suitable invariant requires careful thought about what the\nwhile-statement is really doing. Indeed the eminent computer scientist, the\nlate E. Dijkstra, said that to understand a while-statement is tantamount\nto knowing what its invariant is with respect to given preconditions and\npostconditions for that while-statement.\nThis is because a suitable invariant can be interpreted as saying that the\nintended computation performed by the while-statement is correct up to\nthe current step of the execution. It then follows that, when the execution\n284\n4 Program verification\nterminates, the entire computation is correct. Let us formalize invariants\nand then study how to discover them.\nDeﬁnition 4.15 An invariant of the while-statement while (B) {C} is a\nformula η such that ⊨par\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\nholds; i.e. for all states l, if η and B\nare true in l and C is executed from state l and terminates, then η is again\ntrue in the resulting state.\nwhile-statements was presented in the following form in Figure 4.1 – here\nwe have written η instead of ψ:\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\n\u0001\nη\n\u0002\nwhile B {C}\n\u0001\nη ∧¬B\n\u0002 Partial-while.\n(4.9)\nBefore we look at how Partial-while will be represented in proof tableaux,\nlet us look in more detail at the ideas behind this proof rule. The formula η is\nchosen to be an invariant of the body C of the while-statement: provided the\nboolean guard B is true, if η is true before we start C, and C terminates,\nthen it is also true at the end. This is what the premise\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\nexpresses.\nNow suppose the while-statement executes a terminating run from a state\nthat satisﬁes η; and that the premise of (4.9) holds.\nr If B is false as soon as we embark on the while-statement, then we do not execute\nC at all. Nothing has happened to change the truth value of η, so we end the\nwhile-statement with η ∧¬B.\n4.3 Proof calculus for partial correctness\n283\nr If B is true when we embark on the while-statement, we execute C. By the\npremise of the rule in (4.9), we know η is true at the end of C.\n– if B is now false, we stop with η ∧¬B.\n– if B is true, we execute C again; η is again re-established. No matter how\nmany times we execute C in this way, η is re-established at the end of each\nexecution of C. The while-statement terminates if, and only if, B is false after\nsome ﬁnite (zero including) number of executions of C, in which case we have\nη ∧¬B.\nThis argument shows that Partial-while is sound with respect to the sat-\nisfaction relation for partial correctness, in the sense that anything we prove\nusing it is indeed true. However, as it stands it allows us to prove only things\nof the form\n\u0001\nη\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\n, i.e. triples in which the postcon-\ndition is the same as the precondition conjoined with ¬B. Suppose that we\nare required to prove\n\u0001\nφ\n\u0002\nwhile (B) {C}\n\u0001\nψ\n\u0002\n(4.10)\nfor some φ and ψ which are not related in that way. How can we use\nPartial-while in a situation like this?\nthing if P ‘loops’ indeﬁnitely. In this section, we extend our proof calculus\nfor partial correctness so that it also proves that programs terminate. In the\nprevious section, we already pointed out that only the syntactic construct\nwhile B {C} could be responsible for non-termination.\n4.4 Proof calculus for total correctness\n293\nTherefore, the proof calculus for total correctness is the same as\nfor partial correctness for all the rules except the rule for while-\nstatements.\nA proof of total correctness for a while-statement will consist of two parts:\nthe proof of partial correctness and a proof that the given while-statement\nterminates. Usually, it is a good idea to prove partial correctness ﬁrst since\nthis often provides helpful insights for a termination proof. However, some\nprograms require termination proofs as premises for establishing partial cor-\nrectness, as can be seen in exercise 1(d) on page 303.\nThe proof of termination usually has the following form. We identify an\ninteger expression whose value can be shown to decrease every time we\nexecute the body of the while-statement in question, but which is always\nnon-negative. If we can ﬁnd an expression with these properties, it follows\nthat the while-statement must terminate; because the expression can only\nbe decremented a ﬁnite number of times before it becomes 0. That is because\nthere is only a ﬁnite number of integer values between 0 and the initial value\nof the expression.\nSuch integer expressions are called variants. As an example, for the pro-\ngram Fac1 of Example 4.2, a suitable variant is x −z. The value of this\nexpression is decremented every time the body of the while-statement is\nexecuted. When it is 0, the while-statement terminates.\nWe can codify this intuition in the following rule for total correctness\nwhich replaces the rule for the while statement:\n\u0001\nη ∧B ∧0 ≤E = E0\n\u0002\nC\n\u0001\nη ∧0 ≤E < E0\n\u0002\n\u0001\nη ∧0 ≤E\n\u0002\nwhile B {C}\n\u0001\nη ∧¬B\n\u0002\nTotal-while.\n(4.15) and refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nif-statement and the while-statement, as in languages such as C and Java.\nThey can be omitted if the blocks consist of a single statement. The intuitive\nmeaning of the programming constructs is the following:\n1.\nThe atomic command x = E is the usual assignment statement; it evaluates\nthe integer expression E in the current state of the store and then overwrites\nthe current value stored in x with the result of that evaluation.\n2.\nThe compound command C1; C2 is the sequential composition of the commands\nC1 and C2. It begins by executing C1 in the current state of the store. If that\nexecution terminates, then it executes C2 in the storage state resulting from the\nexecution of C1. Otherwise – if the execution of C1 does not terminate – the\nrun of C1; C2 also does not terminate. Sequential composition is an example of\na control structure since it implements a certain policy of ﬂow of control in a\ncomputation.\n1 In common with languages like C and Java, we use a single equals sign = to mean assignment\nand a double sign == to mean equality. Earlier languages like Pascal used := for assignment and\nsimple = for equality; it is a great pity that C and its successors did not keep this convention.\nThe reason that = is a bad symbol for assignment is that assignment is not symmetric: if we\ninterpret x = y as the assignment, then x becomes y which is not the same thing as y becoming\nx; yet, x = y and y = x are the same thing if we mean equality. The two dots in := helped\nremind the reader that this is an asymmetric assignment operation rather than a symmetric\nassertion of equality. However, the notation = for assignment is now commonplace, so we will\nuse it.\n262\n4 Program verification\n3.\nAnother control structure is if B {C1} else {C2}. It ﬁrst evaluates the boolean\nexpression B in the current state of the store; if that result is true, then C1 is\nexecuted; if B evaluated to false, then C2 is executed.\n4.\nThe third control construct while B {C} allows us to write statements which\n(4) will do. Et alors, qu’est-ce qu’on pense des phrases (5) et (6)? Sentences\n(5) and (6) are ﬁne if you happen to read French and German a bit. Thus,\ndeclarative statements can be made in any natural, or artiﬁcial, language.\nThe kind of sentences we won’t consider here are non-declarative ones,\nlike\nr Could you please pass me the salt?\nr Ready, steady, go!\nr May fortune come your way.\nPrimarily, we are interested in precise declarative sentences, or statements\nabout the behaviour of computer systems, or programs. Not only do we\nwant to specify such statements but we also want to check whether a given\nprogram, or system, fulﬁls a speciﬁcation at hand. Thus, we need to develop\na calculus of reasoning which allows us to draw conclusions from given as-\nsumptions, like initialised variables, which are reliable in the sense that they\npreserve truth: if all our assumptions are true, then our conclusion ought to\nbe true as well. A much more diﬃcult question is whether, given any true\nproperty of a computer program, we can ﬁnd an argument in our calculus\nthat has this property as its conclusion. The declarative sentence (3) above\nmight illuminate the problematic aspect of such questions in the context of\nnumber theory.\nThe logics we intend to design are symbolic in nature. We translate a cer-\ntain suﬃciently large subset of all English declarative sentences into strings\nof symbols. This gives us a compressed but still complete encoding of declar-\native sentences and allows us to concentrate on the mere mechanics of our\nargumentation. This is important since speciﬁcations of systems or software\nare sequences of such declarative sentences. It further opens up the possibil-\nity of automatic manipulation of such speciﬁcations, a job that computers\njust love to do1. Our strategy is to consider certain declarative sentences as\n1 There is a certain, slightly bitter, circularity in such endeavours: in proving that a certain\nz = z + x;\nx = x - 1;\n}\nThis program adds up the ﬁrst x integers and stores the result in z.\nThus,\n\u0001\nx = 3\n\u0002\nSum\n\u0001\nz = 6\n\u0002\n,\n\u0001\nx = 8\n\u0002\nSum\n\u0001\nz = 36\n\u0002\netc. We know from The-\norem 1.31 on page 41 that 1 + 2 + · · · + x = x(x + 1)/2 for all x ≥0, so\n4.3 Proof calculus for partial correctness\n269\nwe would like to express, as a Hoare triple, that the value of z upon\ntermination is x0(x0 + 1)/2 where x0 is the initial value of x. Thus, we write\n\u0001\nx = x0 ∧x ≥0\n\u0002\nSum\n\u0001\nz = x0(x0 + 1)/2\n\u0002\n.\nVariables like x0 in these examples are called logical variables, because they\noccur only in the logical formulas that constitute the precondition and post-\ncondition; they do not occur in the code to be veriﬁed. The state of the\nsystem gives a value to each program variable, but not for the logical vari-\nables. Logical variables take a similar role to the dummy variables of the\nrules for ∀i and ∃e in Chapter 2.\nDeﬁnition 4.10 For a Hoare triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\n, its set of logical variables\nare those variables that are free in φ or ψ; and don’t occur in P.\n4.3 Proof calculus for partial correctness\nThe proof calculus which we now present goes back to R. Floyd and C.\nA. R. Hoare. In the next subsection, we specify proof rules for each of the\ngrammar clauses for commands. We could go on to use these proof rules\ndirectly, but it turns out to be more convenient to present them in a diﬀerent\nform, suitable for the construction of proofs known as proof tableaux. This\nis what we do in the subsection following the next one.\n4.3.1 Proof rules\nThe proof rules for our calculus are given in Figure 4.1. They should be\ninterpreted as rules that allow us to pass from simple assertions of the form\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nto more complex ones. The rule for assignment is an axiom as\nit has no premises. This allows us to construct some triples out of noth-\ning, to get the proof going. Complete proofs are trees, see page 274 for an\nexample.\nComposition.\nGiven speciﬁcations for the program fragments C1 and C2,\nsay\n\u0001\nφ\nLogic Programming, volume 1. Oxford University Press, 1993.\nFit96. M. Fitting. First-Order Logic and Automated Theorem Proving.\nSpringer, 2nd edition, 1996.\nFra92. N. Francez. Program Veriﬁcation. Addison-Wesley, 1992.\nFre03. G. Frege. Grundgesetze der Arithmetik, begriﬀsschriftlich abgeleitet.\n1903. Volumes I and II (Jena).\nGal87. J. H. Gallier. Logic for Computer Science. John Wiley, 1987.\nGen69. G. Gentzen. Investigations into logical deduction. In M. E. Szabo,\neditor, The Collected Papers of Gerhard Gentzen, chapter 3, pages\n68–129. North-Holland Publishing Company, 1969.\nGol87. R. Goldblatt. Logics of Time and Computation. CSLI Lecture Notes,\n1987.\nGri82. D. Gries. A note on a standard strategy for developing loop invariants\nand loops. Science of Computer Programming, 2:207–214, 1982.\nHam78. A. G. Hamilton. Logic for Mathematicians. Cambridge University\nPress, 1978.\nHoa69. C. A. R. Hoare. An axiomatic basis for computer programming.\nCommunications of the ACM, 12:576–580, 1969.\nHod77. W. Hodges. Logic. Penguin Books, 1977.\nHod83. W. Hodges. Elementary predicate logic. In D. Gabbay and\nF. Guenthner, editors, Handbook of Philosophical Logic, volume 1.\nDordrecht: D. Reidel, 1983.\n416\nBibliography\nHol90. G. Holzmann. Design and Validation of Computer Protocols. Prentice\nHall, 1990.\nJSS01. D. Jackson, I. Shlyakhter, and M. Sridharan. A Micromodularity\nMechanism. In Proceedings of the ACM SIGSOFT Conference on the\nFoundations of Software Engineering/European Software Engineering\nConference (FSE/ESEC’01), September 2001.\nKoz83. D. Kozen. Results on the propositional mu-calculus. Theoretical\nComputer Science, 27:333–354, 1983.\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nstatements, while-statements and sequential compositions. Everything that\ncan be computed by large languages like C and Java can also be computed\nby our language, though perhaps not as conveniently, because it does not\nhave any objects, procedures, threads or recursive data structures. While\nthis makes it seem unrealistic compared with fully blown commercial lan-\nguages, it allows us to focus our discussion on the process of formal program\nveriﬁcation. The features missing from our language could be implemented\non top of it; that is the justiﬁcation for saying that they do not add to the\npower of the language, but only to the convenience of using it. Verifying\nprograms using those features would require non-trivial extensions of the\nproof calculus we present here. In particular, dynamic scoping of variables\npresents hard problems for program-veriﬁcation methods, but this is beyond\nthe scope of this book.\nOur core language has three syntactic domains: integer expressions,\nboolean expressions and commands – the latter we consider to be our\nprograms. Integer expressions are built in the familiar way from variables\nx, y, z, . . . , numerals 0, 1, 2, . . . , −1, −2, . . . and basic operations like addition\n(+) and multiplication (∗). For example,\n5\nx\n4 + (x −3)\nx + (x ∗(y −(5 + z)))\nare all valid integer expressions. Our grammar for generating integer expres-\nsions is\nE ::=\nn | x | (−E) | (E + E) | (E −E) | (E ∗E)\n(4.1)\nwhere n is any numeral in {. . . , −2, −1, 0, 1, 2, . . . } and x is any variable.\nNote that we write multiplication in ‘mathematics’ as 2 · 3, whereas our\ncore language writes 2 ∗3 instead.\nConvention 4.1 In the grammar above, negation −binds more tightly\nvariable, 227, 268\nveriﬁcation, 270\nformal, 260\nprogram execution, 316, 319\nprogramming by contract, 296\nEiﬀel, 296\nprogramming language\nimperative, 259\nproof\nbox\nfor →i, 11\nfor forall-introduction, 110\nfor modal logic, 329\nopening, 28\nside by side, 22\nby contradiction, 24\ncalculus, 256, 260\nconstruction, 269\nconstructive, 120\ndashed box, 329, 340\nfragment, 278\nindirect, 29\nof correctness, 239\nof termination, 266\npartial, 281\npartial correctness, 269, 300\nsearch, 49\nsolid box, 329\nstrategy, 115, 265\nsubproof, 272\ntableaux, 269\ntheory, 93, 122, 174\ntotal correctness, 292\nproof rules, 5\nfor implication, 273\nfor assignment, 269\nfor conjunction, 6\nfor disjunction, 16\nfor double negation, 8\nfor equality, 108\nfor existential quantiﬁcation, 112\nfor if-statements, 272, 280\nmodiﬁed, 281\nfor implication, 12, 277\nfor KT45n, 339\nfor negation, 20\nfor quantiﬁers, 112\nfor sequential composition, 269, 275\nfor universal quantiﬁcation, 109\nfor while-statements, 272, 282, 287\nschema, 111\nsubformula property, 113\nproof tableaux\ncomplete, 291\nproof-based veriﬁcation, 172, 256\nproposition, 2\npropositional logic, 93\nprotocol, 187, 188\nprovability\nundecidability of predicate logic, 136\nquantiﬁer, 310, 313\nequivalences, 185\nin predicate logic, 94\nbinding priorities, 101\nequivalences, 130\nmeaning, 123\nQuielle, J., 254\nreachability, 136, 137\nreasoning\nabout knowledge, 326, 331\nconstructive, 29\nin an arbitrary accessible world, 329\ninformal, 343\nquantitative, 259\nunsound, 280\nrecord\nﬁeld, 193\nrecursion\nmutual, 218\nrecursive call, 280\nreductio ad absurdum, 24, 119\nreduction to absurdity, 24\nreﬂexive, transitive closure, 167\nIndex\n425\nregular language, 405\nrelation\nbinary, 178\nEuclidean, 321, 327\nfunctional, 321\nlinear, 321\nreﬂexive, 140, 320, 324\nas formula, 109\nserial, 320, 353\nsymmetric, 320\nas formula, 109\ntotal, 321\ntransition, 178\ntransitive, 140, 320, 324\nas formula, 109\nrelational mu-calculus\nﬁxed-point operators, 392\nrequirement\ninformal, 258, 263, 288\nrequirements, 142\ngramming language you used a list of features of its software development envi-\nronment (compiler, editor, linker, run-time environment etc) that may improve\nthe likelihood that your programs work correctly. Try to rate the eﬀectiveness of\neach such feature.\n2. Repeat the previous exercise by listing and rating features that may decrease\nthe likelihood of procuding correct and reliable programs.\nExercises 4.2\n1.\n*\nIn what circumstances would if (B) {C1} else {C2} fail to terminate?\n2.\n*\nA familiar command missing from our language is the for-statement. It may be\nused to sum the elements in an array, for example, by programming as follows:\ns = 0;\nfor (i = 0; i <= max; i = i+1) {\ns = s + a[i];\n}\nAfter performing the initial assignment s = 0, this executes i = 0 ﬁrst, then\nexecutes the body s = s + a[i] and the incrementation i = i + 1 continually\nuntil i <= max becomes false. Explain how for (C1; B; C2) {C3} can be deﬁned\nas a derived program in our core language.\n3. Suppose that you need a language construct repeat {C} until (B) which re-\npeats C until B becomes true, i.e.\ni. executes C in the current state of the store;\nii. evaluates B in the resulting state of the store;\niii. if B is false, the program resumes with (i); otherwise, the program\nrepeat {C} until (B) terminates.\nThis construct sometimes allows more elegant code than a corresponding while-\nstatement.\n300\n4 Program verification\n(a) Deﬁne repeat C until B as a derived expression using our core language.\n(b) Can one deﬁne every repeat expression in our core language extended with\nfor-statements? (You might need the empty command skip which does noth-\ning.)\nExercises 4.3\n1. For any store l as in Example 4.4 (page 264), determine which of the relations\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.",
                    "summary": "of R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor q",
                    "children": [
                        {
                            "id": "chapter-4-section-2-subsection-1",
                            "title": "A Core Programming Language",
                            "content": "of R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor quantitative reasoning. The meaning of a logic formula φR, on the other\nhand, is deﬁned in a precise mathematical, qualitative and compositional\nway by structural induction on the parse tree of φR – the ﬁrst three chap-\nters contain examples of this.\nThus, the process of ﬁnding a suitable formalisation φR of R requires\nthe utmost care; otherwise it is always possible that φR speciﬁes behaviour\nwhich is diﬀerent from the one described in R. To make matters worse, the\nrequirements R are often inconsistent; customers usually have a fairly vague\nconception of what exactly a program should do for them. Thus, producing\na clear and coherent description R of the requirements for an application do-\nmain is already a crucial step in successful programming; this phase ideally is\nundertaken by customers and project managers around a table, or in a video\nconference, talking to each other. We address this ﬁrst item only implicitly\nin this text, but you should certainly be aware of its importance in practice.\nThe next phase of the software development framework involves construct-\ning the program P and after that the last task is to verify that P satisﬁes φR.\nHere again, our framework is oversimplifying what goes on in practice, since\noften proving that P satisﬁes its speciﬁcation φR goes hand-in-hand with\ninventing a suitable P. This correspondence between proving and program-\nming can be stated quite precisely, but that is beyond the scope of this book.\n4.2.1 A core programming language\nThe programming language which we set out to study here is the typical\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nand refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nstatements, while-statements and sequential compositions. Everything that\ncan be computed by large languages like C and Java can also be computed\nby our language, though perhaps not as conveniently, because it does not\nhave any objects, procedures, threads or recursive data structures. While\nthis makes it seem unrealistic compared with fully blown commercial lan-\nguages, it allows us to focus our discussion on the process of formal program\nveriﬁcation. The features missing from our language could be implemented\non top of it; that is the justiﬁcation for saying that they do not add to the\npower of the language, but only to the convenience of using it. Verifying\nprograms using those features would require non-trivial extensions of the\nproof calculus we present here. In particular, dynamic scoping of variables\npresents hard problems for program-veriﬁcation methods, but this is beyond\nthe scope of this book.\nOur core language has three syntactic domains: integer expressions,\nboolean expressions and commands – the latter we consider to be our\nprograms. Integer expressions are built in the familiar way from variables\nx, y, z, . . . , numerals 0, 1, 2, . . . , −1, −2, . . . and basic operations like addition\n(+) and multiplication (∗). For example,\n5\nx\n4 + (x −3)\nx + (x ∗(y −(5 + z)))\nare all valid integer expressions. Our grammar for generating integer expres-\nsions is\nE ::=\nn | x | (−E) | (E + E) | (E −E) | (E ∗E)\n(4.1)\nwhere n is any numeral in {. . . , −2, −1, 0, 1, 2, . . . } and x is any variable.\nNote that we write multiplication in ‘mathematics’ as 2 · 3, whereas our\ncore language writes 2 ∗3 instead.\nConvention 4.1 In the grammar above, negation −binds more tightly\ngramming language you used a list of features of its software development envi-\nronment (compiler, editor, linker, run-time environment etc) that may improve\nthe likelihood that your programs work correctly. Try to rate the eﬀectiveness of\neach such feature.\n2. Repeat the previous exercise by listing and rating features that may decrease\nthe likelihood of procuding correct and reliable programs.\nExercises 4.2\n1.\n*\nIn what circumstances would if (B) {C1} else {C2} fail to terminate?\n2.\n*\nA familiar command missing from our language is the for-statement. It may be\nused to sum the elements in an array, for example, by programming as follows:\ns = 0;\nfor (i = 0; i <= max; i = i+1) {\ns = s + a[i];\n}\nAfter performing the initial assignment s = 0, this executes i = 0 ﬁrst, then\nexecutes the body s = s + a[i] and the incrementation i = i + 1 continually\nuntil i <= max becomes false. Explain how for (C1; B; C2) {C3} can be deﬁned\nas a derived program in our core language.\n3. Suppose that you need a language construct repeat {C} until (B) which re-\npeats C until B becomes true, i.e.\ni. executes C in the current state of the store;\nii. evaluates B in the resulting state of the store;\niii. if B is false, the program resumes with (i); otherwise, the program\nrepeat {C} until (B) terminates.\nThis construct sometimes allows more elegant code than a corresponding while-\nstatement.\n300\n4 Program verification\n(a) Deﬁne repeat C until B as a derived expression using our core language.\n(b) Can one deﬁne every repeat expression in our core language extended with\nfor-statements? (You might need the empty command skip which does noth-\ning.)\nExercises 4.3\n1. For any store l as in Example 4.4 (page 264), determine which of the relations\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\nalone must take responsibility for those.\nAdded for second edition\nMany people have helped improve this text by pointing out typos and\nmaking other useful comments after the publication date. Among them,\nxiii\nxiv\nAcknowledgements\nwe mention Wolfgang Ahrendt, Yasuhiro Ajiro, Torben Amtoft, Stephan\nAndrei, Bernhard Beckert, Jonathan Brown, James Caldwell, Ruchira Datta,\nAmy Felty, Dimitar Guelev, Hirotsugu Kakugawa, Kamran Kashef, Markus\nKr¨otzsch, Jagun Kwon, Ranko Lazic, David Makinson, Alexander Miczo,\nAart Middeldorp, Robert Morelli, Prakash Panangaden, Aileen Paraguya,\nFrank Pfenning, Shekhar Pradhan, Koichi Takahashi, Kazunori Ueda,\nHiroshi Watanabe, Fuzhi Wang and Reinhard Wilhelm.\n1\nPropositional logic\nThe aim of logic in computer science is to develop languages to model the\nsituations we encounter as computer science professionals, in such a way\nthat we can reason about them formally. Reasoning about situations means\nconstructing arguments about them; we want to do this formally, so that\nthe arguments are valid and can be defended rigorously, or executed on a\nmachine.\nConsider the following argument:\nExample 1.1 If the train arrives late and there are no taxis at the station,\nthen John is late for his meeting. John is not late for his meeting. The train\ndid arrive late. Therefore, there were taxis at the station.\nIntuitively, the argument is valid, since if we put the ﬁrst sentence and\nthe third sentence together, they tell us that if there are no taxis, then John\nwill be late. The second sentence tells us that he was not late, so it must be\nthe case that there were taxis.\nMuch of this book will be concerned with arguments that have this struc-\nture, namely, that consist of a number of sentences followed by the word\n‘therefore’ and then another sentence. The argument is valid if the sentence\nafter the ‘therefore’ logically follows from the sentences before it. Exactly\nwhat we mean by ‘follows from’ is the subject of this chapter and the next\none.\naxiomatic, 91\ncommercially critical, 172, 257\ncomponent, 206\nconcurrent, 173\ndebugging, 174\ndescription, 193\ndesign, 174\ndevelopment, 173\nelevator, 184, 215\nﬁnite-state, 256\nhybrid, 277\ninﬁnite-state, 256\nmission-critical, 172\nmulti-agent, 331\nphysical, 175\nreactive, 173, 257, 358\nsafety-critical, 172, 257\ntransition, 174\nveriﬁcation, 256\ntautology, 50\ntemporal connective\nAF, 212\nAG, 211\nAU, 212\nAX, 211\nEF, 212\nEG, 211\nEU, 212\nEX, 211\ntemporal connectives, 176\ntemporal logic, 174, 306\nterm, 99\ninterpretation, 128\nterm-rewriting system, 170\ntermination\nCollatz 3n + 1, 295\nproof, 266\ntertium non datur, 25\ntheorem, 13\nprover, 106, 136\nproving, 170\ntime\ncontinuous, 174\ndiscrete, 174\ntop\nmarking, 66\ntotal correctness, 265, 266\ntransition relation, 178\nfor SMV programs, 388\ntransition system, 174\nof ABP program, 247\nof Mutex code, 198\nof SMV program, 192\nunwinding, 180, 212, 222\nIndex\n427\ntranslation\nEnglish into predicate logic, 95, 101\ntree\ninﬁnite, 180, 212\ntruth\ndynamic, 174\nmode, 306, 308\nof knowledge, 326\nstatic, 174\nvalue\nfor predicate logic, 127\nfor propositional logic, 3\ntruth table\nfor conjunction, 37\ntruth tables, 38\ntype, 12, 327\nchecking, 12\ntheory, 170\nunary connective, 307\nundecidability\nof provability, 136\nof satisﬁability, 135\nof validity in predicate logic, 133\nuniversal quantiﬁcation, 268\nuniversal quantiﬁer, 216\nuniversal second-order logic, 140, 156\nuniverse of concrete values, 124\nunreachability, 140\nunsound sequent, 164\nUntil\nin natural language, 182\nnegating, 187\nupdated valuation, 391\nvalid sequent\nof modal logic, 330\npartial correctness, 267\ntotal correctness, 267\nvalidity\nin basic modal logic, 314\nin KT45n, 339\nin propositional logic, 85\nundecidability in predicate logic, 133\nvaluation\nfor propositional logic, 37\nin predicate logic, 123\nin relational mu-calculus, 391\nvalue\ninitial, 206, 268, 269\nVardi, M., 254\nvariable, 94, 260\nboolean, 229, 247, 358\nbound, 103\ncapture, 106\ndummy, 110\nfree, 103\nlocal, 263\nlogical, 268, 290\nvariable ordering\nsmall scope hypothesis, 143\nSMV, 254\nmain program for ABP, 207\nmodule, 193\nreceiver, 205\nsender, 204\nfor channel, 206\ninstantiation, 193\nprocess, 389\nprogram\nexample, 192\nfor Mutex, 195\nspeciﬁcation, 192\nsoftware\nlife-cycle, 142\nmicromodel, 142\nreliability, 149\nrequirements, 142\nspeciﬁcation, 142\nvalidation, 142\nsoundness\nof forall-elimination, 109\nof natural deduction\nbasic modal logic, 354\npredicate logic, 96, 122\npropositional logic, 45\nof program logics, 267\nof proof rule for while-statements,\n282\nof the substitution principle, 108\n426\nIndex\nspeciﬁcation\nfor ABP, 207\nformal, 259\ninformal, 259\nlanguage, 172\nof a predicate, 157\npatterns, 254\npractical pattern, 183, 215\ntruth table, 58\nspeciﬁcations, 191\nSpin, 254\nstate\ncritical, 188\nexplosion, 229\nexplosion problem, 254\nfair, 397\nﬁnal, 142\nformula, 218\nglobal, 188\ngraph, 180\ninitial, 142, 189, 222, 247, 252, 264\nnon-critical, 188\nof a system, 269\nof core program, 264\nreachable, 247\nresulting, 263, 299\nspace, 229\nsplitting states, 190\ntransition, 142\ntrying, 188\nstate machine, 142\nstorage\nlocation, 288\nstate, 261\nstore\nof core program, 264\nstring, 247, 307\nbinary, 126, 132\nempty, 126\nstrongly connected component, 225\nstructural equality, 153\nstructural induction, 44, 51\nsubformula, 178\nsubstitution\nin predicate logic, 105\ninstance, 323\ninstance of tautology, 314\nprinciple, 108\nsymbolic model checking, 383\nsyntactic\ndomain, 260, 261\nsyntax\nof basic modal logic, 307\nof boolean expressions, 261\nof boolean formulas, 398\nof CTL, 208\nof CTL*, 218\nof KT45n, 335\nof LTL, 175\nof predicate logic, 100\nof propositional logic, 33\nof relational mu-calculus, 390\nof terms, 99\nsystem\nasynchronous, 254\ninterleaving model, 389\nsimultaneous model, 389\naxiomatic, 91\ncommercially critical, 172, 257\ncomponent, 206\nconcurrent, 173\ndebugging, 174\ndescription, 193\ndesign, 174\ndevelopment, 173\nelevator, 184, 215\nﬁnite-state, 256\nhybrid, 277\ninﬁnite-state, 256\nmission-critical, 172\nmulti-agent, 331\nphysical, 175\nreactive, 173, 257, 358\nLogic Programming, volume 1. Oxford University Press, 1993.\nFit96. M. Fitting. First-Order Logic and Automated Theorem Proving.\nSpringer, 2nd edition, 1996.\nFra92. N. Francez. Program Veriﬁcation. Addison-Wesley, 1992.\nFre03. G. Frege. Grundgesetze der Arithmetik, begriﬀsschriftlich abgeleitet.\n1903. Volumes I and II (Jena).\nGal87. J. H. Gallier. Logic for Computer Science. John Wiley, 1987.\nGen69. G. Gentzen. Investigations into logical deduction. In M. E. Szabo,\neditor, The Collected Papers of Gerhard Gentzen, chapter 3, pages\n68–129. North-Holland Publishing Company, 1969.\nGol87. R. Goldblatt. Logics of Time and Computation. CSLI Lecture Notes,\n1987.\nGri82. D. Gries. A note on a standard strategy for developing loop invariants\nand loops. Science of Computer Programming, 2:207–214, 1982.\nHam78. A. G. Hamilton. Logic for Mathematicians. Cambridge University\nPress, 1978.\nHoa69. C. A. R. Hoare. An axiomatic basis for computer programming.\nCommunications of the ACM, 12:576–580, 1969.\nHod77. W. Hodges. Logic. Penguin Books, 1977.\nHod83. W. Hodges. Elementary predicate logic. In D. Gabbay and\nF. Guenthner, editors, Handbook of Philosophical Logic, volume 1.\nDordrecht: D. Reidel, 1983.\n416\nBibliography\nHol90. G. Holzmann. Design and Validation of Computer Protocols. Prentice\nHall, 1990.\nJSS01. D. Jackson, I. Shlyakhter, and M. Sridharan. A Micromodularity\nMechanism. In Proceedings of the ACM SIGSOFT Conference on the\nFoundations of Software Engineering/European Software Engineering\nConference (FSE/ESEC’01), September 2001.\nKoz83. D. Kozen. Results on the propositional mu-calculus. Theoretical\nComputer Science, 27:333–354, 1983.\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.",
                            "summary": "of R as a piece of natural language is grounded in common sense and gen-\neral knowledge about the real-world domain and often based on heuristics\nor q",
                            "children": []
                        },
                        {
                            "id": "chapter-4-section-2-subsection-2",
                            "title": "Hoare Triples",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-4-section-2-subsection-3",
                            "title": "Partial and Total Correctness",
                            "content": "\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis satisﬁed under partial correctness if, for all states which satisfy φ, the\nstate resulting from P’s execution satisﬁes the postcondition ψ, provided\nthat P actually terminates. In this case, the relation ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\nWe call ⊨par the satisfaction relation for partial correctness.\nThus, we insist on ψ being true of the resulting state only if the program P\nhas terminated on an input satisfying φ. Partial correctness is rather a weak\nrequirement, since any program which does not terminate at all satisﬁes its\n266\n4 Program verification\nspeciﬁcation. In particular, the program\nwhile true { x = 0; }\n– which endlessly ‘loops’ and never terminates – satisﬁes all speciﬁcations,\nsince partial correctness only says what must happen if the program termi-\nnates.\nTotal correctness, on the other hand, requires that the program terminates\nin order for it to satisfy a speciﬁcation.\nDeﬁnition 4.6 (Total correctness) We say that the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis\nsatisﬁed under total correctness if, for all states in which P is executed which\nsatisfy the precondition φ, P is guaranteed to terminate and the resulting\nstate satisﬁes the postcondition ψ. In this case, we say that ⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds and call ⊨tot the satisfaction relation of total correctness.\nA program which ‘loops’ forever on all input does not satisfy any spec-\niﬁcation under total correctness. Clearly, total correctness is more useful\nthan partial correctness, so the reader may wonder why partial correctness\nis introduced at all. Proving total correctness usually beneﬁts from prov-\ning partial correctness ﬁrst and then proving termination. So, although our\nprimary interest is in proving total correctness, it often happens that we\nhave to or may wish to split this into separate proofs of partial correctness\nand of termination. Most of this chapter is devoted to the proof of partial\ncorrectness, though we return to the issue of termination in Section 4.4.\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\n3. Let the relation P ⊢l ; l′ hold iﬀP’s execution in store l terminates, resulting\nin store l′. Use this formal judgment P ⊢l ; l′ along with the relation l ⊨φ to\ndeﬁne ⊨par and ⊨tot symbolically.\n4. Another reason for proving partial correctness in isolation is that some program\nfragments have the form while (true) {C}. Give useful examples of such pro-\ngram fragments in application programming.\n5.\n*\nUse the proof rule for assignment and logical implication as appropriate to show\nthe validity of\n(a) ⊢par\n\u0001\nx > 0\n\u0002\ny = x + 1\n\u0001\ny > 1\n\u0002\n(b) ⊢par\n\u0001\n⊤\n\u0002\ny = x; y = x + x + y\n\u0001\ny = 3 · x\n\u0002\n(c) ⊢par\n\u0001\nx > 1\n\u0002\na = 1; y = x; y = y - a\n\u0001\ny > 0 ∧x > y\n\u0002\n.\n6.\n*\nWrite down a program P such that\n(a)\n\u0001\n⊤\n\u0002\nP\n\u0001\ny = x + 2\n\u0002\n(b)\n\u0001\n⊤\n\u0002\nP\n\u0001\nz > x + y + 4\n\u0002\nholds under partial correctness; then prove that this is so.\n7. For all instances of Implied in the proof on page 274, specify their corresponding\n⊢AR sequents.\n8. There is a safe way of relaxing the format of the proof rule for assignment: as\nlong as no variable occurring in E gets updated in between the assertion ψ[E/x]\nand the assignment x = E we may conclude ψ right after this assignment. Ex-\nplain why such a proof rule is sound.\n9. (a) Show, by means of an example, that the ‘reversed’ version of the rule Implied\n⊢AR φ →φ′\n\u0001\nφ\n\u0002\nC\n\u0001\nψ\n\u0002\n⊢AR ψ′ →ψ\n\u0001\nφ′\u0002\nC\n\u0001\nψ′\u0002\nImplied Reversed\nis unsound for partial correctness.\n(b) Explain why the modiﬁed rule If-Statement in (4.7) is sound with respect\nto the partial and total satisfaction relation.\n4.6 Exercises\n301\n(c)\n*\nShow that any instance of the modiﬁed rule If-Statement in a proof can\nbe replaced by an instance of the original If-statement and instances of the\nrule Implied. Is the converse true as well?\n10.\n*\nProve the validity of the sequent ⊢par\n\u0001\nBefore a discussion of how to ﬁnd invariants for while-statement, we now\nlook at the assignment and the if-statement to see how the weakest precon-\ndition is calculated for each one.\nAssignment.\nThe assignment axiom is easily adapted to work for proof\ntableaux. We write it thus:\n4 φ is weaker than ψ means that φ is implied by ψ in predicate logic enlarged with the basic\nfacts about arithmetic: the sequent ⊢AR ψ →φ is valid. We want the weakest formula, because\nwe want to impose as few constraints as possible on the preceding code. In some cases, espe-\ncially those involving while-statements, it might not be possible to extract the logically weakest\nformula. We just need one which is suﬃciently weak to allow us to complete the proof at hand.\n4.3 Proof calculus for partial correctness\n277\n\u0001\nψ[E/x]\n\u0002\nx = E\n\u0001\nψ\n\u0002\nAssignment\nThe justiﬁcation is written against the ψ, since, once the proof has been con-\nstructed, we want to read it in a forwards direction. The construction itself\nproceeds in a backwards direction, because that is the way the assignment\naxiom facilitates.\nImplied.\nIn tableau form, the Implied rule allows us to write one formula φ2\ndirectly underneath another one φ1 with no code in between, provided that\nφ1 implies φ2 in that the sequent ⊢AR φ1 →φ2 is valid. Thus, the Implied\nrule acts as an interface between predicate logic with arithmetic and program\nlogic. This is a surprising and crucial insight. Our proof calculus for partial\ncorrectness is a hybrid system which interfaces with another proof calculus\nvia the Implied proof rule only.\nWhen we appeal to the Implied rule, we will usually not explicitly write\nout the proof of the implication in predicate logic, for this chapter focuses\non the program logic. Mostly, the implications we typically encounter will\nbe easy to verify.\nThe Implied rule is often used to simplify formulas that are generated by\napplications of the other rules. It is also used when the weakest precondition\nφ and a postcondition ψ in (4.5). Recall that we developed proof calculi\nfor propositional and predicate logic where such proofs could be accom-\nplished by investigating the structure of the formula one wanted to prove.\nFor example, for proving an implication φ →ψ one had to assume φ and\nmanage to show ψ; then the proof could be ﬁnished with the proof rule for\nimplies-introduction. The proof calculi which we are about to develop follow\nsimilar lines. Yet, they are diﬀerent from the logics we previously studied\nsince they prove triples which are built from two diﬀerent sorts of things:\nlogical formulas φ and ψ versus a piece of code P. Our proof calculi have to\naddress each of these appropriately. Nonetheless, we retain proof strategies\nwhich are compositional, but now in the structure of P. Note that this is\nan important advantage in the veriﬁcation of big projects, where code is\nbuilt from a multitude of modules such that the correctness of certain parts\nwill depend on the correctness of certain others. Thus, your code might\ncall subroutines which other members of your project are about to code,\nbut you can already check the correctness of your code by assuming that\nthe subroutines meet their own speciﬁcations. We will explore this topic in\nSection 4.5.\n4.2.3 Partial and total correctness\nOur explanation of when the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds was rather informal. In\nparticular, it did not say what we should conclude if P does not terminate.\nIn fact there are two ways of handling this situation. Partial correctness\nmeans that we do not require the program to terminate, whereas in total\ncorrectness we insist upon its termination.\nDeﬁnition 4.5 (Partial correctness) We say that the triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis satisﬁed under partial correctness if, for all states which satisfy φ, the\nstate resulting from P’s execution satisﬁes the postcondition ψ, provided\nthat P actually terminates. In this case, the relation ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\n, i.e. triples in which the postcon-\ndition is the same as the precondition conjoined with ¬B. Suppose that we\nare required to prove\n\u0001\nφ\n\u0002\nwhile (B) {C}\n\u0001\nψ\n\u0002\n(4.10)\nfor some φ and ψ which are not related in that way. How can we use\nPartial-while in a situation like this?\nThe answer is that we must discover a suitable η, such that\n1.\n⊢AR φ →η,\n2.\n⊢AR η ∧¬B →ψ and\n3.\n⊢par\n\u0001\nη\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\nare all valid, where the latter is shown by means of Partial-while. Then,\nImplied infers that (4.10) is a valid partial-correctness triple.\nThe crucial thing, then, is the discovery of a suitable invariant η. It is a\nnecessary step in order to use the proof rule Partial-while and in general it\nrequires intelligence and ingenuity. This contrasts markedly with the case of\nthe proof rules for if-statements and assignments, which are purely mechan-\nical in nature: their usage is just a matter of symbol-pushing and does not\nrequire any deeper insight.\nDiscovery of a suitable invariant requires careful thought about what the\nwhile-statement is really doing. Indeed the eminent computer scientist, the\nlate E. Dijkstra, said that to understand a while-statement is tantamount\nto knowing what its invariant is with respect to given preconditions and\npostconditions for that while-statement.\nThis is because a suitable invariant can be interpreted as saying that the\nintended computation performed by the while-statement is correct up to\nthe current step of the execution. It then follows that, when the execution\n284\n4 Program verification\nterminates, the entire computation is correct. Let us formalize invariants\nand then study how to discover them.\nDeﬁnition 4.15 An invariant of the while-statement while (B) {C} is a\nformula η such that ⊨par\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\nholds; i.e. for all states l, if η and B\nare true in l and C is executed from state l and terminates, then η is again\ntrue in the resulting state.\nwhile-statements was presented in the following form in Figure 4.1 – here\nwe have written η instead of ψ:\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\n\u0001\nη\n\u0002\nwhile B {C}\n\u0001\nη ∧¬B\n\u0002 Partial-while.\n(4.9)\nBefore we look at how Partial-while will be represented in proof tableaux,\nlet us look in more detail at the ideas behind this proof rule. The formula η is\nchosen to be an invariant of the body C of the while-statement: provided the\nboolean guard B is true, if η is true before we start C, and C terminates,\nthen it is also true at the end. This is what the premise\n\u0001\nη ∧B\n\u0002\nC\n\u0001\nη\n\u0002\nexpresses.\nNow suppose the while-statement executes a terminating run from a state\nthat satisﬁes η; and that the premise of (4.9) holds.\nr If B is false as soon as we embark on the while-statement, then we do not execute\nC at all. Nothing has happened to change the truth value of η, so we end the\nwhile-statement with η ∧¬B.\n4.3 Proof calculus for partial correctness\n283\nr If B is true when we embark on the while-statement, we execute C. By the\npremise of the rule in (4.9), we know η is true at the end of C.\n– if B is now false, we stop with η ∧¬B.\n– if B is true, we execute C again; η is again re-established. No matter how\nmany times we execute C in this way, η is re-established at the end of each\nexecution of C. The while-statement terminates if, and only if, B is false after\nsome ﬁnite (zero including) number of executions of C, in which case we have\nη ∧¬B.\nThis argument shows that Partial-while is sound with respect to the sat-\nisfaction relation for partial correctness, in the sense that anything we prove\nusing it is indeed true. However, as it stands it allows us to prove only things\nof the form\n\u0001\nη\n\u0002\nwhile (B) {C}\n\u0001\nη ∧¬B\n\u0002\n, i.e. triples in which the postcon-\ndition is the same as the precondition conjoined with ¬B. Suppose that we\nare required to prove\n\u0001\nφ\n\u0002\nwhile (B) {C}\n\u0001\nψ\n\u0002\n(4.10)\nfor some φ and ψ which are not related in that way. How can we use\nPartial-while in a situation like this?\nthing if P ‘loops’ indeﬁnitely. In this section, we extend our proof calculus\nfor partial correctness so that it also proves that programs terminate. In the\nprevious section, we already pointed out that only the syntactic construct\nwhile B {C} could be responsible for non-termination.\n4.4 Proof calculus for total correctness\n293\nTherefore, the proof calculus for total correctness is the same as\nfor partial correctness for all the rules except the rule for while-\nstatements.\nA proof of total correctness for a while-statement will consist of two parts:\nthe proof of partial correctness and a proof that the given while-statement\nterminates. Usually, it is a good idea to prove partial correctness ﬁrst since\nthis often provides helpful insights for a termination proof. However, some\nprograms require termination proofs as premises for establishing partial cor-\nrectness, as can be seen in exercise 1(d) on page 303.\nThe proof of termination usually has the following form. We identify an\ninteger expression whose value can be shown to decrease every time we\nexecute the body of the while-statement in question, but which is always\nnon-negative. If we can ﬁnd an expression with these properties, it follows\nthat the while-statement must terminate; because the expression can only\nbe decremented a ﬁnite number of times before it becomes 0. That is because\nthere is only a ﬁnite number of integer values between 0 and the initial value\nof the expression.\nSuch integer expressions are called variants. As an example, for the pro-\ngram Fac1 of Example 4.2, a suitable variant is x −z. The value of this\nexpression is decremented every time the body of the while-statement is\nexecuted. When it is 0, the while-statement terminates.\nWe can codify this intuition in the following rule for total correctness\nwhich replaces the rule for the while statement:\n\u0001\nη ∧B ∧0 ≤E = E0\n\u0002\nC\n\u0001\nη ∧0 ≤E < E0\n\u0002\n\u0001\nη ∧0 ≤E\n\u0002\nwhile B {C}\n\u0001\nη ∧¬B\n\u0002\nTotal-while.\n(4.15)",
                            "summary": "We call ⊨par the satisfaction relation for partial correctness. We insist on being true of the resulting state only if the program P has terminated on an input satisfying φ. Partial correctness is rather a weakrequirement, since any program which does not terminate at all at all is not valid. Program verification is a form of proof that a program has terminated at all. We call it the ‘program verification’ method. We use the term ‘symbolic correctness’ to Total correctness requires that the program terminates in order for it to satisfy a speciﬁcation. A program which ‘loops’ forever on all input does not satisfy any spec-inducing condition. Total correctness is more useful than partial correctness, so the reader may wonder why partial correctness is introduced at all. We call the satisfaction relation of total correctness the ‘satisfaction relation’ and call it ‘tot’. We say that the triple ‘P’ is guaranteed to terminate under total correctness if, for all states in which P is executed which satisfy the precondition φ, the resulting state satis ﬁes the postcondition ψ. This chapter is devoted to the proof of partial correctness. We return to the issue of termination in Section 4.4. Proving total correctness usually beneﬁts from prov-ing partial correctness ﬁrst and then proving termination. So, although ourprimary interest is in proving total correctness, it often happens that we have to or may wish to split this into separate proofs ofpartial correctnessand of termination. The validity of P can be proved to be partially-correct by our partial-correctness calculus. We say that the sequent ⊢totothe sequent is valid if P is partially correct, while the validity of. P cannot be proved in the total-corrects calculus to be developed If our calculus is any good, then the relation ⊢par should be contained in par. A calculus is complete if it is able to prove everything that is true. We say that a calculus is sound if, whenever ittells us something can be proved, that thing is indeed true. The ﬁrst one means it is actually correct, while the second onemeans it is provably correct according to our calculus. For example, we write that a relation is valid if it holds for all φ, ψ and P; and, similarly, ≢tot is soundif the relation holds for P, φ and ω as well. In Chapters 1 and 2, we said that soundness is relatively easy to show, since typically the soundness of individual proof rules can be established independently of the others. Formally, ⊢par is complete if it is valid whenever all of its parts are complete. Establishing its soundness is simply a matter of considering each rule in turn. Completeness, on the other hand, is harder to prove since it depends on the entire set of proof rules cooperating together. The same situation holds for the program logic we introduce in this chapter. We introduce the relation P ⊢l ; l′ to hold iﬀP’s execution in store l terminates. Use this formal judgment, along with the relation l ⊨φ to hold l′ in store, to prove that P is true. The relation l′ holds l′ into store l′ when l′ terminates, resulting in store L′. Use the proof rule for assignment and logical implication as appropriate to show the validity of the program. Another reason for proving partial correctness in isolation is that some program fragments have the form while (true) {C}. Give useful examples of such pro-reprehensible fragments in application programming. For all instances of Implied in the proof on page 274, specify their corresponding AR sequents. The proof rule is a safe way of relaxing the format of the proof rules for assignment: as long as no variable occurring in E gets updated in between the assertion ψ[E/x]and the assignment x = E we may conclude ψ right after this assignment. The program P such that P. is under partial correctness, then prove The assignment axiom is easily adapted to work for proof676tableaux. We write it thus: 4 φ is weaker than ψ means that ω is implied by φ in predicate logic enlarged with the basic facts about arithmetic. We now look at the assignment and the if-statement to see how the weakest precon-dition is calculated for each one. We conclude with a discussion of how to define the invariants for while-statement. We then move on to the next section of the paper. The next section is on the condition that the condition is true. The last section is about the condition for the condition to be true. We end with the question: Is the converse true as well? We want the weakest formula, because we want to impose as few constraints as possible on the preceding code. We just need one which is suﬃciently weak to allow us to complete the proof at hand. In tableau form, the Implied rule allows us to write one formula φ2 directly underneath another one φ1 with no code in between. This is a surprising and crucial insight. The Impliedrule acts as an interface between predicate logic with arithmetic and programhematicallylogic. The construction itself itself proceeds in a backwards direction, because that is the way the assignmentaxiom facilitates. The justiﬁcation is written against the ψ, since, once the proof has been con-structed The Implied rule is often used to simplify formulas that are generated by other rules. It is also used when the weakest precondition and a postcondition in (4.5) are combined. The proof calculi which we are about to develop follow similar lines. We will use the Implied proof rule only for the proof of the implication of a program logic. The implications we typically encounter will typically be easy to verify. For example, for proving an implication φ → ω one had to assume φ and show ω. Then the proof could be ﬁnished with the proof rule forimplies-introduction. The Implied Proof Rule is a hybrid system which interfaces with another proof calculus via the Triples are built from two diﬀerent sorts of things:logical formulas φ and ψ versus a piece of code P. Our proof calculi have toaddress each of these appropriately. Note that this is an important advantage in the veriﬁcation of big projects, where code is built from a multitude of modules. We will explore this topic inSection 4.5.2. The correctness of certain parts of your code will depend on the correctness of other parts of it. We discuss this issue in section 4.2 of the book. The book is published by Oxford University Press, London, UK, priced £16.99, £19.99. Partial correctness means that we do not require the program to terminate, whereas in totalcorrectness we insist upon its termination. In this case, the relation ⊨par                 ‘P’ means ‘that P actually terminates’. The relation ‘par                 ‘‘’ is the same as the precondition conjoined with ¬B. In the case of triples in which the postcon-dition is the. same as ‘B’, the postconditions are not related in that way. We say that the triple. is satisﬁed under partial correctness if, for all states which satisfy φ, the. state resulting from The crucial thing, then, is the discovery of a suitable invariant. It is a necessary step in order to use the proof rule Partial-while. This contrasts markedly with the case of. if-statements and assignments, which are purely mechan-pushing and does not. require any deeper insight. The eminent computer scientist E. P. E. van Dongen says that the proof rules for if-statement and assignments are just a matter of symbol-p pushing and do not require intelligence and ingenuity. In general it is a good idea to think about what a statement is really doing before using it. For example, consider a statement that says that (4.10) is a valid partial-correctness triple. Dijkstra said that to understand a while-statement is tantamount to knowing what its invariant is with respect to given preconditions and postconditions. A suitable invariant can be interpreted as saying that the envisioned computation performed by the while- Statement is correct up to the current step of the execution. It then follows that, when the execution is terminated, the entire computation is correct. Let us formalize invariants and then study how to discover them. We call this the Deﬁnition 4. The proof rule for Partial-while was presented in the following form in Figure 4.1. It states that if a while-statement executes a terminating run from a state l and terminates, then the statement is again true in the resulting state. The premise of (4.9) is that if B is false as soon as we embark on the while- statement, then we do not execute C at all. We will now look in more detail at the ideas behind this proof rule. The proof rule will be shown in a series of tableaux, starting with the proof of the premise of 4.9. The tableaux will be presented in two parts, one for each of the states l and the other for the state If B is true when we embark on the while-statement, we execute C. By the rule in (4.9), we know η is true at the end of C. Nothing has happened to change the truth value of η, so we end thewhile-statement with η. The while- statement terminates if, and only if, B is false after some (zero including) number of executions of C, in which case we have B. The argument shows that Partial-while is sound with respect to the sat-outheasternisfaction relation for partial correctness, in the sense that anything we prove using it is indeed true. However, as it stands it allows us to prove only things of the form of In this section, we extend our proof calculus. for partial correctness so that it also proves that programs terminate. The proof calculus for total correctness is the same as. the proof of partial correctness for all the rules except the rule for. while-statements. We will use the same proof calculus to prove termination of a while-statement. We hope that this will provide some useful insights for a termination proof for a program that is not related in that way. We conclude with the conclusion that the proof calculus is a good way to prove that a program can be terminated if and only if it can be proved that it does not loop in a way that it would not loop if it did not loop. The proof of termination usually has the following form. We identify an integer expression whose value can be shown to decrease every time we execute the body of the while-statement in question. The expression can only be decremented a ﬁnite number of times before it becomes 0. That is because there is only a number of integer values between 0 and the initial value of the expression.Such integer expressions are called variants. As an example, for the pro- purposefullygram Fac1 of Example 4.2, a suitable variant is x −z. The value of this variant is decremented every time the body is executed. For example, the value of x-z is decreasing by 1 every time a statement isexecuted. When it is 0, the while-statement terminates. We can codify this intuition in the following rule for total correctness. The rule replaces the rule for the while statement: \"while B {C} {E}\"",
                            "children": []
                        },
                        {
                            "id": "chapter-4-section-2-subsection-4",
                            "title": "Program Variables and Logical Variables",
                            "content": "and refer to a ﬁeld of the method’s object. Upon validation, this contract\nestablishes that all calls to withdraw leave (the ‘object invariant’) 0 <=\nbalance invariant.\n4.7 Bibliographic notes\nAn early exposition of the program logics for partial and total correctness of\nprograms written in an imperative while-language can be found in [Hoa69].\nThe text [Dij76] contains a formal treatment of weakest preconditions.\n4.7 Bibliographic notes\n305\nBackhouse’s book [Bac86] describes program logic and weakest precondi-\ntions and also contains numerous examples and exercises. Other books giv-\ning more complete expositions of program veriﬁcation than we can in this\nchapter are [AO91, Fra92]; they also extend the basic core language to in-\nclude features such as procedures and parallelism. The issue of writing to\narrays and the problem of array cell aliasing are described in [Fra92]. The\noriginal article describing the minimal-sum section problem is [Gri82]. A\ngentle introduction to the mathematical foundations of functional program-\nming is [Tur91]. Some web sites deal with software liability and possible\nstandards for intellectual property rights applied to computer programs8 9.\nText books on systematic programming language design by uniform exten-\nsions of the core language we presented at the beginning of this chapter are\n[Ten91, Sch94]. A text on functional programming on the freely available\nlanguage Standard ML of New Jersey is [Pau91].\n8 www.opensource.org\n9 www.sims.berkeley.edu/~pam/papers.html\n5\nModal logics and agents\n5.1 Modes of truth\nIn propositional or predicate logic, formulas are either true, or false, in any\nmodel. Propositional logic and predicate logic do not allow for any further\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nif-statement and the while-statement, as in languages such as C and Java.\nThey can be omitted if the blocks consist of a single statement. The intuitive\nmeaning of the programming constructs is the following:\n1.\nThe atomic command x = E is the usual assignment statement; it evaluates\nthe integer expression E in the current state of the store and then overwrites\nthe current value stored in x with the result of that evaluation.\n2.\nThe compound command C1; C2 is the sequential composition of the commands\nC1 and C2. It begins by executing C1 in the current state of the store. If that\nexecution terminates, then it executes C2 in the storage state resulting from the\nexecution of C1. Otherwise – if the execution of C1 does not terminate – the\nrun of C1; C2 also does not terminate. Sequential composition is an example of\na control structure since it implements a certain policy of ﬂow of control in a\ncomputation.\n1 In common with languages like C and Java, we use a single equals sign = to mean assignment\nand a double sign == to mean equality. Earlier languages like Pascal used := for assignment and\nsimple = for equality; it is a great pity that C and its successors did not keep this convention.\nThe reason that = is a bad symbol for assignment is that assignment is not symmetric: if we\ninterpret x = y as the assignment, then x becomes y which is not the same thing as y becoming\nx; yet, x = y and y = x are the same thing if we mean equality. The two dots in := helped\nremind the reader that this is an asymmetric assignment operation rather than a symmetric\nassertion of equality. However, the notation = for assignment is now commonplace, so we will\nuse it.\n262\n4 Program verification\n3.\nAnother control structure is if B {C1} else {C2}. It ﬁrst evaluates the boolean\nexpression B in the current state of the store; if that result is true, then C1 is\nexecuted; if B evaluated to false, then C2 is executed.\n4.\nThe third control construct while B {C} allows us to write statements which\n(4) will do. Et alors, qu’est-ce qu’on pense des phrases (5) et (6)? Sentences\n(5) and (6) are ﬁne if you happen to read French and German a bit. Thus,\ndeclarative statements can be made in any natural, or artiﬁcial, language.\nThe kind of sentences we won’t consider here are non-declarative ones,\nlike\nr Could you please pass me the salt?\nr Ready, steady, go!\nr May fortune come your way.\nPrimarily, we are interested in precise declarative sentences, or statements\nabout the behaviour of computer systems, or programs. Not only do we\nwant to specify such statements but we also want to check whether a given\nprogram, or system, fulﬁls a speciﬁcation at hand. Thus, we need to develop\na calculus of reasoning which allows us to draw conclusions from given as-\nsumptions, like initialised variables, which are reliable in the sense that they\npreserve truth: if all our assumptions are true, then our conclusion ought to\nbe true as well. A much more diﬃcult question is whether, given any true\nproperty of a computer program, we can ﬁnd an argument in our calculus\nthat has this property as its conclusion. The declarative sentence (3) above\nmight illuminate the problematic aspect of such questions in the context of\nnumber theory.\nThe logics we intend to design are symbolic in nature. We translate a cer-\ntain suﬃciently large subset of all English declarative sentences into strings\nof symbols. This gives us a compressed but still complete encoding of declar-\native sentences and allows us to concentrate on the mere mechanics of our\nargumentation. This is important since speciﬁcations of systems or software\nare sequences of such declarative sentences. It further opens up the possibil-\nity of automatic manipulation of such speciﬁcations, a job that computers\njust love to do1. Our strategy is to consider certain declarative sentences as\n1 There is a certain, slightly bitter, circularity in such endeavours: in proving that a certain\nz = z + x;\nx = x - 1;\n}\nThis program adds up the ﬁrst x integers and stores the result in z.\nThus,\n\u0001\nx = 3\n\u0002\nSum\n\u0001\nz = 6\n\u0002\n,\n\u0001\nx = 8\n\u0002\nSum\n\u0001\nz = 36\n\u0002\netc. We know from The-\norem 1.31 on page 41 that 1 + 2 + · · · + x = x(x + 1)/2 for all x ≥0, so\n4.3 Proof calculus for partial correctness\n269\nwe would like to express, as a Hoare triple, that the value of z upon\ntermination is x0(x0 + 1)/2 where x0 is the initial value of x. Thus, we write\n\u0001\nx = x0 ∧x ≥0\n\u0002\nSum\n\u0001\nz = x0(x0 + 1)/2\n\u0002\n.\nVariables like x0 in these examples are called logical variables, because they\noccur only in the logical formulas that constitute the precondition and post-\ncondition; they do not occur in the code to be veriﬁed. The state of the\nsystem gives a value to each program variable, but not for the logical vari-\nables. Logical variables take a similar role to the dummy variables of the\nrules for ∀i and ∃e in Chapter 2.\nDeﬁnition 4.10 For a Hoare triple\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\n, its set of logical variables\nare those variables that are free in φ or ψ; and don’t occur in P.\n4.3 Proof calculus for partial correctness\nThe proof calculus which we now present goes back to R. Floyd and C.\nA. R. Hoare. In the next subsection, we specify proof rules for each of the\ngrammar clauses for commands. We could go on to use these proof rules\ndirectly, but it turns out to be more convenient to present them in a diﬀerent\nform, suitable for the construction of proofs known as proof tableaux. This\nis what we do in the subsection following the next one.\n4.3.1 Proof rules\nThe proof rules for our calculus are given in Figure 4.1. They should be\ninterpreted as rules that allow us to pass from simple assertions of the form\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nto more complex ones. The rule for assignment is an axiom as\nit has no premises. This allows us to construct some triples out of noth-\ning, to get the proof going. Complete proofs are trees, see page 274 for an\nexample.\nComposition.\nGiven speciﬁcations for the program fragments C1 and C2,\nsay\n\u0001\nφ\nLogic Programming, volume 1. Oxford University Press, 1993.\nFit96. M. Fitting. First-Order Logic and Automated Theorem Proving.\nSpringer, 2nd edition, 1996.\nFra92. N. Francez. Program Veriﬁcation. Addison-Wesley, 1992.\nFre03. G. Frege. Grundgesetze der Arithmetik, begriﬀsschriftlich abgeleitet.\n1903. Volumes I and II (Jena).\nGal87. J. H. Gallier. Logic for Computer Science. John Wiley, 1987.\nGen69. G. Gentzen. Investigations into logical deduction. In M. E. Szabo,\neditor, The Collected Papers of Gerhard Gentzen, chapter 3, pages\n68–129. North-Holland Publishing Company, 1969.\nGol87. R. Goldblatt. Logics of Time and Computation. CSLI Lecture Notes,\n1987.\nGri82. D. Gries. A note on a standard strategy for developing loop invariants\nand loops. Science of Computer Programming, 2:207–214, 1982.\nHam78. A. G. Hamilton. Logic for Mathematicians. Cambridge University\nPress, 1978.\nHoa69. C. A. R. Hoare. An axiomatic basis for computer programming.\nCommunications of the ACM, 12:576–580, 1969.\nHod77. W. Hodges. Logic. Penguin Books, 1977.\nHod83. W. Hodges. Elementary predicate logic. In D. Gabbay and\nF. Guenthner, editors, Handbook of Philosophical Logic, volume 1.\nDordrecht: D. Reidel, 1983.\n416\nBibliography\nHol90. G. Holzmann. Design and Validation of Computer Protocols. Prentice\nHall, 1990.\nJSS01. D. Jackson, I. Shlyakhter, and M. Sridharan. A Micromodularity\nMechanism. In Proceedings of the ACM SIGSOFT Conference on the\nFoundations of Software Engineering/European Software Engineering\nConference (FSE/ESEC’01), September 2001.\nKoz83. D. Kozen. Results on the propositional mu-calculus. Theoretical\nComputer Science, 27:333–354, 1983.\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.\ncore language of most imperative programming languages. Modulo trivial\n260\n4 Program verification\nsyntactic variations, it is a subset of Pascal, C, C++ and Java. Our lan-\nguage consists of assignments to integer- and boolean-valued variables, if-\nstatements, while-statements and sequential compositions. Everything that\ncan be computed by large languages like C and Java can also be computed\nby our language, though perhaps not as conveniently, because it does not\nhave any objects, procedures, threads or recursive data structures. While\nthis makes it seem unrealistic compared with fully blown commercial lan-\nguages, it allows us to focus our discussion on the process of formal program\nveriﬁcation. The features missing from our language could be implemented\non top of it; that is the justiﬁcation for saying that they do not add to the\npower of the language, but only to the convenience of using it. Verifying\nprograms using those features would require non-trivial extensions of the\nproof calculus we present here. In particular, dynamic scoping of variables\npresents hard problems for program-veriﬁcation methods, but this is beyond\nthe scope of this book.\nOur core language has three syntactic domains: integer expressions,\nboolean expressions and commands – the latter we consider to be our\nprograms. Integer expressions are built in the familiar way from variables\nx, y, z, . . . , numerals 0, 1, 2, . . . , −1, −2, . . . and basic operations like addition\n(+) and multiplication (∗). For example,\n5\nx\n4 + (x −3)\nx + (x ∗(y −(5 + z)))\nare all valid integer expressions. Our grammar for generating integer expres-\nsions is\nE ::=\nn | x | (−E) | (E + E) | (E −E) | (E ∗E)\n(4.1)\nwhere n is any numeral in {. . . , −2, −1, 0, 1, 2, . . . } and x is any variable.\nNote that we write multiplication in ‘mathematics’ as 2 · 3, whereas our\ncore language writes 2 ∗3 instead.\nConvention 4.1 In the grammar above, negation −binds more tightly\nvariable, 227, 268\nveriﬁcation, 270\nformal, 260\nprogram execution, 316, 319\nprogramming by contract, 296\nEiﬀel, 296\nprogramming language\nimperative, 259\nproof\nbox\nfor →i, 11\nfor forall-introduction, 110\nfor modal logic, 329\nopening, 28\nside by side, 22\nby contradiction, 24\ncalculus, 256, 260\nconstruction, 269\nconstructive, 120\ndashed box, 329, 340\nfragment, 278\nindirect, 29\nof correctness, 239\nof termination, 266\npartial, 281\npartial correctness, 269, 300\nsearch, 49\nsolid box, 329\nstrategy, 115, 265\nsubproof, 272\ntableaux, 269\ntheory, 93, 122, 174\ntotal correctness, 292\nproof rules, 5\nfor implication, 273\nfor assignment, 269\nfor conjunction, 6\nfor disjunction, 16\nfor double negation, 8\nfor equality, 108\nfor existential quantiﬁcation, 112\nfor if-statements, 272, 280\nmodiﬁed, 281\nfor implication, 12, 277\nfor KT45n, 339\nfor negation, 20\nfor quantiﬁers, 112\nfor sequential composition, 269, 275\nfor universal quantiﬁcation, 109\nfor while-statements, 272, 282, 287\nschema, 111\nsubformula property, 113\nproof tableaux\ncomplete, 291\nproof-based veriﬁcation, 172, 256\nproposition, 2\npropositional logic, 93\nprotocol, 187, 188\nprovability\nundecidability of predicate logic, 136\nquantiﬁer, 310, 313\nequivalences, 185\nin predicate logic, 94\nbinding priorities, 101\nequivalences, 130\nmeaning, 123\nQuielle, J., 254\nreachability, 136, 137\nreasoning\nabout knowledge, 326, 331\nconstructive, 29\nin an arbitrary accessible world, 329\ninformal, 343\nquantitative, 259\nunsound, 280\nrecord\nﬁeld, 193\nrecursion\nmutual, 218\nrecursive call, 280\nreductio ad absurdum, 24, 119\nreduction to absurdity, 24\nreﬂexive, transitive closure, 167\nIndex\n425\nregular language, 405\nrelation\nbinary, 178\nEuclidean, 321, 327\nfunctional, 321\nlinear, 321\nreﬂexive, 140, 320, 324\nas formula, 109\nserial, 320, 353\nsymmetric, 320\nas formula, 109\ntotal, 321\ntransition, 178\ntransitive, 140, 320, 324\nas formula, 109\nrelational mu-calculus\nﬁxed-point operators, 392\nrequirement\ninformal, 258, 263, 288\nrequirements, 142\ngramming language you used a list of features of its software development envi-\nronment (compiler, editor, linker, run-time environment etc) that may improve\nthe likelihood that your programs work correctly. Try to rate the eﬀectiveness of\neach such feature.\n2. Repeat the previous exercise by listing and rating features that may decrease\nthe likelihood of procuding correct and reliable programs.\nExercises 4.2\n1.\n*\nIn what circumstances would if (B) {C1} else {C2} fail to terminate?\n2.\n*\nA familiar command missing from our language is the for-statement. It may be\nused to sum the elements in an array, for example, by programming as follows:\ns = 0;\nfor (i = 0; i <= max; i = i+1) {\ns = s + a[i];\n}\nAfter performing the initial assignment s = 0, this executes i = 0 ﬁrst, then\nexecutes the body s = s + a[i] and the incrementation i = i + 1 continually\nuntil i <= max becomes false. Explain how for (C1; B; C2) {C3} can be deﬁned\nas a derived program in our core language.\n3. Suppose that you need a language construct repeat {C} until (B) which re-\npeats C until B becomes true, i.e.\ni. executes C in the current state of the store;\nii. evaluates B in the resulting state of the store;\niii. if B is false, the program resumes with (i); otherwise, the program\nrepeat {C} until (B) terminates.\nThis construct sometimes allows more elegant code than a corresponding while-\nstatement.\n300\n4 Program verification\n(a) Deﬁne repeat C until B as a derived expression using our core language.\n(b) Can one deﬁne every repeat expression in our core language extended with\nfor-statements? (You might need the empty command skip which does noth-\ning.)\nExercises 4.3\n1. For any store l as in Example 4.4 (page 264), determine which of the relations\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.",
                            "summary": "An early exposition of the program logics for partial and total correctness of.programs written in an imperative while-language can be found in. [Hoa69]. The text [Dij76] contains a formal treatment of weakest preconditions. The issue of writing toarrays and the problem of array cell aliasing are described in [Fra92]. The original article describing the minimal-sum section problem is [Gri82].  The first example of an imperative program is found in [Bac86], which also contains numerous examples and exercises. Other books giv-                ing more complete expositions of program veriﬁcation than we can in this chapter are [AO91 In propositional or predicate logic, formulas are either true, or false, in any model. Propositional logic and predicate logic do not allow for any further possibilities. From many points of view, however, this is inadequate. In this chapter, we look at the mathematical foundations of functional programming. We also look at some of the issues surrounding software liability and possible standards for intellectual property rights applied to computer programs. We conclude this chapter with a discussion of the main points of the chapter, and the next section, on how to use these points in your own programs. The atomic command x = E is the usual assignment statement. It evaluates the integer expression E in the current state of the store. It then overwrites the current value stored in x with the result of that evaluation. The compound command C1; C2 is the sequential composition of the commands C1 and C2. If that execution of C1 does not terminate, then C2 executes C2 in the storage state resulting from C1. Otherwise, C2 also does not terminate. The intuitive meaning of the programming constructs is the following: The atomic command is called the ‘atomic command’ and it is used in programming languages such as C and Java. The ‘modes’ of ‘truth� In C and Java, we use a single equals sign = to mean assignment and a double sign == to mean equality. Earlier languages like Pascal used := for assignment andsimple = for equality. Sequential composition is an example of a control structure since it implements a certain policy of ﬂow of control in a                computation. The two dots in := helped remind the reader that this is an asymmetric assignment operation rather than a symmetricassertion of equality. Program verification is a type of control structure where B {C1} else {C2}.  Another control structure is if A {C3} if B {B4} else A {B5}.  The third control construct while B {C} allows us to write statements which                (4) will do. The kind of sentences we won’t consider here are non-declarative ones, like ‘Could you please pass me the salt?’ We are interested in precise declarative sentences, or statements about the behaviour of computer systems, or programs. Not only do we want to specify such statements, but we also want to check whether a givenprogram, or system, fulﬁls a speci�kencation at hand. We use the language of French and German to make these statements. The language of German is ‘Geschichte’. The logics we intend to design are symbolic in nature. We translate a cer-                tain suﬃciently large subset of all English declarative sentences into strings of symbols. This gives us a compressed but still complete encoding of declar-                ative sentences. This is important since speciﬁcations of systems or software can be written as sequences of such declaratives. The declarATIVE sentence (3) above might illuminate the problematic aspect of such questions in the context of number theory. We need to draw conclusions from given as-                sumptions, like initialised variables, which are reliable in the sense that they preserve truth. If all our assumptions are true, then our conclusion ought to This program adds up the ﬁrst x integers and stores the result in z. It further opens up the possibil-                ity of automatic manipulation of such speciﬁcations. We would like to express, as a Hoare triple, that the value of z upontermination is x0(x0 + 1)/2 where x0 is the initial value of x. We know from page 41 that 1 + 2 + · · · + x = x(x + 1/2 for all x ≥0, so we write x0 = x0 (x0 - 1 / 2 / x + 1 / x0 / x1 / x2) The state of the system gives a value to each program variable, but not for the logical variables. Logical variables take a similar role to the dummy variables of the rules for  and  in Chapter 2. In the next subsection, we specify proof rules for each of the Commands clauses for commands. We could go on to use these proof rules. directly, but it turns out to be more convenient to present them in a diﬀerent.form, suitable for the construction of proofs known as proof tableaux. Thisis what we do in the subsection following the next one. The proof calculus which we now present goes back to R. Floyd and C.A. Hoare. The rule for assignment is an axiom as                it has no premises. This allows us to construct some triples out of noth-                ing, to get the proof going. Complete proofs are trees, see page 274 for an example. Given speciﬁcations for the program fragments C1 and C2, say: \"C1. C2. C1\" and \"C2\" can be written as C1: C2: C1, C2; or C3: C3, C4, C5, C6, C7, C8, C9, C10, C11, C12, C13, C14. Aims to provide an axiomatic basis for computer programming. A note on a standard strategy for developing loop invariants and loops. A MicromodularityMechanism. The propositional mu-calculus. Results on the propositional. mu-Calculus. In Proceedings of the ACM SIGSOFT Conference on the. the foundations of Software Engineering/European Software Engineering. (FSE/ESEC’01), September 2001. Theoretical.Computer Science, 27:333–354, 1983. Theory. of the. propositionalmu-calculations. (Theoretical and theoretical. computer science) (27: The language is a subset of Pascal, C, C++ and Java. It does not have any objects, procedures, threads or recursive data structures. Everything that can be computed by large languages like C and Java can also be computed in our language. It allows us to focus our discussion on the process of formal program verification. The language was developed by D. E. Long in 1983 for his PhD thesis at Carnegie Mellon University. It is based on the core language of most imperative programming languages. It has been used in a number of books, including \"The Language of Program Verification\" and \"Program Verification in a Programming Language\" Our language has three syntactic domains: integer expressions,olean expressions and commands. The features missing from our language could be implemented on top of it. Verifyingprograms using those features would require non-trivial extensions of the                proof calculus we present here. In particular, dynamic scoping of variables is a hard problem for program-veriﬁcation methods, but this is beyond the scope of this book. We consider the latter to be our most important domain, and this is where we focus our efforts. We hope that this book will help you understand the language better and improve your knowledge of programming languages and the programming language itself. We are happy to answer any questions you have about our language. , −2, −1, 0, 1, 2, . . .  Convention 4.1 In the grammar above, negation −binds more tightly than negation +. In our language, multiplication in ‘mathematics’ is written as 2 · 3, whereas ourcore language writes 2 ∗3 instead. In the language you used a list of features that may improve the likelihood that your programs work correctly. For example, in the language we used, x is any variable, and we write it as 2 + 3. The language we use is called ‘Peer-to-Peer’, and it is based on the language of ‘Parsing’ and ‘Sophistication’. For more information on Peer-To- A familiar command missing from our language is the for-statement. Explain how for (C1; B; C2) {C3} can be deﬁned as a derived program in our core language. Try to rate the eﬀectiveness of each such feature. Repeat the previous exercise by listing and rating features that may decrease the likelihood of procuding correct and reliable programs. For example, the for statement may be used to sum the elements in an array, for example, by programming as follows:. For (i = 0; i <= max; i = i+1) {.s = s + a[i];.i = i + 1;. i = 0 � If B is false, the program resumes with (i); otherwise, it repeats C until (B) terminates. This construct sometimes allows more elegant code than a corresponding while-statement. For any store l as in Example 4.4 (page 264), determine which of the relations below hold; justify your answers. If φ and P explain why φ, ψ and P hold, justify why they do. For example, φ explains why P holds whenever the relation P holds for φ. If the relation l holds for l, justify your answer: l ⊨(x + y < z) →¬(x ∗y = z)   (u (u < y)",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-4-section-3",
                    "title": "Proof Calculus for Partial Correctness",
                    "content": "In the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nExample 1.4 Let’s use these rules to prove that p ∧q, r |−q ∧r is valid.\nWe start by writing down the premises; then we leave a gap and write the\n1.2 Natural deduction\n7\nconclusion:\np ∧q\nr\nq ∧r\nThe task of constructing the proof is to ﬁll the gap between the premises\nand the conclusion by applying a suitable sequence of proof rules. In this\ncase, we apply ∧e2 to the ﬁrst premise, giving us q. Then we apply ∧i to this\nq and to the second premise, r, giving us q ∧r. That’s it! We also usually\nnumber all the lines, and write in the justiﬁcation for each line, producing\nthis:\n1\np ∧q\npremise\n2\nr\npremise\n3\nq\n∧e2 1\n4\nq ∧r\n∧i 3, 2\nDemonstrate to yourself that you’ve understood this by trying to show on\nyour own that (p ∧q) ∧r, s ∧t |−q ∧s is valid. Notice that the φ and ψ can\nbe instantiated not just to atomic sentences, like p and q in the example we\njust gave, but also to compound sentences. Thus, from (p ∧q) ∧r we can\ndeduce p ∧q by applying ∧e1, instantiating φ to p ∧q and ψ to r.\nIf we applied these proof rules literally, then the proof above would actu-\nally be a tree with root q ∧r and leaves p ∧q and r, like this:\np ∧q\n∧e2\nq\nr\n∧i\nq ∧r\nHowever, we ﬂattened this tree into a linear presentation which necessitates\nthe use of pointers as seen in lines 3 and 4 above. These pointers allow\nus to recreate the actual proof tree. Throughout this text, we will use the\nﬂattened version of presenting proofs. That way you have to concentrate only\non ﬁnding a proof, not on how to ﬁt a growing tree onto a sheet of paper.\nIf a sequent is valid, there may be many diﬀerent ways of proving it. So if\nyou compare your solution to these exercises with those of others, they need\nnot coincide. The important thing to realise, though, is that any putative\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nof proof, which states rules for transforming valid sequents into valid sequents.\nFor example, if we have already a proof for the sequent Γ, φ ⊢ψ, then we ob-\ntain a proof of the sequent Γ ⊢φ →ψ by augmenting this very proof with one\napplication of the rule →i. The new approach expresses this as an inference rule\nbetween sequents:\nΓ, φ ⊢ψ\nΓ ⊢φ →ψ →i.\nThe rule ‘assumption’ is written as\nφ ⊢φ assumption\ni.e. the premise is empty. Such rules are called axioms.\n(a) Express all remaining proof rules of Figure 1.2 in such a form. (Hint: some\nof your rules may have more than one premise.)\n(b) Explain why proofs of Γ ⊢ψ in this new system have a tree-like structure\nwith Γ ⊢ψ as root.\n(c) Prove p ∨(p ∧q) ⊢p in your new proof system.\n1.7 Exercises\n81\n7. Show that\n√\n2 cannot be a rational number. Proceed by proof by contradiction:\nassume that\n√\n2 is a fraction k/l with integers k and l ̸= 0. On squaring both sides\nwe get 2 = k2/l2, or equivalently 2l2 = k2. We may assume that any common 2\nfactors of k and l have been cancelled. Can you now argue that 2l2 has a diﬀerent\nnumber of 2 factors from k2? Why would that be a contradiction and to what?\n8. There is an alternative approach to treating negation. One could simply ban the\noperator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally,\nsuch a logic cannot rely on the natural deduction rules for negation. Which of\nthe rules ¬i, ¬e, ¬¬e and ¬¬i can you simulate with the remaining proof rules\nby letting ¬φ be φ →⊥?\n9. Let us introduce a new connective φ ↔ψ which should abbreviate (φ →ψ) ∧\n(ψ →φ). Design introduction and elimination rules for ↔and show that they\nare derived rules if φ ↔ψ is interpreted as (φ →ψ) ∧(ψ →φ).\nExercises 1.3\nIn order to facilitate reading these exercises we assume below the usual\nconventions about binding priorities agreed upon in Convention 1.3.\n1. Given the following formulas, draw their corresponding parse tree:\n(a) p\n(b)\n*\np ∧q\n(c) p ∧¬q →¬p\n(d)\n*\np ∧(¬q →¬p)\n(e) p →(¬q ∨(q →p))\n(f)\nassertion can be true about a procedure while that same procedure could\ncompute strange things or crash in the case that the input is not an in-\nteger. Showing p →q using the rule →i is now called type checking, an\nimportant topic in the construction of compilers for typed programming\nlanguages.\nWe thus formulate the rule →i as follows:\nφ\n...\nψ\nφ →ψ\n→i.\nIt says: in order to prove φ →ψ, make a temporary assumption of φ and then\nprove ψ. In your proof of ψ, you can use φ and any of the other formulas\nsuch as premises and provisional conclusions that you have made so far.\nProofs may nest boxes or open new boxes after old ones have been closed.\nThere are rules about which formulas can be used at which points in the\nproof. Generally, we can only use a formula φ in a proof at a given point if\nthat formula occurs prior to that point and if no box which encloses that\noccurrence of φ has been closed already.\nThe line immediately following a closed box has to match the pattern\nof the conclusion of the rule that uses the box. For implies-introduction,\nthis means that we have to continue after the box with φ →ψ, where φ\nwas the ﬁrst and ψ the last formula of that box. We will encounter two\nmore proof rules involving proof boxes and they will require similar pattern\nmatching.\n1.2 Natural deduction\n13\nExample 1.9 Here is another example of a proof using →i:\n1\n¬q →¬p\npremise\n2\np\nassumption\n3\n¬¬p\n¬¬i 2\n4\n¬¬q\nMT 1, 3\n5\np →¬¬q\n→i 2−4\nwhich veriﬁes the validity of the sequent ¬q →¬p ⊢p →¬¬q. Notice that\nwe could apply the rule MT to formulas occurring in or above the box: at\nline 4, no box has been closed that would enclose line 1 or 3.\nAt this point it is instructive to consider the one-line argument\n1\np\npremise\nwhich demonstrates p ⊢p. The rule →i (with conclusion φ →ψ) does not\nprohibit the possibility that φ and ψ coincide. They could both be instanti-\nated to p. Therefore we may extend the proof above to\n1\np\nassumption\n2\np →p\n→i 1 −1\ny + 1 < 3 + 1 = 4.\nWe may use ordinary logical and arithmetic implications to change a certain\ncondition φ to any condition φ′ which is implied by φ for reasons which have\nnothing to do with the given code. In the example above, φ was y < 3 and the\nimplied formula φ′ was then y + 1 < 4. The validity of ⊢AR (y < 3) →(y + 1 <\n4) is rooted in general facts about integers and the relation < deﬁned on them.\nCompletely formal proofs would require separate proofs attached to all instances\nof the rule Implied. As already said, we won’t do that here as this chapter focuses\non aspects of proofs which deal directly with code.\n3.\nFor the sequential composition of assignment statements\nz = x;\nz = z + y;\nu = z;\nour goal is to show that u stores the sum of x and y after this sequence of\nassignments terminates. Let us write P for the code above. Thus, we mean to\nprove ⊢par\n\u0001\n⊤\n\u0002\nP\n\u0001\nu = x + y\n\u0002\n.\nWe construct the proof by starting with the postcondition u = x + y and\npushing it up through the assignments, in reverse order, using the assignment\nrule.\n– Pushing it up through u = z involves replacing all occurrences of u by z,\nresulting in z = x + y. We thus have the proof fragment\n\u0001\nz = x + y\n\u0002\nu = z;\n\u0001\nu = x + y\n\u0002\nAssignment\n– Pushing z = x + y upwards through z = z + y involves replacing z by z + y,\nresulting in z + y = x + y.\n4.3 Proof calculus for partial correctness\n279\n– Pushing that upwards through z = x involves replacing z by x, resulting in\nx + y = x + y. The proof fragment now looks like this:\n\u0001\nx + y = x + y\n\u0002\nz = x;\n\u0001\nz + y = x + y\n\u0002\nAssignment\nz = z + y;\n\u0001\nz = x + y\n\u0002\nAssignment\nu = z;\n\u0001\nu = x + y\n\u0002\nAssignment\nThe weakest precondition that thus emerges is x + y = x + y; we have to check\nthat this follows from the given precondition ⊤. This means checking that any\nstate that satisﬁes ⊤also satisﬁes x + y = x + y. Well, ⊤is satisﬁed in all states,\nbut so is x + y = x + y, so the sequent ⊢AR ⊤→(x + y = x + y) is valid.\nThe ﬁnal completed proof therefore looks like this:\n\u0001\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nThis rule looks rather similar to ¬i, except that the negation is in a diﬀerent\nplace. This is the clue to how to derive PBC from our basic proof rules.\nSuppose we have a proof of ⊥from ¬φ. By →i, we can transform this into\na proof of ¬φ →⊥and proceed as follows:\n1\n¬φ →⊥\ngiven\n2\n¬φ\nassumption\n3\n⊥\n→e 1, 2\n4\n¬¬φ\n¬i 2−3\n5\nφ\n¬¬e 4\nThis shows that PBC can be derived from →i, ¬i, →e and ¬¬e.\nThe ﬁnal derived rule we consider in this section is arguably the most\nuseful to use in proofs, because its derivation is rather long and complicated,\nso its usage often saves time and eﬀort. It also has a Latin name, tertium\nnon datur; the English name is the law of the excluded middle, or LEM for\nshort. It simply says that φ ∨¬φ is true: whatever φ is, it must be either true\nor false; in the latter case, ¬φ is true. There is no third possibility (hence\nexcluded middle): the sequent ⊢φ ∨¬φ is valid. Its validity is implicit, for\nexample, whenever you write an if-statement in a programming language:\n‘if B {C1} else {C2}’ relies on the fact that B ∨¬B is always true (and\nthat B and ¬B can never be true at the same time). Here is a proof in\nnatural deduction that derives the law of the excluded middle from basic\nproof rules:\n1\n¬(φ ∨¬φ)\nassumption\n2\nφ\nassumption\n3\nφ ∨¬φ\n∨i1 2\n4\n⊥\n¬e 3, 1\n5\n¬φ\n¬i 2−4\n6\nφ ∨¬φ\n∨i2 5\n7\n⊥\n¬e 6, 1\n8\n¬¬(φ ∨¬φ)\n¬i 1−7\n9\nφ ∨¬φ\n¬¬e 8\n26\n1 Propositional logic\nExample 1.24 Using LEM, we show that p →q ⊢¬p ∨q is valid:\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\non the program logic. Mostly, the implications we typically encounter will\nbe easy to verify.\nThe Implied rule is often used to simplify formulas that are generated by\napplications of the other rules. It is also used when the weakest precondition\nφ′ emerges by pushing the postcondition upwards through the whole pro-\ngram. We use the Implied rule to show that the given precondition implies\nthe weakest precondition. Let’s look at some examples of this.\nExamples 4.13\n1.\nWe show that ⊢par\n\u0001\ny = 5\n\u0002\nx = y + 1\n\u0001\nx = 6\n\u0002\nis valid:\n\u0001\ny = 5\n\u0002\n\u0001\ny + 1 = 6\n\u0002\nImplied\nx = y + 1\n\u0001\nx = 6\n\u0002\nAssignment\nThe proof is constructed from the bottom upwards. We start with\n\u0001\nx = 6\n\u0002\nand, using the assignment axiom, we push it upwards through x = y + 1. This\nmeans substituting y + 1 for all occurrences of x, resulting in\n\u0001\ny + 1 = 6\n\u0002\n. Now,\nwe compare this with the given precondition\n\u0001\ny = 5\n\u0002\n. The given precondition\nand the arithmetic fact 5 + 1 = 6 imply it, so we have ﬁnished the proof.\n278\n4 Program verification\nAlthough the proof is constructed bottom-up, its justiﬁcations make sense\nwhen read top-down: the second line is implied by the ﬁrst and the fourth\nfollows from the second by the intervening assignment.\n2.\nWe prove the validity of ⊢par\n\u0001\ny < 3\n\u0002\ny = y + 1\n\u0001\ny < 4\n\u0002\n:\n\u0001\ny < 3\n\u0002\n\u0001\ny + 1 < 4\n\u0002\nImplied\ny = y + 1;\n\u0001\ny < 4\n\u0002\nAssignment\nNotice that Implied always refers to the immediately preceding line. As already\nremarked, proofs in program logic generally combine two logical levels: the ﬁrst\nlevel is directly concerned with proof rules for programming constructs such as\nthe assignment statement; the second level is ordinary entailment familiar to\nus from Chapters 1 and 2 plus facts from arithmetic – here that y < 3 implies\ny + 1 < 3 + 1 = 4.\nWe may use ordinary logical and arithmetic implications to change a certain\ncondition φ to any condition φ′ which is implied by φ for reasons which have\nnothing to do with the given code. In the example above, φ was y < 3 and the\n1\np\npremise\nwhich demonstrates p ⊢p. The rule →i (with conclusion φ →ψ) does not\nprohibit the possibility that φ and ψ coincide. They could both be instanti-\nated to p. Therefore we may extend the proof above to\n1\np\nassumption\n2\np →p\n→i 1 −1\nWe write ⊢p →p to express that the argumentation for p →p does not\ndepend on any premises at all.\nDeﬁnition 1.10 Logical formulas φ with valid sequent ⊢φ are theorems.\nExample 1.11 Here is an example of a theorem whose proof utilises most\nof the rules introduced so far:\n1\nq →r\nassumption\n2\n¬q →¬p\nassumption\n3\np\nassumption\n4\n¬¬p\n¬¬i 3\n5\n¬¬q\nMT 2, 4\n6\nq\n¬¬e 5\n7\nr\n→e 1, 6\n8\np →r\n→i 3−7\n9\n(¬q →¬p) →(p →r)\n→i 2−8\n10\n(q →r) →((¬q →¬p) →(p →r))\n→i 1−9\n14\n1 Propositional logic\nq →r\n→\n→\n→\n¬q →¬p\nr\np\nFigure 1.1. Part of the structure of the formula (q →r) →((¬q →¬p) →\n(p →r)) to show how it determines the proof structure.\nTherefore the sequent\n⊢(q →r) →((¬q →¬p) →(p →r)) is valid,\nshowing that (q →r) →((¬q →¬p) →(p →r)) is another theorem.\nRemark 1.12 Indeed, this example indicates that we may transform any\nproof of φ1, φ2, . . . , φn ⊢ψ in such a way into a proof of the theorem\n⊢φ1 →(φ2 →(φ3 →(· · · →(φn →ψ) . . . )))\nby ‘augmenting’ the previous proof with n lines of the rule →i applied to\nφn, φn−1,. . . , φ1 in that order.\nThe nested boxes in the proof of Example 1.11 reveal a pattern of using\nelimination rules ﬁrst, to deconstruct assumptions we have made, and then\nintroduction rules to construct our ﬁnal conclusion. More diﬃcult proofs\nmay involve several such phases.\nLet us dwell on this important topic for a while. How did we come up\nwith the proof above? Parts of it are determined by the structure of the for-\nmulas we have, while other parts require us to be creative. Consider the log-\nical structure of (q →r) →((¬q →¬p) →(p →r)) schematically depicted\nin Figure 1.1. The formula is overall an implication since →is the root of\nthe tree in Figure 1.1. But the only way to build an implication is by means\n1.2 Natural deduction\n15 this has to be taken into account by the calculus.\n288\n4 Program verification\nwrite Si,j for the sum of that section: a[i] + a[i + 1] + · · · + a[j]. A minimal-\nsum section is a section a[i], . . . , a[j] of a such that the sum Si,j is less than\nor equal to the sum Si′,j′ of any other section a[i′], . . . , a[j′] of a.\nExample 4.19 Let us illustrate these concepts on the example integer array\n[−1, 3, 15, −6, 4, −5]. Both [3, 15, −6] and [−6] are sections, but [3, −6, 4]\nisn’t since 15 is missing. A minimal-sum section for this particular array is\n[−6, 4, −5] with sum −7; it is the only minimal-sum section in this case.\nIn general, minimal-sum sections need not be unique. For example, the\narray [1, −1, 3, −1, 1] has two minimal-sum sections [1, −1] and [−1, 1] with\nminimal sum 0.\nThe task at hand is to\nr write a program Min Sum, written in our core programming language extended\nwith integer arrays, which computes the sum of a minimal-sum section of a given\narray;\nr make the informal requirement of this problem, given in the previous item, into\na formal speciﬁcation about the behaviour of Min Sum;\nr use our proof calculus for partial correctness to show that Min Sum satisﬁes those\nformal speciﬁcations provided that it terminates.\nThere is an obvious program to do the job: we could list all the possible\nsections of a given array, then traverse that list to compute the sum of\neach section and keep the recent minimal sum in a storage location. For the\nexample array [−1, 3, −2], this results in the list\n[−1], [−1, 3], [−1, 3, −2], [3], [3, −2], [−2]\nand we see that only the last section [−2] produces the minimal sum −2.\nThis idea can easily be coded in our core programming language, but it\nhas a serious drawback: the number of sections of a given array of size n is\nproportional to the square of n; if we also have to sum all those, then our task\nhas worst-case time complexity of the order n · n2 = n3. Computationally,\nthe range of indexes of the array and t stores the minimal sum of sections\nthat end at a[k] – whenever the control ﬂow of the program is about to\nevaluate the boolean expression of its while-statement. As each new value is\nexamined, we can either add it to the current minimal sum, or decide that a\nlower minimal sum can be obtained by starting a new section. The variable\ns stores the minimal sum seen so far; it is computed as the minimum we\nhave seen so far in the last step, or the minimal sum of sections that end at\nthe current point.\nAs you can see, it not intuitively clear that this program is correct, war-\nranting the use of our partial-correctness calculus to prove its correctness.\nTesting the program with a few examples is not suﬃcient to ﬁnd all mis-\ntakes, however, and the reader would rightly not be convinced that this\nprogram really does compute the minimal-sum section in all cases. So let\nus try to use the partial-correctness calculus introduced in this chapter to\nprove it.\n290\n4 Program verification\nWe formalise our requirement of the program as two speciﬁcations6, writ-\nten as Hoare triples.\nS1.\n\u0001\n⊤\n\u0002\nMin Sum\n\u0001\n∀i, j (0 ≤i ≤j < n →s ≤Si,j)\n\u0002\n.\nIt says that, after the program terminates, s is less than or equal to, the\nsum of any section of the array. Note that i and j are logical variables\nin that they don’t occur as program variables.\nS2.\n\u0001\n⊤\n\u0002\nMin Sum\n\u0001\n∃i, j (0 ≤i ≤j < n ∧s = Si,j)\n\u0002\n,\nwhich says that there is a section whose sum is s.\nIf there is a section whose sum is s and no section has a sum less than s,\nthen s is the sum of a minimal-sum section: the ‘conjunction’ of S1 and S2\ngive us the property we want.\nLet us ﬁrst prove S1. This begins with seeking a suitable invariant. As\nalways, the following characteristics of invariants are a useful guide:\nr Invariants express the fact that the computation performed so far by the while-\nstatement is correct.\nr Invariants typically have the same form as the desired postcondition of the while-\nstatement.\nt = a[0];\n(Inv1(a[0], k) ∧Inv2(t, k))\nAssignment\ns = a[0];\n(Inv1(s, k) ∧Inv2(t, k))\nAssignment\nwhile (k != n) {\n(Inv1(s, k) ∧Inv2(t, k) ∧k ̸= n)\nInvariant Hyp. ∧guard\n(Inv1(min(s, min(t + a[k], a[k])), k + 1)\n∧Inv2(min(t + a[k], a[k]), k + 1))\nImplied (Lemma 4.20)\nt = min(t + a[k], a[k]);\n(Inv1(min(s, t), k + 1) ∧Inv2(t, k + 1))\nAssignment\ns = min(s,t);\n(Inv1(s, k + 1) ∧Inv2(t, k + 1))\nAssignment\nk = k + 1;\n(Inv1(s, k) ∧Inv2(t, k))\nAssignment\n}\n(Inv1(s, k) ∧Inv2(t, k) ∧¬¬(k = n))\nPartial-while\n(Inv1(s, n))\nImplied\nFigure 4.3. Tableau proof for specification S1 of Min Sum.\ncomputation is\nInv2(t, k)\ndef\n= ∀i (0 ≤i < k →t ≤Si,k−1)\n(4.13)\nsaying that t is not greater than the sum of any section ending in a[k −1].\nOur invariant is the conjunction of these formulas, namely\nInv1(s, k) ∧Inv2(t, k).\n(4.14)\nThe completed proof tableau of S1 for Min Sum is given in Figure 4.3. The\ntableau is constructed by\nr Proving that the candidate invariant (4.14) is indeed an invariant. This involves\npushing it upwards through the body of the while-statement and showing that\nwhat emerges follows from the invariant and the boolean guard. This non-trivial\nimplication is shown in the proof of Lemma 4.20.\nr Proving that the invariant, together with the negation of the boolean guard, is\nstrong enough to prove the desired postcondition. This is the last implication of\nthe proof tableau.\n292\n4 Program verification\nr Proving that the invariant is established by the code before the while-statement.\nWe simply push it upwards through the three initial assignments and check that\nthe resulting formula is implied by the precondition of the speciﬁcation, here ⊤.\nAs so often the case, in constructing the tableau, we ﬁnd that two formulas\nmeet; and we have to prove that the ﬁrst one implies the second one. Some-\ntimes this is easy and we can just note the implication in the tableau. For\nexample, we readily see that ⊤implies Inv1(a[0], 1) ∧Inv2(a[0], 1): k being\nhas a serious drawback: the number of sections of a given array of size n is\nproportional to the square of n; if we also have to sum all those, then our task\nhas worst-case time complexity of the order n · n2 = n3. Computationally,\nthis is an expensive price to pay, so we should inspect the problem more\nclosely in order to see whether we can do better.\nCan we compute the minimal sum over all sections in time proportional\nto n, by passing through the array just once? Intuitively, this seems diﬃcult,\nsince if we store just the minimal sum seen so far as we pass through the\narray, we may miss the opportunity of some large negative numbers later on\nbecause of some large positive numbers we encounter en route. For example,\n4.3 Proof calculus for partial correctness\n289\nsuppose the array is\n[−8, 3, −65, 20, 45, −100, −8, 17, −4, −14].\nShould we settle for −8 + 3 −65, or should we try to take advantage of the\n−100 – remembering that we can pass through the array only once? In this\ncase, the whole array is a section that gives us the smallest sum, but it\nis diﬃcult to see how a program which passes through the array just once\ncould detect this.\nThe solution is to store two values during the pass: the minimal sum seen\nso far (s in the program below) and also the minimal sum seen so far of\nall sections which end at the current point in the array (t below). Here is a\nprogram that is intended to do this:\nk = 1;\nt = a[0];\ns = a[0];\nwhile (k != n) {\nt = min(t + a[k], a[k]);\ns = min(s,t);\nk = k + 1;\n}\nwhere min is a function which computes the minimum of its two arguments\nas speciﬁed in exercise 10 on page 301. The variable k proceeds through\nthe range of indexes of the array and t stores the minimal sum of sections\nthat end at a[k] – whenever the control ﬂow of the program is about to\nevaluate the boolean expression of its while-statement. As each new value is\nexamined, we can either add it to the current minimal sum, or decide that a\nwhile (r >= y) {\nr = r - y;\nd = d + 1;\n}\nShow that ⊢par\n\u0001\n¬(y = 0)\n\u0002\nDiv\n\u0001\n(x = d · y + r) ∧(r < y)\n\u0002\nis valid.\n18.\n*\nShow that ⊢par\n\u0001\nx ≥0\n\u0002\nDownfac\n\u0001\ny = x!\n\u0002\nis valid7, where Downfac is:\na = x;\ny = 1;\nwhile (a > 0) {\ny = y * a;\na = a - 1;\n}\n19. Why can, or can’t, you prove the validity of ⊢par\n\u0001\n⊤\n\u0002\nCopy1\n\u0001\nx = y\n\u0002\n?\n20. Let all while-statements while (B) {C} in P be annotated with invariant\ncandidates η at the and of their bodies, and η ∧B at the beginning of their\nbody.\n(a) Explain how a proof of ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\ncan be automatically reduced to show-\ning the validity of some ⊢AR ψ1 ∧· · · ∧ψn.\n(b) Identify such a sequent ⊢AR ψ1 ∧· · · ∧ψn for the proof in Example 4.17 on\npage 287.\n21. Given n = 5 test the correctness of Min Sum on the arrays below:\n(a)\n*\n[−3, 1, −2, 1, −8]\n(b) [1, 45, −1, 23, −1]\n(c)\n*\n[−1, −2, −3, −4, 1097].\n22. If we swap the ﬁrst and second assignment in the while-statement of Min Sum,\nso that it ﬁrst assigns to s and then to t, is the program still correct? Justify\nyour answer.\n23.\n*\nProve the partial correctness of S2 for Min Sum.\n24. The program Min Sum does not reveal where a minimal-sum section may be\nfound in an input array. Adapt Min Sum to achieve that. Can you do this with\na single pass through the array?\n25. Consider the proof rule\n\u0001\nφ\n\u0002\nC\n\u0001\nψ1\n\u0002\n\u0001\nφ\n\u0002\nC\n\u0001\nψ2\n\u0002\n\u0001\nφ\n\u0002\nC\n\u0001\nψ1 ∧ψ2\n\u0002\nConj\n7 You may have to strengthen your invariant.\n4.6 Exercises\n303\nfor Hoare triples.\n(a) Show that this proof rule is sound for ⊨par.\n(b) Derive this proof rule from the ones on page 270.\n(c) Explain how this rule, or its derived version, is used to establish the overall\ncorrectness of Min Sum.\n26. The maximal-sum problem is to compute the maximal sum of all sections on\nan array.\n(a) Adapt the program from page 289 so that it computes the maximal sum of\nthese sections.\n(b) Prove the partial correctess of your modiﬁed program.\n(c) Which aspects of the correctness proof given in Figure 4.3 (page 291) can\nbe ‘re-used?’\nExercises 4.4",
                    "summary": "We start by writing down the premises; then we leave a gap and write the conclusion. The task of constructing the proof is to fill the gap between the premises and the conclusion by applying a suitable sequence of proof rules. We also usually usuallynumber all the lines, and write in the justiﬁcation for each line, producing a proof like the one in the following example. The conclusion has to match the second conjunct of the premises, and the formula can be any formula. It is important to engage in this kind of pattern matching before the application of proofrules. Let’s use these rules to prove that p ∧q, r |−q ∧r is valid. If a sequent is valid, there may be many diﬀerent ways of proving it. So if you compare your solution to these exercises with those of others, they need not coincide. Throughout this text, we will use the traditional version of presenting proofs. That way you have to concentrate only on how to prove a proof, not how to grow a growing tree onto a sheet of paper. If we applied these proof rules literally, then the proof above would be a tree with root q and leaves p and r. However, we ﬂattened this tree into a linear presentation which necessitates the use of pointers as seen in lines 3 and 4 above. These pointers allow us to recreate the actual proof tree Let’s now look at our proof rules. We present about ﬁfteen of them in total; we will go through them in turn and then summarise at the end of this section.1. Propositional logic: We expect that we won’t be able to show the sequent p, q ⊢p ≢p ¬q. The important thing to realise, though, is that any putative                 is not a real number.2. Rules for natural deduction: We present the rules for conjunction, and-introduction, and conclusion. The rules for logical deduction are: 1. Conjecture, 2. logical deduction, and 3. Conclusion. For each of the connectives, there is one or more rules to introduce it and one or two rules to eliminate it. The rules for and-elimination are these two: and-introduction. The rule 1 says: if you have a proof of φ, then by applying this rule you can get a proof for φ. And the rule 2 says the same thing, but allows you to conclude φ instead. The exact nature of the second conjunct of the first conjunct is irrelevant. The conclusion φ has to match the ﬁrst conjunct, whereas φ can be any formula. And in the second rule it is just the other way around: the conclusion ψ The new approach expresses this as an inference rule between sequents. It is important to engage in this kind of pattern matching before the application of proof rules. The rule ‘assumption’ is written as the premise is empty. Such rules are called axioms. The new system has a tree-like structure with the root of the proof system as root. It also has a more complex proof system than the previous one. The proof system is described in Figure 1.2. The original version of this article referred to ‘proof by contradiction’. We are happy to clarify that this is not the case and that the new system is based on a different type of proof system. On squaring both sides                we get 2 = k2/l2, or equivalently 2l2 + k2. Can you now argue that 2L2 has a diﬀerentnumber of 2 factors from k2? Why would that be a contradiction and to what? There is an alternative approach to treating negation. One could simply ban the operator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally, such a logic cannot rely on the natural deduction rules forNegation. Which of the rules ¬i, ¬e, e and ¬¬i can you simulate with the remaining proof rules by letting The rule →i is now called type checking, animportant topic in the construction of compilers for typed programming languages. Given the following formulas, draw their corresponding parse tree. Showing p →q using the rule  is now known as type checking. The rule is used to show that a procedure can be true about a procedure while that same procedure couldcompute strange things or crash in the case that the input is not an in-centricteger. It says: in order to prove φ →ψ, make a temporary assumption of φ and then use that assumption to prove that φ is true. In your proof of ψ, you can use any of the other formulas that you have made so far. The line immediately following a closed box has to match the pattern of the conclusion of the rule that uses the box. For implies-introduction, this means that we have to continue after the box with φ. We will encounter two more proof rules involving proof boxes. They will require similar patternmatching and will use a different formula for each line. The rules are: MT 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37 The validity of ⊢AR (y < 3) →(y + 1 < 4) is rooted in general facts about integers and the relation < deﬁned on them. We may use ordinary logical and arithmetic implications to change a certaincondition φ to any condition φ′ which is implied by φ for reasons which have nothing to do with the given code. For the sequential composition of assignment statements, our goal is to show that u stores the sum of x and y after this sequence of assignments terminates. We won’t do that here as this chapter focuses on aspects of proofs which deal directly with code. We’re going to focus on the proof of the rule Implied. We construct the proof by starting with the postcondition u = x + y and pushing it up through the assignments, in reverse order. The weakest precondition that thus emerges is X + y = x - y; we have to check that this follows from the given preconditions. Let us write P for the code above. Thus, we mean to disprove ⊢par                  P =\"P,\" P =\"prove\", P = P, P \"prove\" \"P\" = P, P \"p\" = P, \"P\" = \"P\", P \"proving\" P\" is the proof for the proof. The Latin name reductio ad absurdum means ‘reduc-                tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. The rule says: if from ¬φ we obtain a contradiction, then we are                entitled to deduce φ. This is the clue to how to derive PBC from our basic proof rules. The completed proof therefore looks like this: PBC 1.2 Natural deduction. PBC 2.25 Natural deduction, PBC 3.5 Natural deduction and PBC 4.5 PBC 5. The proof looks rather similar to ¬i, except that the negation is in a diﬀerent PBC can be derived from →i, ¬i, →e and ¬¬e. By transforming this into a proof of ¬φ, we can prove PBC. PBC is the law of the excluded middle, or LEM for short. It simply says that whatever φ is, it must be either true or false. There is no third possibility (hence the LEM name) for PBC to be true. For example, whenever you write an if-statement in a programming language, it relies on the fact that B is always true (and that B and B can never be true at the same time). PBC has a Latin name, tertium non datur, which The Implied rule is often used to simplify formulas that are generated by applications of other rules. It is also used when the weakest precondition emerges by pushing the postcondition upwards through the whole pro-portergram. We use theimplied rule to show that the given preconditions implies the weakest precondition. The implications we typically encounter will be easy to verify, but it can be diﬃcult to decide which instance of LEM would beneﬁt the progress of a proof. Can you re-do the example above with q ∨¬q as LEM? If so, please send us a picture of the proof. We would like to see the proof in its entirety. The proof is constructed from the bottom upwards. We start with the given precondition and the arithmetic fact 5 + 1 = 6 imply it, so we have ﬁnished the proof. The second line is implied by the first and the fourth by the intervening assignment. The justiﬁcations make sense when read top-down. Let’s look at some examples of this.Examples 4.13.1-4.4 Program verification and proof of the correctness of the proof are given. The proof is presented in the form of a series of questions. The answers to these questions will be given in the next section of the book. The book is published by Oxford University Press and is available in Program logic is a form of computer programming. It uses logical and arithmetic implications to change certain conditions. For example, the condition y < 3 implies that y + 1 < 3 + 1 = 4. The rule →i (with conclusion φ) does not prohibit the possibility that φ and ψ coincide. They could both be instanti-phthalated to p. The result is that p ⊢p is the result of a program logic proof, rather than a proof of a code. It is possible to change a certain condition to any condition that is implied by φ for reasons which have nothing to do with the given code. Logical formulas φ with valid sequent ⊢φ are theorems. Theorems can be proved using most of the rules introduced so far. For example, we can prove that the argumentation for p →p does notdepend on any premises at all. We may extend the proof above to prove that (q →r) is valid, showing that (p →p) is another theorem. We can transform any disproved proof of φ1, φ2, . . . , φn into a proof of the theorem, as shown in Figure 1.1. Theorem 1.11 is an example of a theorem whose proof utilises most.of the rules so far: The nested boxes in the proof of Example 1.11 reveal a pattern of usingelimination rules ﬁrst, to deconstruct assumptions we have made, and thenIntroduction rules to construct our conclusion. More diﬃcult proofs may involve several such phases. How did we come up with the proof above? Parts of it are determined by the structure of the for-naire we have, while other parts require us to be creative. The formula is overall an implication since →is the root of the tree. But the only way to build an implication is by means of natural deduction, and this has to be taken into account by the calculus. The proof is now complete. A minimal-sum section is a section a[i], . . . , a[j] of a such that the sum Si,j is less than or equal to the sumSi′,j′ of any other section of a. Let us illustrate these concepts on the example integer array grotesque[−1, 3, 15, −6, 4, −5]. Both [3, 15,. −6] and [−6] are sections, but [3,. 15, 4] is missing. The task at hand is to write a program Min Sum, written in our core programming language extended with integer arrays. Min Sum computes the sum of a minimal-sum section of a given array. We make the informal requirement of this problem into a formal speciﬁcation about the behaviour of Min Sum. We also use our proof calculus for partial correctness to show that Min Sum satisﬄes those formal specﬅcations provided that it terminates. The program is called Min Sum and it is written in the programming language Python. The code is available for download from the GitHub repository. It is available in Python, C, C++, and The idea can easily be coded in our core programming language, but it has a serious drawback. The number of sections of a given array of size n isproportional to the square of n; if we also have to sum all those, then our task has worst-case time complexity of the order n · n2 = n3. Computationally, t stores the minimal sum of sections that end at a[k] – whenever the control ﬂow of the program is about toevaluate the boolean expression of its while-statement. As each new value is added, we can either add it to the current minimal sum, or decide that alower minimal sum can be obtained by starting a new section. We formalise our requirement of the program as two speciﬁcations6, writ-                ten as Hoare triples. The variable                s stores the minimal sum seen so far; it is computed as the minimum we                have seen in the last step. The program is not intuitively clear that this program is correct, war-                ranting the use of our partial-correctness calculus to prove its correctness. The reader would rightly not be convinced that this.program really does compute the minimal-sum section in all cases. So let us try to use the partial- correctness calculus introduced in this chapter to prove it. We call the program S1. It says that, after the program terminates Let us prove S1. This begins with seeking a suitable invariant. As always, the following characteristics of invariants are a useful guide. Invariants express the fact that the computation performed so far by the while-centricstatement is correct. The ‘conjunction’ of S1 and S2.give us the property we want. S1: There is a section whose sum is s, and no section has a sum less than s. S2: S is the sum of a minimal-sum section, and S1 is S1’s ‘condition’ for S1 to be true. S3: S1, S2, S3, S4, S5, The completed proof tableau of S1 for Min Sum is given in Figure 4.3. The tableau is constructed by proving that the candidate invariant (4.14) is indeed an invariant. This involvespushing it upwards through the body of the while-statement and showing that what emerges follows from the invariant and the boolean guard. The proof for S1 of Min Sum can be found in Lemma 4.20, where t is the sum of any section ending in a[k −1]. It can also be found by using the following formula:Inv1(s, k)  Inv2(t, k), where k is the number of sections ending in k. Proving that the invariant, together with the negation of the boolean guard, is strong enough to prove the desired postcondition. This non-trivialimplication is shown in the proof of Lemma 4.20. The last implication of the proof tableau is the last in the tableau. The tableau shows that two formulas meet, and we have to prove that the first one implies the second one. We simply push it upwards through the three initial assignments and check that the resulting formula is implied by the precondition of the speciﬁcation. The number of sections of a given array of size n isproportional to the square of n. If we also have to sum all those, then our task has worst-case time complexity of the order n · n2 = n3. Can we compute the minimal sum over all sections in time proportional to n, by passing through the array just once? Intuitively, this seems diﬃcult, since if we store just the minimalsum seen so far as we pass through thearray, we may miss the opportunity of some large negative numbers later on. But Computationally, this is an expensive price to pay, so we should inspect the problem moreclosely in order to see whether we can A program which passes through the array just once could detect this. The solution is to store two values during the pass: the minimal sum seen so far (s in the program below) and also the minimum sum seen in all sections which end at the current point in the array. Here is a program that is intended to do this. It uses a function which computes the minimum of its two arguments. The function is speciﬁed in exercise 10 on page 301 of the book. It is called min(s,t) and it is used in the proof calculus for partial correctness. For example, the program uses min(t, n) to prove that n is the number of points in an array. The variable k proceeds through                the range of indexes of the array and t stores the minimal sum of sections that end at a[k] – whenever the control ﬂow of the program is about toevaluate the while-statement. As each new value is examined, we can either add it to the current minimal sum, or decide that a is valid. For example, we could show that a while (r < y) is valid by using Downfac, where Downfac is: ‘A = x; a = 1; a + 1; y = y * a;’ or we could say that awhile (a > 0) is also valid by adding a to Downfac. Given n = 5 test the correctness of Min Sum on the arrays below. The program Min Sum does not reveal where a minimal-sum section may be found in an input array. If we swap the ﬁrst and second assignment in the while-statement of MinSum, is the program still correct? Justify your answer. Prove the partial correctness of S2 for Min Sum. Adapt Min Sum to achieve that. Can you do this with a single pass through the array? Prove it with two passes through an array. Proving it with three passes through a single array. proving it with four passes through two arrays. proving that it is possible to prove it with multiple passes. The maximal-sum problem is to compute the maximal sum of all sections on an array. Figure 4.3 (page 291) can be ‘re-used’ as a proof of the correctness of the program. The program can be adapted from page 289 so that it computes the maximalsum of these sections. The maximal sum is the sum of the parts of the array that make up the array. The problem can be solved by multiplying the sum by the number of sections in the array, or by the length of the entire array. It can be used to test the correctness and correctness of a program that is being used for the first time. For more information, see the",
                    "children": [
                        {
                            "id": "chapter-4-section-3-subsection-1",
                            "title": "Proof Rules",
                            "content": "In the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nExample 1.4 Let’s use these rules to prove that p ∧q, r |−q ∧r is valid.\nWe start by writing down the premises; then we leave a gap and write the\n1.2 Natural deduction\n7\nconclusion:\np ∧q\nr\nq ∧r\nThe task of constructing the proof is to ﬁll the gap between the premises\nand the conclusion by applying a suitable sequence of proof rules. In this\ncase, we apply ∧e2 to the ﬁrst premise, giving us q. Then we apply ∧i to this\nq and to the second premise, r, giving us q ∧r. That’s it! We also usually\nnumber all the lines, and write in the justiﬁcation for each line, producing\nthis:\n1\np ∧q\npremise\n2\nr\npremise\n3\nq\n∧e2 1\n4\nq ∧r\n∧i 3, 2\nDemonstrate to yourself that you’ve understood this by trying to show on\nyour own that (p ∧q) ∧r, s ∧t |−q ∧s is valid. Notice that the φ and ψ can\nbe instantiated not just to atomic sentences, like p and q in the example we\njust gave, but also to compound sentences. Thus, from (p ∧q) ∧r we can\ndeduce p ∧q by applying ∧e1, instantiating φ to p ∧q and ψ to r.\nIf we applied these proof rules literally, then the proof above would actu-\nally be a tree with root q ∧r and leaves p ∧q and r, like this:\np ∧q\n∧e2\nq\nr\n∧i\nq ∧r\nHowever, we ﬂattened this tree into a linear presentation which necessitates\nthe use of pointers as seen in lines 3 and 4 above. These pointers allow\nus to recreate the actual proof tree. Throughout this text, we will use the\nﬂattened version of presenting proofs. That way you have to concentrate only\non ﬁnding a proof, not on how to ﬁt a growing tree onto a sheet of paper.\nIf a sequent is valid, there may be many diﬀerent ways of proving it. So if\nyou compare your solution to these exercises with those of others, they need\nnot coincide. The important thing to realise, though, is that any putative\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’\nthen knowing these two facts should not allow us to infer that ‘Gold is a\nmetal whereas silver isn’t.’\nLet’s now look at our proof rules. We present about ﬁfteen of them in\ntotal; we will go through them in turn and then summarise at the end of\nthis section.\n1.2.1 Rules for natural deduction\nThe rules for conjunction\nOur ﬁrst rule is called the rule for conjunc-\ntion (∧): and-introduction. It allows us to conclude φ ∧ψ, given that we\nhave already concluded φ and ψ separately. We write this rule as\nφ\nψ\nφ ∧ψ\n∧i.\nAbove the line are the two premises of the rule. Below the line goes the\nconclusion. (It might not yet be the ﬁnal conclusion of our argument;\nwe might have to apply more rules to get there.) To the right of the line,\nwe write the name of the rule; ∧i is read ‘and-introduction’. Notice that we\nhave introduced a ∧(in the conclusion) where there was none before (in the\npremises).\nFor each of the connectives, there is one or more rules to introduce it and\none or more rules to eliminate it. The rules for and-elimination are these\ntwo:\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2.\n(1.1)\nThe rule ∧e1 says: if you have a proof of φ ∧ψ, then by applying this rule\nyou can get a proof of φ. The rule ∧e2 says the same thing, but allows\nyou to conclude ψ instead. Observe the dependences of these rules: in the\nﬁrst rule of (1.1), the conclusion φ has to match the ﬁrst conjunct of the\npremise, whereas the exact nature of the second conjunct ψ is irrelevant.\nIn the second rule it is just the other way around: the conclusion ψ has to\nmatch the second conjunct ψ and φ can be any formula. It is important\nto engage in this kind of pattern matching before the application of proof\nrules.\nof proof, which states rules for transforming valid sequents into valid sequents.\nFor example, if we have already a proof for the sequent Γ, φ ⊢ψ, then we ob-\ntain a proof of the sequent Γ ⊢φ →ψ by augmenting this very proof with one\napplication of the rule →i. The new approach expresses this as an inference rule\nbetween sequents:\nΓ, φ ⊢ψ\nΓ ⊢φ →ψ →i.\nThe rule ‘assumption’ is written as\nφ ⊢φ assumption\ni.e. the premise is empty. Such rules are called axioms.\n(a) Express all remaining proof rules of Figure 1.2 in such a form. (Hint: some\nof your rules may have more than one premise.)\n(b) Explain why proofs of Γ ⊢ψ in this new system have a tree-like structure\nwith Γ ⊢ψ as root.\n(c) Prove p ∨(p ∧q) ⊢p in your new proof system.\n1.7 Exercises\n81\n7. Show that\n√\n2 cannot be a rational number. Proceed by proof by contradiction:\nassume that\n√\n2 is a fraction k/l with integers k and l ̸= 0. On squaring both sides\nwe get 2 = k2/l2, or equivalently 2l2 = k2. We may assume that any common 2\nfactors of k and l have been cancelled. Can you now argue that 2l2 has a diﬀerent\nnumber of 2 factors from k2? Why would that be a contradiction and to what?\n8. There is an alternative approach to treating negation. One could simply ban the\noperator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally,\nsuch a logic cannot rely on the natural deduction rules for negation. Which of\nthe rules ¬i, ¬e, ¬¬e and ¬¬i can you simulate with the remaining proof rules\nby letting ¬φ be φ →⊥?\n9. Let us introduce a new connective φ ↔ψ which should abbreviate (φ →ψ) ∧\n(ψ →φ). Design introduction and elimination rules for ↔and show that they\nare derived rules if φ ↔ψ is interpreted as (φ →ψ) ∧(ψ →φ).\nExercises 1.3\nIn order to facilitate reading these exercises we assume below the usual\nconventions about binding priorities agreed upon in Convention 1.3.\n1. Given the following formulas, draw their corresponding parse tree:\n(a) p\n(b)\n*\np ∧q\n(c) p ∧¬q →¬p\n(d)\n*\np ∧(¬q →¬p)\n(e) p →(¬q ∨(q →p))\n(f)\nassertion can be true about a procedure while that same procedure could\ncompute strange things or crash in the case that the input is not an in-\nteger. Showing p →q using the rule →i is now called type checking, an\nimportant topic in the construction of compilers for typed programming\nlanguages.\nWe thus formulate the rule →i as follows:\nφ\n...\nψ\nφ →ψ\n→i.\nIt says: in order to prove φ →ψ, make a temporary assumption of φ and then\nprove ψ. In your proof of ψ, you can use φ and any of the other formulas\nsuch as premises and provisional conclusions that you have made so far.\nProofs may nest boxes or open new boxes after old ones have been closed.\nThere are rules about which formulas can be used at which points in the\nproof. Generally, we can only use a formula φ in a proof at a given point if\nthat formula occurs prior to that point and if no box which encloses that\noccurrence of φ has been closed already.\nThe line immediately following a closed box has to match the pattern\nof the conclusion of the rule that uses the box. For implies-introduction,\nthis means that we have to continue after the box with φ →ψ, where φ\nwas the ﬁrst and ψ the last formula of that box. We will encounter two\nmore proof rules involving proof boxes and they will require similar pattern\nmatching.\n1.2 Natural deduction\n13\nExample 1.9 Here is another example of a proof using →i:\n1\n¬q →¬p\npremise\n2\np\nassumption\n3\n¬¬p\n¬¬i 2\n4\n¬¬q\nMT 1, 3\n5\np →¬¬q\n→i 2−4\nwhich veriﬁes the validity of the sequent ¬q →¬p ⊢p →¬¬q. Notice that\nwe could apply the rule MT to formulas occurring in or above the box: at\nline 4, no box has been closed that would enclose line 1 or 3.\nAt this point it is instructive to consider the one-line argument\n1\np\npremise\nwhich demonstrates p ⊢p. The rule →i (with conclusion φ →ψ) does not\nprohibit the possibility that φ and ψ coincide. They could both be instanti-\nated to p. Therefore we may extend the proof above to\n1\np\nassumption\n2\np →p\n→i 1 −1\ny + 1 < 3 + 1 = 4.\nWe may use ordinary logical and arithmetic implications to change a certain\ncondition φ to any condition φ′ which is implied by φ for reasons which have\nnothing to do with the given code. In the example above, φ was y < 3 and the\nimplied formula φ′ was then y + 1 < 4. The validity of ⊢AR (y < 3) →(y + 1 <\n4) is rooted in general facts about integers and the relation < deﬁned on them.\nCompletely formal proofs would require separate proofs attached to all instances\nof the rule Implied. As already said, we won’t do that here as this chapter focuses\non aspects of proofs which deal directly with code.\n3.\nFor the sequential composition of assignment statements\nz = x;\nz = z + y;\nu = z;\nour goal is to show that u stores the sum of x and y after this sequence of\nassignments terminates. Let us write P for the code above. Thus, we mean to\nprove ⊢par\n\u0001\n⊤\n\u0002\nP\n\u0001\nu = x + y\n\u0002\n.\nWe construct the proof by starting with the postcondition u = x + y and\npushing it up through the assignments, in reverse order, using the assignment\nrule.\n– Pushing it up through u = z involves replacing all occurrences of u by z,\nresulting in z = x + y. We thus have the proof fragment\n\u0001\nz = x + y\n\u0002\nu = z;\n\u0001\nu = x + y\n\u0002\nAssignment\n– Pushing z = x + y upwards through z = z + y involves replacing z by z + y,\nresulting in z + y = x + y.\n4.3 Proof calculus for partial correctness\n279\n– Pushing that upwards through z = x involves replacing z by x, resulting in\nx + y = x + y. The proof fragment now looks like this:\n\u0001\nx + y = x + y\n\u0002\nz = x;\n\u0001\nz + y = x + y\n\u0002\nAssignment\nz = z + y;\n\u0001\nz = x + y\n\u0002\nAssignment\nu = z;\n\u0001\nu = x + y\n\u0002\nAssignment\nThe weakest precondition that thus emerges is x + y = x + y; we have to check\nthat this follows from the given precondition ⊤. This means checking that any\nstate that satisﬁes ⊤also satisﬁes x + y = x + y. Well, ⊤is satisﬁed in all states,\nbut so is x + y = x + y, so the sequent ⊢AR ⊤→(x + y = x + y) is valid.\nThe ﬁnal completed proof therefore looks like this:\n\u0001\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25\nThis rule looks rather similar to ¬i, except that the negation is in a diﬀerent\nplace. This is the clue to how to derive PBC from our basic proof rules.\nSuppose we have a proof of ⊥from ¬φ. By →i, we can transform this into\na proof of ¬φ →⊥and proceed as follows:\n1\n¬φ →⊥\ngiven\n2\n¬φ\nassumption\n3\n⊥\n→e 1, 2\n4\n¬¬φ\n¬i 2−3\n5\nφ\n¬¬e 4\nThis shows that PBC can be derived from →i, ¬i, →e and ¬¬e.\nThe ﬁnal derived rule we consider in this section is arguably the most\nuseful to use in proofs, because its derivation is rather long and complicated,\nso its usage often saves time and eﬀort. It also has a Latin name, tertium\nnon datur; the English name is the law of the excluded middle, or LEM for\nshort. It simply says that φ ∨¬φ is true: whatever φ is, it must be either true\nor false; in the latter case, ¬φ is true. There is no third possibility (hence\nexcluded middle): the sequent ⊢φ ∨¬φ is valid. Its validity is implicit, for\nexample, whenever you write an if-statement in a programming language:\n‘if B {C1} else {C2}’ relies on the fact that B ∨¬B is always true (and\nthat B and ¬B can never be true at the same time). Here is a proof in\nnatural deduction that derives the law of the excluded middle from basic\nproof rules:\n1\n¬(φ ∨¬φ)\nassumption\n2\nφ\nassumption\n3\nφ ∨¬φ\n∨i1 2\n4\n⊥\n¬e 3, 1\n5\n¬φ\n¬i 2−4\n6\nφ ∨¬φ\n∨i2 5\n7\n⊥\n¬e 6, 1\n8\n¬¬(φ ∨¬φ)\n¬i 1−7\n9\nφ ∨¬φ\n¬¬e 8\n26\n1 Propositional logic\nExample 1.24 Using LEM, we show that p →q ⊢¬p ∨q is valid:\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\non the program logic. Mostly, the implications we typically encounter will\nbe easy to verify.\nThe Implied rule is often used to simplify formulas that are generated by\napplications of the other rules. It is also used when the weakest precondition\nφ′ emerges by pushing the postcondition upwards through the whole pro-\ngram. We use the Implied rule to show that the given precondition implies\nthe weakest precondition. Let’s look at some examples of this.\nExamples 4.13\n1.\nWe show that ⊢par\n\u0001\ny = 5\n\u0002\nx = y + 1\n\u0001\nx = 6\n\u0002\nis valid:\n\u0001\ny = 5\n\u0002\n\u0001\ny + 1 = 6\n\u0002\nImplied\nx = y + 1\n\u0001\nx = 6\n\u0002\nAssignment\nThe proof is constructed from the bottom upwards. We start with\n\u0001\nx = 6\n\u0002\nand, using the assignment axiom, we push it upwards through x = y + 1. This\nmeans substituting y + 1 for all occurrences of x, resulting in\n\u0001\ny + 1 = 6\n\u0002\n. Now,\nwe compare this with the given precondition\n\u0001\ny = 5\n\u0002\n. The given precondition\nand the arithmetic fact 5 + 1 = 6 imply it, so we have ﬁnished the proof.\n278\n4 Program verification\nAlthough the proof is constructed bottom-up, its justiﬁcations make sense\nwhen read top-down: the second line is implied by the ﬁrst and the fourth\nfollows from the second by the intervening assignment.\n2.\nWe prove the validity of ⊢par\n\u0001\ny < 3\n\u0002\ny = y + 1\n\u0001\ny < 4\n\u0002\n:\n\u0001\ny < 3\n\u0002\n\u0001\ny + 1 < 4\n\u0002\nImplied\ny = y + 1;\n\u0001\ny < 4\n\u0002\nAssignment\nNotice that Implied always refers to the immediately preceding line. As already\nremarked, proofs in program logic generally combine two logical levels: the ﬁrst\nlevel is directly concerned with proof rules for programming constructs such as\nthe assignment statement; the second level is ordinary entailment familiar to\nus from Chapters 1 and 2 plus facts from arithmetic – here that y < 3 implies\ny + 1 < 3 + 1 = 4.\nWe may use ordinary logical and arithmetic implications to change a certain\ncondition φ to any condition φ′ which is implied by φ for reasons which have\nnothing to do with the given code. In the example above, φ was y < 3 and the\n1\np\npremise\nwhich demonstrates p ⊢p. The rule →i (with conclusion φ →ψ) does not\nprohibit the possibility that φ and ψ coincide. They could both be instanti-\nated to p. Therefore we may extend the proof above to\n1\np\nassumption\n2\np →p\n→i 1 −1\nWe write ⊢p →p to express that the argumentation for p →p does not\ndepend on any premises at all.\nDeﬁnition 1.10 Logical formulas φ with valid sequent ⊢φ are theorems.\nExample 1.11 Here is an example of a theorem whose proof utilises most\nof the rules introduced so far:\n1\nq →r\nassumption\n2\n¬q →¬p\nassumption\n3\np\nassumption\n4\n¬¬p\n¬¬i 3\n5\n¬¬q\nMT 2, 4\n6\nq\n¬¬e 5\n7\nr\n→e 1, 6\n8\np →r\n→i 3−7\n9\n(¬q →¬p) →(p →r)\n→i 2−8\n10\n(q →r) →((¬q →¬p) →(p →r))\n→i 1−9\n14\n1 Propositional logic\nq →r\n→\n→\n→\n¬q →¬p\nr\np\nFigure 1.1. Part of the structure of the formula (q →r) →((¬q →¬p) →\n(p →r)) to show how it determines the proof structure.\nTherefore the sequent\n⊢(q →r) →((¬q →¬p) →(p →r)) is valid,\nshowing that (q →r) →((¬q →¬p) →(p →r)) is another theorem.\nRemark 1.12 Indeed, this example indicates that we may transform any\nproof of φ1, φ2, . . . , φn ⊢ψ in such a way into a proof of the theorem\n⊢φ1 →(φ2 →(φ3 →(· · · →(φn →ψ) . . . )))\nby ‘augmenting’ the previous proof with n lines of the rule →i applied to\nφn, φn−1,. . . , φ1 in that order.\nThe nested boxes in the proof of Example 1.11 reveal a pattern of using\nelimination rules ﬁrst, to deconstruct assumptions we have made, and then\nintroduction rules to construct our ﬁnal conclusion. More diﬃcult proofs\nmay involve several such phases.\nLet us dwell on this important topic for a while. How did we come up\nwith the proof above? Parts of it are determined by the structure of the for-\nmulas we have, while other parts require us to be creative. Consider the log-\nical structure of (q →r) →((¬q →¬p) →(p →r)) schematically depicted\nin Figure 1.1. The formula is overall an implication since →is the root of\nthe tree in Figure 1.1. But the only way to build an implication is by means\n1.2 Natural deduction\n15",
                            "summary": "We start by writing down the premises; then we leave a gap and write the conclusion. The task of constructing the proof is to fill the gap between the premises and the conclusion by applying a suitable sequence of proof rules. We also usually usuallynumber all the lines, and write in the justiﬁcation for each line, producing a proof like the one in the following example. The conclusion has to match the second conjunct of the premises, and the formula can be any formula. It is important to engage in this kind of pattern matching before the application of proofrules. Let’s use these rules to prove that p ∧q, r |−q ∧r is valid. If a sequent is valid, there may be many diﬀerent ways of proving it. So if you compare your solution to these exercises with those of others, they need not coincide. Throughout this text, we will use the traditional version of presenting proofs. That way you have to concentrate only on how to prove a proof, not how to grow a growing tree onto a sheet of paper. If we applied these proof rules literally, then the proof above would be a tree with root q and leaves p and r. However, we ﬂattened this tree into a linear presentation which necessitates the use of pointers as seen in lines 3 and 4 above. These pointers allow us to recreate the actual proof tree Let’s now look at our proof rules. We present about ﬁfteen of them in total; we will go through them in turn and then summarise at the end of this section.1. Propositional logic: We expect that we won’t be able to show the sequent p, q ⊢p ≢p ¬q. The important thing to realise, though, is that any putative                 is not a real number.2. Rules for natural deduction: We present the rules for conjunction, and-introduction, and conclusion. The rules for logical deduction are: 1. Conjecture, 2. logical deduction, and 3. Conclusion. For each of the connectives, there is one or more rules to introduce it and one or two rules to eliminate it. The rules for and-elimination are these two: and-introduction. The rule 1 says: if you have a proof of φ, then by applying this rule you can get a proof for φ. And the rule 2 says the same thing, but allows you to conclude φ instead. The exact nature of the second conjunct of the first conjunct is irrelevant. The conclusion φ has to match the ﬁrst conjunct, whereas φ can be any formula. And in the second rule it is just the other way around: the conclusion ψ The new approach expresses this as an inference rule between sequents. It is important to engage in this kind of pattern matching before the application of proof rules. The rule ‘assumption’ is written as the premise is empty. Such rules are called axioms. The new system has a tree-like structure with the root of the proof system as root. It also has a more complex proof system than the previous one. The proof system is described in Figure 1.2. The original version of this article referred to ‘proof by contradiction’. We are happy to clarify that this is not the case and that the new system is based on a different type of proof system. On squaring both sides                we get 2 = k2/l2, or equivalently 2l2 + k2. Can you now argue that 2L2 has a diﬀerentnumber of 2 factors from k2? Why would that be a contradiction and to what? There is an alternative approach to treating negation. One could simply ban the operator ¬ from propositional logic and think of φ →⊥as ‘being’ ¬φ. Naturally, such a logic cannot rely on the natural deduction rules forNegation. Which of the rules ¬i, ¬e, e and ¬¬i can you simulate with the remaining proof rules by letting The rule →i is now called type checking, animportant topic in the construction of compilers for typed programming languages. Given the following formulas, draw their corresponding parse tree. Showing p →q using the rule  is now known as type checking. The rule is used to show that a procedure can be true about a procedure while that same procedure couldcompute strange things or crash in the case that the input is not an in-centricteger. It says: in order to prove φ →ψ, make a temporary assumption of φ and then use that assumption to prove that φ is true. In your proof of ψ, you can use any of the other formulas that you have made so far. The line immediately following a closed box has to match the pattern of the conclusion of the rule that uses the box. For implies-introduction, this means that we have to continue after the box with φ. We will encounter two more proof rules involving proof boxes. They will require similar patternmatching and will use a different formula for each line. The rules are: MT 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37 The validity of ⊢AR (y < 3) →(y + 1 < 4) is rooted in general facts about integers and the relation < deﬁned on them. We may use ordinary logical and arithmetic implications to change a certaincondition φ to any condition φ′ which is implied by φ for reasons which have nothing to do with the given code. For the sequential composition of assignment statements, our goal is to show that u stores the sum of x and y after this sequence of assignments terminates. We won’t do that here as this chapter focuses on aspects of proofs which deal directly with code. We’re going to focus on the proof of the rule Implied. We construct the proof by starting with the postcondition u = x + y and pushing it up through the assignments, in reverse order. The weakest precondition that thus emerges is X + y = x - y; we have to check that this follows from the given preconditions. Let us write P for the code above. Thus, we mean to disprove ⊢par                  P =\"P,\" P =\"prove\", P = P, P \"prove\" \"P\" = P, P \"p\" = P, \"P\" = \"P\", P \"proving\" P\" is the proof for the proof. The Latin name reductio ad absurdum means ‘reduc-                tion to absurdity’ and we will simply call it proof by contradiction (PBC), for short. The rule says: if from ¬φ we obtain a contradiction, then we are                entitled to deduce φ. This is the clue to how to derive PBC from our basic proof rules. The completed proof therefore looks like this: PBC 1.2 Natural deduction. PBC 2.25 Natural deduction, PBC 3.5 Natural deduction and PBC 4.5 PBC 5. The proof looks rather similar to ¬i, except that the negation is in a diﬀerent PBC can be derived from →i, ¬i, →e and ¬¬e. By transforming this into a proof of ¬φ, we can prove PBC. PBC is the law of the excluded middle, or LEM for short. It simply says that whatever φ is, it must be either true or false. There is no third possibility (hence the LEM name) for PBC to be true. For example, whenever you write an if-statement in a programming language, it relies on the fact that B is always true (and that B and B can never be true at the same time). PBC has a Latin name, tertium non datur, which The Implied rule is often used to simplify formulas that are generated by applications of other rules. It is also used when the weakest precondition emerges by pushing the postcondition upwards through the whole pro-portergram. We use theimplied rule to show that the given preconditions implies the weakest precondition. The implications we typically encounter will be easy to verify, but it can be diﬃcult to decide which instance of LEM would beneﬁt the progress of a proof. Can you re-do the example above with q ∨¬q as LEM? If so, please send us a picture of the proof. We would like to see the proof in its entirety. The proof is constructed from the bottom upwards. We start with the given precondition and the arithmetic fact 5 + 1 = 6 imply it, so we have ﬁnished the proof. The second line is implied by the first and the fourth by the intervening assignment. The justiﬁcations make sense when read top-down. Let’s look at some examples of this.Examples 4.13.1-4.4 Program verification and proof of the correctness of the proof are given. The proof is presented in the form of a series of questions. The answers to these questions will be given in the next section of the book. The book is published by Oxford University Press and is available in Program logic is a form of computer programming. It uses logical and arithmetic implications to change certain conditions. For example, the condition y < 3 implies that y + 1 < 3 + 1 = 4. The rule →i (with conclusion φ) does not prohibit the possibility that φ and ψ coincide. They could both be instanti-phthalated to p. The result is that p ⊢p is the result of a program logic proof, rather than a proof of a code. It is possible to change a certain condition to any condition that is implied by φ for reasons which have nothing to do with the given code. Logical formulas φ with valid sequent ⊢φ are theorems. Theorems can be proved using most of the rules introduced so far. For example, we can prove that the argumentation for p →p does notdepend on any premises at all. We may extend the proof above to prove that (q →r) is valid, showing that (p →p) is another theorem. We can transform any disproved proof of φ1, φ2, . . . , φn into a proof of the theorem, as shown in Figure 1.1. Theorem 1.11 is an example of a theorem whose proof utilises most.of the rules so far: The nested boxes in the proof of Example 1.11 reveal a pattern of usingelimination rules ﬁrst, to deconstruct assumptions we have made, and thenIntroduction rules to construct our conclusion. More diﬃcult proofs may involve several such phases. The formula is overall an implication since →is the root of the tree in Figure 1.1. But the only way to build an implication is by means of a natural deduction. The proof above is an example of how this can be carried out in a number of ways. For more information on natural deduction, see the Natural Deduction section of the book. The book is published by Oxford University Press.",
                            "children": []
                        },
                        {
                            "id": "chapter-4-section-3-subsection-2",
                            "title": "Proof Tableaux",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-4-section-3-subsection-3",
                            "title": "A Case Study: Minimal-Sum Section",
                            "content": "this has to be taken into account by the calculus.\n288\n4 Program verification\nwrite Si,j for the sum of that section: a[i] + a[i + 1] + · · · + a[j]. A minimal-\nsum section is a section a[i], . . . , a[j] of a such that the sum Si,j is less than\nor equal to the sum Si′,j′ of any other section a[i′], . . . , a[j′] of a.\nExample 4.19 Let us illustrate these concepts on the example integer array\n[−1, 3, 15, −6, 4, −5]. Both [3, 15, −6] and [−6] are sections, but [3, −6, 4]\nisn’t since 15 is missing. A minimal-sum section for this particular array is\n[−6, 4, −5] with sum −7; it is the only minimal-sum section in this case.\nIn general, minimal-sum sections need not be unique. For example, the\narray [1, −1, 3, −1, 1] has two minimal-sum sections [1, −1] and [−1, 1] with\nminimal sum 0.\nThe task at hand is to\nr write a program Min Sum, written in our core programming language extended\nwith integer arrays, which computes the sum of a minimal-sum section of a given\narray;\nr make the informal requirement of this problem, given in the previous item, into\na formal speciﬁcation about the behaviour of Min Sum;\nr use our proof calculus for partial correctness to show that Min Sum satisﬁes those\nformal speciﬁcations provided that it terminates.\nThere is an obvious program to do the job: we could list all the possible\nsections of a given array, then traverse that list to compute the sum of\neach section and keep the recent minimal sum in a storage location. For the\nexample array [−1, 3, −2], this results in the list\n[−1], [−1, 3], [−1, 3, −2], [3], [3, −2], [−2]\nand we see that only the last section [−2] produces the minimal sum −2.\nThis idea can easily be coded in our core programming language, but it\nhas a serious drawback: the number of sections of a given array of size n is\nproportional to the square of n; if we also have to sum all those, then our task\nhas worst-case time complexity of the order n · n2 = n3. Computationally,\nthe range of indexes of the array and t stores the minimal sum of sections\nthat end at a[k] – whenever the control ﬂow of the program is about to\nevaluate the boolean expression of its while-statement. As each new value is\nexamined, we can either add it to the current minimal sum, or decide that a\nlower minimal sum can be obtained by starting a new section. The variable\ns stores the minimal sum seen so far; it is computed as the minimum we\nhave seen so far in the last step, or the minimal sum of sections that end at\nthe current point.\nAs you can see, it not intuitively clear that this program is correct, war-\nranting the use of our partial-correctness calculus to prove its correctness.\nTesting the program with a few examples is not suﬃcient to ﬁnd all mis-\ntakes, however, and the reader would rightly not be convinced that this\nprogram really does compute the minimal-sum section in all cases. So let\nus try to use the partial-correctness calculus introduced in this chapter to\nprove it.\n290\n4 Program verification\nWe formalise our requirement of the program as two speciﬁcations6, writ-\nten as Hoare triples.\nS1.\n\u0001\n⊤\n\u0002\nMin Sum\n\u0001\n∀i, j (0 ≤i ≤j < n →s ≤Si,j)\n\u0002\n.\nIt says that, after the program terminates, s is less than or equal to, the\nsum of any section of the array. Note that i and j are logical variables\nin that they don’t occur as program variables.\nS2.\n\u0001\n⊤\n\u0002\nMin Sum\n\u0001\n∃i, j (0 ≤i ≤j < n ∧s = Si,j)\n\u0002\n,\nwhich says that there is a section whose sum is s.\nIf there is a section whose sum is s and no section has a sum less than s,\nthen s is the sum of a minimal-sum section: the ‘conjunction’ of S1 and S2\ngive us the property we want.\nLet us ﬁrst prove S1. This begins with seeking a suitable invariant. As\nalways, the following characteristics of invariants are a useful guide:\nr Invariants express the fact that the computation performed so far by the while-\nstatement is correct.\nr Invariants typically have the same form as the desired postcondition of the while-\nstatement.\nt = a[0];\n(Inv1(a[0], k) ∧Inv2(t, k))\nAssignment\ns = a[0];\n(Inv1(s, k) ∧Inv2(t, k))\nAssignment\nwhile (k != n) {\n(Inv1(s, k) ∧Inv2(t, k) ∧k ̸= n)\nInvariant Hyp. ∧guard\n(Inv1(min(s, min(t + a[k], a[k])), k + 1)\n∧Inv2(min(t + a[k], a[k]), k + 1))\nImplied (Lemma 4.20)\nt = min(t + a[k], a[k]);\n(Inv1(min(s, t), k + 1) ∧Inv2(t, k + 1))\nAssignment\ns = min(s,t);\n(Inv1(s, k + 1) ∧Inv2(t, k + 1))\nAssignment\nk = k + 1;\n(Inv1(s, k) ∧Inv2(t, k))\nAssignment\n}\n(Inv1(s, k) ∧Inv2(t, k) ∧¬¬(k = n))\nPartial-while\n(Inv1(s, n))\nImplied\nFigure 4.3. Tableau proof for specification S1 of Min Sum.\ncomputation is\nInv2(t, k)\ndef\n= ∀i (0 ≤i < k →t ≤Si,k−1)\n(4.13)\nsaying that t is not greater than the sum of any section ending in a[k −1].\nOur invariant is the conjunction of these formulas, namely\nInv1(s, k) ∧Inv2(t, k).\n(4.14)\nThe completed proof tableau of S1 for Min Sum is given in Figure 4.3. The\ntableau is constructed by\nr Proving that the candidate invariant (4.14) is indeed an invariant. This involves\npushing it upwards through the body of the while-statement and showing that\nwhat emerges follows from the invariant and the boolean guard. This non-trivial\nimplication is shown in the proof of Lemma 4.20.\nr Proving that the invariant, together with the negation of the boolean guard, is\nstrong enough to prove the desired postcondition. This is the last implication of\nthe proof tableau.\n292\n4 Program verification\nr Proving that the invariant is established by the code before the while-statement.\nWe simply push it upwards through the three initial assignments and check that\nthe resulting formula is implied by the precondition of the speciﬁcation, here ⊤.\nAs so often the case, in constructing the tableau, we ﬁnd that two formulas\nmeet; and we have to prove that the ﬁrst one implies the second one. Some-\ntimes this is easy and we can just note the implication in the tableau. For\nexample, we readily see that ⊤implies Inv1(a[0], 1) ∧Inv2(a[0], 1): k being\nhas a serious drawback: the number of sections of a given array of size n is\nproportional to the square of n; if we also have to sum all those, then our task\nhas worst-case time complexity of the order n · n2 = n3. Computationally,\nthis is an expensive price to pay, so we should inspect the problem more\nclosely in order to see whether we can do better.\nCan we compute the minimal sum over all sections in time proportional\nto n, by passing through the array just once? Intuitively, this seems diﬃcult,\nsince if we store just the minimal sum seen so far as we pass through the\narray, we may miss the opportunity of some large negative numbers later on\nbecause of some large positive numbers we encounter en route. For example,\n4.3 Proof calculus for partial correctness\n289\nsuppose the array is\n[−8, 3, −65, 20, 45, −100, −8, 17, −4, −14].\nShould we settle for −8 + 3 −65, or should we try to take advantage of the\n−100 – remembering that we can pass through the array only once? In this\ncase, the whole array is a section that gives us the smallest sum, but it\nis diﬃcult to see how a program which passes through the array just once\ncould detect this.\nThe solution is to store two values during the pass: the minimal sum seen\nso far (s in the program below) and also the minimal sum seen so far of\nall sections which end at the current point in the array (t below). Here is a\nprogram that is intended to do this:\nk = 1;\nt = a[0];\ns = a[0];\nwhile (k != n) {\nt = min(t + a[k], a[k]);\ns = min(s,t);\nk = k + 1;\n}\nwhere min is a function which computes the minimum of its two arguments\nas speciﬁed in exercise 10 on page 301. The variable k proceeds through\nthe range of indexes of the array and t stores the minimal sum of sections\nthat end at a[k] – whenever the control ﬂow of the program is about to\nevaluate the boolean expression of its while-statement. As each new value is\nexamined, we can either add it to the current minimal sum, or decide that a\nwhile (r >= y) {\nr = r - y;\nd = d + 1;\n}\nShow that ⊢par\n\u0001\n¬(y = 0)\n\u0002\nDiv\n\u0001\n(x = d · y + r) ∧(r < y)\n\u0002\nis valid.\n18.\n*\nShow that ⊢par\n\u0001\nx ≥0\n\u0002\nDownfac\n\u0001\ny = x!\n\u0002\nis valid7, where Downfac is:\na = x;\ny = 1;\nwhile (a > 0) {\ny = y * a;\na = a - 1;\n}\n19. Why can, or can’t, you prove the validity of ⊢par\n\u0001\n⊤\n\u0002\nCopy1\n\u0001\nx = y\n\u0002\n?\n20. Let all while-statements while (B) {C} in P be annotated with invariant\ncandidates η at the and of their bodies, and η ∧B at the beginning of their\nbody.\n(a) Explain how a proof of ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\ncan be automatically reduced to show-\ning the validity of some ⊢AR ψ1 ∧· · · ∧ψn.\n(b) Identify such a sequent ⊢AR ψ1 ∧· · · ∧ψn for the proof in Example 4.17 on\npage 287.\n21. Given n = 5 test the correctness of Min Sum on the arrays below:\n(a)\n*\n[−3, 1, −2, 1, −8]\n(b) [1, 45, −1, 23, −1]\n(c)\n*\n[−1, −2, −3, −4, 1097].\n22. If we swap the ﬁrst and second assignment in the while-statement of Min Sum,\nso that it ﬁrst assigns to s and then to t, is the program still correct? Justify\nyour answer.\n23.\n*\nProve the partial correctness of S2 for Min Sum.\n24. The program Min Sum does not reveal where a minimal-sum section may be\nfound in an input array. Adapt Min Sum to achieve that. Can you do this with\na single pass through the array?\n25. Consider the proof rule\n\u0001\nφ\n\u0002\nC\n\u0001\nψ1\n\u0002\n\u0001\nφ\n\u0002\nC\n\u0001\nψ2\n\u0002\n\u0001\nφ\n\u0002\nC\n\u0001\nψ1 ∧ψ2\n\u0002\nConj\n7 You may have to strengthen your invariant.\n4.6 Exercises\n303\nfor Hoare triples.\n(a) Show that this proof rule is sound for ⊨par.\n(b) Derive this proof rule from the ones on page 270.\n(c) Explain how this rule, or its derived version, is used to establish the overall\ncorrectness of Min Sum.\n26. The maximal-sum problem is to compute the maximal sum of all sections on\nan array.\n(a) Adapt the program from page 289 so that it computes the maximal sum of\nthese sections.\n(b) Prove the partial correctess of your modiﬁed program.\n(c) Which aspects of the correctness proof given in Figure 4.3 (page 291) can\nbe ‘re-used?’\nExercises 4.4",
                            "summary": "A minimal-sum section is a section a[i], . . . , a[j] of a such that the sum Si,j is less than or equal to the sum of any other section of that section. In general, minimal-Sum sections need not be unique. Let us illustrate these concepts on the example integer array [−1, 3, 15, −6, 4, −5]. Both [3, 15,. −6] and [−6] are sections, but [3,. 15, 4] is not since 15 is missing. This has to be taken into account by the calculus. A minimal- sum section for this particular array is [ The task at hand is to write a program Min Sum, written in our core programming language extended with integer arrays. Min Sum computes the sum of a minimal-sum section of a given array. We make the informal requirement of this problem into a formal speciﬁcation about the behaviour of Min Sum. We also use our proof calculus for partial correctness to show that Min Sum satisﬄes those formal specﬅcations provided that it terminates. The program is called Min Sum and it is written in the programming language Python. The code is available for download from the GitHub repository. It is available in Python, C, C++, and The idea can easily be coded in our core programming language, but it has a serious drawback. The number of sections of a given array of size n isproportional to the square of n; if we also have to sum all those, then our task has worst-case time complexity of the order n · n2 = n3. Computationally, t stores the minimal sum of sections that end at a[k] – whenever the control ﬂow of the program is about toevaluate the boolean expression of its while-statement. As each new value is added, we can either add it to the current minimal sum, or decide that alower minimal sum can be obtained by starting a new section. We formalise our requirement of the program as two speciﬁcations6, writ-                ten as Hoare triples. The variable                s stores the minimal sum seen so far; it is computed as the minimum we                have seen in the last step. The program is not intuitively clear that this program is correct, war-                ranting the use of our partial-correctness calculus to prove its correctness. The reader would rightly not be convinced that this.program really does compute the minimal-sum section in all cases. So let us try to use the partial- correctness calculus introduced in this chapter to prove it. We call the program S1. It says that, after the program terminates Let us prove S1. This begins with seeking a suitable invariant. As always, the following characteristics of invariants are a useful guide. Invariants express the fact that the computation performed so far by the while-centricstatement is correct. The ‘conjunction’ of S1 and S2.give us the property we want. S1: There is a section whose sum is s, and no section has a sum less than s. S2: S is the sum of a minimal-sum section, and S1 is S1’s ‘condition’ for S1 to be true. S3: S1, S2, S3, S4, S5, The completed proof tableau of S1 for Min Sum is given in Figure 4.3. The tableau is constructed by proving that the candidate invariant (4.14) is indeed an invariant. This involvespushing it upwards through the body of the while-statement and showing that what emerges follows from the invariant and the boolean guard. The proof for S1 of Min Sum can be found in Lemma 4.20, where t is the sum of any section ending in a[k −1]. It can also be found by using the following formula:Inv1(s, k)  Inv2(t, k), where k is the number of sections ending in k. Proving that the invariant, together with the negation of the boolean guard, is strong enough to prove the desired postcondition. This non-trivialimplication is shown in the proof of Lemma 4.20. The last implication of the proof tableau is the last in the tableau. The tableau shows that two formulas meet, and we have to prove that the first one implies the second one. We simply push it upwards through the three initial assignments and check that the resulting formula is implied by the precondition of the speciﬁcation. The number of sections of a given array of size n isproportional to the square of n. If we also have to sum all those, then our task has worst-case time complexity of the order n · n2 = n3. Can we compute the minimal sum over all sections in time proportional to n, by passing through the array just once? Intuitively, this seems diﬃcult, since if we store just the minimalsum seen so far as we pass through thearray, we may miss the opportunity of some large negative numbers later on. But Computationally, this is an expensive price to pay, so we should inspect the problem moreclosely in order to see whether we can A program which passes through the array just once could detect this. The solution is to store two values during the pass: the minimal sum seen so far (s in the program below) and also the minimum sum seen in all sections which end at the current point in the array. Here is a program that is intended to do this. It uses a function which computes the minimum of its two arguments. The function is speciﬁed in exercise 10 on page 301 of the book. It is called min(s,t) and it is used in the proof calculus for partial correctness. For example, the program uses min(t, n) to prove that n is the number of points in an array. The variable k proceeds through                the range of indexes of the array and t stores the minimal sum of sections that end at a[k] – whenever the control ﬂow of the program is about toevaluate the while-statement. As each new value is examined, we can either add it to the current minimal sum, or decide that a is valid. For example, we could show that a while (r < y) is valid by using Downfac, where Downfac is: ‘A = x; a = 1; a + 1; y = y * a;’ or we could say that awhile (a > 0) is also valid by adding a to Downfac. Given n = 5 test the correctness of Min Sum on the arrays below. The program Min Sum does not reveal where a minimal-sum section may be found in an input array. If we swap the ﬁrst and second assignment in the while-statement of MinSum, is the program still correct? Justify your answer. Prove the partial correctness of S2 for Min Sum. Adapt Min Sum to achieve that. Can you do this with a single pass through the array? Prove it with two passes through an array. Proving it with three passes through a single array. proving it with four passes through two arrays. proving that it is possible to prove it with multiple passes. The maximal-sum problem is to compute the maximal sum of all sections on an array. Figure 4.3 (page 291) can be ‘re-used’ as a proof of the correctness of the program. The program can be adapted from page 289 so that it computes the maximalsum of these sections. The maximal sum is the sum of the parts of the array that make up the array. The problem can be solved by multiplying the sum by the number of sections in the array, or by the length of the entire array. It can be used to test the correctness and correctness of a program that is being used for the first time. For more information, see the",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-4-section-4",
                    "title": "Proof Calculus for Total Correctness",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-4-section-5",
                    "title": "Programming by Contract",
                    "content": null,
                    "summary": null,
                    "children": []
                }
            ]
        },
        {
            "id": "chapter-5",
            "title": "Modal Logics and Agents",
            "content": "long as they match the pattern required by the respective rule. For example,\n32\n1 Propositional logic\nthe application of the proof rule →e in\n1\np →q\npremise\n2\np\npremise\n3\nq\n→e 1, 2\nis equally valid if we substitute p with p ∨¬r and q with r →p:\n1\np ∨¬r →(r →p)\npremise\n2\np ∨¬r\npremise\n3\nr →p\n→e 1, 2\nThis is why we expressed such rules as schemes with Greek symbols stand-\ning for generic formulas. Yet, it is time that we make precise the notion of\n‘any formula we may form.’ Because this text concerns various logics, we will\nintroduce in (1.3) an easy formalism for specifying well-formed formulas. In\ngeneral, we need an unbounded supply of propositional atoms p, q, r, . . ., or\np1, p2, p3, . . . You should not be too worried about the need for inﬁnitely\nmany such symbols. Although we may only need ﬁnitely many of these\npropositions to describe a property of a computer program successfully, we\ncannot specify how many such atomic propositions we will need in any con-\ncrete situation, so having inﬁnitely many symbols at our disposal is a cheap\nway out. This can be compared with the potentially inﬁnite nature of En-\nglish: the number of grammatically correct English sentences is inﬁnite, but\nﬁnitely many such sentences will do in whatever situation you might be in\n(writing a book, attending a lecture, listening to the radio, having a dinner\ndate, . . . ).\nFormulas in our propositional logic should certainly be strings over the\nalphabet {p, q, r, . . . } ∪{p1, p2, p3, . . . } ∪{¬, ∧, ∨, →, (, )}. This is a trivial\nobservation and as such is not good enough for what we are trying to capture.\nFor example, the string (¬)() ∨pq →is a word over that alphabet, yet, it\ndoes not seem to make a lot of sense as far as propositional logic is concerned.\nSo what we have to deﬁne are those strings which we want to call formulas.\nWe call such formulas well-formed.\nDeﬁnition 1.27 The well-formed formulas of propositional logic are those\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nvaluation\nfor propositional logic, 37\nin predicate logic, 123\nin relational mu-calculus, 391\nvalue\ninitial, 206, 268, 269\nVardi, M., 254\nvariable, 94, 260\nboolean, 229, 247, 358\nbound, 103\ncapture, 106\ndummy, 110\nfree, 103\nlocal, 263\nlogical, 268, 290\nvariable ordering\ncompatible, 368\nlist, 367\nvariant, 293\nveriﬁcation\nfull, 173\nmethod, 172\nof communication protocols, 175\nof hardware, 175\nof software, 175\nof systems, 256\npost-development, 173, 257\npre-development, 173, 257\nprocess, 271\nprogram, 270\nproperty, 173\nproperty-oriented, 256\nsemi-automatic, 256\ntechniques, 172\nweakest precondition, 276\nwhile-statement, 261, 262\nbody, 273, 282, 286\nnon-termination, 292\nwise-men puzzle, 342\nWolper, P., 254\nword\nempty, 126\nworld\naccessible, 309\npossible, 309, 336\nyear-2000 problem, 258\n(f) Prove that for every preﬁx of a well-formed propositional logic formula the\nnumber of left brackets is greater or equal to the number of right brackets.\n8.\n*\nThe Fibonacci numbers are most useful in modelling the growth of populations.\nWe deﬁne them by F1\ndef\n= 1, F2\ndef\n= 1 and Fn+1\ndef\n= Fn + Fn−1 for all n ≥2. So\nF3\ndef\n= F1 + F2 = 1 + 1 = 2 etc. Show the assertion ‘F3n is even.’ by mathemat-\nical induction on n ≥1. Note that this assertion is saying that the sequence\nF3, F6, F9, . . . consists of even numbers only.\n86\n1 Propositional logic\n9. Consider the function rank, deﬁned by\nrank(p)\ndef\n= 1\nrank(¬φ)\ndef\n= 1 + rank(φ)\nrank(φ ◦ψ)\ndef\n= 1 + max(rank(φ), rank(ψ))\nwhere p is any atom, ◦∈{→, ∨, ∧} and max(n, m) is n if n ≥m and m other-\nwise. Recall the concept of the height of a formula (Deﬁnition 1.32 on page 44).\nUse mathematical induction on the height of φ to show that rank(φ) is nothing\nbut the height of φ for all formulas φ of propositional logic.\n10.\n*\nHere is an example of why we need to secure the base case for mathematical\ninduction. Consider the assertion\n‘The number n2 + 5n + 1 is even for all n ≥1.’\n(a) Prove the inductive step of that assertion.\n(b) Show that the base case fails to hold.\n(c) Conclude that the assertion is false.\n(d) Use mathematical induction to show that n2 + 5n + 1 is odd for all n ≥1.\n11. For the soundness proof of Theorem 1.35 on page 46,\n(a) explain why we could not use mathematical induction but had to resort to\ncourse-of-values induction;\n(b) give justiﬁcations for all inferences that were annotated with ‘why?’ and\n(c) complete the case analysis ranging over the ﬁnal proof rule applied; inspect\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional terms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-\nWe saw in the preceding section that there appeared to be a correspondence\nbetween the validity of 2φ →φ and the property that the accessibility re-\nlation R is reﬂexive. The connection between them is that both relied on\nthe intuition that anything which is known by an agent is true. Moreover,\nthere also seemed to be a correspondence between 2φ →22φ and R being\ntransitive; they both seem to assert the property of positive introspection,\ni.e. that which is known is known to be known.\nIn this section, we will see that there is a precise mathematical relation-\nship between these formulas and properties of R. Indeed, to every formula\nscheme there corresponds a property of R. From the point of view of logic\nengineering, it is important to see this relationship, because it helps one to\nunderstand the logic being studied. For example, if you believe that a cer-\ntain formula scheme should be accepted in the system of modal logic you are\nengineering, then it is well worth looking at the corresponding property of\nR and checking that this property makes sense for the application, too. Al-\nternatively, the meaning of some formulas may seem diﬃcult to understand,\nso looking at their corresponding properties of R can help.\nTo state the relationship between formula schemes and their correspond-\ning properties, we need the notion of a (modal) frame.\nDeﬁnition 5.10 A frame F = (W, R) is a set W of worlds and a binary\nrelation R on W.\nA frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-\nbelling function. From any model we can extract a frame, by just forgetting\nabout the labelling function; for example, Figure 5.9 shows the frame ex-\ntracted from the Kripke model of Figure 5.3. A frame is just a set of worlds\nand an accessibility relationship between them. It has no information about\nwhat atomic formulas are true at the various worlds. However, it is useful to\nsay sometimes that the frame, as a whole, satisﬁes a formula. This is deﬁned\nas follows.\n{x1, x2, x3, x4, x5, x6} is shown in Figure 5.13. The links between the worlds\nhave to be labelled with the name of the accessibility relation, since we have\nseveral relations. For example, x1 and x2 are related by R1, whereas x4 and\n5.5 Reasoning about knowledge in a multi-agent system\n337\nx5 are related both by R1 and by R2. We simplify by no longer requiring ar-\nrows on the links. This is because we know that the relations are symmetric,\nso the links are bi-directional. Moreover, the relations are also reﬂexive, so\nthere should be loops like the one on x4 in Figure 5.11 in all the worlds and\nfor all of the relations. We can simply omit these from the diagram, since we\ndon’t need to distinguish between worlds which are self-related and those\nwhich are not.\nDeﬁnition 5.25 Take a model M = (W, (Ri)i∈A, L) of KT45n and a world\nx ∈W. We deﬁne when φ is true in x via a satisfaction relation x ⊩φ by\ninduction on φ:\nx ⊩p iﬀp ∈L(x)\nx ⊩¬φ iﬀx ̸⊩φ\nx ⊩φ ∧ψ\niﬀx ⊩φ and x ⊩ψ\nx ⊩φ ∨ψ\niﬀx ⊩φ or x ⊩ψ\nx ⊩φ →ψ\niﬀx ⊩ψ whenever we have x ⊩φ\nx ⊩Ki ψ\niﬀ, for each y ∈W, Ri(x, y) implies y ⊩ψ\nx ⊩EG ψ\niﬀ, for each i ∈G, x ⊩Ki ψ\nx ⊩CG ψ\niﬀ, for each k ≥1, we have x ⊩Ek\nGψ,\nwhere Ek\nG means EGEG . . . EG – k times\nx ⊩DG ψ\niﬀ, for each y ∈W, we have y ⊩ψ,\nwhenever Ri(x, y) for all i ∈G.\nAgain, we write M, x ⊩φ if we want to emphasise the model M.\nCompare this with Deﬁnition 5.4. The cases for the boolean connectives\nare the same as for basic modal logic. Each Ki behaves like a 2, but refers to\nits own accessibility relation Ri. As already stated, there are no equivalents\nof 3, but we can recover them as ¬Ki¬. The connective EG is deﬁned in\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of The interpretation of P on M is just what we expect it to be:\nP M def\n= {(s, t) | there is a sequence of indices (i1, i2, . . . , im) such that\ns equals si1si2 . . . sim and t equals ti1ti2 . . . tim}\nwhere s and t are binary strings and the si and ti are the data of the\ncorrespondence problem C. A pair of strings (s, t) lies in P M iﬀ, using the\nsame sequence of indices (i1, i2, . . . , im), s is built using the corresponding\nsi and t is built using the respective ti.\nSince ⊨φ holds we infer that M ⊨φ holds, too. We claim that M ⊨\nφ2 holds as well, which says that whenever the pair (s, t) is in P M, then\nthe pair (s si, t ti) is also in P M for i = 1, 2, . . . , k (you can verify that is\nsays this by inspecting the deﬁnition of P M). Now (s, t) ∈P M implies that\nthere is some sequence (i1, i2, . . . , im) such that s equals si1si2 . . . sim and t\nequals ti1ti2 . . . tim. We simply choose the new sequence (i1, i2, . . . , im, i) and\nobserve that s si equals si1si2 . . . simsi and t ti equals ti1ti2 . . . timti and so\nM ⊨φ2 holds as claimed. (Why does M ⊨φ1 hold?)\nSince M ⊨φ1 ∧φ2 →φ3 and M ⊨φ1 ∧φ2 hold, it follows that M ⊨φ3\nholds as well. By deﬁnition of φ3 and P M, this tells us there is a solution\nto C.\nConversely, let us assume that the Post correspondence problem C has\nsome solution, namely the sequence of indices (i1, i2, . . . , in). Now we have to\nshow that, if M′ is any model having a constant eM′, two unary functions,\n2.5 Undecidability of predicate logic\n135\nfM′\n0\nand fM′\n1\n, and a binary predicate P M′, then that model has to satisfy\nφ. Notice that the root of the parse tree of φ is an implication, so this is\nthe crucial clause for the deﬁnition of M′ ⊨φ. By that very deﬁnition, we\nare already done if M′ ̸⊨φ1, or if M′ ̸⊨φ2. The harder part is therefore the\none where M′ ⊨φ1 ∧φ2, for in that case we need to verify M′ ⊨φ3 as well.\nThe way we proceed here is by interpreting ﬁnite, binary strings in the knowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nhave connectives for expressing several modes of truth in the same logic; we\nwill see some of these towards the end of this chapter.\nWe take a logic engineering approach in this chapter, in which we address\nthe following question: given a particular mode of truth, how may we develop\na logic capable of expressing and formalising that concept? To answer this\nquestion, we need to decide what properties the logic should have and what\nexamples of reasoning it should be able to express. Our main case study will\nbe the logic of knowledge in a multi-agent system. But ﬁrst, we look at the\nsyntax and semantics of basic modal logic.\n5.2 Basic modal logic\n5.2.1 Syntax\nThe language of basic modal logic is that of propositional logic with two\nextra connectives, 2 and 3. Like negation (¬), they are unary connectives\nas they apply themselves to a single formula only. As done in Chapters 1\nand 3, we write p, q, r, p3 . . . to denote atomic formulas.\nDeﬁnition 5.1 The formulas of basic modal logic φ are deﬁned by the\nfollowing Backus Naur form (BNF):\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) | (2φ) | (3φ)\n(5.1)\nwhere p is any atomic formula.\nExample formulas of basic modal logic are (p ∧3(p →2¬r)) and 2((3q ∧\n¬r) →2p), having the parse trees shown in Figure 5.1. The following strings\nare not formulas, because they cannot be constructed using the grammar\nin (5.1): (p2 →q) and (p →3(q 3 r)).\nConvention 5.2 As done in Chapter 1, we assume that the unary connec-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin various ways to give us the properties appropriate for the intended ap-\nplications. Logic engineering is the subject of engineering logics to ﬁt new\napplications. It is potentially a very broad subject, drawing on all branches\nof logic, computer science and mathematics. In this chapter, however, we\nare restricting ourselves to the particular engineering of modal logics.\nWe will consider how to re-engineer basic modal logic to ﬁt the following\nreadings of 2φ:\nr It is necessarily true that φ\nr It will always be true that φ\nr It ought to be that φ\nr Agent Q believes that φ\nr Agent Q knows that φ\nr After any execution of program P, φ holds.\nAs modal logic automatically gives us the connective 3, which is equivalent\nto ¬2¬, we can ﬁnd out what the corresponding readings of 3 in our system\nwill be. For example, ‘it is not necessarily true that not φ’ means that it is\npossibly true that φ. You could work this out in steps:\nIt is not necessarily true that φ\n= it is possible that not φ.\nTherefore,\nIt is not necessarily true that not φ\n= it is possible that not not φ\n= it is possible that φ.\nLet us work this out with the reading ‘agent Q knows φ’ for 2φ. Then, 3φ\nis read as\nagent Q does not know not φ\n= as far as Q’s knowledge is concerned, φ could be the case\n= φ is consistent with what agent Q knows\n= for all agent Q knows, φ.\nThe readings for 3 for the other modes are given in Table 5.6.\n5.3 Logic engineering\n317\nTable 5.6. The readings of 3 corresponding to each reading of 2.\n2φ\n3φ\nIt is necessarily true that φ\nIt is possibly true that φ\nIt will always be true that φ\nSometime in the future φ\nIt ought to be that φ\nIt is permitted to be that φ\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-\nSo ¬p1, ¬p2 mean they (respectively) are wearing a white one. Informally\njustify each of the following premises in terms of the description of the\nproblem:\ni. K2K1 (p1 ∨p2)\nii. K2(¬p2 →K1 ¬p2)\niii. K2¬K1 p1.\n(c) Using natural deduction, prove from these premises that K2 p2.\n(d) Show that the third premise was essential, by exhibiting a model/world\nwhich satisﬁes the ﬁrst two, but not the conclusion.\n(e) Now is it easy to answer questions like ‘If man 2 were blind would he still be\nable to tell?’ and ‘if man 1 were blind, would man 2 still be able to tell?’?\n12. Recall our informal discussion on positive-knowledge formulas and negative-\nknowledge formulas. Give formal deﬁnitions of these notions.\n5.7 Bibliographic notes\nThe ﬁrst systematic approaches to modal logic were made by C. I. Lewis\nin the 1950s. The possible-worlds approach, which greatly simpliﬁed modal\nlogic and is now almost synonymous with it, was invented by S. Kripke.\nBooks devoted to modal logic include [Che80, Gol87, Pop94], where exten-\nsive references to the literature may be found. All these books discuss the\nsoundness and completeness of proof calculi for modal logics. They also in-\nvestigate which modal logics have the ﬁnite-model property: if a sequent\ndoes not have a proof, there is a ﬁnite model which demonstrates that. Not\nall modal logics enjoy this property, which is important for decidability.\nIntuitionistic propositional logic has the ﬁnite-model property; an anima-\ntion which generates such ﬁnite models (called PORGI) is available from\nA. Stoughton’s website2.\nThe idea of using modal logic to reason about knowledge is due to J.\nHintikka. A great deal of work on applying modal logic to multi-agent sys-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nin the future. For example, we would say that, although the sentence\nGeorge W. Bush is president of the United States of America.\nis currently true, it will not be true at some point in the future. Equally, the\nsentence\nThere are nine planets in the solar system.\nwhile true, and maybe true for ever in the future, is not necessarily true, in\nthe sense that it could have been a diﬀerent number. However, the sentence\nThe cube root of 27 is 3.\nas well as being true is also necessarily true and true in the future. It does\nnot enjoy all modes of truth, however. It may not be known to be true by\nsome people (children, for example); it may not be believed by others (if\nthey are mistaken).\nIn computer science, it is often useful to reason about modes of truth. In\nChapter 3, we studied the logic CTL in which we could distinguish not only\nbetween truth at diﬀerent points in the future, but also between diﬀerent\nfutures. Temporal logic is thus a special case of modal logic. The modalities\nof CTL allow us to express a host of computational behaviour of systems.\nModalities are also extremely useful in modelling other domains of com-\nputer science. In artiﬁcial intelligence, for example, scenarios with several\n306\n5.2 Basic modal logic\n307\ninteracting agents are developed. Each agent may have diﬀerent knowledge\nabout the environment and also about the knowledge of other agents. In this\nchapter, we will look in depth at modal logics applied to reasoning about\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\nfunction and world which does satisfy p →23p in your frame?\n15. Give two examples of frames which are Euclidean – i.e. their accessibility rela-\ntion is Euclidean – and two which are not. Explain intuitively why 3p →23p\nholds on the ﬁrst two, but not on the latter two.\n16. For each of the following formulas, ﬁnd the property of R which corresponds to\nit.\n(a) φ →2φ\n(b)\n*\n2⊥\n(c)\n*\n32φ →23φ.\n17.\n*\nFind a formula whose corresponding property is density: for all x, z ∈W such\nthat R(x, z), there exists y ∈W such that R(x, y) and R(y, z).\n18. The modal logic KD45 is used to model belief; see Table 5.12 for the axiom\nschemes D, 4, and 5.\n(a) Explain how it diﬀers from KT45.\n(b) Show that ⊨KD45 2p →3p is valid. What is the signiﬁcance of this, in terms\nof knowledge and belief?\n(c) Explain why the condition of seriality is relevant to belief.\n19. Recall Deﬁnition 5.7. How would you deﬁne ≡L for a modal logic L?\nExercises 5.4\n1. Find natural deduction proofs for the following sequents over the basic modal\nlogic K.\n(a)\n*\n⊢K 2(p →q) |−2p →2q\n(b) ⊢K 2(p →q) |−3p →3q\n(c)\n*\n⊢K|−2(p →q) ∧2(q →r) →2(p →r)\n(d) ⊢K 2(p ∧q) |−2p ∧2q\n(e) ⊢K|−3⊤→(2p →3p)\n(f)\n*\n⊢K 3(p →q) |−2p →3q\n(g) ⊢K 3(p ∨q) |−3p ∨3q.\n354\n5 Modal logics and agents\n2. Find natural deduction proofs for the following, in modal logic KT45.\n(a) p →23p\n(b) 23p ↔3p\n(c)\n*\n32p ↔2p\n(d) 2(2p →2q) ∨2(2q →2p)\n(e) 2(3p →q) ↔2(p →2q).\n3. Study the proofs you gave for the previous exercise to see whether any of\nthese formula schemes could be valid in basic modal logic. Inspect where and\nhow these proofs used the axioms T, 4 and 5 to see whether you can ﬁnd a\ncounter example, i.e. a Kripke model and a world which does not satisfy the\nformula.\n4. Provide a sketch of an argument which shows that the natural deduction rules\nfor basic modal logic are sound with respect to the semantics x ⊩φ over Kripke\nstructures.\nExercises 5.5\n1. This exercise is about the wise-men puzzle. Justify your answers. knowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nhave connectives for expressing several modes of truth in the same logic; we\nwill see some of these towards the end of this chapter.\nWe take a logic engineering approach in this chapter, in which we address\nthe following question: given a particular mode of truth, how may we develop\na logic capable of expressing and formalising that concept? To answer this\nquestion, we need to decide what properties the logic should have and what\nexamples of reasoning it should be able to express. Our main case study will\nbe the logic of knowledge in a multi-agent system. But ﬁrst, we look at the\nsyntax and semantics of basic modal logic.\n5.2 Basic modal logic\n5.2.1 Syntax\nThe language of basic modal logic is that of propositional logic with two\nextra connectives, 2 and 3. Like negation (¬), they are unary connectives\nas they apply themselves to a single formula only. As done in Chapters 1\nand 3, we write p, q, r, p3 . . . to denote atomic formulas.\nDeﬁnition 5.1 The formulas of basic modal logic φ are deﬁned by the\nfollowing Backus Naur form (BNF):\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) | (2φ) | (3φ)\n(5.1)\nwhere p is any atomic formula.\nExample formulas of basic modal logic are (p ∧3(p →2¬r)) and 2((3q ∧\n¬r) →2p), having the parse trees shown in Figure 5.1. The following strings\nare not formulas, because they cannot be constructed using the grammar\nin (5.1): (p2 →q) and (p →3(q 3 r)).\nConvention 5.2 As done in Chapter 1, we assume that the unary connec-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin various ways to give us the properties appropriate for the intended ap-\nplications. Logic engineering is the subject of engineering logics to ﬁt new\napplications. It is potentially a very broad subject, drawing on all branches\nof logic, computer science and mathematics. In this chapter, however, we\nare restricting ourselves to the particular engineering of modal logics.\nWe will consider how to re-engineer basic modal logic to ﬁt the following\nreadings of 2φ:\nr It is necessarily true that φ\nr It will always be true that φ\nr It ought to be that φ\nr Agent Q believes that φ\nr Agent Q knows that φ\nr After any execution of program P, φ holds.\nAs modal logic automatically gives us the connective 3, which is equivalent\nto ¬2¬, we can ﬁnd out what the corresponding readings of 3 in our system\nwill be. For example, ‘it is not necessarily true that not φ’ means that it is\npossibly true that φ. You could work this out in steps:\nIt is not necessarily true that φ\n= it is possible that not φ.\nTherefore,\nIt is not necessarily true that not φ\n= it is possible that not not φ\n= it is possible that φ.\nLet us work this out with the reading ‘agent Q knows φ’ for 2φ. Then, 3φ\nis read as\nagent Q does not know not φ\n= as far as Q’s knowledge is concerned, φ could be the case\n= φ is consistent with what agent Q knows\n= for all agent Q knows, φ.\nThe readings for 3 for the other modes are given in Table 5.6.\n5.3 Logic engineering\n317\nTable 5.6. The readings of 3 corresponding to each reading of 2.\n2φ\n3φ\nIt is necessarily true that φ\nIt is possibly true that φ\nIt will always be true that φ\nSometime in the future φ\nIt ought to be that φ\nIt is permitted to be that φ\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nis equivalent to one of the following: −, 2, 3, ¬, ¬2 and ¬3, where −\nindicates the absence of any negation or modality.\nThe modal logic KT4\nThe modal logic KT4, that is L equals {T, 4},\nis also called S4 in the literature. Correspondence theory tells us that its\nmodels are precisely the Kripke models M = (W, R, L), where R is reﬂexive\nand transitive. Such structures are often very useful in computer science. For\nexample, if φ stands for the type of a piece of code – φ could be int × int →\nbool, indicating some code which expects a pair of integers as input and\noutputs a boolean value – then 2φ could stand for residual code of type φ.\nThus, in the current world x this code would not have to be executed, but\ncould be saved (= residualised) for execution at a later computation stage.\nThe formula scheme 2φ →φ, the axiom T, then means that code may be\nexecuted right away, whereas the formula scheme 2φ →22φ, the axiom 4,\nallows that residual code remain residual, i.e. we can repeatedly postpone its\nexecution in future computation stages. Such type systems have important\napplications in the specialisation and partial evaluation of code. We refer\nthe interested reader to the bibliographic notes at the end of the chapter.\nTheorem 5.18 Any sequence of modal operators and negations in KT4 is\nequivalent to one of the following: −, 2, 3, 23, 32, 232, 323, ¬, ¬2,\n¬3, ¬23, ¬32, ¬232 and ¬323.\nIntuitionistic propositional logic\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\nThe natural deduction proof system for modal logic presented in this\nchapter is based on ideas in [Fit93].\n2 www.cis.ksu.edu/~allen/porgi.html\n5.7 Bibliographic notes\n357\nAn application of the modal logic KT4 (more precisely, its fragment with-\nout negation) as a type system for staged computation in a functional pro-\ngramming language can be found in [DP96].\nWe should stress that our framework was deliberately ‘classical;’ the thesis\n[Sim94] is a good source for discussions of intuitionistic modal logics; it also\ncontains a gentle introduction to basic ﬁrst-order modal logic.\n6\nBinary decision diagrams\n6.1 Representing boolean functions\nBoolean functions are an important descriptive formalism for many hard-\nware and software systems, such as synchronous and asynchronous circuits,\nreactive systems and ﬁnite-state programs. Representing those systems in a\ncomputer in order to reason about them requires an eﬃcient representation\nfor boolean functions. We look at such a representation in this chapter and\ndescribe in detail how the systems discussed in Chapter 3 can be veriﬁed\nusing the representation.\nDeﬁnition 6.1 A boolean variable x is a variable ranging over the values\n0 and 1. We write x1, x2, . . . and x, y, z, . . . to denote boolean variables. We\ndeﬁne the following functions on the set {0, 1}:\nr 0\ndef\n= 1 and 1\ndef\n= 0;\nr x · y\ndef\n= 1 if x and y have value 1; otherwise x · y\ndef\n= 0;\nr x + y\ndef\n= 0 if x and y have value 0; otherwise x + y\ndef\n= 1;\nr x ⊕y\ndef\n= 1 if exactly one of x and y equals 1.\nA boolean function f of n arguments is a function from {0, 1}n to {0, 1}.\nWe write f(x1, x2, . . . , xn), or f(V ), to indicate that a syntactic representa-\ntion of f depends on the boolean variables in V only.\ndistributed among them.\nDeﬁnition 5.23 A formula φ in the multi-modal logic of KT45n is deﬁned\nby the following grammar:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) |\n(Ki φ) | (EG φ) | (CG φ) | (DG φ)\n336\n5 Modal logics and agents\nq\nq\np, q\nx1\nx2\nx4\nx5\np\nx6\np\nx3\nR1\nR1, R2\nR1, R3\nR1, R2\nR3\nFigure 5.13. A KT45n model for n = 3.\nwhere p is any atomic formula, i ∈A and G ⊆A. We simply write E, C and\nD without subscripts if we refer to EA, CA and DA.\nCompare this deﬁnition with Deﬁnition 5.1. Instead of 2, we have several\nmodalities Ki and we also have EG, CG and DG for each G ⊆A. Actually,\nall of these connectives will shortly be seen to be ‘box-like’ rather than\n‘diamond-like’, in the sense that they distribute over ∧rather than over ∨–\ncompare this to the discussion of equivalences on page 308. The ‘diamond-\nlike’ correspondents of these connectives are not explicitly in the language,\nbut may of course be obtained using negations, i.e. ¬Ki¬, ¬CG¬ etc.\nDeﬁnition 5.24 A model M = (W, (Ri)i∈A, L) of the multi-modal logic\nKT45n with the set A of n agents is speciﬁed by three things:\n1.\na set W of possible worlds;\n2.\nfor each i ∈A, an equivalence relation Ri on W (Ri ⊆W × W), called the\naccessibility relations; and\n3.\na labelling function L : W →P(Atoms).\nCompare this with Deﬁnition 5.3. The diﬀerence is that, instead of just one\naccessibility relation, we now have a family, one for each agent in A; and we\nassume the accessibility relations are equivalence relations.\nWe exploit these properties of Ri in the graphical illustrations of Kripke\nmodels for KT45n. For example, a model of KT453 with set of worlds\n{x1, x2, x3, x4, x5, x6} is shown in Figure 5.13. The links between the worlds\nhave to be labelled with the name of the accessibility relation, since we have\nseveral relations. For example, x1 and x2 are related by R1, whereas x4 and\n5.5 Reasoning about knowledge in a multi-agent system\n337\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nin the future. For example, we would say that, although the sentence\nGeorge W. Bush is president of the United States of America.\nis currently true, it will not be true at some point in the future. Equally, the\nsentence\nThere are nine planets in the solar system.\nwhile true, and maybe true for ever in the future, is not necessarily true, in\nthe sense that it could have been a diﬀerent number. However, the sentence\nThe cube root of 27 is 3.\nas well as being true is also necessarily true and true in the future. It does\nnot enjoy all modes of truth, however. It may not be known to be true by\nsome people (children, for example); it may not be believed by others (if\nthey are mistaken).\nIn computer science, it is often useful to reason about modes of truth. In\nChapter 3, we studied the logic CTL in which we could distinguish not only\nbetween truth at diﬀerent points in the future, but also between diﬀerent\nfutures. Temporal logic is thus a special case of modal logic. The modalities\nof CTL allow us to express a host of computational behaviour of systems.\nModalities are also extremely useful in modelling other domains of com-\nputer science. In artiﬁcial intelligence, for example, scenarios with several\n306\n5.2 Basic modal logic\n307\ninteracting agents are developed. Each agent may have diﬀerent knowledge\nabout the environment and also about the knowledge of other agents. In this\nchapter, we will look in depth at modal logics applied to reasoning about\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nKT45, require extra rules if one wants to capture their semantic entailment\nvia proofs. In the case of KT45, this extra strength is expressed by rule\nschemes for the axioms T, 4 and 5:\n2φ\nφ\nT\n2φ\n22φ\n4\n¬2φ\n2¬2φ\n5\nAn equivalent alternative to the rules 4 and 5 would be to stipulate relax-\nations of the rules about moving formulas in and out of dashed boxes. Since\nrule 4 allows us to double-up boxes, we could instead think of it as allowing\nus to move formulas beginning with 2 into dashed boxes. Similarly, axiom\n5 has the eﬀect of allowing us to move formulas beginning with ¬2 into\ndashed boxes. Since 5 is a scheme and since φ and ¬¬φ are equivalent in ba-\nsic modal logic, we could write ¬φ instead of φ throughout without changing\nthe expressive power and meaning of that axiom.\nDeﬁnition 5.20 Let L be a set of formula schemes. We say that Γ ⊢L ψ is\nvalid if ψ has a proof in the natural deduction system for basic modal logic\nextended with the axioms from L and premises from Γ.\nExamples 5.21 We show that the following sequents are valid:\n1.\n|−K 2p ∧2q →2(p ∧q).\n1\n2p ∧2q\nassumption\n2\n2p\n∧e1 1\n3\n2q\n∧e2 1\n4\np\n2e 2\n5\nq\n2e 3\n6\np ∧q\n∧i 4, 5\n7\n2(p ∧q)\n2i 4−6\n8\n2p ∧2q →2(p ∧q)\n→i 1−7\n5.5 Reasoning about knowledge in a multi-agent system\n331\n2.\n|−KT45 p →23p.\n1\np\nassumption\n2\n2¬p\nassumption\n3\n¬p\nT 2\n4\n⊥\n¬e 1, 3\n5\n¬2¬p\n¬i 2−4\n6\n2¬2¬p\naxiom 5 on line 5\n7\np →2¬2¬p\n→i 1−6\n3.\n|−KT45 232p →2p.\n1\n2¬2¬2p\nassumption\n2\n¬2¬2p\n2e 1\n3\n¬2p\nassumption\n4\n2¬2p\naxiom 5 on line 3\n5\n⊥\n¬e 4, 2\n6\n¬¬2p\n¬i 3−5\n7\n2p\n¬¬e 6\n8\np\nT 7\n9\n2p\n2i 2−8\n10\n2¬2¬2p →2p\n→i 1−9\n5.5 Reasoning about knowledge in\na multi-agent system\nIn a multi-agent system, diﬀerent agents have diﬀerent knowledge of the\nworld. An agent may need to reason about its own knowledge about the\nworld; it may also need to reason about what other agents know about\nthe world. For example, in a bargaining situation, the seller of a car must\nconsider what a buyer knows about the car’s value. The buyer must also KT45, require extra rules if one wants to capture their semantic entailment\nvia proofs. In the case of KT45, this extra strength is expressed by rule\nschemes for the axioms T, 4 and 5:\n2φ\nφ\nT\n2φ\n22φ\n4\n¬2φ\n2¬2φ\n5\nAn equivalent alternative to the rules 4 and 5 would be to stipulate relax-\nations of the rules about moving formulas in and out of dashed boxes. Since\nrule 4 allows us to double-up boxes, we could instead think of it as allowing\nus to move formulas beginning with 2 into dashed boxes. Similarly, axiom\n5 has the eﬀect of allowing us to move formulas beginning with ¬2 into\ndashed boxes. Since 5 is a scheme and since φ and ¬¬φ are equivalent in ba-\nsic modal logic, we could write ¬φ instead of φ throughout without changing\nthe expressive power and meaning of that axiom.\nDeﬁnition 5.20 Let L be a set of formula schemes. We say that Γ ⊢L ψ is\nvalid if ψ has a proof in the natural deduction system for basic modal logic\nextended with the axioms from L and premises from Γ.\nExamples 5.21 We show that the following sequents are valid:\n1.\n|−K 2p ∧2q →2(p ∧q).\n1\n2p ∧2q\nassumption\n2\n2p\n∧e1 1\n3\n2q\n∧e2 1\n4\np\n2e 2\n5\nq\n2e 3\n6\np ∧q\n∧i 4, 5\n7\n2(p ∧q)\n2i 4−6\n8\n2p ∧2q →2(p ∧q)\n→i 1−7\n5.5 Reasoning about knowledge in a multi-agent system\n331\n2.\n|−KT45 p →23p.\n1\np\nassumption\n2\n2¬p\nassumption\n3\n¬p\nT 2\n4\n⊥\n¬e 1, 3\n5\n¬2¬p\n¬i 2−4\n6\n2¬2¬p\naxiom 5 on line 5\n7\np →2¬2¬p\n→i 1−6\n3.\n|−KT45 232p →2p.\n1\n2¬2¬2p\nassumption\n2\n¬2¬2p\n2e 1\n3\n¬2p\nassumption\n4\n2¬2p\naxiom 5 on line 3\n5\n⊥\n¬e 4, 2\n6\n¬¬2p\n¬i 3−5\n7\n2p\n¬¬e 6\n8\np\nT 7\n9\n2p\n2i 2−8\n10\n2¬2¬2p →2p\n→i 1−9\n5.5 Reasoning about knowledge in\na multi-agent system\nIn a multi-agent system, diﬀerent agents have diﬀerent knowledge of the\nworld. An agent may need to reason about its own knowledge about the\nworld; it may also need to reason about what other agents know about\nthe world. For example, in a bargaining situation, the seller of a car must\nconsider what a buyer knows about the car’s value. The buyer must also",
            "summary": "We will introduce in (1.3) an easy formalism for specifying well-formed formulas. In general, we need an unbounded supply of propositional atoms p, q, r, . . ., or p1, p2, p3. You should not be too worried about the need for inﬁnitely many such symbols. For example, the application of the proof rule →e in 1, 2 is equally valid if we substitute p with p ∨¬r and q with r →p. We expressed such rules as schemes with Greek symbols stand-inducing for generic formulas. Yet, it is time that we make precise the notion of ‘any formula we may form’ Having inﬁnitely many symbols at our disposal is a cheap                way out. This can be compared with the potentially in-                glish nature of English sentences. The number of grammatically correct English sentences is in  in-                nite, but many such sentences will do in whatever situation you might be in. The formula in our propositional logic should certainly be strings over the                alphabet {p, q, r, . . . }  .   ‘’, ‘ , “”, ‬, ’’,.’”,.� For example, the string (¬)() ∨pq →is a word over that alphabet, yet, it does not seem to make a lot of sense as far as propositional logic is concerned. This is a trivialobservation and as such is not good enough for what we are trying to capture. So what we have to deﬁne are those strings which we want to call formulas. We call such formulas well-formed. Well-formed formulas are those for all valuations in which � We will execute this marking algorithm on the parse tree of formulas. At the same time, (1.9) serves as a guide for designing an algorithm and as an invariantfor proving its correctness. We will translate formulas into the adequate fragment of the resulting parse tree. We then share common subformulas, making the resulting tree into a directed, acyclic graph (DAG) The set of valuations for which φ is true equals the set ofValuation for which T(φ) is true. The latter ensures that the diagnostics of a SAT solver, applied to the original formula φ, is meaningful for the original form of the formula. In the exercises, you are asked to prove these claims. In Figure 1.48, we compute T(φ) = p ∧¬(q ∨¬p) for φ being p. The formal set of rules for forcing new constraints from old ones is depicted in Figure 1,14. A small circle indicates any node (¬, ∧or atom)  In the same manner, we arrive at acomplete set of constraints in Figure, 1.13. The time stamps ‘1:’ etc. indicate the order in which we applied our intuitive reasoning about these constraints. This order is generally not unique. The Fibonacci numbers are most useful in modelling the growth of populations. Prove that for every preﬁx of a well-formed propositional logic formula the number of left brackets is greater or equal to thenumber of right brackets. The force is the force that drives a person to do a certain thing. We call this force the force of change. We use the following terms: force, value, force, force of action, force-to-value, force to force. We also use the terms force, change, force and force of motion. We refer to these terms as F1, F2, F3, F4, F5, F6, F7 and F8. Use mathematical induction on the height of φ to show that rank(φ) is nothing but φ for all formulas φ of propositional logic. So F1 + F2 = 1 + 1 = 2 etc. Show the assertion ‘F3n is even.’ by Mathematical induction on n ≥1. Note that this assertion is saying that the sequence. F3, F6, F9, . . . consists of even numbers only. F1, F2, F4, F5, F7, F8, F10, F11, F12, F13, F14, F15, F16, F17, F18, F19, F Prove the inductive step of that assertion. Show that the base case fails to hold. Conclude that the assertion is false. Use mathematical induction to show that n2 + 5n + 1 is odd for all n ≥1. For the soundness proof of Theorem 1.35 on page 46, explain why we could not use mathematical induction but had to resort to course-of-values induction. Give justiﬁcations for all inferences that were annotated with ‘why?’ and complete the case analysis ranging over the proof rule applied. inspect the summary of natural deduction rules in Figure 1.2 on page 27 to see which viewpoints are still missing. Do you need to include derived Propositional and predicate logic can be found in the bibliographicremarks at the end of Chapter 2. For an introduction to algorithms and datastructures see e.g. [Wei98]. The need for a richer language for propositional logic is discussed in the first chapter of the book. The second chapter is devoted to the subject of predicate logic. The third chapter is dedicated to the topic of propositional logic. The fourth and fifth chapters are devoted to propositional and predicate logics. The sixth and seventh chapters are dedicated to propositional and predicates logical exercises. The final chapter focuses on the exercise of We begin this second chapter by pointing out the limitations of propo-                sitional logic with respect to encoding declarative sentences. PropositionalLogic dealt quite satisfactorily with sentence components like not, and, or. And if . . . then, but the logical aspects of natural and artiﬁcial languages are much richer than that. What can we do with modi-œnative languages like there exists? And what can we say about them? In propositional logic, we could identify this assertion with a propositional terms of the Ki and CG is deﬁned in terms of EG. Many of the results we had for basic modal logic with a single accessi-bility relation also hold in this more general setting of several accessibilityrelations. Summarising, we say that a frame F for KT45n (W, (Ri)i∈A) is said to satisfy φ if, for each labellingfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds. The following theorem is useful for answering questions about formu-                las involving E and Y is G-reachable in k steps from x if there are w1, w2, . . . , wk−1, ik in G such that there is a path of the form x Ri1 w1 Ri2 w2 .. . . Rik−1 wk+1 Rik y. For all y that are G- reachable from x, we have y ⊩φ. It is suﬃcient to show that x ⊉Ki1Ki2 . .. Kik φ holds for any                i1, i2, , ik ∈G. Theorem 5.26 is the proof that y is G Reachable in K Steps. We saw in the preceding section that there appeared to be a correspondence between the validity of 2 φ and the property that the accessibility re-                lation R is reﬂexive. In this section, we will see that there is a precise mathematical relation between these formulas and properties of R. To every formula in KT45n there corresponds a property of R, and the formula K holds for the connec-phthalmological formula K. We will also look at some of the arguments used to prove the property of positive introspection, i.e. that that which is known is known to be known. We hope that this will help us understand the meaning of the formulas we have been given. From the point of view of logicengineering, it is important to see this relationship, because it helps one to understand the logic being studied. For example, if you believe that a formula scheme should be accepted in the system of modal logic, then it is well worth looking at the corresponding property of R. The meaning of some formulas may seem diﬃcult to understand, so looking at their corresponding properties of R can help. The notion of a (modal) frame. is like a Kripke model (Deﬁnition 5.3), except that it has no la-                belling function. A frame F = (W, R) is a set W of worlds and a binaryrelation A frame is just a set of worlds and an accessibility relationship between them. From any model we can extract a frame, by just forgetting about the labelling function. The links between the worlds have to be labelled with the name of the accessibility relation. For example, x1 and x2 are related by R1, whereas x4 and 5.337x5 are related both by R2. We simplify by no longer requiring ar-                rows on the links. This is because we know that the relations are symmetric,                so the links are bi-directional. The frame, as a whole, satisﬁes a formula, which is shown in Figure 5.13. Deﬁnition 5.25: Take a model M = (W, (Ri)i∈A, L) of KT45n and a world X. We deﬃne when φ is true in x via a satisfaction relation x ⊩φ byuctiveinduction on φ. The relations are also reﬂexive, so there should be loops like the one on x4 in Figure 5.11 in all the worlds. We can simply omit these from the diagram, since we don’t need to distinguish between worlds which are self-related and those which are not. The cases for the boolean connectives are the same as for basic modal Each Ki behaves like a 2, but refers toits own accessibility relation Ri. There are no equivalents of 3, but we can recover them as ¬Ki¬. A pair of strings (s, t) lies in P M iﬀ, using the same sequence of indices (i1, i2, . . . , im) The interpretation of P on M is just what we expect it to be. The connective EG is deﬁned in terms of the connective CG. The relations between the Ki and CG are also de ﬁed. The result is that a frame F for KT45n (W, (Ri)i∈A) for the mod We claim that M ⊨                φ2 holds as well, which says that whenever the pair (s, t) is in P M, then the pair is also in M for i = 1, 2, . . . , k. By deﬁnition of φ3 and P M this tells us there is a solution to the Post correspondence problem C. We simply choose a new sequence (i1, i2) and observe that s si equals si1si2 .. . . simsi and t ti equals ti1ti2 . . ... timti and so on. (Why does M ≹ ≿1 hold?) Modal logic adds unary connectives to express one, or more, of these modes of truth. The simplest modal logics just deal with one con-centriccept – such as knowledge, necessity, or time. We show that, if M′ is any model having a constant eM′, two unary functions, grotesque2.5 Undecidability of predicate logic is a non-trivial problem. We also show that the root of the parse tree of φ is an implication, so this is the crucial clause for the deﬁnition of M′ ⊨φ. The way we proceed here is by interpreting, binary strings in the knowledge. This chapter looks at the syntax and semantics of basic modal logic. More sophisticated modal logics have connectives for expressing several modes of truth in the same logic. Our main case study will be the logic of knowledge in a multi-agent system. We look at the language of propositional logic with two extra connectives, 2 and 3. We also look at some of the concepts used in the logic engineering approach. We conclude with a discussion of the meaning of the words p, q, r, p3 and p4. The book is published by Oxford University Press, priced £16.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here for The formulas of basic modal logic φ are deﬁned by the following Backus Naur form (BNF): p | (¬φ) | (φ ∧ φ) – (2 φ), where p is any atomic formula. The following strings are not formulas, because they cannot be constructed using the grammar                in (5.1): (p2 →q) and (p →3(q 3 r) Conventions 5.2 As done in Chapter 1, we assume that the unary connec- tumultuoustives (½, 2, 3) bind most closely, followed by  and then followed by                by. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modallogics we study in this text are normal, as they all have the same formula scheme, L. We conclude with a look at the results of our study of the KT45 logic, where L = {T, 4, 5} with T, 4 and 5 from Table 5 The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience. If the agent Q knows something, then she knows                that she knows it. If she doesn’t know something, she knows that she doesn't know it. Even computer agents may not have all of these properties. We will not consider them here. The logic is based on the theory of knowledge. It is not a theory of human knowledge. We are not trying to prove that human knowledge is better than computer knowledge. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 can be re-engineered in various ways to give us the properties appropriate for the intended ap-                plications. We will consider how to re-Engineer basic modal logic to give the following readings of 2: It is necessarily true that φ is an equivalence relation. After any execution of program P, φ holds. If we take the connective 3, which is equivalent to ¬2¬, we can figure out what the corresponding readings of 3 in our system will be. For example, ‘it is not necessarily true that not φ’ means that it is possibly true that φ. The readings for 3 for the other modes are given in Table 5.6.3. The reading ‘agent Q knows φ' for 2φ. is read as ‘ agent Q does not know not’ for 3’s ‘not’ reading is ‘nothing’. For all agent Q knows, φ is consistent with what it knows, so it could be ‘something’ as far as Q is concerned, and this could be the case for all agents Q knows. We saw in the last section some valid formulas of basic modal logic, such as the terms of the Ki and CG is deﬁned in terms of EG. The readings of 3 corresponding to each reading of 2. The stock of valid formulas is shown in the next section. The formulas are given in the second section of this article. The third section of the article is the fourth and final part of the series. The final section is the last and final section, which includes the formulas for the first and second sections of this section. It is the first time that we use the term ‘accessibility’ to refer to the formulas. A frame F for KT45n is said to satisfy φ if, for each labelling L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds. We say that y is G-reachable in k steps from x if there are w1, w2, wk−1 and i1, i2, . . . , ik in G such that Ri1 w1 Ri2 w2 .. . . Rik−1 wk+1 Rik y means Ri1(x, w1), Ri2(w1,. w2), . .. , Rik(wk, y). Theorem 5.26: Y is G-reachable from x if there is some k such that it is G in k steps. We will prove that y holds by proving that x ⊩EkophobicGφ holds. Theorem: Take any i1, i2, . . . , ik ∈G and any w1, w2,. . ., wk−1 and y                such that there is a path of the form x Ri1 w1 Ri2 w2 . .. Rik−1 wk+1 Rik y. We also say that y is. G- Reachable From x if and only if y is G Reachable from X. The formula K holds for the connec-                So ¬p1, ¬ p2 mean they (respectively) are wearing a white one. Kik φ, we have y ⊩�.                Some valid formulas in KT45n are: K2K1 (p1 ∨p2)                 K2(¬p2 →K1 ¬P2)                 K2¬K1 p1.                 K1 p2.              ‘If man 1 were blind, would man 2 still be able to tell?’?         “If man 2 were blind would he still be. able to. tell? If man 1 was blind The possible-worlds approach, which greatly simpliﬁed modallogic and is now almost synonymous with it, was invented by S. Kripke. Not all modal logics enjoy this property, which is important for decidability. A great deal of work on applying modal logic to multi-agent sys-tems has been done in [FHMV95] and [MvdH95] The idea of using modal Logic to reason about knowledge is due to J.Hintikka. The idea that modalLogic can be used to reason in terms of knowledge is the work of J. Hintsikka and others. In nat-ural language, for example, we often distinguish between various ‘modes’ oftruth, such as necessarily true, known to be true, believed to betrue and true in the future. From many points of view, however, this is inadequate. Many examples in this chapter are taken from this literature (some of them are attributed to other people there), though our treatment of them                is original. It does not enjoy all modes of truth, however. For example, although the sentenceGeorge W. Bush is president of the United States of America is currently true, it will not be true at some point in thefuture. Equally, the sentenceThere are nine planets in the solar system is not necessarily true In computer science, it is often useful to reason about modes of truth. Temporal logic is a special case of modal logic. The modalities of CTL allow us to express a host of computational behaviour of systems. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed. Each agent may have diﬀerent knowledge about the environment and also about the knowledge of other agents. In this chapter, we will look in depth at modal logics applied to reasoning about knowledge. We will also look at how these logics can be used to model other domains of com-puter science. We conclude with a discussion of the implications of our findings. The simplest modal logics just deal with one con-ceive – such as knowledge, necessity, or time. More sophisticated modallogics bind most closely, followed by  and then followed by by. The convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. In basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when we apply modalLogics to express various modes of truth, we may read them ‘boxes’ or ‘iamonds’ in a different way. We cannot omit theremaining brackets, however, for 23q ∧¬ For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. A model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W : W →P(Atoms) These models are often called Kripke models, in honour of S.Kripke who invented them in the 1950s and 1960s. The parse tree for 23q ∧¬r →2p is given in 5.3 of the book. The full book is available to download now from: http://www.amazon.co.uk/kripke-modal-logic Exercises 5.4 and 5.5: Find natural deduction proofs for the following. The modal logic KD45 is used to model belief; see Table 5.12 for the axiom.schemes D, 4, and 5: Explain why the condition of seriality is relevant to belief. Recall Deﬁnition 5.7. How would you deﬅne L for a modal Logic L? Exercises 6 and 7: Study the proofs you gave for the previous exercise to see whether any of the formula schemes could be valid in basic modal. logic KT45. Exercise 8: Find the proof for the rule that the signi﬉cance of Modal logic adds unary connectives to express one, or more, of these modes of truth. The simplest modal logics just deal with one con-CEPT – such as knowledge, necessity, or time. This exercise is about the wise-men puzzle. Justify your answers to the questions in order to get to the bottom of the puzzle. Back to Mail Online home. Back into the page you came from. Follow the instructions to the next page for the rest of the exercise. This chapter looks at the syntax and semantics of basic modal logic. More sophisticated modal logics have connectives for expressing several modes of truth in the same logic. Our main case study will be the logic of knowledge in a multi-agent system. We look at the language of propositional logic with two extra connectives, 2 and 3. We also look at some of the concepts used in the logic engineering approach. We conclude with a discussion of the meaning of the words p, q, r, p3 and p4. The book is published by Oxford University Press, priced £16.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here for The formulas of basic modal logic φ are deﬁned by the following Backus Naur form (BNF): p | (¬φ) | (φ ∧ φ) – (2 φ), where p is any atomic formula. The following strings are not formulas, because they cannot be constructed using the grammar                in (5.1): (p2 →q) and (p →3(q 3 r) Conventions 5.2 As done in Chapter 1, we assume that the unary connec- tumultuoustives (½, 2, 3) bind most closely, followed by  and then followed by                by. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modallogics we study in this text are normal, as they all have the same formula scheme, L. We conclude with a look at the results of our study of the KT45 logic, where L = {T, 4, 5} with T, 4 and 5 from Table 5 The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience. If the agent Q knows something, then she knows                that she knows it. If she doesn’t know something, she knows that she doesn't know it. Even computer agents may not have all of these properties. We will not consider them here. The logic is based on the theory of knowledge. It is not a theory of human knowledge. We are not trying to prove that human knowledge is better than computer knowledge. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 can be re-engineered in various ways to give us the properties appropriate for the intended ap-                plications. We will consider how to re-Engineer basic modal logic to give the following readings of 2: It is necessarily true that φ is an equivalence relation. After any execution of program P, φ holds. If we take the connective 3, which is equivalent to ¬2¬, we can figure out what the corresponding readings of 3 in our system will be. For example, ‘it is not necessarily true that not φ’ means that it is possibly true that φ. The readings for 3 for the other modes are given in Table 5.6.3. The reading ‘agent Q knows φ' for 2φ. is read as ‘ agent Q does not know not’ for 3’s ‘not’ reading is ‘nothing’. For all agent Q knows, φ is consistent with what it knows, so it could be ‘something’ as far as Q is concerned, and this could be the case for all agents Q knows. The stock of valid formulas of basic modal logic is shown. The readings of 3 corresponding to each reading of 2. Theorem 5.17: Any sequence of modal operators and negations in KT45 is equivalent to one of the following: −, 2, 3, ¬, 2 and ¬3, where −indicates the absence of any negation or modality. The modal Logic KT4, that is L equals {T, 4}. It is also called S4 in the literature. It is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. The logic KT4 is also known as KT45 or KT4.  Correspondence theory tells us that its models are precisely the Kripke models M = (W, R, L), where R is reﬂexive and transitive. Such structures are often very useful in computer science. For example, if φ stands for the type of a piece of code – φ could be int × int → bool, indicating some code which expects a pair of integers as input andoutputs a boolean value – then 2φ could stand for residual code of type φ. Such type systems have important applications in the specialisation and partial evaluation of code. The formula scheme 2 φ → 22 φ, the axiom T, then means that code may beexecuted right Theorem 5.18 Any sequence of modal operators and negations in KT4 is equivalent to one of the following: −, 2, 3, 23, 32, 232, 323. We also pointed out that the proof rules PBC, LEM and ¬¬e are questionable in certain com-                tems. We refer the interested reader to the bibliographic notes at the end of the chapter. We give a natural de-duction system for propositional logic which was sound and complete. The natural deduction proof system for modal logic presented in this chapter is based on ideas in [Fit93]. Many examples in the chapter are taken from this literature (some of them are attributed to other people there), though our treatment of them is original. We should stress that our framework was deliberately ‘classical;’ the thesis[Sim94] is a good source for discussions of intuitionistic modal logics. An application of the modal Logic KT4 as a type system for staged computation in a functional pro-                gramming language can be found in [DP96]. The chapter is divided into seven sections: 1. Introduction, 2. Bibliographic notes, 3, 4, 5, The systems discussed in Chapter 3 can be veriﬁed                using the representation. Representing those systems in a computer requires an eﬃcient representation for boolean functions. We look at such a representation in this chapter and describe in detail how it can be used to reason about the systems we discussed in the previous chapter. We write x1, x2, . . . and x, y, z,. . . to denote boolean variables. A boolean variable x is a variable ranging over the values                0 and 1. A function f of n arguments is a function from {0, 1}n to {0,. 1}. We write f(x1, X2,    . .  A formula φ in the multi-modal logic of KT45n is deﬁned by the following grammar. We simply write E, C and D without subscripts if we refer to EA, CA and DA. Instead of 2, we have several modules Ki and we also have EG, CG and DG for each G ⊆A. Actually, all of these connectives will shortly be seen to be ‘box-like’ rather than ‘diamond-like.’ in the sense that they distribute over  rather than over   . We call this ‘Box Theory’ and it is the basis for the rest of this article. Deﬁnition 5.24: A model M = (W, (Ri)i∈A, L) of the multi-modal logic hypert45n with the set A of n agents. The ‘diamond-like’ correspondents of these connectives are not explicitly in the language, but may of course be obtained using negations, i.e. ¬Ki¬, ¬CG¬ etc. We exploit these properties of Ri in the graphical illustrations of KT45n. For example, a model of KT453 with set of worlds is shown in Figure 5.13. The links between the worlds have to be labelled with the name of the accessibility relation In language, we often distinguish between various ‘modes’ of truth. For example, x1 and x2 are related by R1, whereas x4 and                5.5. The cube root of 27 is 3 as well as being true is also necessarily true and true in the future. It does not enjoy all modes of truth, however,    as it could have been a diﬀerent number. We would say that, although the sentence.George W. Bush is president of the United States of America. is currently true, it will not be true at some point in the. future, but it is not necessarily true, in the sense that it could be true for ever. In computer science, it is often useful to reason about modes of truth. Temporal logic is a special case of modal logic. The modalities of CTL allow us to express a host of computational behaviour of systems. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed. Each agent may have diﬀerent knowledge about the environment and also about the knowledge of other agents. In this chapter, we will look in depth at modal logics applied to reasoning about knowledge. We will also look at how these logics can be used to model other domains of com-puter science. We conclude with a discussion of the implications of our findings. More sophisticated modal logics require extra rules if one wants to capture their semantic entailmentvia proofs. In the case of KT45, this extra strength is expressed by ruleschemes for the axioms T, 4 and 5. Let L be a set of formula schemes and let T be a scheme for T, T, and T, with T being the axiom T and T the formula scheme for KT45. For example, we could write ¬φ instead of φ throughout without changing the expressive power and meaning of that axiom. We could also use the scheme L instead of the scheme T and L would be the formula schemes L and L, with L being L, L, and L. We say that a proof in the natural deduction system for basic modal logic is valid if it is extended with the axioms from L and premises from L. We show that the following sequents are valid: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, KT45, require extra rules if one wants to capture their semantic entailmentvia proofs. In the case of KT45, this extra strength is expressed by rule.schemes for the axioms T, 4 and 5. For example, in a bargaining situation, the seller of a car mustconsider what a buyer knows about the car’s value. The buyer must also KT45 to know what the seller knows about that car. For the purposes of this article, we will assume that KT45 is a set of formula schemes and that L is the set of L schemes. We will also use the term ‘symbolic logic’ to refer to this type of logic. We say that a proof in the natural deduction system for basic modal logic is valid if it is extended with the axioms from L and premises from L. We show that the following sequents are valid: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, In a bargaining situation, the seller of a car mustconsider what a buyer knows about the car’s",
            "children": [
                {
                    "id": "chapter-5-section-1",
                    "title": "Modes of Truth",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-5-section-2",
                    "title": "Basic Modal Logic",
                    "content": "",
                    "summary": "",
                    "children": [
                        {
                            "id": "chapter-5-section-2-subsection-1",
                            "title": "Syntax",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-5-section-2-subsection-2",
                            "title": "Semantics",
                            "content": "",
                            "summary": null,
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-5-section-3",
                    "title": "Logic Engineering",
                    "content": "long as they match the pattern required by the respective rule. For example,\n32\n1 Propositional logic\nthe application of the proof rule →e in\n1\np →q\npremise\n2\np\npremise\n3\nq\n→e 1, 2\nis equally valid if we substitute p with p ∨¬r and q with r →p:\n1\np ∨¬r →(r →p)\npremise\n2\np ∨¬r\npremise\n3\nr →p\n→e 1, 2\nThis is why we expressed such rules as schemes with Greek symbols stand-\ning for generic formulas. Yet, it is time that we make precise the notion of\n‘any formula we may form.’ Because this text concerns various logics, we will\nintroduce in (1.3) an easy formalism for specifying well-formed formulas. In\ngeneral, we need an unbounded supply of propositional atoms p, q, r, . . ., or\np1, p2, p3, . . . You should not be too worried about the need for inﬁnitely\nmany such symbols. Although we may only need ﬁnitely many of these\npropositions to describe a property of a computer program successfully, we\ncannot specify how many such atomic propositions we will need in any con-\ncrete situation, so having inﬁnitely many symbols at our disposal is a cheap\nway out. This can be compared with the potentially inﬁnite nature of En-\nglish: the number of grammatically correct English sentences is inﬁnite, but\nﬁnitely many such sentences will do in whatever situation you might be in\n(writing a book, attending a lecture, listening to the radio, having a dinner\ndate, . . . ).\nFormulas in our propositional logic should certainly be strings over the\nalphabet {p, q, r, . . . } ∪{p1, p2, p3, . . . } ∪{¬, ∧, ∨, →, (, )}. This is a trivial\nobservation and as such is not good enough for what we are trying to capture.\nFor example, the string (¬)() ∨pq →is a word over that alphabet, yet, it\ndoes not seem to make a lot of sense as far as propositional logic is concerned.\nSo what we have to deﬁne are those strings which we want to call formulas.\nWe call such formulas well-formed.\nDeﬁnition 1.27 The well-formed formulas of propositional logic are those\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nvaluation\nfor propositional logic, 37\nin predicate logic, 123\nin relational mu-calculus, 391\nvalue\ninitial, 206, 268, 269\nVardi, M., 254\nvariable, 94, 260\nboolean, 229, 247, 358\nbound, 103\ncapture, 106\ndummy, 110\nfree, 103\nlocal, 263\nlogical, 268, 290\nvariable ordering\ncompatible, 368\nlist, 367\nvariant, 293\nveriﬁcation\nfull, 173\nmethod, 172\nof communication protocols, 175\nof hardware, 175\nof software, 175\nof systems, 256\npost-development, 173, 257\npre-development, 173, 257\nprocess, 271\nprogram, 270\nproperty, 173\nproperty-oriented, 256\nsemi-automatic, 256\ntechniques, 172\nweakest precondition, 276\nwhile-statement, 261, 262\nbody, 273, 282, 286\nnon-termination, 292\nwise-men puzzle, 342\nWolper, P., 254\nword\nempty, 126\nworld\naccessible, 309\npossible, 309, 336\nyear-2000 problem, 258\n(f) Prove that for every preﬁx of a well-formed propositional logic formula the\nnumber of left brackets is greater or equal to the number of right brackets.\n8.\n*\nThe Fibonacci numbers are most useful in modelling the growth of populations.\nWe deﬁne them by F1\ndef\n= 1, F2\ndef\n= 1 and Fn+1\ndef\n= Fn + Fn−1 for all n ≥2. So\nF3\ndef\n= F1 + F2 = 1 + 1 = 2 etc. Show the assertion ‘F3n is even.’ by mathemat-\nical induction on n ≥1. Note that this assertion is saying that the sequence\nF3, F6, F9, . . . consists of even numbers only.\n86\n1 Propositional logic\n9. Consider the function rank, deﬁned by\nrank(p)\ndef\n= 1\nrank(¬φ)\ndef\n= 1 + rank(φ)\nrank(φ ◦ψ)\ndef\n= 1 + max(rank(φ), rank(ψ))\nwhere p is any atom, ◦∈{→, ∨, ∧} and max(n, m) is n if n ≥m and m other-\nwise. Recall the concept of the height of a formula (Deﬁnition 1.32 on page 44).\nUse mathematical induction on the height of φ to show that rank(φ) is nothing\nbut the height of φ for all formulas φ of propositional logic.\n10.\n*\nHere is an example of why we need to secure the base case for mathematical\ninduction. Consider the assertion\n‘The number n2 + 5n + 1 is even for all n ≥1.’\n(a) Prove the inductive step of that assertion.\n(b) Show that the base case fails to hold.\n(c) Conclude that the assertion is false.\n(d) Use mathematical induction to show that n2 + 5n + 1 is odd for all n ≥1.\n11. For the soundness proof of Theorem 1.35 on page 46,\n(a) explain why we could not use mathematical induction but had to resort to\ncourse-of-values induction;\n(b) give justiﬁcations for all inferences that were annotated with ‘why?’ and\n(c) complete the case analysis ranging over the ﬁnal proof rule applied; inspect\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional terms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-\nWe saw in the preceding section that there appeared to be a correspondence\nbetween the validity of 2φ →φ and the property that the accessibility re-\nlation R is reﬂexive. The connection between them is that both relied on\nthe intuition that anything which is known by an agent is true. Moreover,\nthere also seemed to be a correspondence between 2φ →22φ and R being\ntransitive; they both seem to assert the property of positive introspection,\ni.e. that which is known is known to be known.\nIn this section, we will see that there is a precise mathematical relation-\nship between these formulas and properties of R. Indeed, to every formula\nscheme there corresponds a property of R. From the point of view of logic\nengineering, it is important to see this relationship, because it helps one to\nunderstand the logic being studied. For example, if you believe that a cer-\ntain formula scheme should be accepted in the system of modal logic you are\nengineering, then it is well worth looking at the corresponding property of\nR and checking that this property makes sense for the application, too. Al-\nternatively, the meaning of some formulas may seem diﬃcult to understand,\nso looking at their corresponding properties of R can help.\nTo state the relationship between formula schemes and their correspond-\ning properties, we need the notion of a (modal) frame.\nDeﬁnition 5.10 A frame F = (W, R) is a set W of worlds and a binary\nrelation R on W.\nA frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-\nbelling function. From any model we can extract a frame, by just forgetting\nabout the labelling function; for example, Figure 5.9 shows the frame ex-\ntracted from the Kripke model of Figure 5.3. A frame is just a set of worlds\nand an accessibility relationship between them. It has no information about\nwhat atomic formulas are true at the various worlds. However, it is useful to\nsay sometimes that the frame, as a whole, satisﬁes a formula. This is deﬁned\nas follows.\n{x1, x2, x3, x4, x5, x6} is shown in Figure 5.13. The links between the worlds\nhave to be labelled with the name of the accessibility relation, since we have\nseveral relations. For example, x1 and x2 are related by R1, whereas x4 and\n5.5 Reasoning about knowledge in a multi-agent system\n337\nx5 are related both by R1 and by R2. We simplify by no longer requiring ar-\nrows on the links. This is because we know that the relations are symmetric,\nso the links are bi-directional. Moreover, the relations are also reﬂexive, so\nthere should be loops like the one on x4 in Figure 5.11 in all the worlds and\nfor all of the relations. We can simply omit these from the diagram, since we\ndon’t need to distinguish between worlds which are self-related and those\nwhich are not.\nDeﬁnition 5.25 Take a model M = (W, (Ri)i∈A, L) of KT45n and a world\nx ∈W. We deﬁne when φ is true in x via a satisfaction relation x ⊩φ by\ninduction on φ:\nx ⊩p iﬀp ∈L(x)\nx ⊩¬φ iﬀx ̸⊩φ\nx ⊩φ ∧ψ\niﬀx ⊩φ and x ⊩ψ\nx ⊩φ ∨ψ\niﬀx ⊩φ or x ⊩ψ\nx ⊩φ →ψ\niﬀx ⊩ψ whenever we have x ⊩φ\nx ⊩Ki ψ\niﬀ, for each y ∈W, Ri(x, y) implies y ⊩ψ\nx ⊩EG ψ\niﬀ, for each i ∈G, x ⊩Ki ψ\nx ⊩CG ψ\niﬀ, for each k ≥1, we have x ⊩Ek\nGψ,\nwhere Ek\nG means EGEG . . . EG – k times\nx ⊩DG ψ\niﬀ, for each y ∈W, we have y ⊩ψ,\nwhenever Ri(x, y) for all i ∈G.\nAgain, we write M, x ⊩φ if we want to emphasise the model M.\nCompare this with Deﬁnition 5.4. The cases for the boolean connectives\nare the same as for basic modal logic. Each Ki behaves like a 2, but refers to\nits own accessibility relation Ri. As already stated, there are no equivalents\nof 3, but we can recover them as ¬Ki¬. The connective EG is deﬁned in\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of The interpretation of P on M is just what we expect it to be:\nP M def\n= {(s, t) | there is a sequence of indices (i1, i2, . . . , im) such that\ns equals si1si2 . . . sim and t equals ti1ti2 . . . tim}\nwhere s and t are binary strings and the si and ti are the data of the\ncorrespondence problem C. A pair of strings (s, t) lies in P M iﬀ, using the\nsame sequence of indices (i1, i2, . . . , im), s is built using the corresponding\nsi and t is built using the respective ti.\nSince ⊨φ holds we infer that M ⊨φ holds, too. We claim that M ⊨\nφ2 holds as well, which says that whenever the pair (s, t) is in P M, then\nthe pair (s si, t ti) is also in P M for i = 1, 2, . . . , k (you can verify that is\nsays this by inspecting the deﬁnition of P M). Now (s, t) ∈P M implies that\nthere is some sequence (i1, i2, . . . , im) such that s equals si1si2 . . . sim and t\nequals ti1ti2 . . . tim. We simply choose the new sequence (i1, i2, . . . , im, i) and\nobserve that s si equals si1si2 . . . simsi and t ti equals ti1ti2 . . . timti and so\nM ⊨φ2 holds as claimed. (Why does M ⊨φ1 hold?)\nSince M ⊨φ1 ∧φ2 →φ3 and M ⊨φ1 ∧φ2 hold, it follows that M ⊨φ3\nholds as well. By deﬁnition of φ3 and P M, this tells us there is a solution\nto C.\nConversely, let us assume that the Post correspondence problem C has\nsome solution, namely the sequence of indices (i1, i2, . . . , in). Now we have to\nshow that, if M′ is any model having a constant eM′, two unary functions,\n2.5 Undecidability of predicate logic\n135\nfM′\n0\nand fM′\n1\n, and a binary predicate P M′, then that model has to satisfy\nφ. Notice that the root of the parse tree of φ is an implication, so this is\nthe crucial clause for the deﬁnition of M′ ⊨φ. By that very deﬁnition, we\nare already done if M′ ̸⊨φ1, or if M′ ̸⊨φ2. The harder part is therefore the\none where M′ ⊨φ1 ∧φ2, for in that case we need to verify M′ ⊨φ3 as well.\nThe way we proceed here is by interpreting ﬁnite, binary strings in the knowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nhave connectives for expressing several modes of truth in the same logic; we\nwill see some of these towards the end of this chapter.\nWe take a logic engineering approach in this chapter, in which we address\nthe following question: given a particular mode of truth, how may we develop\na logic capable of expressing and formalising that concept? To answer this\nquestion, we need to decide what properties the logic should have and what\nexamples of reasoning it should be able to express. Our main case study will\nbe the logic of knowledge in a multi-agent system. But ﬁrst, we look at the\nsyntax and semantics of basic modal logic.\n5.2 Basic modal logic\n5.2.1 Syntax\nThe language of basic modal logic is that of propositional logic with two\nextra connectives, 2 and 3. Like negation (¬), they are unary connectives\nas they apply themselves to a single formula only. As done in Chapters 1\nand 3, we write p, q, r, p3 . . . to denote atomic formulas.\nDeﬁnition 5.1 The formulas of basic modal logic φ are deﬁned by the\nfollowing Backus Naur form (BNF):\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) | (2φ) | (3φ)\n(5.1)\nwhere p is any atomic formula.\nExample formulas of basic modal logic are (p ∧3(p →2¬r)) and 2((3q ∧\n¬r) →2p), having the parse trees shown in Figure 5.1. The following strings\nare not formulas, because they cannot be constructed using the grammar\nin (5.1): (p2 →q) and (p →3(q 3 r)).\nConvention 5.2 As done in Chapter 1, we assume that the unary connec-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin various ways to give us the properties appropriate for the intended ap-\nplications. Logic engineering is the subject of engineering logics to ﬁt new\napplications. It is potentially a very broad subject, drawing on all branches\nof logic, computer science and mathematics. In this chapter, however, we\nare restricting ourselves to the particular engineering of modal logics.\nWe will consider how to re-engineer basic modal logic to ﬁt the following\nreadings of 2φ:\nr It is necessarily true that φ\nr It will always be true that φ\nr It ought to be that φ\nr Agent Q believes that φ\nr Agent Q knows that φ\nr After any execution of program P, φ holds.\nAs modal logic automatically gives us the connective 3, which is equivalent\nto ¬2¬, we can ﬁnd out what the corresponding readings of 3 in our system\nwill be. For example, ‘it is not necessarily true that not φ’ means that it is\npossibly true that φ. You could work this out in steps:\nIt is not necessarily true that φ\n= it is possible that not φ.\nTherefore,\nIt is not necessarily true that not φ\n= it is possible that not not φ\n= it is possible that φ.\nLet us work this out with the reading ‘agent Q knows φ’ for 2φ. Then, 3φ\nis read as\nagent Q does not know not φ\n= as far as Q’s knowledge is concerned, φ could be the case\n= φ is consistent with what agent Q knows\n= for all agent Q knows, φ.\nThe readings for 3 for the other modes are given in Table 5.6.\n5.3 Logic engineering\n317\nTable 5.6. The readings of 3 corresponding to each reading of 2.\n2φ\n3φ\nIt is necessarily true that φ\nIt is possibly true that φ\nIt will always be true that φ\nSometime in the future φ\nIt ought to be that φ\nIt is permitted to be that φ\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-\nSo ¬p1, ¬p2 mean they (respectively) are wearing a white one. Informally\njustify each of the following premises in terms of the description of the\nproblem:\ni. K2K1 (p1 ∨p2)\nii. K2(¬p2 →K1 ¬p2)\niii. K2¬K1 p1.\n(c) Using natural deduction, prove from these premises that K2 p2.\n(d) Show that the third premise was essential, by exhibiting a model/world\nwhich satisﬁes the ﬁrst two, but not the conclusion.\n(e) Now is it easy to answer questions like ‘If man 2 were blind would he still be\nable to tell?’ and ‘if man 1 were blind, would man 2 still be able to tell?’?\n12. Recall our informal discussion on positive-knowledge formulas and negative-\nknowledge formulas. Give formal deﬁnitions of these notions.\n5.7 Bibliographic notes\nThe ﬁrst systematic approaches to modal logic were made by C. I. Lewis\nin the 1950s. The possible-worlds approach, which greatly simpliﬁed modal\nlogic and is now almost synonymous with it, was invented by S. Kripke.\nBooks devoted to modal logic include [Che80, Gol87, Pop94], where exten-\nsive references to the literature may be found. All these books discuss the\nsoundness and completeness of proof calculi for modal logics. They also in-\nvestigate which modal logics have the ﬁnite-model property: if a sequent\ndoes not have a proof, there is a ﬁnite model which demonstrates that. Not\nall modal logics enjoy this property, which is important for decidability.\nIntuitionistic propositional logic has the ﬁnite-model property; an anima-\ntion which generates such ﬁnite models (called PORGI) is available from\nA. Stoughton’s website2.\nThe idea of using modal logic to reason about knowledge is due to J.\nHintikka. A great deal of work on applying modal logic to multi-agent sys-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nin the future. For example, we would say that, although the sentence\nGeorge W. Bush is president of the United States of America.\nis currently true, it will not be true at some point in the future. Equally, the\nsentence\nThere are nine planets in the solar system.\nwhile true, and maybe true for ever in the future, is not necessarily true, in\nthe sense that it could have been a diﬀerent number. However, the sentence\nThe cube root of 27 is 3.\nas well as being true is also necessarily true and true in the future. It does\nnot enjoy all modes of truth, however. It may not be known to be true by\nsome people (children, for example); it may not be believed by others (if\nthey are mistaken).\nIn computer science, it is often useful to reason about modes of truth. In\nChapter 3, we studied the logic CTL in which we could distinguish not only\nbetween truth at diﬀerent points in the future, but also between diﬀerent\nfutures. Temporal logic is thus a special case of modal logic. The modalities\nof CTL allow us to express a host of computational behaviour of systems.\nModalities are also extremely useful in modelling other domains of com-\nputer science. In artiﬁcial intelligence, for example, scenarios with several\n306\n5.2 Basic modal logic\n307\ninteracting agents are developed. Each agent may have diﬀerent knowledge\nabout the environment and also about the knowledge of other agents. In this\nchapter, we will look in depth at modal logics applied to reasoning about\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\nfunction and world which does satisfy p →23p in your frame?\n15. Give two examples of frames which are Euclidean – i.e. their accessibility rela-\ntion is Euclidean – and two which are not. Explain intuitively why 3p →23p\nholds on the ﬁrst two, but not on the latter two.\n16. For each of the following formulas, ﬁnd the property of R which corresponds to\nit.\n(a) φ →2φ\n(b)\n*\n2⊥\n(c)\n*\n32φ →23φ.\n17.\n*\nFind a formula whose corresponding property is density: for all x, z ∈W such\nthat R(x, z), there exists y ∈W such that R(x, y) and R(y, z).\n18. The modal logic KD45 is used to model belief; see Table 5.12 for the axiom\nschemes D, 4, and 5.\n(a) Explain how it diﬀers from KT45.\n(b) Show that ⊨KD45 2p →3p is valid. What is the signiﬁcance of this, in terms\nof knowledge and belief?\n(c) Explain why the condition of seriality is relevant to belief.\n19. Recall Deﬁnition 5.7. How would you deﬁne ≡L for a modal logic L?\nExercises 5.4\n1. Find natural deduction proofs for the following sequents over the basic modal\nlogic K.\n(a)\n*\n⊢K 2(p →q) |−2p →2q\n(b) ⊢K 2(p →q) |−3p →3q\n(c)\n*\n⊢K|−2(p →q) ∧2(q →r) →2(p →r)\n(d) ⊢K 2(p ∧q) |−2p ∧2q\n(e) ⊢K|−3⊤→(2p →3p)\n(f)\n*\n⊢K 3(p →q) |−2p →3q\n(g) ⊢K 3(p ∨q) |−3p ∨3q.\n354\n5 Modal logics and agents\n2. Find natural deduction proofs for the following, in modal logic KT45.\n(a) p →23p\n(b) 23p ↔3p\n(c)\n*\n32p ↔2p\n(d) 2(2p →2q) ∨2(2q →2p)\n(e) 2(3p →q) ↔2(p →2q).\n3. Study the proofs you gave for the previous exercise to see whether any of\nthese formula schemes could be valid in basic modal logic. Inspect where and\nhow these proofs used the axioms T, 4 and 5 to see whether you can ﬁnd a\ncounter example, i.e. a Kripke model and a world which does not satisfy the\nformula.\n4. Provide a sketch of an argument which shows that the natural deduction rules\nfor basic modal logic are sound with respect to the semantics x ⊩φ over Kripke\nstructures.\nExercises 5.5\n1. This exercise is about the wise-men puzzle. Justify your answers.",
                    "summary": "We will introduce in (1.3) an easy formalism for specifying well-formed formulas. In general, we need an unbounded supply of propositional atoms p, q, r, . . ., or p1, p2, p3. You should not be too worried about the need for inﬁnitely many such symbols. For example, the application of the proof rule →e in 1, 2 is equally valid if we substitute p with p ∨¬r and q with r →p. We expressed such rules as schemes with Greek symbols stand-inducing for generic formulas. Yet, it is time that we make precise the notion of ‘any formula we may form’ Having inﬁnitely many symbols at our disposal is a cheap                way out. This can be compared with the potentially in-                glish nature of English sentences. The number of grammatically correct English sentences is in  in-                nite, but many such sentences will do in whatever situation you might be in. The formula in our propositional logic should certainly be strings over the                alphabet {p, q, r, . . . }  .   ‘’, ‘ , “”, ‬, ’’,.’”,.� For example, the string (¬)() ∨pq →is a word over that alphabet, yet, it does not seem to make a lot of sense as far as propositional logic is concerned. This is a trivialobservation and as such is not good enough for what we are trying to capture. So what we have to deﬁne are those strings which we want to call formulas. We call such formulas well-formed. Well-formed formulas are those for all valuations in which � We will execute this marking algorithm on the parse tree of formulas. At the same time, (1.9) serves as a guide for designing an algorithm and as an invariantfor proving its correctness. We will translate formulas into the adequate fragment of the resulting parse tree. We then share common subformulas, making the resulting tree into a directed, acyclic graph (DAG) The set of valuations for which φ is true equals the set ofValuation for which T(φ) is true. The latter ensures that the diagnostics of a SAT solver, applied to the original formula φ, is meaningful for the original form of the formula. In the exercises, you are asked to prove these claims. In Figure 1.48, we compute T(φ) = p ∧¬(q ∨¬p) for φ being p. The formal set of rules for forcing new constraints from old ones is depicted in Figure 1,14. A small circle indicates any node (¬, ∧or atom)  In the same manner, we arrive at acomplete set of constraints in Figure, 1.13. The time stamps ‘1:’ etc. indicate the order in which we applied our intuitive reasoning about these constraints. This order is generally not unique. The Fibonacci numbers are most useful in modelling the growth of populations. Prove that for every preﬁx of a well-formed propositional logic formula the number of left brackets is greater or equal to thenumber of right brackets. The force is the force that drives a person to do a certain thing. We call this force the force of change. We use the following terms: force, value, force, force of action, force-to-value, force to force. We also use the terms force, change, force and force of motion. We refer to these terms as F1, F2, F3, F4, F5, F6, F7 and F8. Use mathematical induction on the height of φ to show that rank(φ) is nothing but φ for all formulas φ of propositional logic. So F1 + F2 = 1 + 1 = 2 etc. Show the assertion ‘F3n is even.’ by Mathematical induction on n ≥1. Note that this assertion is saying that the sequence. F3, F6, F9, . . . consists of even numbers only. F1, F2, F4, F5, F7, F8, F10, F11, F12, F13, F14, F15, F16, F17, F18, F19, F Prove the inductive step of that assertion. Show that the base case fails to hold. Conclude that the assertion is false. Use mathematical induction to show that n2 + 5n + 1 is odd for all n ≥1. For the soundness proof of Theorem 1.35 on page 46, explain why we could not use mathematical induction but had to resort to course-of-values induction. Give justiﬁcations for all inferences that were annotated with ‘why?’ and complete the case analysis ranging over the proof rule applied. inspect the summary of natural deduction rules in Figure 1.2 on page 27 to see which viewpoints are still missing. Do you need to include derived Propositional and predicate logic can be found in the bibliographicremarks at the end of Chapter 2. For an introduction to algorithms and datastructures see e.g. [Wei98]. The need for a richer language for propositional logic is discussed in the first chapter of the book. The second chapter is devoted to the subject of predicate logic. The third chapter is dedicated to the topic of propositional logic. The fourth and fifth chapters are devoted to propositional and predicate logics. The sixth and seventh chapters are dedicated to propositional and predicates logical exercises. The final chapter focuses on the exercise of We begin this second chapter by pointing out the limitations of propo-                sitional logic with respect to encoding declarative sentences. PropositionalLogic dealt quite satisfactorily with sentence components like not, and, or. And if . . . then, but the logical aspects of natural and artiﬁcial languages are much richer than that. What can we do with modi-œnative languages like there exists? And what can we say about them? In propositional logic, we could identify this assertion with a propositional terms of the Ki and CG is deﬁned in terms of EG. Many of the results we had for basic modal logic with a single accessi-bility relation also hold in this more general setting of several accessibilityrelations. Summarising, we say that a frame F for KT45n (W, (Ri)i∈A) is said to satisfy φ if, for each labellingfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds. The following theorem is useful for answering questions about formu-                las involving E and Y is G-reachable in k steps from x if there are w1, w2, . . . , wk−1, ik in G such that there is a path of the form x Ri1 w1 Ri2 w2 .. . . Rik−1 wk+1 Rik y. For all y that are G- reachable from x, we have y ⊩φ. It is suﬃcient to show that x ⊉Ki1Ki2 . .. Kik φ holds for any                i1, i2, , ik ∈G. Theorem 5.26 is the proof that y is G Reachable in K Steps. We saw in the preceding section that there appeared to be a correspondence between the validity of 2 φ and the property that the accessibility re-                lation R is reﬂexive. In this section, we will see that there is a precise mathematical relation between these formulas and properties of R. To every formula in KT45n there corresponds a property of R, and the formula K holds for the connec-phthalmological formula K. We will also look at some of the arguments used to prove the property of positive introspection, i.e. that that which is known is known to be known. We hope that this will help us understand the meaning of the formulas we have been given. From the point of view of logicengineering, it is important to see this relationship, because it helps one to understand the logic being studied. For example, if you believe that a formula scheme should be accepted in the system of modal logic, then it is well worth looking at the corresponding property of R. The meaning of some formulas may seem diﬃcult to understand, so looking at their corresponding properties of R can help. The notion of a (modal) frame. is like a Kripke model (Deﬁnition 5.3), except that it has no la-                belling function. A frame F = (W, R) is a set W of worlds and a binaryrelation A frame is just a set of worlds and an accessibility relationship between them. From any model we can extract a frame, by just forgetting about the labelling function. The links between the worlds have to be labelled with the name of the accessibility relation. For example, x1 and x2 are related by R1, whereas x4 and 5.337x5 are related both by R2. We simplify by no longer requiring ar-                rows on the links. This is because we know that the relations are symmetric,                so the links are bi-directional. The frame, as a whole, satisﬁes a formula, which is shown in Figure 5.13. Deﬁnition 5.25: Take a model M = (W, (Ri)i∈A, L) of KT45n and a world X. We deﬃne when φ is true in x via a satisfaction relation x ⊩φ byuctiveinduction on φ. The relations are also reﬂexive, so there should be loops like the one on x4 in Figure 5.11 in all the worlds. We can simply omit these from the diagram, since we don’t need to distinguish between worlds which are self-related and those which are not. The cases for the boolean connectives are the same as for basic modal Each Ki behaves like a 2, but refers toits own accessibility relation Ri. There are no equivalents of 3, but we can recover them as ¬Ki¬. A pair of strings (s, t) lies in P M iﬀ, using the same sequence of indices (i1, i2, . . . , im) The interpretation of P on M is just what we expect it to be. The connective EG is deﬁned in terms of the connective CG. The relations between the Ki and CG are also de ﬁed. The result is that a frame F for KT45n (W, (Ri)i∈A) for the mod We claim that M ⊨                φ2 holds as well, which says that whenever the pair (s, t) is in P M, then the pair is also in M for i = 1, 2, . . . , k. By deﬁnition of φ3 and P M this tells us there is a solution to the Post correspondence problem C. We simply choose a new sequence (i1, i2) and observe that s si equals si1si2 .. . . simsi and t ti equals ti1ti2 . . ... timti and so on. (Why does M ≹ ≿1 hold?) Modal logic adds unary connectives to express one, or more, of these modes of truth. The simplest modal logics just deal with one con-centriccept – such as knowledge, necessity, or time. We show that, if M′ is any model having a constant eM′, two unary functions, grotesque2.5 Undecidability of predicate logic is a non-trivial problem. We also show that the root of the parse tree of φ is an implication, so this is the crucial clause for the deﬁnition of M′ ⊨φ. The way we proceed here is by interpreting, binary strings in the knowledge. This chapter looks at the syntax and semantics of basic modal logic. More sophisticated modal logics have connectives for expressing several modes of truth in the same logic. Our main case study will be the logic of knowledge in a multi-agent system. We look at the language of propositional logic with two extra connectives, 2 and 3. We also look at some of the concepts used in the logic engineering approach. We conclude with a discussion of the meaning of the words p, q, r, p3 and p4. The book is published by Oxford University Press, priced £16.99. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or click here for The formulas of basic modal logic φ are deﬁned by the following Backus Naur form (BNF): p | (¬φ) | (φ ∧ φ) – (2 φ), where p is any atomic formula. The following strings are not formulas, because they cannot be constructed using the grammar                in (5.1): (p2 →q) and (p →3(q 3 r) Conventions 5.2 As done in Chapter 1, we assume that the unary connec- tumultuoustives (½, 2, 3) bind most closely, followed by  and then followed by                by. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modallogics we study in this text are normal, as they all have the same formula scheme, L. We conclude with a look at the results of our study of the KT45 logic, where L = {T, 4, 5} with T, 4 and 5 from Table 5 The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience. If the agent Q knows something, then she knows                that she knows it. If she doesn’t know something, she knows that she doesn't know it. Even computer agents may not have all of these properties. We will not consider them here. The logic is based on the theory of knowledge. It is not a theory of human knowledge. We are not trying to prove that human knowledge is better than computer knowledge. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 can be re-engineered in various ways to give us the properties appropriate for the intended ap-                plications. We will consider how to re-Engineer basic modal logic to give the following readings of 2: It is necessarily true that φ is an equivalence relation. After any execution of program P, φ holds. If we take the connective 3, which is equivalent to ¬2¬, we can figure out what the corresponding readings of 3 in our system will be. For example, ‘it is not necessarily true that not φ’ means that it is possibly true that φ. The readings for 3 for the other modes are given in Table 5.6.3. The reading ‘agent Q knows φ' for 2φ. is read as ‘ agent Q does not know not’ for 3’s ‘not’ reading is ‘nothing’. For all agent Q knows, φ is consistent with what it knows, so it could be ‘something’ as far as Q is concerned, and this could be the case for all agents Q knows. We saw in the last section some valid formulas of basic modal logic, such as the terms of the Ki and CG is deﬁned in terms of EG. The readings of 3 corresponding to each reading of 2. The stock of valid formulas is shown in the next section. The formulas are given in the second section of this article. The third section of the article is the fourth and final part of the series. The final section is the last and final section, which includes the formulas for the first and second sections of this section. It is the first time that we use the term ‘accessibility’ to refer to the formulas. A frame F for KT45n is said to satisfy φ if, for each labelling L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds. We say that y is G-reachable in k steps from x if there are w1, w2, wk−1 and i1, i2, . . . , ik in G such that Ri1 w1 Ri2 w2 .. . . Rik−1 wk+1 Rik y means Ri1(x, w1), Ri2(w1,. w2), . .. , Rik(wk, y). Theorem 5.26: Y is G-reachable from x if there is some k such that it is G in k steps. We will prove that y holds by proving that x ⊩EkophobicGφ holds. Theorem: Take any i1, i2, . . . , ik ∈G and any w1, w2,. . ., wk−1 and y                such that there is a path of the form x Ri1 w1 Ri2 w2 . .. Rik−1 wk+1 Rik y. We also say that y is. G- Reachable From x if and only if y is G Reachable from X. The formula K holds for the connec-                So ¬p1, ¬ p2 mean they (respectively) are wearing a white one. Kik φ, we have y ⊩�.                Some valid formulas in KT45n are: K2K1 (p1 ∨p2)                 K2(¬p2 →K1 ¬P2)                 K2¬K1 p1.                 K1 p2.              ‘If man 1 were blind, would man 2 still be able to tell?’?         “If man 2 were blind would he still be. able to. tell? If man 1 was blind The possible-worlds approach, which greatly simpliﬁed modallogic and is now almost synonymous with it, was invented by S. Kripke. Not all modal logics enjoy this property, which is important for decidability. A great deal of work on applying modal logic to multi-agent sys-tems has been done in [FHMV95] and [MvdH95] The idea of using modal Logic to reason about knowledge is due to J.Hintikka. The idea that modalLogic can be used to reason in terms of knowledge is the work of J. Hintsikka and others. In nat-ural language, for example, we often distinguish between various ‘modes’ oftruth, such as necessarily true, known to be true, believed to betrue and true in the future. From many points of view, however, this is inadequate. Many examples in this chapter are taken from this literature (some of them are attributed to other people there), though our treatment of them                is original. It does not enjoy all modes of truth, however. For example, although the sentenceGeorge W. Bush is president of the United States of America is currently true, it will not be true at some point in thefuture. Equally, the sentenceThere are nine planets in the solar system is not necessarily true In computer science, it is often useful to reason about modes of truth. Temporal logic is a special case of modal logic. The modalities of CTL allow us to express a host of computational behaviour of systems. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed. Each agent may have diﬀerent knowledge about the environment and also about the knowledge of other agents. In this chapter, we will look in depth at modal logics applied to reasoning about knowledge. We will also look at how these logics can be used to model other domains of com-puter science. We conclude with a discussion of the implications of our findings. The simplest modal logics just deal with one con-ceive – such as knowledge, necessity, or time. More sophisticated modallogics bind most closely, followed by  and then followed by by. The convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. In basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when we apply modalLogics to express various modes of truth, we may read them ‘boxes’ or ‘iamonds’ in a different way. We cannot omit theremaining brackets, however, for 23q ∧¬ For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. A model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W : W →P(Atoms) These models are often called Kripke models, in honour of S.Kripke who invented them in the 1950s and 1960s. The parse tree for 23q ∧¬r →2p is given in 5.3 of the book. The full book is available to download now from: http://www.amazon.co.uk/kripke-modal-logic Exercises 5.4 and 5.5: Find natural deduction proofs for the following. The modal logic KD45 is used to model belief; see Table 5.12 for the axiom.schemes D, 4, and 5: Explain why the condition of seriality is relevant to belief. Recall Deﬁnition 5.7. How would you deﬅne L for a modal Logic L? Exercises 6 and 7: Study the proofs you gave for the previous exercise to see whether any of the formula schemes could be valid in basic modal. logic KT45. Exercise 8: Find the proof for the rule that the signi﬉cance of Exercises 5.1 - 5.5 are about the wise-men puzzle. Justify your answers. Exercises 6 - 6 are about Kripke model and the world which does not satisfy the formulae T, 4 and 5. Justifying your answers is the same as explaining why you think they are sound.",
                    "children": [
                        {
                            "id": "chapter-5-section-3-subsection-1",
                            "title": "The Stock of Valid Formulas",
                            "content": "long as they match the pattern required by the respective rule. For example,\n32\n1 Propositional logic\nthe application of the proof rule →e in\n1\np →q\npremise\n2\np\npremise\n3\nq\n→e 1, 2\nis equally valid if we substitute p with p ∨¬r and q with r →p:\n1\np ∨¬r →(r →p)\npremise\n2\np ∨¬r\npremise\n3\nr →p\n→e 1, 2\nThis is why we expressed such rules as schemes with Greek symbols stand-\ning for generic formulas. Yet, it is time that we make precise the notion of\n‘any formula we may form.’ Because this text concerns various logics, we will\nintroduce in (1.3) an easy formalism for specifying well-formed formulas. In\ngeneral, we need an unbounded supply of propositional atoms p, q, r, . . ., or\np1, p2, p3, . . . You should not be too worried about the need for inﬁnitely\nmany such symbols. Although we may only need ﬁnitely many of these\npropositions to describe a property of a computer program successfully, we\ncannot specify how many such atomic propositions we will need in any con-\ncrete situation, so having inﬁnitely many symbols at our disposal is a cheap\nway out. This can be compared with the potentially inﬁnite nature of En-\nglish: the number of grammatically correct English sentences is inﬁnite, but\nﬁnitely many such sentences will do in whatever situation you might be in\n(writing a book, attending a lecture, listening to the radio, having a dinner\ndate, . . . ).\nFormulas in our propositional logic should certainly be strings over the\nalphabet {p, q, r, . . . } ∪{p1, p2, p3, . . . } ∪{¬, ∧, ∨, →, (, )}. This is a trivial\nobservation and as such is not good enough for what we are trying to capture.\nFor example, the string (¬)() ∨pq →is a word over that alphabet, yet, it\ndoes not seem to make a lot of sense as far as propositional logic is concerned.\nSo what we have to deﬁne are those strings which we want to call formulas.\nWe call such formulas well-formed.\nDeﬁnition 1.27 The well-formed formulas of propositional logic are those\nfor all valuations in which φ evaluates to T.’\n(1.9)\nIn that way, marking atomic formulas generalizes to marking subformu-\nlas; and ‘true’ marks generalize into ‘true’ and ‘false’ marks. At the same\n1.6 SAT solvers\n69\ntime, (1.9) serves as a guide for designing an algorithm and as an invariant\nfor proving its correctness.\n1.6.1 A linear solver\nWe will execute this marking algorithm on the parse tree of formulas, except\nthat we will translate formulas into the adequate fragment\nφ ::= p | (¬φ) | (φ ∧φ)\n(1.10)\nand then share common subformulas of the resulting parse tree, making the\ntree into a directed, acyclic graph (DAG). The inductively deﬁned transla-\ntion\nT(p) = p\nT(¬φ) = ¬T(φ)\nT(φ1 ∧φ2) = T(φ1) ∧T(φ2)\nT(φ1 ∨φ2) = ¬(¬T(φ1) ∧¬T(φ2))\nT(φ1 →φ2) = ¬(T(φ1) ∧¬T(φ2))\ntransforms formulas generated by (1.3) into formulas generated by (1.10)\nsuch that φ and T(φ) are semantically equivalent and have the same propo-\nsitional atoms. Therefore, φ is satisﬁable iﬀT(φ) is satisﬁable; and the set\nof valuations for which φ is true equals the set of valuations for which T(φ)\nis true. The latter ensures that the diagnostics of a SAT solver, applied to\nT(φ), is meaningful for the original formula φ. In the exercises, you are asked\nto prove these claims.\nExample 1.48 For the formula φ being p ∧¬(q ∨¬p) we compute T(φ) =\np ∧¬¬(¬q ∧¬¬p). The parse tree and DAG of T(φ) are depicted in Fig-\nure 1.12.\nAny valuation that makes p ∧¬¬(¬q ∧¬¬p) true has to assign T to the\ntopmost ∧-node in its DAG of Figure 1.12. But that forces the mark T on\nthe p-node and the topmost ¬-node. In the same manner, we arrive at a\ncomplete set of constraints in Figure 1.13, where the time stamps ‘1:’ etc\nindicate the order in which we applied our intuitive reasoning about these\nconstraints; this order is generally not unique.\nThe formal set of rules for forcing new constraints from old ones is depicted\nin Figure 1.14. A small circle indicates any node (¬, ∧or atom). The force\nvaluation\nfor propositional logic, 37\nin predicate logic, 123\nin relational mu-calculus, 391\nvalue\ninitial, 206, 268, 269\nVardi, M., 254\nvariable, 94, 260\nboolean, 229, 247, 358\nbound, 103\ncapture, 106\ndummy, 110\nfree, 103\nlocal, 263\nlogical, 268, 290\nvariable ordering\ncompatible, 368\nlist, 367\nvariant, 293\nveriﬁcation\nfull, 173\nmethod, 172\nof communication protocols, 175\nof hardware, 175\nof software, 175\nof systems, 256\npost-development, 173, 257\npre-development, 173, 257\nprocess, 271\nprogram, 270\nproperty, 173\nproperty-oriented, 256\nsemi-automatic, 256\ntechniques, 172\nweakest precondition, 276\nwhile-statement, 261, 262\nbody, 273, 282, 286\nnon-termination, 292\nwise-men puzzle, 342\nWolper, P., 254\nword\nempty, 126\nworld\naccessible, 309\npossible, 309, 336\nyear-2000 problem, 258\n(f) Prove that for every preﬁx of a well-formed propositional logic formula the\nnumber of left brackets is greater or equal to the number of right brackets.\n8.\n*\nThe Fibonacci numbers are most useful in modelling the growth of populations.\nWe deﬁne them by F1\ndef\n= 1, F2\ndef\n= 1 and Fn+1\ndef\n= Fn + Fn−1 for all n ≥2. So\nF3\ndef\n= F1 + F2 = 1 + 1 = 2 etc. Show the assertion ‘F3n is even.’ by mathemat-\nical induction on n ≥1. Note that this assertion is saying that the sequence\nF3, F6, F9, . . . consists of even numbers only.\n86\n1 Propositional logic\n9. Consider the function rank, deﬁned by\nrank(p)\ndef\n= 1\nrank(¬φ)\ndef\n= 1 + rank(φ)\nrank(φ ◦ψ)\ndef\n= 1 + max(rank(φ), rank(ψ))\nwhere p is any atom, ◦∈{→, ∨, ∧} and max(n, m) is n if n ≥m and m other-\nwise. Recall the concept of the height of a formula (Deﬁnition 1.32 on page 44).\nUse mathematical induction on the height of φ to show that rank(φ) is nothing\nbut the height of φ for all formulas φ of propositional logic.\n10.\n*\nHere is an example of why we need to secure the base case for mathematical\ninduction. Consider the assertion\n‘The number n2 + 5n + 1 is even for all n ≥1.’\n(a) Prove the inductive step of that assertion.\n(b) Show that the base case fails to hold.\n(c) Conclude that the assertion is false.\n(d) Use mathematical induction to show that n2 + 5n + 1 is odd for all n ≥1.\n11. For the soundness proof of Theorem 1.35 on page 46,\n(a) explain why we could not use mathematical induction but had to resort to\ncourse-of-values induction;\n(b) give justiﬁcations for all inferences that were annotated with ‘why?’ and\n(c) complete the case analysis ranging over the ﬁnal proof rule applied; inspect\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional",
                            "summary": "We will introduce in (1.3) an easy formalism for specifying well-formed formulas. In general, we need an unbounded supply of propositional atoms p, q, r, . . ., or p1, p2, p3. You should not be too worried about the need for inﬁnitely many such symbols. For example, the application of the proof rule →e in 1, 2 is equally valid if we substitute p with p ∨¬r and q with r →p. We expressed such rules as schemes with Greek symbols stand-inducing for generic formulas. Yet, it is time that we make precise the notion of ‘any formula we may form’ Having inﬁnitely many symbols at our disposal is a cheap                way out. This can be compared with the potentially in-                glish nature of English sentences. The number of grammatically correct English sentences is in  in-                nite, but many such sentences will do in whatever situation you might be in. The formula in our propositional logic should certainly be strings over the                alphabet {p, q, r, . . . }  .   ‘’, ‘ , “”, ‬, ’’,.’”,.� For example, the string (¬)() ∨pq →is a word over that alphabet, yet, it does not seem to make a lot of sense as far as propositional logic is concerned. This is a trivialobservation and as such is not good enough for what we are trying to capture. So what we have to deﬁne are those strings which we want to call formulas. We call such formulas well-formed. Well-formed formulas are those for all valuations in which � We will execute this marking algorithm on the parse tree of formulas. At the same time, (1.9) serves as a guide for designing an algorithm and as an invariantfor proving its correctness. We will translate formulas into the adequate fragment of the resulting parse tree. We then share common subformulas, making the resulting tree into a directed, acyclic graph (DAG) The set of valuations for which φ is true equals the set ofValuation for which T(φ) is true. The latter ensures that the diagnostics of a SAT solver, applied to the original formula φ, is meaningful for the original form of the formula. In the exercises, you are asked to prove these claims. In Figure 1.48, we compute T(φ) = p ∧¬(q ∨¬p) for φ being p. The formal set of rules for forcing new constraints from old ones is depicted in Figure 1,14. A small circle indicates any node (¬, ∧or atom)  In the same manner, we arrive at acomplete set of constraints in Figure, 1.13. The time stamps ‘1:’ etc. indicate the order in which we applied our intuitive reasoning about these constraints. This order is generally not unique. The Fibonacci numbers are most useful in modelling the growth of populations. Prove that for every preﬁx of a well-formed propositional logic formula the number of left brackets is greater or equal to thenumber of right brackets. The force is the force that drives a person to do a certain thing. We call this force the force of change. We use the following terms: force, value, force, force of action, force-to-value, force to force. We also use the terms force, change, force and force of motion. We refer to these terms as F1, F2, F3, F4, F5, F6, F7 and F8. Use mathematical induction on the height of φ to show that rank(φ) is nothing but φ for all formulas φ of propositional logic. So F1 + F2 = 1 + 1 = 2 etc. Show the assertion ‘F3n is even.’ by Mathematical induction on n ≥1. Note that this assertion is saying that the sequence. F3, F6, F9, . . . consists of even numbers only. F1, F2, F4, F5, F7, F8, F10, F11, F12, F13, F14, F15, F16, F17, F18, F19, F Prove the inductive step of that assertion. Show that the base case fails to hold. Conclude that the assertion is false. Use mathematical induction to show that n2 + 5n + 1 is odd for all n ≥1. For the soundness proof of Theorem 1.35 on page 46, explain why we could not use mathematical induction but had to resort to course-of-values induction. Give justiﬁcations for all inferences that were annotated with ‘why?’ and complete the case analysis ranging over the proof rule applied. inspect the summary of natural deduction rules in Figure 1.2 on page 27 to see which viewpoints are still missing. Do you need to include derived Propositional and predicate logic can be found in the bibliographicremarks at the end of Chapter 2. For an introduction to algorithms and datastructures see e.g. [Wei98]. The need for a richer language for propositional logic is discussed in the first chapter of the book. The second chapter is devoted to the subject of predicate logic. The third chapter is dedicated to the topic of propositional logic. The fourth and fifth chapters are devoted to propositional and predicate logics. The sixth and seventh chapters are dedicated to propositional and predicates logical exercises. The final chapter focuses on the exercise of In propositional logic, we could identify this assertion with a propositional. The desire to express more subtle declarative sentences led to the design of predicate logic, which is also called ﬁrst-order logic. Here, propositional Logic shows clear shortcomings and we look at a different way to express the same assertion. The goal of this book is to show how propositional and predicate logic can be used to express a range of different statements. The aim of the second chapter is to explain how these different ways of expressing statements can be combined to form a single statement. The book is intended to be a guide for students of propositional, predicate, and artiﬁcial languages. It is also intended to",
                            "children": []
                        },
                        {
                            "id": "chapter-5-section-3-subsection-2",
                            "title": "Important Properties of the Accessibility Relation",
                            "content": "terms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-\nWe saw in the preceding section that there appeared to be a correspondence\nbetween the validity of 2φ →φ and the property that the accessibility re-\nlation R is reﬂexive. The connection between them is that both relied on\nthe intuition that anything which is known by an agent is true. Moreover,\nthere also seemed to be a correspondence between 2φ →22φ and R being\ntransitive; they both seem to assert the property of positive introspection,\ni.e. that which is known is known to be known.\nIn this section, we will see that there is a precise mathematical relation-\nship between these formulas and properties of R. Indeed, to every formula\nscheme there corresponds a property of R. From the point of view of logic\nengineering, it is important to see this relationship, because it helps one to\nunderstand the logic being studied. For example, if you believe that a cer-\ntain formula scheme should be accepted in the system of modal logic you are\nengineering, then it is well worth looking at the corresponding property of\nR and checking that this property makes sense for the application, too. Al-\nternatively, the meaning of some formulas may seem diﬃcult to understand,\nso looking at their corresponding properties of R can help.\nTo state the relationship between formula schemes and their correspond-\ning properties, we need the notion of a (modal) frame.\nDeﬁnition 5.10 A frame F = (W, R) is a set W of worlds and a binary\nrelation R on W.\nA frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-\nbelling function. From any model we can extract a frame, by just forgetting\nabout the labelling function; for example, Figure 5.9 shows the frame ex-\ntracted from the Kripke model of Figure 5.3. A frame is just a set of worlds\nand an accessibility relationship between them. It has no information about\nwhat atomic formulas are true at the various worlds. However, it is useful to\nsay sometimes that the frame, as a whole, satisﬁes a formula. This is deﬁned\nas follows.\n{x1, x2, x3, x4, x5, x6} is shown in Figure 5.13. The links between the worlds\nhave to be labelled with the name of the accessibility relation, since we have\nseveral relations. For example, x1 and x2 are related by R1, whereas x4 and\n5.5 Reasoning about knowledge in a multi-agent system\n337\nx5 are related both by R1 and by R2. We simplify by no longer requiring ar-\nrows on the links. This is because we know that the relations are symmetric,\nso the links are bi-directional. Moreover, the relations are also reﬂexive, so\nthere should be loops like the one on x4 in Figure 5.11 in all the worlds and\nfor all of the relations. We can simply omit these from the diagram, since we\ndon’t need to distinguish between worlds which are self-related and those\nwhich are not.\nDeﬁnition 5.25 Take a model M = (W, (Ri)i∈A, L) of KT45n and a world\nx ∈W. We deﬁne when φ is true in x via a satisfaction relation x ⊩φ by\ninduction on φ:\nx ⊩p iﬀp ∈L(x)\nx ⊩¬φ iﬀx ̸⊩φ\nx ⊩φ ∧ψ\niﬀx ⊩φ and x ⊩ψ\nx ⊩φ ∨ψ\niﬀx ⊩φ or x ⊩ψ\nx ⊩φ →ψ\niﬀx ⊩ψ whenever we have x ⊩φ\nx ⊩Ki ψ\niﬀ, for each y ∈W, Ri(x, y) implies y ⊩ψ\nx ⊩EG ψ\niﬀ, for each i ∈G, x ⊩Ki ψ\nx ⊩CG ψ\niﬀ, for each k ≥1, we have x ⊩Ek\nGψ,\nwhere Ek\nG means EGEG . . . EG – k times\nx ⊩DG ψ\niﬀ, for each y ∈W, we have y ⊩ψ,\nwhenever Ri(x, y) for all i ∈G.\nAgain, we write M, x ⊩φ if we want to emphasise the model M.\nCompare this with Deﬁnition 5.4. The cases for the boolean connectives\nare the same as for basic modal logic. Each Ki behaves like a 2, but refers to\nits own accessibility relation Ri. As already stated, there are no equivalents\nof 3, but we can recover them as ¬Ki¬. The connective EG is deﬁned in\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of",
                            "summary": "Many of the results we had for basic modal logic with a single accessi-bility relation also hold in this more general setting of several accessibility relations. terms of the Ki and CG is deﬁned in terms of EG. We say that y is G-reachable in k steps from x if there are i1, i2, . . . , ik in G such that Ri1 w1, Ri2 w2, wk−1 wk, y, w1 w2 w3, w3 w4, w5, w6, w7, w8, w9, w10, w11, w12, w13, w14, w15, w Theorem 5.26: Y is G-reachable from x if there is some k such that it is G in k steps. We will prove that y holds by proving that x ⊩EkophobicGφ holds. Theorem: Take any i1, i2, . . . , ik ∈G and any w1, w2,. . ., wk−1 and y                such that there is a path of the form x Ri1 w1 Ri2 w2 . .. Rik−1 wk+1 Rik y. We also say that y is. G- Reachable From x if and only if y is G Reachable from X. We saw in the preceding section that there appeared to be a correspondence between the validity of 2 φ and the property that the accessibility re-                lation R is reﬂexive. In this section, we will see that there is a precise mathematical relation-ship between these formulas and properties of R. From the point of view of logic engineering, it is important to see this relationship, because it helps one to understand the logic being studied. To every formula in KT45n there corresponds a property of R, and this relationship is important for the study of logic and engineering. The formula K holds for the connec-                The formula K hold for the connec- A frame F = (W, R) is a set W of worlds and a binaryrelation R on W. A frame is like a Kripke model (Deﬁnition 5.3), except that it has no la-                belling function. From any model we can extract a frame, by just forgetting about the labelling function. For example, Figure 5.9 shows the frame ex-                tracted from the K Ripke model of Figure 5-3. A Frame is just a set of worlds                and an accessibility relationship between them. The meaning of some formulas may seem diﬃcult to understand, so looking at their corresponding properties of R can help. It has no information about what atomic formulas are true at the various worlds. However, it is useful to say sometimes that the frame, as a whole, satisﬁes a formula. The links between the worlds have to be labelled with the name of the accessibility relation. For example, x1 and x2 are related by R1, whereas x4 and                5.5 are related both by R 1 and by R2. We simplify by no longer requiring ar-                rows on the links. This is because we know that the relations are symmetric,                so the links are bi-directional. Also, there should be loops like the one on x4 in Figure 5.11 in all the worlds Deﬁnition 5.25: Take a model M = (W, (Ri)i∈A, L) of KT45n and a worldx ∈W. We deﬅne when φ is true in x via a satisfaction relation x ⊩φ by auctiveinduction on φ. The cases for the boolean connectives are the same as for basic modal logic. Each Ki behaves like a 2, but refers to its own accessibility relation Ri. There are no equivalents for 3, but we can recover them as ¬Ki¬. De﬉nition 4.4.1: The case for the Boolean connectives is the Many of the results we had for basic modal logic with a single accessi-bility relation also hold in this more general setting. Summarising, a frame F for KT45n (W, (Ri)i∉A) is a set W of. The connective EG",
                            "children": []
                        },
                        {
                            "id": "chapter-5-section-3-subsection-3",
                            "title": "Correspondence Theory",
                            "content": "The interpretation of P on M is just what we expect it to be:\nP M def\n= {(s, t) | there is a sequence of indices (i1, i2, . . . , im) such that\ns equals si1si2 . . . sim and t equals ti1ti2 . . . tim}\nwhere s and t are binary strings and the si and ti are the data of the\ncorrespondence problem C. A pair of strings (s, t) lies in P M iﬀ, using the\nsame sequence of indices (i1, i2, . . . , im), s is built using the corresponding\nsi and t is built using the respective ti.\nSince ⊨φ holds we infer that M ⊨φ holds, too. We claim that M ⊨\nφ2 holds as well, which says that whenever the pair (s, t) is in P M, then\nthe pair (s si, t ti) is also in P M for i = 1, 2, . . . , k (you can verify that is\nsays this by inspecting the deﬁnition of P M). Now (s, t) ∈P M implies that\nthere is some sequence (i1, i2, . . . , im) such that s equals si1si2 . . . sim and t\nequals ti1ti2 . . . tim. We simply choose the new sequence (i1, i2, . . . , im, i) and\nobserve that s si equals si1si2 . . . simsi and t ti equals ti1ti2 . . . timti and so\nM ⊨φ2 holds as claimed. (Why does M ⊨φ1 hold?)\nSince M ⊨φ1 ∧φ2 →φ3 and M ⊨φ1 ∧φ2 hold, it follows that M ⊨φ3\nholds as well. By deﬁnition of φ3 and P M, this tells us there is a solution\nto C.\nConversely, let us assume that the Post correspondence problem C has\nsome solution, namely the sequence of indices (i1, i2, . . . , in). Now we have to\nshow that, if M′ is any model having a constant eM′, two unary functions,\n2.5 Undecidability of predicate logic\n135\nfM′\n0\nand fM′\n1\n, and a binary predicate P M′, then that model has to satisfy\nφ. Notice that the root of the parse tree of φ is an implication, so this is\nthe crucial clause for the deﬁnition of M′ ⊨φ. By that very deﬁnition, we\nare already done if M′ ̸⊨φ1, or if M′ ̸⊨φ2. The harder part is therefore the\none where M′ ⊨φ1 ∧φ2, for in that case we need to verify M′ ⊨φ3 as well.\nThe way we proceed here is by interpreting ﬁnite, binary strings in the",
                            "summary": "P on M is just what we expect it to be: P on M def                = {(s, t) | there is a sequence of indices (i1, i2, . . . , im) such that s equals si1si2 and t equals ti1ti2. We claim that M ⊨φ2 holds as well, which says that whenever the pair (s,t) is in P M, then the pair is also in P P M for i = 1, 2,. . ., k (you can verify that is                says this by inspecting the deﬁnition of P M). Since ⊩φ holds we infer that M  holds, The Post correspondence problem C has some solution, namely the sequence of indices (i1, i2, . . . , in). Now we have to show that, if M′ is any model having a constant eM′, two unary functions, and a binary predicate P M′, then that model has to satisfy P M. The root of the parse tree of φ is an implication, so this is the crucial clause for the deﬁnition of M′ ⊨φ. The way we proceed here is by interpreting binary strings in the. timti and so we need to verify that M′   ≹ ≢ ≳.",
                            "children": []
                        },
                        {
                            "id": "chapter-5-section-3-subsection-4",
                            "title": "Some Modal Logics",
                            "content": "knowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nhave connectives for expressing several modes of truth in the same logic; we\nwill see some of these towards the end of this chapter.\nWe take a logic engineering approach in this chapter, in which we address\nthe following question: given a particular mode of truth, how may we develop\na logic capable of expressing and formalising that concept? To answer this\nquestion, we need to decide what properties the logic should have and what\nexamples of reasoning it should be able to express. Our main case study will\nbe the logic of knowledge in a multi-agent system. But ﬁrst, we look at the\nsyntax and semantics of basic modal logic.\n5.2 Basic modal logic\n5.2.1 Syntax\nThe language of basic modal logic is that of propositional logic with two\nextra connectives, 2 and 3. Like negation (¬), they are unary connectives\nas they apply themselves to a single formula only. As done in Chapters 1\nand 3, we write p, q, r, p3 . . . to denote atomic formulas.\nDeﬁnition 5.1 The formulas of basic modal logic φ are deﬁned by the\nfollowing Backus Naur form (BNF):\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) | (2φ) | (3φ)\n(5.1)\nwhere p is any atomic formula.\nExample formulas of basic modal logic are (p ∧3(p →2¬r)) and 2((3q ∧\n¬r) →2p), having the parse trees shown in Figure 5.1. The following strings\nare not formulas, because they cannot be constructed using the grammar\nin (5.1): (p2 →q) and (p →3(q 3 r)).\nConvention 5.2 As done in Chapter 1, we assume that the unary connec-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin various ways to give us the properties appropriate for the intended ap-\nplications. Logic engineering is the subject of engineering logics to ﬁt new\napplications. It is potentially a very broad subject, drawing on all branches\nof logic, computer science and mathematics. In this chapter, however, we\nare restricting ourselves to the particular engineering of modal logics.\nWe will consider how to re-engineer basic modal logic to ﬁt the following\nreadings of 2φ:\nr It is necessarily true that φ\nr It will always be true that φ\nr It ought to be that φ\nr Agent Q believes that φ\nr Agent Q knows that φ\nr After any execution of program P, φ holds.\nAs modal logic automatically gives us the connective 3, which is equivalent\nto ¬2¬, we can ﬁnd out what the corresponding readings of 3 in our system\nwill be. For example, ‘it is not necessarily true that not φ’ means that it is\npossibly true that φ. You could work this out in steps:\nIt is not necessarily true that φ\n= it is possible that not φ.\nTherefore,\nIt is not necessarily true that not φ\n= it is possible that not not φ\n= it is possible that φ.\nLet us work this out with the reading ‘agent Q knows φ’ for 2φ. Then, 3φ\nis read as\nagent Q does not know not φ\n= as far as Q’s knowledge is concerned, φ could be the case\n= φ is consistent with what agent Q knows\n= for all agent Q knows, φ.\nThe readings for 3 for the other modes are given in Table 5.6.\n5.3 Logic engineering\n317\nTable 5.6. The readings of 3 corresponding to each reading of 2.\n2φ\n3φ\nIt is necessarily true that φ\nIt is possibly true that φ\nIt will always be true that φ\nSometime in the future φ\nIt ought to be that φ\nIt is permitted to be that φ\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\nterms of the Ki and CG is deﬁned in terms of EG.\nMany of the results we had for basic modal logic with a single accessi-\nbility relation also hold in this more general setting of several accessibility\nrelations. Summarising,\nr a frame F for KT45n (W, (Ri)i∈A) for the modal logic KT45n is a set W of\nworlds and, for each i ∈A, an equivalence relation Ri on W.\nr a frame F = (W, (Ri)i∈A) for KT45n is said to satisfy φ if, for each labelling\nfunction L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds, where\nM = (W, (Ri)i∈A, L). In that case, we say that F ⊨φ holds.\nThe following theorem is useful for answering questions about formu-\nlas involving E and C. Let M = (W, (Ri)i∈A, L) be a model for KT45n\n338\n5 Modal logics and agents\nand x, y ∈W. We say that y is G-reachable in k steps from x if there are\nw1, w2, . . . , wk−1 ∈W and i1, i2, . . . , ik in G such that\nx Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y\nmeaning Ri1(x, w1), Ri2(w1, w2), . . . , Rik(wk, y). We also say that y is G-\nreachable from x if there is some k such that it is G-reachable in k steps.\nTheorem 5.26\n1.\nx ⊩Ek\nGφ iﬀ, for all y that are G-reachable from x in k steps, we have y ⊩φ.\n2.\nx ⊩CG φ iﬀ, for all y that are G-reachable from x, we have y ⊩φ.\nPROOF:\n1.\nFirst, suppose y ⊩φ for all y G-reachable from x in k steps. We will prove\nthat x ⊩Ek\nGφ holds. It is suﬃcient to show that x ⊩Ki1Ki2 . . . Kik φ for any\ni1, i2, . . . , ik ∈G. Take any i1, i2, . . . , ik ∈G and any w1, w2,. . . , wk−1 and y\nsuch that there is a path of the form x Ri1 w1 Ri2 w2 . . . Rik−1 wk−1 Rik y. Since\ny is G-reachable from x in k steps, we have y ⊩φ by our assumption, so x ⊩\nKi1Ki2 . . . Kik φ as required.\nConversely, suppose x ⊩Ek\nGφ holds and y is G-reachable from x in k steps. We\nmust show that y ⊩φ holds. Take i1, i2, . . . , ik by G-reachability; since x ⊩Ek\nGφ\nimplies x ⊩Ki1Ki2 . . . Kik φ, we have y ⊩φ.\n2.\nThis argument is similar.\nSome valid formulas in KT45n\nThe formula K holds for the connec-\nSo ¬p1, ¬p2 mean they (respectively) are wearing a white one. Informally\njustify each of the following premises in terms of the description of the\nproblem:\ni. K2K1 (p1 ∨p2)\nii. K2(¬p2 →K1 ¬p2)\niii. K2¬K1 p1.\n(c) Using natural deduction, prove from these premises that K2 p2.\n(d) Show that the third premise was essential, by exhibiting a model/world\nwhich satisﬁes the ﬁrst two, but not the conclusion.\n(e) Now is it easy to answer questions like ‘If man 2 were blind would he still be\nable to tell?’ and ‘if man 1 were blind, would man 2 still be able to tell?’?\n12. Recall our informal discussion on positive-knowledge formulas and negative-\nknowledge formulas. Give formal deﬁnitions of these notions.\n5.7 Bibliographic notes\nThe ﬁrst systematic approaches to modal logic were made by C. I. Lewis\nin the 1950s. The possible-worlds approach, which greatly simpliﬁed modal\nlogic and is now almost synonymous with it, was invented by S. Kripke.\nBooks devoted to modal logic include [Che80, Gol87, Pop94], where exten-\nsive references to the literature may be found. All these books discuss the\nsoundness and completeness of proof calculi for modal logics. They also in-\nvestigate which modal logics have the ﬁnite-model property: if a sequent\ndoes not have a proof, there is a ﬁnite model which demonstrates that. Not\nall modal logics enjoy this property, which is important for decidability.\nIntuitionistic propositional logic has the ﬁnite-model property; an anima-\ntion which generates such ﬁnite models (called PORGI) is available from\nA. Stoughton’s website2.\nThe idea of using modal logic to reason about knowledge is due to J.\nHintikka. A great deal of work on applying modal logic to multi-agent sys-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nin the future. For example, we would say that, although the sentence\nGeorge W. Bush is president of the United States of America.\nis currently true, it will not be true at some point in the future. Equally, the\nsentence\nThere are nine planets in the solar system.\nwhile true, and maybe true for ever in the future, is not necessarily true, in\nthe sense that it could have been a diﬀerent number. However, the sentence\nThe cube root of 27 is 3.\nas well as being true is also necessarily true and true in the future. It does\nnot enjoy all modes of truth, however. It may not be known to be true by\nsome people (children, for example); it may not be believed by others (if\nthey are mistaken).\nIn computer science, it is often useful to reason about modes of truth. In\nChapter 3, we studied the logic CTL in which we could distinguish not only\nbetween truth at diﬀerent points in the future, but also between diﬀerent\nfutures. Temporal logic is thus a special case of modal logic. The modalities\nof CTL allow us to express a host of computational behaviour of systems.\nModalities are also extremely useful in modelling other domains of com-\nputer science. In artiﬁcial intelligence, for example, scenarios with several\n306\n5.2 Basic modal logic\n307\ninteracting agents are developed. Each agent may have diﬀerent knowledge\nabout the environment and also about the knowledge of other agents. In this\nchapter, we will look in depth at modal logics applied to reasoning about\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\nfunction and world which does satisfy p →23p in your frame?\n15. Give two examples of frames which are Euclidean – i.e. their accessibility rela-\ntion is Euclidean – and two which are not. Explain intuitively why 3p →23p\nholds on the ﬁrst two, but not on the latter two.\n16. For each of the following formulas, ﬁnd the property of R which corresponds to\nit.\n(a) φ →2φ\n(b)\n*\n2⊥\n(c)\n*\n32φ →23φ.\n17.\n*\nFind a formula whose corresponding property is density: for all x, z ∈W such\nthat R(x, z), there exists y ∈W such that R(x, y) and R(y, z).\n18. The modal logic KD45 is used to model belief; see Table 5.12 for the axiom\nschemes D, 4, and 5.\n(a) Explain how it diﬀers from KT45.\n(b) Show that ⊨KD45 2p →3p is valid. What is the signiﬁcance of this, in terms\nof knowledge and belief?\n(c) Explain why the condition of seriality is relevant to belief.\n19. Recall Deﬁnition 5.7. How would you deﬁne ≡L for a modal logic L?\nExercises 5.4\n1. Find natural deduction proofs for the following sequents over the basic modal\nlogic K.\n(a)\n*\n⊢K 2(p →q) |−2p →2q\n(b) ⊢K 2(p →q) |−3p →3q\n(c)\n*\n⊢K|−2(p →q) ∧2(q →r) →2(p →r)\n(d) ⊢K 2(p ∧q) |−2p ∧2q\n(e) ⊢K|−3⊤→(2p →3p)\n(f)\n*\n⊢K 3(p →q) |−2p →3q\n(g) ⊢K 3(p ∨q) |−3p ∨3q.\n354\n5 Modal logics and agents\n2. Find natural deduction proofs for the following, in modal logic KT45.\n(a) p →23p\n(b) 23p ↔3p\n(c)\n*\n32p ↔2p\n(d) 2(2p →2q) ∨2(2q →2p)\n(e) 2(3p →q) ↔2(p →2q).\n3. Study the proofs you gave for the previous exercise to see whether any of\nthese formula schemes could be valid in basic modal logic. Inspect where and\nhow these proofs used the axioms T, 4 and 5 to see whether you can ﬁnd a\ncounter example, i.e. a Kripke model and a world which does not satisfy the\nformula.\n4. Provide a sketch of an argument which shows that the natural deduction rules\nfor basic modal logic are sound with respect to the semantics x ⊩φ over Kripke\nstructures.\nExercises 5.5\n1. This exercise is about the wise-men puzzle. Justify your answers.",
                            "summary": "Modal logic adds unary connectives to express one, or more, of these modes of truth. The language of basic modal logic is that of propositional logic with two extra connectives, 2 and 3. The main case study will be the logic of knowledge in a multi-agent system. But first, we look at the syntax and semantics of basicmodal logic.5.2.1 Syntax and Semantics of Basic modal Logic. 5.3.1. The Logic of Knowledge in a Multi-agent System. knowledge. knowledge, necessity, or time. knowledge and necessity. time. time and knowledge and time. Knowledge and time, necessity and knowledge, knowledge, time and necessity, knowledge and The formulas of basic modal logic φ are deﬁned by the Backus Naur form (BNF): p, q, r, p3 . . to denote atomic formulas. Like negation (¬), they are unary connectives                as they apply themselves to a single formula only. The following strings                are not formulas, because they cannot be constructed using the grammar                in (5.1): (p2 →q) and (p →3(q 3 r) Convention 5.2 As done in Chapter 1, we assume that the unary connec-                tives (¹, 2 and 3) bind most closely. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modallogics we study in this text are normal, as they all have the same formula scheme, L. We conclude with a look at the results of our study of the KT45 logic, where L = {T, 4, 5} with T, 4 and 5 from Table 5 The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience. If the agent Q knows something, then she knows                that she knows it. If she doesn’t know something, she knows that she doesn't know it. Even computer agents may not have all of these properties. We will not consider them here. The logic is based on the theory of knowledge. It is not a theory of human knowledge. We are not trying to prove that human knowledge is better than computer knowledge. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 can be re-engineered in various ways to give us the properties appropriate for the intended ap-                plications. We will consider how to re-Engineer basic modal logic to give the following readings of 2: It is necessarily true that φ is an equivalence relation. After any execution of program P, φ holds. If we take the connective 3, which is equivalent to ¬2¬, we can figure out what the corresponding readings of 3 in our system will be. For example, ‘it is not necessarily true that not φ’ means that it is possibly true that φ. The readings for 3 for the other modes are given in Table 5.6.3. The reading ‘agent Q knows φ' for 2φ. is read as ‘ agent Q does not know not’ for 3’s ‘not’ reading is ‘nothing’. For all agent Q knows, φ is consistent with what it knows, so it could be ‘something’ as far as Q is concerned, and this could be the case for all agents Q knows. We saw in the last section some valid formulas of basic modal logic, such as the terms of the Ki and CG is deﬁned in terms of EG. The readings of 3 corresponding to each reading of 2. The stock of valid formulas is shown in the next section. The formulas are given in the second section of this article. The third section of the article is the fourth and final part of the series. The final section is the last and final section, which includes the formulas for the first and second sections of this section. It is the first time that we use the term ‘accessibility’ to refer to the formulas. A frame F for KT45n is said to satisfy φ if, for each labelling L: W →P(Atoms) and each w ∈W, we have M, w ⊩φ holds. We say that y is G-reachable in k steps from x if there are w1, w2, wk−1 and i1, i2, . . . , ik in G such that Ri1 w1 Ri2 w2 .. . . Rik−1 wk+1 Rik y means Ri1(x, w1), Ri2(w1,. w2), . .. , Rik(wk, y). Theorem 5.26: Y is G-reachable from x if there is some k such that it is G in k steps. We will prove that y holds by proving that x ⊩EkophobicGφ holds. Theorem: Take any i1, i2, . . . , ik ∈G and any w1, w2,. . ., wk−1 and y                such that there is a path of the form x Ri1 w1 Ri2 w2 . .. Rik−1 wk+1 Rik y. We also say that y is. G- Reachable From x if and only if y is G Reachable from X. The formula K holds for the connec-                So ¬p1, ¬ p2 mean they (respectively) are wearing a white one. Kik φ, we have y ⊩�.                Some valid formulas in KT45n are: K2K1 (p1 ∨p2)                 K2(¬p2 →K1 ¬P2)                 K2¬K1 p1.                 K1 p2.              ‘If man 1 were blind, would man 2 still be able to tell?’?         “If man 2 were blind would he still be. able to. tell? If man 1 was blind The possible-worlds approach, which greatly simpliﬁed modallogic and is now almost synonymous with it, was invented by S. Kripke. Not all modal logics enjoy this property, which is important for decidability. A great deal of work on applying modal logic to multi-agent sys-tems has been done in [FHMV95] and [MvdH95] The idea of using modal Logic to reason about knowledge is due to J.Hintikka. The idea that modalLogic can be used to reason in terms of knowledge is the work of J. Hintsikka and others. In nat-ural language, for example, we often distinguish between various ‘modes’ oftruth, such as necessarily true, known to be true, believed to betrue and true in the future. From many points of view, however, this is inadequate. Many examples in this chapter are taken from this literature (some of them are attributed to other people there), though our treatment of them                is original. It does not enjoy all modes of truth, however. For example, although the sentenceGeorge W. Bush is president of the United States of America is currently true, it will not be true at some point in thefuture. Equally, the sentenceThere are nine planets in the solar system is not necessarily true In computer science, it is often useful to reason about modes of truth. Temporal logic is a special case of modal logic. The modalities of CTL allow us to express a host of computational behaviour of systems. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed. Each agent may have diﬀerent knowledge about the environment and also about the knowledge of other agents. In this chapter, we will look in depth at modal logics applied to reasoning about knowledge. We will also look at how these logics can be used to model other domains of com-puter science. We conclude with a discussion of the implications of our findings. The simplest modal logics just deal with one con-ceive – such as knowledge, necessity, or time. More sophisticated modallogics bind most closely, followed by  and then followed by by. The convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. In basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when we apply modalLogics to express various modes of truth, we may read them ‘boxes’ or ‘iamonds’ in a different way. We cannot omit theremaining brackets, however, for 23q ∧¬ For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. A model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W : W →P(Atoms) These models are often called Kripke models, in honour of S.Kripke who invented them in the 1950s and 1960s. The parse tree for 23q ∧¬r →2p is given in 5.3 of the book. The full book is available to download now from: http://www.amazon.co.uk/kripke-modal-logic Exercises 5.4 and 5.5: Find natural deduction proofs for the following. The modal logic KD45 is used to model belief; see Table 5.12 for the axiom.schemes D, 4, and 5: Explain why the condition of seriality is relevant to belief. Recall Deﬁnition 5.7. How would you deﬅne L for a modal Logic L? Exercises 6 and 7: Study the proofs you gave for the previous exercise to see whether any of the formula schemes could be valid in basic modal. logic KT45. Exercise 8: Find the proof for the rule that the signi﬉cance of Exercises 5.1 - 5.5 are about the wise-men puzzle. Justify your answers. Exercises 6 - 6 are about Kripke model and the world which does not satisfy the formulae T, 4 and 5. Justifying your answers is the same as explaining why you think they are sound.",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-5-section-4",
                    "title": "Natural Deduction",
                    "content": null,
                    "summary": null,
                    "children": []
                },
                {
                    "id": "chapter-5-section-5",
                    "title": "Reasoning About Knowledge in a Multi-Agent System",
                    "content": "knowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nhave connectives for expressing several modes of truth in the same logic; we\nwill see some of these towards the end of this chapter.\nWe take a logic engineering approach in this chapter, in which we address\nthe following question: given a particular mode of truth, how may we develop\na logic capable of expressing and formalising that concept? To answer this\nquestion, we need to decide what properties the logic should have and what\nexamples of reasoning it should be able to express. Our main case study will\nbe the logic of knowledge in a multi-agent system. But ﬁrst, we look at the\nsyntax and semantics of basic modal logic.\n5.2 Basic modal logic\n5.2.1 Syntax\nThe language of basic modal logic is that of propositional logic with two\nextra connectives, 2 and 3. Like negation (¬), they are unary connectives\nas they apply themselves to a single formula only. As done in Chapters 1\nand 3, we write p, q, r, p3 . . . to denote atomic formulas.\nDeﬁnition 5.1 The formulas of basic modal logic φ are deﬁned by the\nfollowing Backus Naur form (BNF):\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) | (2φ) | (3φ)\n(5.1)\nwhere p is any atomic formula.\nExample formulas of basic modal logic are (p ∧3(p →2¬r)) and 2((3q ∧\n¬r) →2p), having the parse trees shown in Figure 5.1. The following strings\nare not formulas, because they cannot be constructed using the grammar\nin (5.1): (p2 →q) and (p →3(q 3 r)).\nConvention 5.2 As done in Chapter 1, we assume that the unary connec-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin various ways to give us the properties appropriate for the intended ap-\nplications. Logic engineering is the subject of engineering logics to ﬁt new\napplications. It is potentially a very broad subject, drawing on all branches\nof logic, computer science and mathematics. In this chapter, however, we\nare restricting ourselves to the particular engineering of modal logics.\nWe will consider how to re-engineer basic modal logic to ﬁt the following\nreadings of 2φ:\nr It is necessarily true that φ\nr It will always be true that φ\nr It ought to be that φ\nr Agent Q believes that φ\nr Agent Q knows that φ\nr After any execution of program P, φ holds.\nAs modal logic automatically gives us the connective 3, which is equivalent\nto ¬2¬, we can ﬁnd out what the corresponding readings of 3 in our system\nwill be. For example, ‘it is not necessarily true that not φ’ means that it is\npossibly true that φ. You could work this out in steps:\nIt is not necessarily true that φ\n= it is possible that not φ.\nTherefore,\nIt is not necessarily true that not φ\n= it is possible that not not φ\n= it is possible that φ.\nLet us work this out with the reading ‘agent Q knows φ’ for 2φ. Then, 3φ\nis read as\nagent Q does not know not φ\n= as far as Q’s knowledge is concerned, φ could be the case\n= φ is consistent with what agent Q knows\n= for all agent Q knows, φ.\nThe readings for 3 for the other modes are given in Table 5.6.\n5.3 Logic engineering\n317\nTable 5.6. The readings of 3 corresponding to each reading of 2.\n2φ\n3φ\nIt is necessarily true that φ\nIt is possibly true that φ\nIt will always be true that φ\nSometime in the future φ\nIt ought to be that φ\nIt is permitted to be that φ\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nis equivalent to one of the following: −, 2, 3, ¬, ¬2 and ¬3, where −\nindicates the absence of any negation or modality.\nThe modal logic KT4\nThe modal logic KT4, that is L equals {T, 4},\nis also called S4 in the literature. Correspondence theory tells us that its\nmodels are precisely the Kripke models M = (W, R, L), where R is reﬂexive\nand transitive. Such structures are often very useful in computer science. For\nexample, if φ stands for the type of a piece of code – φ could be int × int →\nbool, indicating some code which expects a pair of integers as input and\noutputs a boolean value – then 2φ could stand for residual code of type φ.\nThus, in the current world x this code would not have to be executed, but\ncould be saved (= residualised) for execution at a later computation stage.\nThe formula scheme 2φ →φ, the axiom T, then means that code may be\nexecuted right away, whereas the formula scheme 2φ →22φ, the axiom 4,\nallows that residual code remain residual, i.e. we can repeatedly postpone its\nexecution in future computation stages. Such type systems have important\napplications in the specialisation and partial evaluation of code. We refer\nthe interested reader to the bibliographic notes at the end of the chapter.\nTheorem 5.18 Any sequence of modal operators and negations in KT4 is\nequivalent to one of the following: −, 2, 3, 23, 32, 232, 323, ¬, ¬2,\n¬3, ¬23, ¬32, ¬232 and ¬323.\nIntuitionistic propositional logic\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\nThe natural deduction proof system for modal logic presented in this\nchapter is based on ideas in [Fit93].\n2 www.cis.ksu.edu/~allen/porgi.html\n5.7 Bibliographic notes\n357\nAn application of the modal logic KT4 (more precisely, its fragment with-\nout negation) as a type system for staged computation in a functional pro-\ngramming language can be found in [DP96].\nWe should stress that our framework was deliberately ‘classical;’ the thesis\n[Sim94] is a good source for discussions of intuitionistic modal logics; it also\ncontains a gentle introduction to basic ﬁrst-order modal logic.\n6\nBinary decision diagrams\n6.1 Representing boolean functions\nBoolean functions are an important descriptive formalism for many hard-\nware and software systems, such as synchronous and asynchronous circuits,\nreactive systems and ﬁnite-state programs. Representing those systems in a\ncomputer in order to reason about them requires an eﬃcient representation\nfor boolean functions. We look at such a representation in this chapter and\ndescribe in detail how the systems discussed in Chapter 3 can be veriﬁed\nusing the representation.\nDeﬁnition 6.1 A boolean variable x is a variable ranging over the values\n0 and 1. We write x1, x2, . . . and x, y, z, . . . to denote boolean variables. We\ndeﬁne the following functions on the set {0, 1}:\nr 0\ndef\n= 1 and 1\ndef\n= 0;\nr x · y\ndef\n= 1 if x and y have value 1; otherwise x · y\ndef\n= 0;\nr x + y\ndef\n= 0 if x and y have value 0; otherwise x + y\ndef\n= 1;\nr x ⊕y\ndef\n= 1 if exactly one of x and y equals 1.\nA boolean function f of n arguments is a function from {0, 1}n to {0, 1}.\nWe write f(x1, x2, . . . , xn), or f(V ), to indicate that a syntactic representa-\ntion of f depends on the boolean variables in V only.\ndistributed among them.\nDeﬁnition 5.23 A formula φ in the multi-modal logic of KT45n is deﬁned\nby the following grammar:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) |\n(Ki φ) | (EG φ) | (CG φ) | (DG φ)\n336\n5 Modal logics and agents\nq\nq\np, q\nx1\nx2\nx4\nx5\np\nx6\np\nx3\nR1\nR1, R2\nR1, R3\nR1, R2\nR3\nFigure 5.13. A KT45n model for n = 3.\nwhere p is any atomic formula, i ∈A and G ⊆A. We simply write E, C and\nD without subscripts if we refer to EA, CA and DA.\nCompare this deﬁnition with Deﬁnition 5.1. Instead of 2, we have several\nmodalities Ki and we also have EG, CG and DG for each G ⊆A. Actually,\nall of these connectives will shortly be seen to be ‘box-like’ rather than\n‘diamond-like’, in the sense that they distribute over ∧rather than over ∨–\ncompare this to the discussion of equivalences on page 308. The ‘diamond-\nlike’ correspondents of these connectives are not explicitly in the language,\nbut may of course be obtained using negations, i.e. ¬Ki¬, ¬CG¬ etc.\nDeﬁnition 5.24 A model M = (W, (Ri)i∈A, L) of the multi-modal logic\nKT45n with the set A of n agents is speciﬁed by three things:\n1.\na set W of possible worlds;\n2.\nfor each i ∈A, an equivalence relation Ri on W (Ri ⊆W × W), called the\naccessibility relations; and\n3.\na labelling function L : W →P(Atoms).\nCompare this with Deﬁnition 5.3. The diﬀerence is that, instead of just one\naccessibility relation, we now have a family, one for each agent in A; and we\nassume the accessibility relations are equivalence relations.\nWe exploit these properties of Ri in the graphical illustrations of Kripke\nmodels for KT45n. For example, a model of KT453 with set of worlds\n{x1, x2, x3, x4, x5, x6} is shown in Figure 5.13. The links between the worlds\nhave to be labelled with the name of the accessibility relation, since we have\nseveral relations. For example, x1 and x2 are related by R1, whereas x4 and\n5.5 Reasoning about knowledge in a multi-agent system\n337\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nin the future. For example, we would say that, although the sentence\nGeorge W. Bush is president of the United States of America.\nis currently true, it will not be true at some point in the future. Equally, the\nsentence\nThere are nine planets in the solar system.\nwhile true, and maybe true for ever in the future, is not necessarily true, in\nthe sense that it could have been a diﬀerent number. However, the sentence\nThe cube root of 27 is 3.\nas well as being true is also necessarily true and true in the future. It does\nnot enjoy all modes of truth, however. It may not be known to be true by\nsome people (children, for example); it may not be believed by others (if\nthey are mistaken).\nIn computer science, it is often useful to reason about modes of truth. In\nChapter 3, we studied the logic CTL in which we could distinguish not only\nbetween truth at diﬀerent points in the future, but also between diﬀerent\nfutures. Temporal logic is thus a special case of modal logic. The modalities\nof CTL allow us to express a host of computational behaviour of systems.\nModalities are also extremely useful in modelling other domains of com-\nputer science. In artiﬁcial intelligence, for example, scenarios with several\n306\n5.2 Basic modal logic\n307\ninteracting agents are developed. Each agent may have diﬀerent knowledge\nabout the environment and also about the knowledge of other agents. In this\nchapter, we will look in depth at modal logics applied to reasoning about\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nKT45, require extra rules if one wants to capture their semantic entailment\nvia proofs. In the case of KT45, this extra strength is expressed by rule\nschemes for the axioms T, 4 and 5:\n2φ\nφ\nT\n2φ\n22φ\n4\n¬2φ\n2¬2φ\n5\nAn equivalent alternative to the rules 4 and 5 would be to stipulate relax-\nations of the rules about moving formulas in and out of dashed boxes. Since\nrule 4 allows us to double-up boxes, we could instead think of it as allowing\nus to move formulas beginning with 2 into dashed boxes. Similarly, axiom\n5 has the eﬀect of allowing us to move formulas beginning with ¬2 into\ndashed boxes. Since 5 is a scheme and since φ and ¬¬φ are equivalent in ba-\nsic modal logic, we could write ¬φ instead of φ throughout without changing\nthe expressive power and meaning of that axiom.\nDeﬁnition 5.20 Let L be a set of formula schemes. We say that Γ ⊢L ψ is\nvalid if ψ has a proof in the natural deduction system for basic modal logic\nextended with the axioms from L and premises from Γ.\nExamples 5.21 We show that the following sequents are valid:\n1.\n|−K 2p ∧2q →2(p ∧q).\n1\n2p ∧2q\nassumption\n2\n2p\n∧e1 1\n3\n2q\n∧e2 1\n4\np\n2e 2\n5\nq\n2e 3\n6\np ∧q\n∧i 4, 5\n7\n2(p ∧q)\n2i 4−6\n8\n2p ∧2q →2(p ∧q)\n→i 1−7\n5.5 Reasoning about knowledge in a multi-agent system\n331\n2.\n|−KT45 p →23p.\n1\np\nassumption\n2\n2¬p\nassumption\n3\n¬p\nT 2\n4\n⊥\n¬e 1, 3\n5\n¬2¬p\n¬i 2−4\n6\n2¬2¬p\naxiom 5 on line 5\n7\np →2¬2¬p\n→i 1−6\n3.\n|−KT45 232p →2p.\n1\n2¬2¬2p\nassumption\n2\n¬2¬2p\n2e 1\n3\n¬2p\nassumption\n4\n2¬2p\naxiom 5 on line 3\n5\n⊥\n¬e 4, 2\n6\n¬¬2p\n¬i 3−5\n7\n2p\n¬¬e 6\n8\np\nT 7\n9\n2p\n2i 2−8\n10\n2¬2¬2p →2p\n→i 1−9\n5.5 Reasoning about knowledge in\na multi-agent system\nIn a multi-agent system, diﬀerent agents have diﬀerent knowledge of the\nworld. An agent may need to reason about its own knowledge about the\nworld; it may also need to reason about what other agents know about\nthe world. For example, in a bargaining situation, the seller of a car must\nconsider what a buyer knows about the car’s value. The buyer must also KT45, require extra rules if one wants to capture their semantic entailment\nvia proofs. In the case of KT45, this extra strength is expressed by rule\nschemes for the axioms T, 4 and 5:\n2φ\nφ\nT\n2φ\n22φ\n4\n¬2φ\n2¬2φ\n5\nAn equivalent alternative to the rules 4 and 5 would be to stipulate relax-\nations of the rules about moving formulas in and out of dashed boxes. Since\nrule 4 allows us to double-up boxes, we could instead think of it as allowing\nus to move formulas beginning with 2 into dashed boxes. Similarly, axiom\n5 has the eﬀect of allowing us to move formulas beginning with ¬2 into\ndashed boxes. Since 5 is a scheme and since φ and ¬¬φ are equivalent in ba-\nsic modal logic, we could write ¬φ instead of φ throughout without changing\nthe expressive power and meaning of that axiom.\nDeﬁnition 5.20 Let L be a set of formula schemes. We say that Γ ⊢L ψ is\nvalid if ψ has a proof in the natural deduction system for basic modal logic\nextended with the axioms from L and premises from Γ.\nExamples 5.21 We show that the following sequents are valid:\n1.\n|−K 2p ∧2q →2(p ∧q).\n1\n2p ∧2q\nassumption\n2\n2p\n∧e1 1\n3\n2q\n∧e2 1\n4\np\n2e 2\n5\nq\n2e 3\n6\np ∧q\n∧i 4, 5\n7\n2(p ∧q)\n2i 4−6\n8\n2p ∧2q →2(p ∧q)\n→i 1−7\n5.5 Reasoning about knowledge in a multi-agent system\n331\n2.\n|−KT45 p →23p.\n1\np\nassumption\n2\n2¬p\nassumption\n3\n¬p\nT 2\n4\n⊥\n¬e 1, 3\n5\n¬2¬p\n¬i 2−4\n6\n2¬2¬p\naxiom 5 on line 5\n7\np →2¬2¬p\n→i 1−6\n3.\n|−KT45 232p →2p.\n1\n2¬2¬2p\nassumption\n2\n¬2¬2p\n2e 1\n3\n¬2p\nassumption\n4\n2¬2p\naxiom 5 on line 3\n5\n⊥\n¬e 4, 2\n6\n¬¬2p\n¬i 3−5\n7\n2p\n¬¬e 6\n8\np\nT 7\n9\n2p\n2i 2−8\n10\n2¬2¬2p →2p\n→i 1−9\n5.5 Reasoning about knowledge in\na multi-agent system\nIn a multi-agent system, diﬀerent agents have diﬀerent knowledge of the\nworld. An agent may need to reason about its own knowledge about the\nworld; it may also need to reason about what other agents know about\nthe world. For example, in a bargaining situation, the seller of a car must\nconsider what a buyer knows about the car’s value. The buyer must also",
                    "summary": "Modal logic adds unary connectives to express one, or more, of these modes of truth. The language of basic modal logic is that of propositional logic with two extra connectives, 2 and 3. The main case study will be the logic of knowledge in a multi-agent system. But first, we look at the syntax and semantics of basicmodal logic.5.2.1 Syntax and Semantics of Basic modal Logic. 5.3.1. The Logic of Knowledge in a Multi-agent System. knowledge. knowledge, necessity, or time. knowledge and necessity. time. time and knowledge and time. Knowledge and time, necessity and knowledge, knowledge, time and necessity, knowledge and The formulas of basic modal logic φ are deﬁned by the Backus Naur form (BNF): p, q, r, p3 . . to denote atomic formulas. Like negation (¬), they are unary connectives                as they apply themselves to a single formula only. The following strings                are not formulas, because they cannot be constructed using the grammar                in (5.1): (p2 →q) and (p →3(q 3 r) Convention 5.2 As done in Chapter 1, we assume that the unary connec-                tives (¹, 2 and 3) bind most closely. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modallogics we study in this text are normal, as they all have the same formula scheme, L. We conclude with a look at the results of our study of the KT45 logic, where L = {T, 4, 5} with T, 4 and 5 from Table 5 The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience. If the agent Q knows something, then she knows                that she knows it. If she doesn’t know something, she knows that she doesn't know it. Even computer agents may not have all of these properties. We will not consider them here. The logic is based on the theory of knowledge. It is not a theory of human knowledge. We are not trying to prove that human knowledge is better than computer knowledge. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 can be re-engineered in various ways to give us the properties appropriate for the intended ap-                plications. We will consider how to re-Engineer basic modal logic to give the following readings of 2: It is necessarily true that φ is an equivalence relation. After any execution of program P, φ holds. If we take the connective 3, which is equivalent to ¬2¬, we can figure out what the corresponding readings of 3 in our system will be. For example, ‘it is not necessarily true that not φ’ means that it is possibly true that φ. The readings for 3 for the other modes are given in Table 5.6.3. The reading ‘agent Q knows φ' for 2φ. is read as ‘ agent Q does not know not’ for 3’s ‘not’ reading is ‘nothing’. For all agent Q knows, φ is consistent with what it knows, so it could be ‘something’ as far as Q is concerned, and this could be the case for all agents Q knows. The stock of valid formulas of basic modal logic is shown. The readings of 3 corresponding to each reading of 2. Theorem 5.17: Any sequence of modal operators and negations in KT45 is equivalent to one of the following: −, 2, 3, ¬, 2 and ¬3, where −indicates the absence of any negation or modality. The modal Logic KT4, that is L equals {T, 4}. It is also called S4 in the literature. It is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. The logic KT4 is also known as KT45 or KT4.  Correspondence theory tells us that its models are precisely the Kripke models M = (W, R, L), where R is reﬂexive and transitive. Such structures are often very useful in computer science. For example, if φ stands for the type of a piece of code – φ could be int × int → bool, indicating some code which expects a pair of integers as input andoutputs a boolean value – then 2φ could stand for residual code of type φ. Such type systems have important applications in the specialisation and partial evaluation of code. The formula scheme 2 φ → 22 φ, the axiom T, then means that code may beexecuted right Theorem 5.18 Any sequence of modal operators and negations in KT4 is equivalent to one of the following: −, 2, 3, 23, 32, 232, 323. We also pointed out that the proof rules PBC, LEM and ¬¬e are questionable in certain com-                tems. We refer the interested reader to the bibliographic notes at the end of the chapter. We give a natural de-duction system for propositional logic which was sound and complete. The natural deduction proof system for modal logic presented in this chapter is based on ideas in [Fit93]. Many examples in the chapter are taken from this literature (some of them are attributed to other people there), though our treatment of them is original. We should stress that our framework was deliberately ‘classical;’ the thesis[Sim94] is a good source for discussions of intuitionistic modal logics. An application of the modal Logic KT4 as a type system for staged computation in a functional pro-                gramming language can be found in [DP96]. The chapter is divided into seven sections: 1. Introduction, 2. Bibliographic notes, 3, 4, 5, The systems discussed in Chapter 3 can be veriﬁed                using the representation. Representing those systems in a computer requires an eﬃcient representation for boolean functions. We look at such a representation in this chapter and describe in detail how it can be used to reason about the systems we discussed in the previous chapter. We write x1, x2, . . . and x, y, z,. . . to denote boolean variables. A boolean variable x is a variable ranging over the values                0 and 1. A function f of n arguments is a function from {0, 1}n to {0,. 1}. We write f(x1, X2,    . .  A formula φ in the multi-modal logic of KT45n is deﬁned by the following grammar. We simply write E, C and D without subscripts if we refer to EA, CA and DA. Instead of 2, we have several modules Ki and we also have EG, CG and DG for each G ⊆A. Actually, all of these connectives will shortly be seen to be ‘box-like’ rather than ‘diamond-like.’ in the sense that they distribute over  rather than over   . We call this ‘Box Theory’ and it is the basis for the rest of this article. Deﬁnition 5.24: A model M = (W, (Ri)i∈A, L) of the multi-modal logic hypert45n with the set A of n agents. The ‘diamond-like’ correspondents of these connectives are not explicitly in the language, but may of course be obtained using negations, i.e. ¬Ki¬, ¬CG¬ etc. We exploit these properties of Ri in the graphical illustrations of KT45n. For example, a model of KT453 with set of worlds is shown in Figure 5.13. The links between the worlds have to be labelled with the name of the accessibility relation In language, we often distinguish between various ‘modes’ of truth. For example, x1 and x2 are related by R1, whereas x4 and                5.5. The cube root of 27 is 3 as well as being true is also necessarily true and true in the future. It does not enjoy all modes of truth, however,    as it could have been a diﬀerent number. We would say that, although the sentence.George W. Bush is president of the United States of America. is currently true, it will not be true at some point in the. future, but it is not necessarily true, in the sense that it could be true for ever. In computer science, it is often useful to reason about modes of truth. Temporal logic is a special case of modal logic. The modalities of CTL allow us to express a host of computational behaviour of systems. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed. Each agent may have diﬀerent knowledge about the environment and also about the knowledge of other agents. In this chapter, we will look in depth at modal logics applied to reasoning about knowledge. We will also look at how these logics can be used to model other domains of com-puter science. We conclude with a discussion of the implications of our findings. More sophisticated modal logics require extra rules if one wants to capture their semantic entailmentvia proofs. In the case of KT45, this extra strength is expressed by ruleschemes for the axioms T, 4 and 5. Let L be a set of formula schemes and let T be a scheme for T, T, and T, with T being the axiom T and T the formula scheme for KT45. For example, we could write ¬φ instead of φ throughout without changing the expressive power and meaning of that axiom. We could also use the scheme L instead of the scheme T and L would be the formula schemes L and L, with L being L, L, and L. We say that a proof in the natural deduction system for basic modal logic is valid if it is extended with the axioms from L and premises from L. We show that the following sequents are valid: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, KT45, require extra rules if one wants to capture their semantic entailmentvia proofs. In the case of KT45, this extra strength is expressed by rule.schemes for the axioms T, 4 and 5. For example, in a bargaining situation, the seller of a car mustconsider what a buyer knows about the car’s value. The buyer must also KT45 to know what the seller knows about that car. For the purposes of this article, we will assume that KT45 is a set of formula schemes and that L is the set of L schemes. We will also use the term ‘symbolic logic’ to refer to this type of logic. We say that a proof in the natural deduction system for basic modal logic is valid if it is extended with the axioms from L and premises from L. We show that the following sequents are valid: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, In a bargaining situation, the seller of a car mustconsider what a buyer knows about the car’s",
                    "children": [
                        {
                            "id": "chapter-5-section-5-subsection-1",
                            "title": "Some Examples",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-5-section-5-subsection-2",
                            "title": "The Modal Logic KT45n",
                            "content": "knowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nhave connectives for expressing several modes of truth in the same logic; we\nwill see some of these towards the end of this chapter.\nWe take a logic engineering approach in this chapter, in which we address\nthe following question: given a particular mode of truth, how may we develop\na logic capable of expressing and formalising that concept? To answer this\nquestion, we need to decide what properties the logic should have and what\nexamples of reasoning it should be able to express. Our main case study will\nbe the logic of knowledge in a multi-agent system. But ﬁrst, we look at the\nsyntax and semantics of basic modal logic.\n5.2 Basic modal logic\n5.2.1 Syntax\nThe language of basic modal logic is that of propositional logic with two\nextra connectives, 2 and 3. Like negation (¬), they are unary connectives\nas they apply themselves to a single formula only. As done in Chapters 1\nand 3, we write p, q, r, p3 . . . to denote atomic formulas.\nDeﬁnition 5.1 The formulas of basic modal logic φ are deﬁned by the\nfollowing Backus Naur form (BNF):\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) | (2φ) | (3φ)\n(5.1)\nwhere p is any atomic formula.\nExample formulas of basic modal logic are (p ∧3(p →2¬r)) and 2((3q ∧\n¬r) →2p), having the parse trees shown in Figure 5.1. The following strings\nare not formulas, because they cannot be constructed using the grammar\nin (5.1): (p2 →q) and (p →3(q 3 r)).\nConvention 5.2 As done in Chapter 1, we assume that the unary connec-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nerwise, Γ ⊨L ψ holds for all Γ and ψ! In most applications of logic engineering,\nconsistency is easy to establish.\nWe now study a few important modal logics that extend basic modal logic\nwith a consistent set of formula schemes L.\nThe modal logic K\nThe weakest modal logic doesn’t have any chosen\nformula schemes, like those of Tables 5.7 and 5.12. So L = ∅and this modal\nlogic is called K as it satisﬁes all instances of the formula scheme K; modal\nlogics with this property are called normal and all modal logics we study in\nthis text are normal.\nThe modal logic KT45\nA well-known modal logic is KT45 – also called\nS5 in the technical literature – where L = {T, 4, 5} with T, 4 and 5 from\nTable 5.12. This logic is used to reason about knowledge; 2φ means that\nthe agent Q knows φ. Table 5.12 tell us, respectively, that\nT. Truth: the agent Q knows only true things.\n4. Positive introspection: if the agent Q knows something, then she knows\nthat she knows it.\n5. Negative introspection: if the agent Q doesn’t know something, then\nshe knows that she doesn’t know it.\n5.3 Logic engineering\n327\nIn this application, the formula scheme K means logical omniscience: the\nagent’s knowledge is closed under logical consequence. Note that these prop-\nerties represent idealisations of knowledge. Human knowledge has none of\nthese properties! Even computer agents may not have them all. There are\nseveral attempts in the literature to deﬁne logics of knowledge that are more\nrealistic, but we will not consider them here.\nThe semantics of the logic KT45 must consider only relations R which\nare: reﬂexive (T), transitive (4) and Euclidean (5).\nFact 5.16 A relation is reﬂexive, transitive and Euclidean iﬀit is reﬂexive,\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nin various ways to give us the properties appropriate for the intended ap-\nplications. Logic engineering is the subject of engineering logics to ﬁt new\napplications. It is potentially a very broad subject, drawing on all branches\nof logic, computer science and mathematics. In this chapter, however, we\nare restricting ourselves to the particular engineering of modal logics.\nWe will consider how to re-engineer basic modal logic to ﬁt the following\nreadings of 2φ:\nr It is necessarily true that φ\nr It will always be true that φ\nr It ought to be that φ\nr Agent Q believes that φ\nr Agent Q knows that φ\nr After any execution of program P, φ holds.\nAs modal logic automatically gives us the connective 3, which is equivalent\nto ¬2¬, we can ﬁnd out what the corresponding readings of 3 in our system\nwill be. For example, ‘it is not necessarily true that not φ’ means that it is\npossibly true that φ. You could work this out in steps:\nIt is not necessarily true that φ\n= it is possible that not φ.\nTherefore,\nIt is not necessarily true that not φ\n= it is possible that not not φ\n= it is possible that φ.\nLet us work this out with the reading ‘agent Q knows φ’ for 2φ. Then, 3φ\nis read as\nagent Q does not know not φ\n= as far as Q’s knowledge is concerned, φ could be the case\n= φ is consistent with what agent Q knows\n= for all agent Q knows, φ.\nThe readings for 3 for the other modes are given in Table 5.6.\n5.3 Logic engineering\n317\nTable 5.6. The readings of 3 corresponding to each reading of 2.\n2φ\n3φ\nIt is necessarily true that φ\nIt is possibly true that φ\nIt will always be true that φ\nSometime in the future φ\nIt ought to be that φ\nIt is permitted to be that φ\nAgent Q believes that φ\nφ is consistent with Q’s beliefs\nAgent Q knows that φ\nFor all Q knows, φ\nAfter any execution of program P, φ holds\nAfter some execution of P, φ holds\n5.3.1 The stock of valid formulas\nWe saw in the last section some valid formulas of basic modal logic, such\ntransitive and symmetric, i.e. if it is an equivalence relation.\nKT45 is simpler than K in the sense that it has few essentially diﬀerent ways\nof composing modalities.\nTheorem 5.17 Any sequence of modal operators and negations in KT45\nis equivalent to one of the following: −, 2, 3, ¬, ¬2 and ¬3, where −\nindicates the absence of any negation or modality.\nThe modal logic KT4\nThe modal logic KT4, that is L equals {T, 4},\nis also called S4 in the literature. Correspondence theory tells us that its\nmodels are precisely the Kripke models M = (W, R, L), where R is reﬂexive\nand transitive. Such structures are often very useful in computer science. For\nexample, if φ stands for the type of a piece of code – φ could be int × int →\nbool, indicating some code which expects a pair of integers as input and\noutputs a boolean value – then 2φ could stand for residual code of type φ.\nThus, in the current world x this code would not have to be executed, but\ncould be saved (= residualised) for execution at a later computation stage.\nThe formula scheme 2φ →φ, the axiom T, then means that code may be\nexecuted right away, whereas the formula scheme 2φ →22φ, the axiom 4,\nallows that residual code remain residual, i.e. we can repeatedly postpone its\nexecution in future computation stages. Such type systems have important\napplications in the specialisation and partial evaluation of code. We refer\nthe interested reader to the bibliographic notes at the end of the chapter.\nTheorem 5.18 Any sequence of modal operators and negations in KT4 is\nequivalent to one of the following: −, 2, 3, 23, 32, 232, 323, ¬, ¬2,\n¬3, ¬23, ¬32, ¬232 and ¬323.\nIntuitionistic propositional logic\nIn Chapter 1, we gave a natural de-\nduction system for propositional logic which was sound and complete with\n328\n5 Modal logics and agents\nrespect to semantic entailment based on truth tables. We also pointed out\nthat the proof rules PBC, LEM and ¬¬e are questionable in certain com-\ntems has been done in [FHMV95] and [MvdH95] and other work by those\nauthors. Many examples in this chapter are taken from this literature (some\nof them are attributed to other people there), though our treatment of them\nis original.\nThe natural deduction proof system for modal logic presented in this\nchapter is based on ideas in [Fit93].\n2 www.cis.ksu.edu/~allen/porgi.html\n5.7 Bibliographic notes\n357\nAn application of the modal logic KT4 (more precisely, its fragment with-\nout negation) as a type system for staged computation in a functional pro-\ngramming language can be found in [DP96].\nWe should stress that our framework was deliberately ‘classical;’ the thesis\n[Sim94] is a good source for discussions of intuitionistic modal logics; it also\ncontains a gentle introduction to basic ﬁrst-order modal logic.\n6\nBinary decision diagrams\n6.1 Representing boolean functions\nBoolean functions are an important descriptive formalism for many hard-\nware and software systems, such as synchronous and asynchronous circuits,\nreactive systems and ﬁnite-state programs. Representing those systems in a\ncomputer in order to reason about them requires an eﬃcient representation\nfor boolean functions. We look at such a representation in this chapter and\ndescribe in detail how the systems discussed in Chapter 3 can be veriﬁed\nusing the representation.\nDeﬁnition 6.1 A boolean variable x is a variable ranging over the values\n0 and 1. We write x1, x2, . . . and x, y, z, . . . to denote boolean variables. We\ndeﬁne the following functions on the set {0, 1}:\nr 0\ndef\n= 1 and 1\ndef\n= 0;\nr x · y\ndef\n= 1 if x and y have value 1; otherwise x · y\ndef\n= 0;\nr x + y\ndef\n= 0 if x and y have value 0; otherwise x + y\ndef\n= 1;\nr x ⊕y\ndef\n= 1 if exactly one of x and y equals 1.\nA boolean function f of n arguments is a function from {0, 1}n to {0, 1}.\nWe write f(x1, x2, . . . , xn), or f(V ), to indicate that a syntactic representa-\ntion of f depends on the boolean variables in V only.\ndistributed among them.\nDeﬁnition 5.23 A formula φ in the multi-modal logic of KT45n is deﬁned\nby the following grammar:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) |\n(Ki φ) | (EG φ) | (CG φ) | (DG φ)\n336\n5 Modal logics and agents\nq\nq\np, q\nx1\nx2\nx4\nx5\np\nx6\np\nx3\nR1\nR1, R2\nR1, R3\nR1, R2\nR3\nFigure 5.13. A KT45n model for n = 3.\nwhere p is any atomic formula, i ∈A and G ⊆A. We simply write E, C and\nD without subscripts if we refer to EA, CA and DA.\nCompare this deﬁnition with Deﬁnition 5.1. Instead of 2, we have several\nmodalities Ki and we also have EG, CG and DG for each G ⊆A. Actually,\nall of these connectives will shortly be seen to be ‘box-like’ rather than\n‘diamond-like’, in the sense that they distribute over ∧rather than over ∨–\ncompare this to the discussion of equivalences on page 308. The ‘diamond-\nlike’ correspondents of these connectives are not explicitly in the language,\nbut may of course be obtained using negations, i.e. ¬Ki¬, ¬CG¬ etc.\nDeﬁnition 5.24 A model M = (W, (Ri)i∈A, L) of the multi-modal logic\nKT45n with the set A of n agents is speciﬁed by three things:\n1.\na set W of possible worlds;\n2.\nfor each i ∈A, an equivalence relation Ri on W (Ri ⊆W × W), called the\naccessibility relations; and\n3.\na labelling function L : W →P(Atoms).\nCompare this with Deﬁnition 5.3. The diﬀerence is that, instead of just one\naccessibility relation, we now have a family, one for each agent in A; and we\nassume the accessibility relations are equivalence relations.\nWe exploit these properties of Ri in the graphical illustrations of Kripke\nmodels for KT45n. For example, a model of KT453 with set of worlds\n{x1, x2, x3, x4, x5, x6} is shown in Figure 5.13. The links between the worlds\nhave to be labelled with the name of the accessibility relation, since we have\nseveral relations. For example, x1 and x2 are related by R1, whereas x4 and\n5.5 Reasoning about knowledge in a multi-agent system\n337\npossibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nin the future. For example, we would say that, although the sentence\nGeorge W. Bush is president of the United States of America.\nis currently true, it will not be true at some point in the future. Equally, the\nsentence\nThere are nine planets in the solar system.\nwhile true, and maybe true for ever in the future, is not necessarily true, in\nthe sense that it could have been a diﬀerent number. However, the sentence\nThe cube root of 27 is 3.\nas well as being true is also necessarily true and true in the future. It does\nnot enjoy all modes of truth, however. It may not be known to be true by\nsome people (children, for example); it may not be believed by others (if\nthey are mistaken).\nIn computer science, it is often useful to reason about modes of truth. In\nChapter 3, we studied the logic CTL in which we could distinguish not only\nbetween truth at diﬀerent points in the future, but also between diﬀerent\nfutures. Temporal logic is thus a special case of modal logic. The modalities\nof CTL allow us to express a host of computational behaviour of systems.\nModalities are also extremely useful in modelling other domains of com-\nputer science. In artiﬁcial intelligence, for example, scenarios with several\n306\n5.2 Basic modal logic\n307\ninteracting agents are developed. Each agent may have diﬀerent knowledge\nabout the environment and also about the knowledge of other agents. In this\nchapter, we will look in depth at modal logics applied to reasoning about\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nKT45, require extra rules if one wants to capture their semantic entailment\nvia proofs. In the case of KT45, this extra strength is expressed by rule\nschemes for the axioms T, 4 and 5:\n2φ\nφ\nT\n2φ\n22φ\n4\n¬2φ\n2¬2φ\n5\nAn equivalent alternative to the rules 4 and 5 would be to stipulate relax-\nations of the rules about moving formulas in and out of dashed boxes. Since\nrule 4 allows us to double-up boxes, we could instead think of it as allowing\nus to move formulas beginning with 2 into dashed boxes. Similarly, axiom\n5 has the eﬀect of allowing us to move formulas beginning with ¬2 into\ndashed boxes. Since 5 is a scheme and since φ and ¬¬φ are equivalent in ba-\nsic modal logic, we could write ¬φ instead of φ throughout without changing\nthe expressive power and meaning of that axiom.\nDeﬁnition 5.20 Let L be a set of formula schemes. We say that Γ ⊢L ψ is\nvalid if ψ has a proof in the natural deduction system for basic modal logic\nextended with the axioms from L and premises from Γ.\nExamples 5.21 We show that the following sequents are valid:\n1.\n|−K 2p ∧2q →2(p ∧q).\n1\n2p ∧2q\nassumption\n2\n2p\n∧e1 1\n3\n2q\n∧e2 1\n4\np\n2e 2\n5\nq\n2e 3\n6\np ∧q\n∧i 4, 5\n7\n2(p ∧q)\n2i 4−6\n8\n2p ∧2q →2(p ∧q)\n→i 1−7\n5.5 Reasoning about knowledge in a multi-agent system\n331\n2.\n|−KT45 p →23p.\n1\np\nassumption\n2\n2¬p\nassumption\n3\n¬p\nT 2\n4\n⊥\n¬e 1, 3\n5\n¬2¬p\n¬i 2−4\n6\n2¬2¬p\naxiom 5 on line 5\n7\np →2¬2¬p\n→i 1−6\n3.\n|−KT45 232p →2p.\n1\n2¬2¬2p\nassumption\n2\n¬2¬2p\n2e 1\n3\n¬2p\nassumption\n4\n2¬2p\naxiom 5 on line 3\n5\n⊥\n¬e 4, 2\n6\n¬¬2p\n¬i 3−5\n7\n2p\n¬¬e 6\n8\np\nT 7\n9\n2p\n2i 2−8\n10\n2¬2¬2p →2p\n→i 1−9\n5.5 Reasoning about knowledge in\na multi-agent system\nIn a multi-agent system, diﬀerent agents have diﬀerent knowledge of the\nworld. An agent may need to reason about its own knowledge about the\nworld; it may also need to reason about what other agents know about\nthe world. For example, in a bargaining situation, the seller of a car must\nconsider what a buyer knows about the car’s value. The buyer must also",
                            "summary": "Modal logic adds unary connectives to express one, or more, of these modes of truth. The language of basic modal logic is that of propositional logic with two extra connectives, 2 and 3. The main case study will be the logic of knowledge in a multi-agent system. But first, we look at the syntax and semantics of basicmodal logic.5.2.1 Syntax and Semantics of Basic modal Logic. 5.3.1. The Logic of Knowledge in a Multi-agent System. knowledge. knowledge, necessity, or time. knowledge and necessity. time. time and knowledge and time. Knowledge and time, necessity and knowledge, knowledge, time and necessity, knowledge and The formulas of basic modal logic φ are deﬁned by the Backus Naur form (BNF): p, q, r, p3 . . to denote atomic formulas. Like negation (¬), they are unary connectives                as they apply themselves to a single formula only. The following strings                are not formulas, because they cannot be constructed using the grammar                in (5.1): (p2 →q) and (p →3(q 3 r) Convention 5.2 As done in Chapter 1, we assume that the unary connec-                tives (¹, 2 and 3) bind most closely. In most applications of logic engineering, consistency is easy to establish. We now study a few important modal logics that extend basic modal logic with a consistent set of formula schemes L. The weakestmodal logic doesn’t have any chosenformula schemes, like those of Tables 5.7 and 5.12. This logic is called K as it satisﬁes all instances of the formula scheme K. All modallogics we study in this text are normal, as they all have the same formula scheme, L. We conclude with a look at the results of our study of the KT45 logic, where L = {T, 4, 5} with T, 4 and 5 from Table 5 The semantics of the logic KT45 must consider only relations R which are reﬂexive (T), transitive (4) and Euclidean (5) The formula scheme K means logical omniscience. If the agent Q knows something, then she knows                that she knows it. If she doesn’t know something, she knows that she doesn't know it. Even computer agents may not have all of these properties. We will not consider them here. The logic is based on the theory of knowledge. It is not a theory of human knowledge. We are not trying to prove that human knowledge is better than computer knowledge. KT45 is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. Any sequence of modal operators and negations in KT45 can be re-engineered in various ways to give us the properties appropriate for the intended ap-                plications. We will consider how to re-Engineer basic modal logic to give the following readings of 2: It is necessarily true that φ is an equivalence relation. After any execution of program P, φ holds. If we take the connective 3, which is equivalent to ¬2¬, we can figure out what the corresponding readings of 3 in our system will be. For example, ‘it is not necessarily true that not φ’ means that it is possibly true that φ. The readings for 3 for the other modes are given in Table 5.6.3. The reading ‘agent Q knows φ' for 2φ. is read as ‘ agent Q does not know not’ for 3’s ‘not’ reading is ‘nothing’. For all agent Q knows, φ is consistent with what it knows, so it could be ‘something’ as far as Q is concerned, and this could be the case for all agents Q knows. The stock of valid formulas of basic modal logic is shown. The readings of 3 corresponding to each reading of 2. Theorem 5.17: Any sequence of modal operators and negations in KT45 is equivalent to one of the following: −, 2, 3, ¬, 2 and ¬3, where −indicates the absence of any negation or modality. The modal Logic KT4, that is L equals {T, 4}. It is also called S4 in the literature. It is simpler than K in the sense that it has few essentially diﬀerent ways of composing modalities. The logic KT4 is also known as KT45 or KT4.  Correspondence theory tells us that its models are precisely the Kripke models M = (W, R, L), where R is reﬂexive and transitive. Such structures are often very useful in computer science. For example, if φ stands for the type of a piece of code – φ could be int × int → bool, indicating some code which expects a pair of integers as input andoutputs a boolean value – then 2φ could stand for residual code of type φ. Such type systems have important applications in the specialisation and partial evaluation of code. The formula scheme 2 φ → 22 φ, the axiom T, then means that code may beexecuted right Theorem 5.18 Any sequence of modal operators and negations in KT4 is equivalent to one of the following: −, 2, 3, 23, 32, 232, 323. We also pointed out that the proof rules PBC, LEM and ¬¬e are questionable in certain com-                tems. We refer the interested reader to the bibliographic notes at the end of the chapter. We give a natural de-duction system for propositional logic which was sound and complete. The natural deduction proof system for modal logic presented in this chapter is based on ideas in [Fit93]. Many examples in the chapter are taken from this literature (some of them are attributed to other people there), though our treatment of them is original. We should stress that our framework was deliberately ‘classical;’ the thesis[Sim94] is a good source for discussions of intuitionistic modal logics. An application of the modal Logic KT4 as a type system for staged computation in a functional pro-                gramming language can be found in [DP96]. The chapter is divided into seven sections: 1. Introduction, 2. Bibliographic notes, 3, 4, 5, The systems discussed in Chapter 3 can be veriﬁed                using the representation. Representing those systems in a computer requires an eﬃcient representation for boolean functions. We look at such a representation in this chapter and describe in detail how it can be used to reason about the systems we discussed in the previous chapter. We write x1, x2, . . . and x, y, z,. . . to denote boolean variables. A boolean variable x is a variable ranging over the values                0 and 1. A function f of n arguments is a function from {0, 1}n to {0,. 1}. We write f(x1, X2,    . .  A formula φ in the multi-modal logic of KT45n is deﬁned by the following grammar. We simply write E, C and D without subscripts if we refer to EA, CA and DA. Instead of 2, we have several modules Ki and we also have EG, CG and DG for each G ⊆A. Actually, all of these connectives will shortly be seen to be ‘box-like’ rather than ‘diamond-like.’ in the sense that they distribute over  rather than over   . We call this ‘Box Theory’ and it is the basis for the rest of this article. Deﬁnition 5.24: A model M = (W, (Ri)i∈A, L) of the multi-modal logic hypert45n with the set A of n agents. The ‘diamond-like’ correspondents of these connectives are not explicitly in the language, but may of course be obtained using negations, i.e. ¬Ki¬, ¬CG¬ etc. We exploit these properties of Ri in the graphical illustrations of KT45n. For example, a model of KT453 with set of worlds is shown in Figure 5.13. The links between the worlds have to be labelled with the name of the accessibility relation In language, we often distinguish between various ‘modes’ of truth. For example, x1 and x2 are related by R1, whereas x4 and                5.5. The cube root of 27 is 3 as well as being true is also necessarily true and true in the future. It does not enjoy all modes of truth, however,    as it could have been a diﬀerent number. We would say that, although the sentence.George W. Bush is president of the United States of America. is currently true, it will not be true at some point in the. future, but it is not necessarily true, in the sense that it could be true for ever. In computer science, it is often useful to reason about modes of truth. Temporal logic is a special case of modal logic. The modalities of CTL allow us to express a host of computational behaviour of systems. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed. Each agent may have diﬀerent knowledge about the environment and also about the knowledge of other agents. In this chapter, we will look in depth at modal logics applied to reasoning about knowledge. We will also look at how these logics can be used to model other domains of com-puter science. We conclude with a discussion of the implications of our findings. More sophisticated modal logics require extra rules if one wants to capture their semantic entailmentvia proofs. In the case of KT45, this extra strength is expressed by ruleschemes for the axioms T, 4 and 5. Let L be a set of formula schemes and let T be a scheme for T, T, and T, with T being the axiom T and T the formula scheme for KT45. For example, we could write ¬φ instead of φ throughout without changing the expressive power and meaning of that axiom. We could also use the scheme L instead of the scheme T and L would be the formula schemes L and L, with L being L, L, and L. We say that a proof in the natural deduction system for basic modal logic is valid if it is extended with the axioms from L and premises from L. We show that the following sequents are valid: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, In a bargaining situation, the seller of a car mustconsider what a buyer knows about the car’s",
                            "children": []
                        },
                        {
                            "id": "chapter-5-section-5-subsection-3",
                            "title": "Natural Deduction for KT45n",
                            "content": "KT45, require extra rules if one wants to capture their semantic entailment\nvia proofs. In the case of KT45, this extra strength is expressed by rule\nschemes for the axioms T, 4 and 5:\n2φ\nφ\nT\n2φ\n22φ\n4\n¬2φ\n2¬2φ\n5\nAn equivalent alternative to the rules 4 and 5 would be to stipulate relax-\nations of the rules about moving formulas in and out of dashed boxes. Since\nrule 4 allows us to double-up boxes, we could instead think of it as allowing\nus to move formulas beginning with 2 into dashed boxes. Similarly, axiom\n5 has the eﬀect of allowing us to move formulas beginning with ¬2 into\ndashed boxes. Since 5 is a scheme and since φ and ¬¬φ are equivalent in ba-\nsic modal logic, we could write ¬φ instead of φ throughout without changing\nthe expressive power and meaning of that axiom.\nDeﬁnition 5.20 Let L be a set of formula schemes. We say that Γ ⊢L ψ is\nvalid if ψ has a proof in the natural deduction system for basic modal logic\nextended with the axioms from L and premises from Γ.\nExamples 5.21 We show that the following sequents are valid:\n1.\n|−K 2p ∧2q →2(p ∧q).\n1\n2p ∧2q\nassumption\n2\n2p\n∧e1 1\n3\n2q\n∧e2 1\n4\np\n2e 2\n5\nq\n2e 3\n6\np ∧q\n∧i 4, 5\n7\n2(p ∧q)\n2i 4−6\n8\n2p ∧2q →2(p ∧q)\n→i 1−7\n5.5 Reasoning about knowledge in a multi-agent system\n331\n2.\n|−KT45 p →23p.\n1\np\nassumption\n2\n2¬p\nassumption\n3\n¬p\nT 2\n4\n⊥\n¬e 1, 3\n5\n¬2¬p\n¬i 2−4\n6\n2¬2¬p\naxiom 5 on line 5\n7\np →2¬2¬p\n→i 1−6\n3.\n|−KT45 232p →2p.\n1\n2¬2¬2p\nassumption\n2\n¬2¬2p\n2e 1\n3\n¬2p\nassumption\n4\n2¬2p\naxiom 5 on line 3\n5\n⊥\n¬e 4, 2\n6\n¬¬2p\n¬i 3−5\n7\n2p\n¬¬e 6\n8\np\nT 7\n9\n2p\n2i 2−8\n10\n2¬2¬2p →2p\n→i 1−9\n5.5 Reasoning about knowledge in\na multi-agent system\nIn a multi-agent system, diﬀerent agents have diﬀerent knowledge of the\nworld. An agent may need to reason about its own knowledge about the\nworld; it may also need to reason about what other agents know about\nthe world. For example, in a bargaining situation, the seller of a car must\nconsider what a buyer knows about the car’s value. The buyer must also",
                            "summary": " KT45, require extra rules if one wants to capture their semantic entailmentvia proofs. This extra strength is expressed by rule.schemes for the axioms T, 4 and 5. An equivalent alternative to the rules 4 and. 5 would be to stipulate relax-ishlyations of the rules about moving. formulas in and out of dashed boxes.20 Let L be a set of formula schemes and let L be the set of KT45 schemes. We will use L as the basis for the next section of this article. For example, we can use L to prove that KT45 is not a formula scheme. We can also use the L-scheme to show that the KT45 rules are not a scheme. We say that a proof in the natural deduction system for basic modal logic is valid if it is extended with the axioms from L and premises from L. We show that the following sequents are valid: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, In a bargaining situation, the seller of a car mustconsider what a buyer knows about the car’s",
                            "children": []
                        },
                        {
                            "id": "chapter-5-section-5-subsection-4",
                            "title": "Formalising the Examples",
                            "content": "",
                            "summary": null,
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-6",
            "title": "Binary Decision Diagrams",
            "content": "reality (they are true), or they don’t (they are false).\nIf we combine declarative sentences p and q with a logical connective, say\n∧, then the truth value of p ∧q is determined by three things: the truth value\nof p, the truth value of q and the meaning of ∧. The meaning of ∧is captured\nby the observation that p ∧q is true iﬀp and q are both true; otherwise p ∧q\nis false. Thus, as far as ∧is concerned, it needs only to know whether p and\nq are true, it does not need to know what p and q are actually saying about\nthe world out there. This is also the case for all the other logical connectives\nand is the reason why we can compute the truth value of a formula just by\nknowing the truth values of the atomic propositions occurring in it.\nDeﬁnition 1.28 1.\nThe set of truth values contains two elements T and F, where\nT represents ‘true’ and F represents ‘false’.\n2.\nA valuation or model of a formula φ is an assignment of each propositional atom\nin φ to a truth value.\nExample 1.29 The map which assigns T to q and F to p is a valuation for\np ∨¬q. Please list the remaining three valuations for this formula.\nWe can think of the meaning of ∧as a function of two arguments; each\nargument is a truth value and the result is again such a truth value. We\nspecify this function in a table, called the truth table for conjunction, which\nyou can see in Figure 1.5. In the ﬁrst column, labelled φ, we list all possible\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nFigure 1.5. The truth table for conjunction, the logical connective ∧.\n38\n1 Propositional logic\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nφ\nψ\nφ ∨ψ\nT\nT\nT\nT\nF\nT\nF\nT\nT\nF\nF\nF\nφ\nψ\nφ →ψ\nT\nT\nT\nT\nF\nF\nF\nT\nT\nF\nF\nT\nφ\n¬φ\nT\nF\nF\nT\n⊤\nT\n⊥\nF\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nmeans F, so the disjunction of F and F is still F. We have to take that result,\nF, and compute its conjunction with the meaning of p which is T. Since the\nconjunction of T and F is F, we get F as the meaning of the right subtree\nof →. Finally, to evaluate the meaning of φ, we compute F →F which is T.\nFigure 1.7 shows how the truth values propagate upwards to reach the root\nwhose associated truth value is the truth value of φ given the meanings of\np, q and r above.\nIt should now be quite clear how to build a truth table for more com-\nplex formulas. Figure 1.8 contains a truth table for the formula (p →¬q) →\n(q ∨¬p). To be more precise, the ﬁrst two columns list all possible combina-\ntions of values for p and q. The next two columns compute the corresponding\nvalues for ¬p and ¬q. Using these four columns, we may compute the column\nfor p →¬q and q ∨¬p. To do so we think of the ﬁrst and fourth columns\nas the data for the →truth table and compute the column of p →¬q ac-\ncordingly. For example, in the ﬁrst line p is T and ¬q is F so the entry for\np →¬q is T →F = F by deﬁnition of the meaning of →. In this fashion, we\ncan ﬁll out the rest of the ﬁfth column. Column 6 works similarly, only we\nnow need to look up the truth table for ∨with columns 2 and 3 as input.\n40\n1 Propositional logic\np\nq\np\nr\nT\nT\nF\nT\nF\nF\nF\nF\n¬\nF\n∧\n∨\nq\nT\nF\n∧\n¬\n→\nFigure 1.7. The evaluation of a logical formula under a given valuation.\np\nq\n¬p\n¬q\np →¬q\nq ∨¬p\n(p →¬q) →(q ∨¬p)\nT\nT\nF\nF\nF\nT\nT\nT\nF\nF\nT\nT\nF\nF\nF\nT\nT\nF\nT\nT\nT\nF\nF\nT\nT\nT\nT\nT\nFigure 1.8. An example of a truth table for a more complex logical formula.\nFinally, column 7 results from applying the truth table of →to columns 5\nand 6.\n1.4.2 Mathematical induction\nHere is a little anecdote about the German mathematician Gauss who, as a\npupil at age 8, did not pay attention in class (can you imagine?), with the\nresult that his teacher made him sum up all natural numbers from 1 to 100.\nThe story has it that Gauss came up with the correct answer 5050 within\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nGiven a formula φ which contains the propositional atoms p1, p2, . . . , pn,\nwe can construct a truth table for φ, at least in principle. The caveat is that\nthis truth table has 2n many lines, each line listing a possible combination\nof truth values for p1, p2, . . . , pn; and for large n this task is impossible to\ncomplete. Our aim is thus to compute the value of φ for each of these 2n\ncases for moderately small values of n. Let us consider the example φ in\nFigure 1.3. It involves three propositional atoms (n = 3) so we have 23 = 8\ncases to consider.\nWe illustrate how things go for one particular case, namely for the val-\nuation in which q evaluates to F; and p and r evaluate to T. What does\n¬p ∧q →p ∧(q ∨¬r) evaluate to? Well, the beauty of our semantics is that\nit is compositional. If we know the meaning of the subformulas ¬p ∧q and\np ∧(q ∨¬r), then we just have to look up the appropriate line of the →\ntruth table to ﬁnd the value of φ, for φ is an implication of these two sub-\nformulas. Therefore, we can do the calculation by traversing the parse tree\nof φ in a bottom-up fashion. We know what its leaves evaluate to since we\nstated what the atoms p, q and r evaluated to. Because the meaning of p is\nT, we see that ¬p computes to F. Now q is assumed to represent F and the\nconjunction of F and F is F. Thus, the left subtree of the node →evaluates\nto F. As for the right subtree of →, r stands for T so ¬r computes to F and q\nmeans F, so the disjunction of F and F is still F. We have to take that result,\nF, and compute its conjunction with the meaning of p which is T. Since the\nconjunction of T and F is F, we get F as the meaning of the right subtree\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nvalues in the ﬁrst two columns really exhaust all those possibilities (TT, TF,\nFT and FF). In the third column, we list the result of φ ∧ψ according to the\ntruth values of φ and ψ. So in the ﬁrst line, where φ and ψ have value T,\nthe result is T again. In all other lines, the result is F since at least one of\nthe propositions φ or ψ has value F.\nIn Figure 1.6 you ﬁnd the truth tables for all logical connectives of propo-\nsitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the\nmirror image of conjunction if we swap T and F, namely, a disjunction re-\nturns F iﬀboth arguments are equal to F, otherwise (= at least one of the\narguments equals T) it returns T. The behaviour of implication is not quite\nas intuitive. Think of the meaning of →as checking whether truth is being\npreserved. Clearly, this is not the case when we have T →F, since we infer\nsomething that is false from something that is true. So the second entry\nin the column φ →ψ equals F. On the other hand, T →T obviously pre-\nserves truth, but so do the cases F →T and F →F, because there is no truth\nto be preserved in the ﬁrst place as the assumption of the implication is\nfalse.\nIf you feel slightly uncomfortable with the semantics (= the meaning)\nof →, then it might be good to think of φ →ψ as an abbreviation of the\nformula ¬φ ∨ψ as far as meaning is concerned; these two formulas are very\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nwriting down a full truth table for φ. For example, take the truth table\nof (p →¬q) →(q ∨¬p) in Figure 1.8 (page 40). For each line where (p →\n¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. Since\nthere is only one such line, we have only one conjunct ψ1. That conjunct\nis now obtained by a disjunction of literals, where we include literals ¬p\nand q. Note that the literals are just the syntactic opposites of the truth\nvalues in that line: here p is T and q is F. The resulting formula in CNF\nis thus ¬p ∨q which is readily seen to be in CNF and to be equivalent to\n(p →¬q) →(q ∨¬p).\nWhy does this always work for any formula φ? Well, the constructed\nformula will be false iﬀat least one of its conjuncts ψi will be false. This\nmeans that all the disjuncts in such a ψi must be F. Using the de Morgan\n58\n1 Propositional logic\nrule ¬φ1 ∨¬φ2 ∨· · · ∨¬φn ≡¬(φ1 ∧φ2 ∧· · · ∧φn), we infer that the con-\njunction of the syntactic opposites of those literals must be true. Thus, φ\nand the constructed formula have the same truth table.\nConsider another example, in which φ is given by the truth table:\np\nq\nr\nφ\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nT\nT\nF\nF\nT\nF\nT\nT\nF\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nNote that this table is really just a speciﬁcation of φ; it does not tell us what\nφ looks like syntactically, but it does tells us how it ought to ‘behave.’ Since\nthis truth table has four entries which compute F, we construct four con-\njuncts ψi (1 ≤i ≤4). We read the ψi oﬀthat table by listing the disjunction\nof all atoms, where we negate those atoms which are true in those lines:\nψ1\ndef\n= ¬p ∨¬q ∨r (line 2)\nψ2\ndef\n= p ∨¬q ∨¬r (line 5)\nψ3\ndef\n= p ∨¬q ∨r\netc\nψ4\ndef\n= p ∨q ∨¬r.\nThe resulting φ in CNF is therefore\n(¬p ∨¬q ∨r) ∧(p ∨¬q ∨¬r) ∧(p ∨¬q ∨r) ∧(p ∨q ∨¬r).\nIf we don’t have a full truth table at our disposal, but do know the structure\nof φ, then we would like to compute a version of φ in CNF. It should be\nclear by now that a full truth table of φ and an equivalent formula in\nwell-formed:\n(a) p ∧¬(p ∨¬q) →(r →s)\n(b) p ∧¬(p ∨q ∧s) →(r →s)\n(c) p ∧¬(p ∨∧s) →(r →s).\nAmong the ill-formed formulas above which ones, and in how many ways, could\nyou ‘ﬁx’ by the insertion of brackets only?\nExercises 1.4\n1.\n*\nConstruct the truth table for ¬p ∨q and verify that it coincides with the one for\np →q. (By ‘coincide’ we mean that the respective columns of T and F values are\nthe same.)\n2. Compute the complete truth table of the formula\n(a)\n*\n((p →q) →p) →p\n(b) represented by the parse tree in Figure 1.3 on page 34\n1.7 Exercises\n83\n¬\n→\n¬\nr\n∨\np\n∧\nq\n¬\np\nFigure 1.22. A parse tree of a negated implication.\n84\n1 Propositional logic\n¬\n→\n¬\n∧\n→\nq\np\n∨\nq\nr\np\nFigure 1.23. Another parse tree of a negated implication.\n(c)\n*\np ∨(¬(q ∧(r →q)))\n(d) (p ∧q) →(p ∨q)\n(e) ((p →¬q) →¬p) →q\n(f) (p →q) ∨(p →¬q)\n(g) ((p →q) →p) →p\n(h) ((p ∨q) →r) →((p →r) ∨(q →r))\n(i) (p →q) →(¬p →¬q).\n3. Given a valuation and a parsetree of a formula, compute the truth value of the\nformula for that valuation (as done in a bottom-up fashion in Figure 1.7 on\npage 40) with the parse tree in\n(a)\n*\nFigure 1.10 on page 44 and the valuation in which q and r evaluate to T and\np to F;\n(b) Figure 1.4 on page 36 and the valuation in which q evaluates to T and p and\nr evaluate to F;\n(c) Figure 1.23 where we let p be T, q be F and r be T; and\n(d) Figure 1.23 where we let p be F, q be T and r be F.\n4. Compute the truth value on the formula’s parse tree, or specify the corresponding\nline of a truth table where\n(a)\n*\np evaluates to F, q to T and the formula is p →(¬q ∨(q →p))\n(b)\n*\nthe formula is ¬((¬q ∧(p →r)) ∧(r →q)), p evaluates to F, q to T and r\nevaluates to T.\n1.7 Exercises\n85\n5.\n*\nA formula is valid iﬀit computes T for all its valuations; it is satisﬁable iﬀit\ncomputes T for at least one of its valuations. Is the formula of the parse tree in\nFigure 1.10 on page 44 valid? Is it satisﬁable?\n6. Let ∗be a new logical connective such that p ∗q does not hold iﬀp and q are\neither both false or both true.\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nthe equivalence of formulas φ and ψ via ⊨: if φ semantically entails ψ and\nvice versa, then these formulas should be the same as far as our truth-table\nsemantics is concerned.\nDeﬁnition 1.40 Let φ and ψ be formulas of propositional logic. We say\nthat φ and ψ are semantically equivalent iﬀφ ⊨ψ and ψ ⊨φ hold. In that\ncase we write φ ≡ψ. Further, we call φ valid if ⊨φ holds.\nNote that we could also have deﬁned φ ≡ψ to mean that ⊨(φ →ψ) ∧\n(ψ →φ) holds; it amounts to the same concept. Indeed, because of soundness\nand completeness, semantic equivalence is identical to provable equivalence\n1.5 Normal forms\n55\n(Deﬁnition 1.25). Examples of equivalent formulas are\np →q ≡¬q →¬p\np →q ≡¬p ∨q\np ∧q →p ≡r ∨¬r\np ∧q →r ≡p →(q →r).\nRecall that a formula η is called a tautology if ⊨η holds, so the tautologies\nare exactly the valid formulas. The following lemma says that any decision\nprocedure for tautologies is in fact a decision procedure for the validity of\nsequents as well.\nLemma 1.41 Given formulas φ1, φ2, . . . , φn and ψ of propositional logic,\nφ1, φ2, . . . , φn ⊨ψ holds iﬀ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nProof: First, suppose that ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nIf φ1, φ2, . . . , φn are all true under some valuation, then ψ has to be true\nas well for that same valuation. Otherwise,\n⊨φ1 →(φ2 →(φ3 →· · · →\n(φn →ψ))) would not hold (compare this with Figure 1.11). Second, if\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s. line; otherwise we take the solid line. We continue for each node until we\nreach a terminal node. Since the BDD is ﬁnite by deﬁnition, we eventually\nreach a terminal node which is labelled with 0 or 1. That label is the result\nof f for that particular assignment of truth values.\nThe deﬁnition of a BDD does not prohibit that a boolean variable occur\nmore than once on a path in the dag. For example, consider the BDD in\nFigure 6.7.\nSuch a representation is wasteful, however. The solid link from the left-\nmost x to the 1-terminal is never taken, for example, because one can only\nget to that x-node when x has value 0.\nThanks to the reductions C1–C3, BDDs can often be quite compact rep-\nresentations of boolean functions. Let us consider how to check satisﬁability\nand perform the boolean operations on functions represented as BDDs. A\nBDD represents a satisﬁable function if a 1-terminal node is reachable from\nthe root along a consistent path in a BDD which represents it. A consistent\npath is one which, for every variable, has only dashed lines or only solid lines\nleaving nodes labelled by that variable. (In other words, we cannot assign\n366\n6 Binary decision diagrams\nx\ny\nz\nx\ny\nx\n0\n1\nFigure 6.7. A BDD where some boolean variables occur more than\nonce on an evaluation path.\na variable the values 0 and 1 simultaneously.) Checking validity is similar,\nbut we check that no 0-terminal is reachable by a consistent path.\nThe operations · and + can be performed by ‘surgery’ on the component\nBDDs. Given BDDs Bf and Bg representing boolean functions f and g, a\nBDD representing f · g can be obtained by taking the BDD f and replacing\nall its 1-terminals by Bg. To see why this is so, consider how to get to a\n1-terminal in the resulting BDD. You have to satisfy the requirements for\ngetting to a 1 imposed by both of the BDDs. Similarly, a BDD for f + g\ncan be obtained by replacing all 0 terminals of Bf by Bg. Note that these\nnodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we\nsee that decision trees as such are not a more compact representation of\nboolean functions. However, binary decision trees often contain some redun-\ndancy which we can exploit.\nSince 0 and 1 are the only terminal nodes of binary decision trees, we can\noptimise the representation by having pointers to just one copy of 0 and\none copy of 1. For example, the binary decision tree in Figure 6.2 can be\noptimised in this way and the resulting structure is depicted in Figure 6.3(a).\nNote that we saved storage space for two redundant terminal 0-nodes, but\nthat we still have as many edges (pointers) as before.\n6.1 Representing boolean functions\n363\nx\nx\n1\n0\nz\ny\ny\ny\ny\nFigure 6.4. A BDD with duplicated subBDDs.\nA second optimisation we can do is to remove unnecessary decision points\nin the tree. In Figure 6.3(a), the right-hand y is unnecessary, because we go\nto the same place whether it is 0 or 1. Therefore the structure could be\nfurther reduced, to the one shown on the right, (b).\nAll these structures are examples of binary decision diagrams (BDDs).\nThey are more general than binary decision trees; the sharing of the leaves\nmeans they are not trees. As a third optimisation, we also allow subBDDs to\nbe shared. A subBDD is the part of a BDD occurring below a given node. For\nexample, in the BDD of Figure 6.4, the two inner y-nodes perform the same\nrole, because the subBDDs below them have the same structure. Therefore,\none of them could be removed, resulting in the BDD in Figure 6.5(a). Indeed,\nthe left-most y-node could also be merged with the middle one; then the\nx-node above both of them would become redundant. Removing it would\nresult in the BDD on the right of Figure 6.5.\nTo summarise, we encountered three diﬀerent ways of reducing a BDD to\na more compact form:\nC1. Removal of duplicate terminals. If a BDD contains more than one\n5. Let T be a binary decision tree for a boolean function f(x1, x2, . . . , xn) of n\nboolean variables. Suppose that every variable occurs exactly once as one travels\ndown on any path of the tree T. Use mathematical induction to show that T has\n2n+1 −1 nodes.\nExercises 6.3\n1.\n*\nExplain why all reductions C1–C3 (page 363) on a BDD B result in BDDs which\nstill represent the same function as B.\n2. Consider the BDD in Figure 6.7.\n(a)\n*\nSpecify the truth table for the boolean function f(x, y, z) represented by\nthis BDD.\n400\n6 Binary decision diagrams\n(b) Find a BDD for that function which does not have multiple occurrences of\nvariables along any path.\n3. Let f be the function represented by the BDD of Figure 6.3(b). Using also the\nBDDs B0, B1 and Bx illustrated in Figure 6.6, ﬁnd BDDs representing\n(a) f · x\n(b) x + f\n(c) f · 0\n(d) f · 1.\nExercises 6.4\n1. Figure 6.9 (page 367) shows a BDD with ordering [x, y, z].\n(a)\n*\nFind an equivalent reduced BDD with ordering [z, y, x]. (Hint: ﬁnd ﬁrst the\ndecision tree with the ordering [z, y, x], and then reduce it using C1–C3.)\n(b) Carry out the same construction process for the variable ordering [y, z, x].\nDoes the reduced BDD have more or fewer nodes than the ones for the\norderings [x, y, z] and [z, y, x]?\n2. Consider the BDDs in Figures 6.4–6.10. Determine which of them are OBDDs.\nIf you ﬁnd an OBDD, you need to specify a list of its boolean variables without\ndouble occurrences which demonstrates that ordering.\n3. Consider the following boolean formulas. Compute their unique reduced OBDDs\nwith respect to the ordering [x, y, z]. It is advisable to ﬁrst compute a binary\ndecision tree and then to perform the removal of redundancies.\n(a) f(x, y)\ndef\n= x · y\n(b)\n*\nf(x, y)\ndef\n= x + y\n(c) f(x, y)\ndef\n= x ⊕y\n(d)\n*\nf(x, y, z)\ndef\n= (x ⊕y) · (x + z).\n4. Recall the derived connective φ ↔ψ from Chapter 1 saying that for all valuations\nφ is true if, and only if, ψ is true.\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\nsize of an OBDD: the OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with\nvariable ordering [x1, x3, x5, x2, x4, x6].\n372\n6 Binary decision diagrams\nand g denote the same boolean functions if, and only if, the reduced OBDDs\nhave identical structure.\nTest for validity. We can test a function f(x1, x2, . . . , xn) for validity (i.e.\nf always computes 1) in the following way. Compute a reduced OBDD for\nf. Then f is valid if, and only if, its reduced OBDD is B1.\nTest for implication. We can test whether f(x1, x2, . . . , xn) implies g(x1,\nx2, . . . , xn) (i.e. whenever f computes 1, then so does g) by computing the\nreduced OBDD for f · g. This is B0 iﬀthe implication holds.\nTest for satisﬁability. We can test a function f(x1, x2, . . . , xn) for satis-\nﬁability (f computes 1 for at least one assignment of 0 and 1 values to its\nvariables). The function f is satisﬁable iﬀits reduced OBDD is not B0.\n6.2 Algorithms for reduced OBDDs\n6.2.1 The algorithm reduce\nThe reductions C1–C3 are at the core of any serious use of OBDDs, for\nwhenever we construct a BDD we will want to convert it to its reduced form.\nIn this section, we describe an algorithm reduce which does this eﬃciently\nfor ordered BDDs.\nIf the ordering of B is [x1, x2, . . . , xl], then B has at most l + 1 layers. The\nalgorithm reduce now traverses B layer by layer in a bottom-up fashion,\nbeginning with the terminal nodes. In traversing B, it assigns an integer\nlabel id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\n6.5 Exercises\nExercises 6.1\n1. Write down the truth tables for the boolean formulas in Example 6.2 on page 359.\nIn your table, you may use 0 and 1, or F and T, whatever you prefer. What truth\nvalue does the boolean formula of item (4) on page 359 compute?\n2. ⊕is the exclusive-or: x ⊕y\ndef\n= 1 if the values of x and y are diﬀerent; otherwise,\nx ⊕y\ndef\n= 0. Express this in propositional logic, i.e. ﬁnd a formula φ having the\nsame truth table as ⊕.\n3.\n*\nWrite down a boolean formula f(x, y) in terms of ·, +, ¯, 0 and 1, such that f\nhas the same truth table as p →q.\n4. Write down a BNF for the syntax of boolean formulas based on the operations\nin Deﬁnition 6.1.\nExercises 6.2\n1.\n*\nSuppose we swap all dashed and solid lines in the binary decision tree of Fig-\nure 6.2. Write out the truth table of the resulting binary decision tree and ﬁnd\na formula for it.\n6.5 Exercises\n399\n2.\n*\nConsider the following truth table:\np\nq\nr\nφ\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nT\nF\nF\nF\nF\nT\nT\nT\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\nWrite down a binary decision tree which represents the boolean function speciﬁed\nin this truth table.\n3. Construct a binary decision tree for the boolean function speciﬁed in Figure 6.2,\nbut now the root should be a y-node and its two successors should be x-nodes.\n4. Consider the following boolean function given by its truth table:\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n(a) Construct a binary decision tree for f(x, y, z) such that the root is an x-node\nfollowed by y- and then z-nodes.\n(b) Construct another binary decision tree for f(x, y, z), but now let its root be\na z-node followed by y- and then x-nodes.\n5. Let T be a binary decision tree for a boolean function f(x1, x2, . . . , xn) of n\nboolean variables. Suppose that every variable occurs exactly once as one travels\ndown on any path of the tree T. Use mathematical induction to show that T has\n2n+1 −1 nodes.\nExercises 6.3\n1.\n*\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nFigure 6.24. A simple CTL model (Example 6.12).\nset of\nrepresentation by\nrepresentation by\nstates\nboolean values\nboolean function\n∅\n0\n{s0}\n(1, 0)\nx1 · x2\n{s1}\n(0, 1)\nx1 · x2\n{s2}\n(0, 0)\nx1 · x2\n{s0, s1}\n(1, 0), (0, 1)\nx1 · x2 + x1 · x2\n{s0, s2}\n(1, 0), (0, 0)\nx1 · x2 + x1 · x2\n{s1, s2}\n(0, 1), (0, 0)\nx1 · x2 + x1 · x2\nS\n(1, 0), (0, 1), (0, 0)\nx1 · x2 + x1 · x2 + x1 · x2\nFigure 6.25. Representation of subsets of states of the model of Figure 6.24.\nThe key point which makes this representation interesting is that the\nOBDD representing a set of states may be quite small.\nExample 6.12 Consider the CTL model in Figure 6.24, given by:\nS\ndef\n= {s0, s1, s2}\n→\ndef\n= {(s0, s1), (s1, s2), (s2, s0), (s2, s2)}\nL(s0)\ndef\n= {x1}\nL(s1)\ndef\n= {x2}\nL(s2)\ndef\n= ∅.\nNote that it has the property that, for all states s1 and s2, L(s1) = L(s2)\nimplies s1 = s2, i.e. a state is determined entirely by the atomic formulas\ntrue in it. Sets of states may be represented by boolean values and by boolean\nformulas with the ordering [x1, x2], as shown in Figure 6.25.\nNotice that the vector (1, 1) and the corresponding function x1 · x2 are\nunused. Therefore, we are free to include it in the representation of a subset\n6.3 Symbolic model checking\n385\nx2\n0\n1\nx1\n0\n1\nx1\nx2\nx2\nFigure 6.26. Two OBDDs for the set {s0, s1} (Example 6.12).\nof S or not; so we may choose to include it or not in order to optimise the\nsize of the OBDD. For example, the subset {s0, s1} is better represented\nby the boolean function x1 + x2, since its OBDD is smaller than that for\nx1 · x2 + x1 · x2 (Figure 6.26).\nIn order to justify the claim that the representation of subsets of S as\nOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need\nordering and then to apply all possible reductions.\n(a) [x, y, z].\n(b) [y, x, z].\n(c) [z, x, y].\n(d) Find an ordering of variables for which the resulting reduced OBDD Bf has a\nminimal number of edges; i.e. there is no ordering for which the corresponding\nBf has fewer edges. (How many possible orderings for x, y and z are there?)\n4. Given the truth table\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n1\ncompute the reduced OBDD with respect to the following ordering of variables:\n(a) [x, y, z]\n(b) [z, y, x]\n(c) [y, z, x]\n(d) [x, z, y].\n5. Given the ordering [p, q, r], compute the reduced BDDs for p ∧(q ∨r) and (p ∧\nq) ∨(p ∧r) and explain why they are identical.\n6.\n*\nConsider the BDD in Figure 6.11 (page 370).\n(a) Construct its truth table.\n(b) Compute its conjunctive normal form.\n(c) Compare the length of that normal form with the size of the BDD. What is\nyour assessment?\n402\n6 Binary decision diagrams\nExercises 6.6\n1. Perform the execution of reduce on the following OBDDs:\n(a) The binary decision tree for\ni. x ⊕y\nii. x · y\niii. x + y\niv. x ↔y.\n(b) The OBDD in Figure 6.2 (page 361).\n(c)\n*\nThe OBDD in Figure 6.4 (page 363).\nExercises 6.7\n1. Recall the Shannon expansion in (6.1) on page 374. Suppose that x does not\noccur in f at all. Why does (6.1) still hold?\n2. Let f(x, y, z)\ndef\n= y + z · x + z · y + y · x be a boolean formula. Compute f’s\nShannon expansion with respect to\n(a) x\n(b) y\n(c) z.\n3. Show that boolean formulas f and g are semantically equivalent if, and only if,\nthe boolean formula (f + g) · (f + g) computes 1 for all possible assignments of\n0s and 1s to their variables.\n4. We may use the Shannon expansion to deﬁne formally how BDDs determine\nboolean functions. Let B be a BDD. It is intuitively clear that B determines\na unique boolean function. Formally, we compute a function fn inductively\n(bottom-up) for all nodes n of B:\n– If n is a terminal node labelled 0, then fn is the constant 0 function.\nvariables x and y.\nDeﬁnition 6.3 Let T be a ﬁnite binary decision tree. Then T determines\na unique boolean function of the variables in non-terminal nodes, in the\nfollowing way. Given an assignment of 0s and 1s to the boolean variables\n362\n6 Binary decision diagrams\n1\n0\ny\nx\ny\n1\n0\ny\nx\nFigure 6.3. (a) Sharing the terminal nodes of the binary decision tree\nin Figure 6.2; (b) further optimisation by removing a redundant decision\npoint.\noccurring in T, we start at the root of T and take the dashed line when-\never the value of the variable at the current node is 0; otherwise, we travel\nalong the solid line. The function value is the value of the terminal node we\nreach.\nFor example, the binary decision tree of Figure 6.2 represents a boolean\nfunction f(x, y). To ﬁnd f(0, 1), start at the root of the tree. Since the value\nof x is 0 we follow the dashed line out of the node labelled x and arrive\nat the leftmost node labelled y. Since y’s value is 1, we follow the solid\nline out of that y-node and arrive at the leftmost terminal node labelled\n0. Thus, f(0, 1) equals 0. In computing f(0, 0), we similarly travel down\nthe tree, but now following two dashed lines to obtain 1 as a result. You\ncan see that the two other possibilities result in reaching the remaining\ntwo terminal nodes labelled 0. Thus, this binary decision tree computes the\nfunction f(x, y)\ndef\n= x + y.\nBinary decision trees are quite close to the representation of boolean func-\ntions as truth tables as far as their sizes are concerned. If the root of a binary\ndecision tree is an x-node then it has two subtrees (one for the value of x\nbeing 0 and another one for x having value 1). So if f depends on n boolean\nvariables, the corresponding binary decision tree will have at least 2n+1 −1\nnodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we\nsee that decision trees as such are not a more compact representation of\nboolean functions. However, binary decision trees often contain some redun- ring along any path. We then adhere to that same ordering for all the BDDs\nwe manipulate.\nDeﬁnition 6.6 Let [x1, . . . , xn] be an ordered list of variables without du-\nplications and let B be a BDD all of whose variables occur somewhere in\nthe list. We say that B has the ordering [x1, . . . , xn] if all variable labels of\nB occur in that list and, for every occurrence of xi followed by xj along any\npath in B, we have i < j.\nAn ordered BDD (OBDD) is a BDD which has an ordering for some list\nof variables.\nNote that the BDDs of Figures 6.3(a,b) and 6.9 are ordered (with ordering\n[x, y]). We don’t insist that every variable in the list is used in the paths.\nThus, the OBDDs of Figures 6.3 and 6.9 have the ordering [x, y, z] and so\n368\n6 Binary decision diagrams\n0\n1\nz\nx\ny\ny\nx\nFigure 6.10. A BDD which does not have an ordering of variables.\ndoes any list having x, y and z in it in that order, such as [u, x, y, v, z, w] and\n[x, u, y, z]. Even the BDDs B0 and B1 in Figure 6.6 are OBDDs, a suitable\nordering list being the empty list (there are no variables), or indeed any list.\nThe BDD Bx of Figure 6.6(b) is also an OBDD, with any list containing x\nas its ordering.\nThe BDD of Figure 6.7 is not ordered. To see why this is so, consider the\npath taken if the values of x and y are 0. We begin with the root, an x-\nnode, and reach a y-node and then an x-node again. Thus, no matter what\nlist arrangement we choose (remembering that no double occurrences are\nallowed), this path violates the ordering condition. Another example of a\nBDD that is not ordered can be seen in Figure 6.10. In that case, we cannot\nﬁnd an order since the path for (x, y, z) ⇒(0, 0, 0) – meaning that x, y and z\nare assigned 0 – shows that y needs to occur before x in such a list, whereas\nthe path for (x, y, z) ⇒(1, 1, 1) demands that x be before y.\nIt follows from the deﬁnition of OBDDs that one cannot have multiple\noccurrences of any variable along a path. label id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\nlabel (say #0) to the ﬁrst 0-node it encounters. All other terminal 0-nodes\ndenote the same function as the ﬁrst 0-node and therefore get the same label\n(compare with reduction C1). Similarly, the 1-nodes all get the next label,\nsay #1.\nNow let us inductively assume that reduce has already assigned integer\nlabels to all nodes of a layer > i (i.e. all terminal nodes and xj-nodes with\nj > i). We describe how nodes of layer i (i.e. xi-nodes) are being handled.\nDeﬁnition 6.8 Given a non-terminal node n in a BDD, we deﬁne lo(n) to\nbe the node pointed to via the dashed line from n. Dually, hi(n) is the node\npointed to via the solid line from n.\nLet us describe how the labelling is done. Given an xi-node n, there are\nthree ways in which it may get its label:\n6.2 Algorithms for reduced OBDDs\n373\n0\n1\n#0\n#1\n0\n1\n0\n1\nx3\nx3\nx2\nx2\nx1\n#0\n#1\n#0\n#1\n#2\n#2\n#3\n#2\n#4\n=⇒\nx3\nx2\nx1\n#2\n#3\n#4\nReduce\nFigure 6.14. An example execution of the algorithm reduce.\nr If the label id(lo(n)) is the same as id(hi(n)), then we set id(n) to be that label.\nThat is because the boolean function represented at n is the same function as the\none represented at lo(n) and hi(n). In other words, node n performs a redundant\ntest and can be eliminated by reduction C2.\nr If there is another node m such that n and m have the same variable xi, and\nid(lo(n)) = id(lo(m)) and id(hi(n)) = id(hi(m)), then we set id(n) to be id(m).\nThis is because the nodes n and m compute the same boolean function (compare\nwith reduction C3).\nr Otherwise, we set id(n) to the next unused integer label.\nNote that only the last case creates a new label. Consider the OBDD\nin left side of Figure 6.14; each node has an integer label obtained in the\nwith reduction C3).\nr Otherwise, we set id(n) to the next unused integer label.\nNote that only the last case creates a new label. Consider the OBDD\nin left side of Figure 6.14; each node has an integer label obtained in the\nmanner just described. The algorithm reduce then ﬁnishes by redirecting\nedges bottom-up as outlined in C1–C3. The resulting reduced OBDD is in\nright of Figure 6.14. Since there are eﬃcient bottom-up traversal algorithms\nfor dags, reduce is an eﬃcient operation in the number of nodes of an\nOBDD.\n6.2.2 The algorithm apply\nAnother procedure at the heart of OBDDs is the algorithm apply. It is\nused to implement operations on boolean functions such as +, · , ⊕and\ncomplementation (via f ⊕1). Given OBDDs Bf and Bg for boolean formulas\nf and g, the call apply (op, Bf, Bg) computes the reduced OBDD of the\nboolean formula f op g, where op denotes any function from {0, 1} × {0, 1}\nto {0, 1}.\n374\n6 Binary decision diagrams\nThe intuition behind the apply algorithm is fairly simple. The algorithm\noperates recursively on the structure of the two OBDDs:\n1.\nlet v be the variable highest in the ordering (=leftmost in the list) which occurs\nin Bf or Bg.\n2.\nsplit the problem into two subproblems for v being 0 and v being 1 and solve\nrecursively;\n3.\nat the leaves, apply the boolean operation op directly.\nThe result will usually have to be reduced to make it into an OBDD. Some\nreduction can be done ‘on the ﬂy’ in step 2, by avoiding the creation of a new\nnode if both branches are equal (in which case return the common result),\nor if an equivalent node already exists (in which case, use it).\nLet us make all this more precise and detailed.\nDeﬁnition 6.9 Let f be a boolean formula and x a variable.\n1.\nWe denote by f[0/x] the boolean formula obtained by replacing all occurrences\nof x in f by 0. The formula f[1/x] is deﬁned similarly. The expressions f[0/x]\nand f[1/x] are called restrictions of f.\n2.\nordering and then to apply all possible reductions.\n(a) [x, y, z].\n(b) [y, x, z].\n(c) [z, x, y].\n(d) Find an ordering of variables for which the resulting reduced OBDD Bf has a\nminimal number of edges; i.e. there is no ordering for which the corresponding\nBf has fewer edges. (How many possible orderings for x, y and z are there?)\n4. Given the truth table\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n1\ncompute the reduced OBDD with respect to the following ordering of variables:\n(a) [x, y, z]\n(b) [z, y, x]\n(c) [y, z, x]\n(d) [x, z, y].\n5. Given the ordering [p, q, r], compute the reduced BDDs for p ∧(q ∨r) and (p ∧\nq) ∨(p ∧r) and explain why they are identical.\n6.\n*\nConsider the BDD in Figure 6.11 (page 370).\n(a) Construct its truth table.\n(b) Compute its conjunctive normal form.\n(c) Compare the length of that normal form with the size of the BDD. What is\nyour assessment?\n402\n6 Binary decision diagrams\nExercises 6.6\n1. Perform the execution of reduce on the following OBDDs:\n(a) The binary decision tree for\ni. x ⊕y\nii. x · y\niii. x + y\niv. x ↔y.\n(b) The OBDD in Figure 6.2 (page 361).\n(c)\n*\nThe OBDD in Figure 6.4 (page 363).\nExercises 6.7\n1. Recall the Shannon expansion in (6.1) on page 374. Suppose that x does not\noccur in f at all. Why does (6.1) still hold?\n2. Let f(x, y, z)\ndef\n= y + z · x + z · y + y · x be a boolean formula. Compute f’s\nShannon expansion with respect to\n(a) x\n(b) y\n(c) z.\n3. Show that boolean formulas f and g are semantically equivalent if, and only if,\nthe boolean formula (f + g) · (f + g) computes 1 for all possible assignments of\n0s and 1s to their variables.\n4. We may use the Shannon expansion to deﬁne formally how BDDs determine\nboolean functions. Let B be a BDD. It is intuitively clear that B determines\na unique boolean function. Formally, we compute a function fn inductively\n(bottom-up) for all nodes n of B:\n– If n is a terminal node labelled 0, then fn is the constant 0 function.\nv op x = 1 or v op x = 0 for all values of x. We say that v is a controlling value\nif it is a left- and right-controlling value.\n(a) Deﬁne the notion of a right-controlling value.\n(b) Give examples of operations with controlling values.\n(c) Describe informally how apply can be optimised when op has a controlling\nvalue.\n(d) Could one still do some optimisation if op had only a left- or right-controlling\nvalue?\n12. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that\nthis upper bound is hard, i.e. it cannot be improved:\n(a) Consider the functions f(x1, x2, . . . , x2n+2m)\ndef\n= x1 · xn+m+1 + · · · + xn ·\nx2n+m and g(x1, x2, . . . , x2n+2m)\ndef\n= xn+1 · x2n+m+1 + · · · + xn+m · x2n+2m\nwhich are in sum-of-product form. Compute the sum-of-product form of\nf + g.\n(b) Choose the ordering [x1, x2, . . . , x2n+2m] and argue that the OBDDs Bf\nand Bg have 2n+1 and 2m+1 edges, respectively.\n(c) Use the result from part (a) to conclude that Bf+g has 2n+m+1 edges, i.e.\n0.5 · |Bf| · |Bg|.\nExercises 6.8\n1. Let f be the reduced OBDD represented in Figure 6.5(b) (page 364). Compute\nthe reduced OBDD for the restrictions:\n(a) f[0/x]\n(b)\n*\nf[1/x]\n6.5 Exercises\n405\n(c) f[1/y]\n(d)\n*\nf[0/z].\n2.\n*\nSuppose that we intend to modify the algorithm restrict so that it is capable\nof computing reduced OBDDs for a general composition f[g/x].\n(a) Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation\n[g/x].\n(b) What fact about OBDDs causes problems for computing this composition\ndirectly?\n(c) How can we compute this composition given the algorithms discussed so far?\n3. We deﬁne read-1-BDDs as BDDs B where each boolean variable occurs at most\nonce on any evaluation path of B. In particular, read-1-BDDs need not possess\nan ordering on their boolean variables. Clearly, every OBDD is a read-1-BDD;\nbut not every read-1-BDD is an OBDD (see Figure 6.10). In Figure 6.18 we see\na BDD which is not a read-1-BDD; the path for (x, y, z) ⇒(1, 0, 1) ‘reads’ the v op x = 1 or v op x = 0 for all values of x. We say that v is a controlling value\nif it is a left- and right-controlling value.\n(a) Deﬁne the notion of a right-controlling value.\n(b) Give examples of operations with controlling values.\n(c) Describe informally how apply can be optimised when op has a controlling\nvalue.\n(d) Could one still do some optimisation if op had only a left- or right-controlling\nvalue?\n12. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that\nthis upper bound is hard, i.e. it cannot be improved:\n(a) Consider the functions f(x1, x2, . . . , x2n+2m)\ndef\n= x1 · xn+m+1 + · · · + xn ·\nx2n+m and g(x1, x2, . . . , x2n+2m)\ndef\n= xn+1 · x2n+m+1 + · · · + xn+m · x2n+2m\nwhich are in sum-of-product form. Compute the sum-of-product form of\nf + g.\n(b) Choose the ordering [x1, x2, . . . , x2n+2m] and argue that the OBDDs Bf\nand Bg have 2n+1 and 2m+1 edges, respectively.\n(c) Use the result from part (a) to conclude that Bf+g has 2n+m+1 edges, i.e.\n0.5 · |Bf| · |Bg|.\nExercises 6.8\n1. Let f be the reduced OBDD represented in Figure 6.5(b) (page 364). Compute\nthe reduced OBDD for the restrictions:\n(a) f[0/x]\n(b)\n*\nf[1/x]\n6.5 Exercises\n405\n(c) f[1/y]\n(d)\n*\nf[0/z].\n2.\n*\nSuppose that we intend to modify the algorithm restrict so that it is capable\nof computing reduced OBDDs for a general composition f[g/x].\n(a) Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation\n[g/x].\n(b) What fact about OBDDs causes problems for computing this composition\ndirectly?\n(c) How can we compute this composition given the algorithms discussed so far?\n3. We deﬁne read-1-BDDs as BDDs B where each boolean variable occurs at most\nonce on any evaluation path of B. In particular, read-1-BDDs need not possess\nan ordering on their boolean variables. Clearly, every OBDD is a read-1-BDD;\nbut not every read-1-BDD is an OBDD (see Figure 6.10). In Figure 6.18 we see\na BDD which is not a read-1-BDD; the path for (x, y, z) ⇒(1, 0, 1) ‘reads’ the\nonly if x is 1; or y is 0 and z is 1 – this is a constraint on x, y, and z.\nIt is useful to be able to express the relaxation of the constraint on a subset\nof the variables concerned. To allow this, we write ∃x. f for the boolean\nfunction f with the constraint on x relaxed. Formally, ∃x. f is deﬁned as\nf[0/x] + f[1/x]; that is, ∃x. f is true if f could be made true by putting x\nto 0 or to 1. Given that ∃x. f\ndef\n= f[0/x] + f[1/x] the exists algorithm can\nbe implemented in terms of the algorithms apply and restrict as\napply (+, restrict (0, x, Bf), restrict (1, x, Bf)) .\n(6.3)\nConsider, for example, the OBDD Bf for the function f\ndef\n= x1 · y1 + x2 ·\ny2 + x3 · y3, shown in Figure 6.19. Figure 6.20 shows restrict(0, x3, Bf)\nand restrict(1, x3, Bf) and the result of applying + to them. (In this case\nthe apply function happens to return its second argument.)\nWe can improve the eﬃciency of this algorithm. Consider what happens\nduring the apply stage of (6.3). In that case, the apply algorithm works on\ntwo BDDs which are identical all the way down to the level of the x-nodes;\n378\n6 Binary decision diagrams\n1\n0\nx\nx\nx\nz\ny\nFigure 6.18. An example of a BDD which is not a read-1-BDD.\n1\n0\nx1\nx2\nx3\ny1\ny2\ny3\nFigure 6.19. A BDD Bf to illustrate the exists algorithm.\ntherefore the returned BDD also has that structure down to the x-nodes.\nAt the x-nodes, the two argument BDDs diﬀer, so the apply algorithm\nwill compute the apply of + to these two subBDDs and return that as the\nsubBDD of the result. This is illustrated in Figure 6.20. Therefore, we can\ncompute the OBDD for ∃x. f by taking the OBDD for f and replacing each\nnode labelled with x by the result of calling apply on + and its two branches.\nThis can easily be generalised to a sequence of exists operations. We\nwrite ∃ˆx. f to mean ∃x1.∃x2. . . . ∃xn. f, where ˆx denotes (x1, x2, . . . , xn).\n6.2 Algorithms for reduced OBDDs\n379\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\n1\n0\nx1\nx2\ny1\ny2\nx1\nx2\ny1\ny2\ny3 represent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nelements in S. If |S| is not an exact power of 2, there will be some vec-\ntors which do not correspond to any element of S; they are just ignored.\nThe function fT : {0, 1}n →{0, 1} which tells us, for each s, represented by\n(v1, v2, . . . , vn), whether it is in the set T or not, is called the characteristic\nfunction of T.\nIn the case that S is the set of states of a transition system M = (S, →, L)\n(see Deﬁnition 3.4), there is a natural way of choosing the representation\nof S as boolean vectors. The labelling function L : S →P(Atoms) (where\nP(Atoms) is the set of subsets of Atoms) gives us the encoding. We assume\na ﬁxed ordering on the set Atoms, say x1, x2, . . . , xn, and then represent\ns ∈S by the vector (v1, v2, . . . , vn), where, for each i, vi equals 1 if xi ∈\nL(s) and vi is 0 otherwise. In order to guarantee that each s has a unique\nrepresentation as a boolean vector, we require that, for all s1, s2 ∈S, L(s1) =\nL(s2) implies s1 = s2. If this is not the case, perhaps because 2|Atoms| < |S|,\nwe can add extra atomic propositions in order to make enough distinctions\n(Cf. introduction of the turn variable for mutual exclusion in Section 3.3.4.)\nFrom now on, we refer to a state s ∈S by its representing boolean vector\n(v1, v2, . . . , vn), where vi is 1 if xi ∈L(s) and 0 otherwise. As an OBDD,\nthis state is represented by the OBDD of the boolean function l1 · l2 · · · · · ln,\nwhere li is xi if xi ∈L(s) and xi otherwise. The set of states {s1, s2, . . . , sm}\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nFigure 6.24. A simple CTL model (Example 6.12).\nset of\nrepresentation by\nrepresentation by\nstates\nboolean values\nboolean function\n∅\n0\n{s0}\n(1, 0)\nx1 · x2\n{s1}\n(0, 1)\nx1 · x2\n{s2}\n(0, 0)\nx1 · x2\n{s0, s1}\n(1, 0), (0, 1)\nx1 · x2 + x1 · x2\n{s0, s2}\n(1, 0), (0, 0)\nx1 · x2 + x1 · x2\n{s1, s2}\n(0, 1), (0, 0)\nx1 · x2 + x1 · x2\nS\n(1, 0), (0, 1), (0, 0)\nx1 · x2 + x1 · x2 + x1 · x2\nFigure 6.25. Representation of subsets of states of the model of Figure 6.24.\nThe key point which makes this representation interesting is that the\nOBDD representing a set of states may be quite small.\nExample 6.12 Consider the CTL model in Figure 6.24, given by:\nS\ndef\n= {s0, s1, s2}\n→\ndef\n= {(s0, s1), (s1, s2), (s2, s0), (s2, s2)}\nL(s0)\ndef\n= {x1}\nL(s1)\ndef\n= {x2}\nL(s2)\ndef\n= ∅.\nNote that it has the property that, for all states s1 and s2, L(s1) = L(s2)\nimplies s1 = s2, i.e. a state is determined entirely by the atomic formulas\ntrue in it. Sets of states may be represented by boolean values and by boolean\nformulas with the ordering [x1, x2], as shown in Figure 6.25.\nNotice that the vector (1, 1) and the corresponding function x1 · x2 are\nunused. Therefore, we are free to include it in the representation of a subset\n6.3 Symbolic model checking\n385\nx2\n0\n1\nx1\n0\n1\nx1\nx2\nx2\nFigure 6.26. Two OBDDs for the set {s0, s1} (Example 6.12).\nof S or not; so we may choose to include it or not in order to optimise the\nsize of the OBDD. For example, the subset {s0, s1} is better represented\nby the boolean function x1 + x2, since its OBDD is smaller than that for\nx1 · x2 + x1 · x2 (Figure 6.26).\nIn order to justify the claim that the representation of subsets of S as\nOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of x1\nx2\nx′\n1\nx′\n2\n→\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\nx1\nx′\n1\nx2\nx′\n2\n→\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\nFigure 6.27. The truth table for the transition relation of Figure 6.24\n(see Example 6.13). The left version shows the ordering of variables\n[x1, x2, x′\n1, x′\n2], while the right one orders the variables [x1, x′\n1, x2, x′\n2] (the\nrows are ordered lexicographically).\nboolean vectors ((v1, v2, . . . , vn), (v′\n1, v′\n2, . . . , v′\nn)), where vi is 1 if pi ∈L(s)\nand 0 otherwise; and similarly, v′\ni is 1 if pi ∈L(s′) and 0 otherwise. As an\nOBDD, the link is represented by the OBDD for the boolean function\n(l1 · l2 · · · · · ln) · (l′\n1 · l′\n2 · · · · · l′\nn)\nand a set of links (for example, the entire relation →) is the OBDD for the\n+ of such formulas.\nExample 6.13 To compute the OBDD for the transition relation of Fig-\nure 6.24, we ﬁrst show it as a truth table (Figure 6.27 (left)). Each 1 in\nthe ﬁnal column corresponds to a link in the transition relation and each 0\ncorresponds to the absence of a link. The boolean function is obtained by\ntaking the disjunction of the rows having 1 in the last column and is\nf→def\n= x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2.\n(6.5)\nIt turns out that it is usually more eﬃcient to interleave unprimed and\nprimed variables in the OBDD variable ordering for →. We therefore use\n6.3 Symbolic model checking\n387\n0\n1\nx2\nx2\nx′\n2\nx′\n2\nx1\nx′\n1\nx′\n1\nFigure 6.28. An OBDD for the transition relation of Example 6.13.\n[x1, x′\n1, x2, x′\n2] rather than [x1, x2, x′\n1, x′\n2]. Figure 6.27 (right) shows the truth\ntable redrawn with the interleaved ordering of the columns and the rows\nreordered lexicographically. The resulting OBDD is shown in Figure 6.28.\n4.\nThe formula\n∀x∃y R(x, y)\nstates that the model is free of states that deadlock: all states have a transition\nto some state. This is true in our model: a can move to a, b or c; and b and c\ncan move to c.\nExample 2.16 Let F\ndef\n= {e, ·} and P\ndef\n= {≤}, where e is a constant, · is a\nfunction of two arguments and ≤is a predicate in need of two arguments as\nwell. Again, we write · and ≤in inﬁx notation as in (t1 · t2) ≤(t · t).\n126\n2 Predicate logic\nThe model M we have in mind has as set A all binary strings, ﬁnite\nwords over the alphabet {0, 1}, including the empty string denoted by ϵ. The\ninterpretation eM of e is just the empty word ϵ. The interpretation ·M of · is\nthe concatenation of words. For example, 0110 ·M 1110 equals 01101110. In\ngeneral, if a1a2 . . . ak and b1b2 . . . bn are such words with ai, bj ∈{0, 1}, then\na1a2 . . . ak ·M b1b2 . . . bn equals a1a2 . . . akb1b2 . . . bn. Finally, we interpret ≤\nas the preﬁx ordering of words. We say that s1 is a preﬁx of s2 if there is\na binary word s3 such that s1 ·M s3 equals s2. For example, 011 is a preﬁx\nof 011001 and of 011, but 010 is neither. Thus, ≤M is the set {(s1, s2) |\ns1 is a preﬁx of s2}. Here are again some informal model checks:\n1.\nIn our model, the formula\n∀x ((x ≤x · e) ∧(x · e ≤x))\nsays that every word is a preﬁx of itself concatenated with the empty word and\nconversely. Clearly, this holds in our model, for s ·M ϵ is just s and every word\nis a preﬁx of itself.\n2.\nIn our model, the formula\n∃y ∀x (y ≤x)\nsays that there exists a word s that is a preﬁx of every other word. This is true,\nfor we may chose ϵ as such a word (there is no other choice in this case).\n3.\nIn our model, the formula\n∀x ∃y (y ≤x)\nsays that every word has a preﬁx. This is clearly the case and there are in\ngeneral multiple choices for y, which are dependent on x.\n4.\nIn our model, the formula ∀x ∀y ∀z ((x ≤y) →(x · z ≤y · z)) says that when-\never a word s1 is a preﬁx of s2, then s1s has to be a preﬁx of s2s for every word\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;\nand if L(s0) = {p, q}, L(s1) = {q, r} and L(s2) = {r}, then we can condense\nall this information into Figure 3.3. We prefer to present models by means\nof such pictures whenever that is feasible.\nThe requirement in Deﬁnition 3.4 that for every s ∈S there is at least\none s′ ∈S such that s →s′ means that no state of the system can ‘dead-\nlock.’ This is a technical convenience, and in fact it does not represent any\nreal restriction on the systems we can model. If a system did deadlock, we\ncould always add an extra state sd representing deadlock, together with new\n3.2 Linear-time temporal logic\n179\ns0\np, q\ns1\nq, r\ns2\nr\nFigure 3.3. A concise representation of a transition system M =\n(S, →,L) as a directed graph. We label state s with l iff l ∈L(s).\ns1\ns3\ns0\ns2\ns4\ns1\ns3\ns0\ns2\ns4\nsd\nFigure 3.4. On the left, we have a system with a state s4 that does not\nhave any further transitions. On the right, we expand that system with a\n‘deadlock’ state sd such that no state can deadlock; of course, it is then\nour understanding that reaching the ‘deadlock’ state sd corresponds to\ndeadlock in the original system.\ntransitions s →sd for each s which was a deadlock in the old system, as well\nas sd →sd. See Figure 3.4 for such an example.\nDeﬁnition 3.5 A path in a model M = (S, →, L) is an inﬁnite sequence of\nstates s1, s2, s3, . . . in S such that, for each i ≥1, si →si+1. We write the\npath as s1 →s2 →. . . .\nConsider the path π = s1 →s2 →. . . . It represents a possible future of\nour system: ﬁrst it is in state s1, then it is in state s2, and so on. We write\nπi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .\n180\n3 Verification by model checking\np, q\nr\nr\nr\nq, r\np, q\nq, r\ns0\ns2\ns2\ns2\ns0\ns1 further optimisation techniques, such as parallelisation.\nNote that the operations apply, restrict, etc. are only eﬃcient in the\nsize of the input OBDDs. So if a function f does not have a compact repre-\nsentation as an OBDD, then computing with its OBDD will not be eﬃcient.\nThere are such nasty functions; indeed, one of them is integer multiplication.\nLet bn−1bn−2 . . . b0 and an−1an−2 . . . a0 be two n-bit integers, where bn−1 and\nan−1 are the most signiﬁcant bits and b0 and a0 are the least signiﬁcant bits.\nThe multiplication of these two integers results in a 2n-bit integer. Thus, we\nmay think of multiplication as 2n many boolean functions fi in 2n variables\n(n bits for input b and n bits for input a), where fi denotes the ith output\nbit of the multiplication. The following negative result, due to R. E. Bryant,\nshows that OBDDs cannot be used for implementing integer multiplication.\nTheorem 6.11 Any OBDD representation of fn−1 has at least a number\nof vertices proportional to 1.09n, i.e. its size is exponential in n.\nExtensions and variations of OBDDs\nThere are many variations and\nextensions to the OBDD data structure. Many of them can implement cer-\ntain operations more eﬃciently than their OBDD counterparts, but it seems\nthat none of them perform as well as OBDDs overall. In particular, one fea-\nture which many of the variations lack is the canonical form; therefore they\nlack an eﬃcient algorithm for deciding when two objects denote the same\nboolean function.\nOne kind of variation allows non-terminal nodes to be labelled with bi-\nnary operators as well as boolean variables. Parity OBDDs are like OBDDs\nin that there is an ordering on variables and every variable may occur at\n2 Another NP-complete problem is to decide the satisﬁability of formulas of propositional logic.\n382\n6 Binary decision diagrams\nmost once on a path; but some non-terminal nodes may be labelled with ⊕,\nthe exclusive-or operation. The meaning is that the function represented by\n[x1, x′\n1, x2, x′\n2] rather than [x1, x2, x′\n1, x′\n2]. Figure 6.27 (right) shows the truth\ntable redrawn with the interleaved ordering of the columns and the rows\nreordered lexicographically. The resulting OBDD is shown in Figure 6.28.\n6.3.3 Implementing the functions pre∃and pre∀\nIt remains to show how an OBDD for pre∃(X) and pre∀(X) can be com-\nputed, given OBDDs BX for X and B→for the transition relation →. First\nwe observe that pre∀can be expressed in terms of complementation and\npre∃, as follows: pre∀(X) = S −pre∃(S −X), where we write S −Y for the\nset of all s ∈S which are not in Y . Therefore, we need only explain how to\ncompute the OBDD for pre∃(X) in terms of BX and B→. Now (6.4) suggests\nthat one should proceed as follows:\n1.\nRename the variables in BX to their primed versions; call the resulting OBDD\nBX′.\n2.\nCompute the OBDD for exists(ˆx′, apply(·, B→, BX′)) using the apply and\nexists algorithms (Sections 6.2.2 and 6.2.4).\n6.3.4 Synthesising OBDDs\nThe method used in Example 6.13 for producing an OBDD for the transi-\ntion relation was to compute ﬁrst the truth table and then an OBDD which\nmight not be in its fully reduced form; hence the need for a ﬁnal call to\n388\n6 Binary decision diagrams\nthe reduce function. However, this procedure would be unacceptable if ap-\nplied to realistically sized systems with a large number of variables, for the\ntruth table’s size is exponential in the number of boolean variables. The\nkey idea and attraction of applying OBDDs to ﬁnite systems is therefore to\ntake a system description in a language such as SMV and to synthesise the\nOBDD directly, without having to go via intermediate representations (such\nas binary decision trees or truth tables) which are exponential in size.\nSMV allows us to deﬁne the next value of a variable in terms of the\ncurrent values of variables (see the examples of code in Section 3.3.2)3. This\ncan be compiled into a set of boolean functions fi, one for each variable xi,\nBf (reduced)\nB∃x1.∃x2....∃xn.f (reduced)\nNP-complete\nFigure 6.23. Upper bounds in terms of the input OBDD(s) for the\nworst-case running times of our algorithms needed in our implementa-\ntion of boolean formulas.\n6.2.5 Assessment of OBDDs\nTime complexities for computing OBDDs\nWe can measure the com-\nplexity of the algorithms of the preceding section by giving upper bounds\nfor the running time in terms of the sizes of the input OBDDs. The table\nin Figure 6.23 summarises these upper bounds (some of those upper bounds\nmay require more sophisticated versions of the algorithms than the versions\npresented in this chapter). All the operations except nested boolean quantiﬁ-\ncation are practically eﬃcient in the size of the participating OBDDs. Thus,\nmodelling very large systems with this approach will work if the OBDDs\n6.2 Algorithms for reduced OBDDs\n381\nwhich represent the systems don’t grow too large too fast. If we can some-\nhow control the size of OBDDs, e.g. by using good heuristics for the choice\nof variable ordering, then these operations are computationally feasible. It\nhas already been shown that OBDDs modelling certain classes of systems\nand networks don’t grow excessively.\nThe expensive computational operations are the nested boolean quantiﬁ-\ncations ∃z1. . . . ∃zn.f and ∀z1. . . . ∀zn.f. By exercise 1 on page 406, the com-\nputation of the OBDD for ∃z1. . . . ∃zn.f, given the OBDD for f, is an NP-\ncomplete problem2; thus, it is unlikely that there exists an algorithm with\na feasible worst-time complexity. This is not to say that boolean functions\nmodelling practical systems may not have eﬃcient nested boolean quan-\ntiﬁcations. The performance of our algorithms can be improved by using\nfurther optimisation techniques, such as parallelisation.\nNote that the operations apply, restrict, etc. are only eﬃcient in the\nsize of the input OBDDs. So if a function f does not have a compact repre-\nsentation as an OBDD, then computing with its OBDD will not be eﬃcient.\nThis can easily be generalised to a sequence of exists operations. We\nwrite ∃ˆx. f to mean ∃x1.∃x2. . . . ∃xn. f, where ˆx denotes (x1, x2, . . . , xn).\n6.2 Algorithms for reduced OBDDs\n379\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\n1\n0\nx1\nx2\ny1\ny2\nx1\nx2\ny1\ny2\ny3\nFigure 6.20. restrict(0, x3, Bf) and restrict(1, x3, Bf) and the result\nof applying + to them.\n1\n0\nx1\nx2\nx3\ny1\ny2\ny3\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\nx1\ny1\ny2\ny3\n∃x3\n⇒\n∃x2\n⇒\nFigure 6.21. OBDDs for f, ∃x3. f and ∃x2.∃x3. f.\nThe OBDD for this boolean function is obtained from the OBDD for f by\nreplacing every node labelled with an xi by the + of its two branches.\nFigure 6.21 shows the computation of ∃x3. f and ∃x2.∃x3. f (which is\nsemantically equivalent to x1 · y1 + y2 + y3) in this way.\nThe boolean quantiﬁer ∀is the dual of ∃:\n∀x.f\ndef\n= f[0/x] · f[1/x]\nasserting that f could be made false by putting x to 0 or to 1.\nThe translation of boolean formulas into OBDDs using the algorithms of\nthis section is summarised in Figure 6.22.\n380\n6 Binary decision diagrams\nBoolean formula f\nRepresenting OBDD Bf\n0\nB0 (Fig. 6.6)\n1\nB1 (Fig. 6.6)\nx\nBx (Fig. 6.6)\nf\nswap the 0- and 1-nodes in Bf\nf + g\napply (+, Bf, Bg)\nf · g\napply (· , Bf, Bg)\nf ⊕g\napply (⊕, Bf, Bg)\nf[1/x]\nrestrict (1, x, Bf)\nf[0/x]\nrestrict (0, x, Bf)\n∃x.f\napply (+, Bf[0/x], Bf[1/x])\n∀x.f\napply (· , Bf[0/x], Bf[1/x])\nFigure 6.22. Translating boolean formulas f to OBDDs Bf, given a\nfixed, global ordering on boolean variables.\nAlgorithm Input OBDD(s)\nOutput OBDD\nTime-complexity\nreduce\nB\nreduced B\nO(|B| · log |B|)\napply\nBf, Bg (reduced) Bf op g (reduced)\nO(|Bf| · |Bg|)\nrestrict Bf (reduced)\nBf[0/x] or Bf[1/x] (reduced) O(|Bf| · log |Bf|)\n∃\nBf (reduced)\nB∃x1.∃x2....∃xn.f (reduced)\nNP-complete\nFigure 6.23. Upper bounds in terms of the input OBDD(s) for the\nworst-case running times of our algorithms needed in our implementa-\ntion of boolean formulas.\n6.2.5 Assessment of OBDDs\nTime complexities for computing OBDDs\nWe can measure the com-\nin which we applied the reductions does not matter. We therefore say that\nOBDDs have a canonical form, namely their unique reduced OBDD. Most\nother representations (conjunctive normal forms, etc.) do not have canonical\nforms.\nThe algorithms for · and + for BDDs, presented in Section 6.1.2, won’t\nwork for OBDDs as they may introduce multiple occurrences of the same\nvariable on a path. We will soon develop more sophisticated algorithms\nfor these operations on OBDDs, which exploit the compatible ordering of\nvariables in paths.\nOBDDs allow compact representations of certain classes of boolean func-\ntions which only have exponential representations in other systems, such as\ntruth tables and conjunctive normal forms. As an example consider the even\nparity function feven(x1, x2, . . . , xn) which is deﬁned to be 1 if there is an\neven number of variables xi with value 1; otherwise, it is deﬁned to be 0.\nIts representation as an OBDD requires only 2n + 1 nodes. Its OBDD for\nn = 4 and the ordering [x1, x2, x3, x4] can be found in Figure 6.11.\nThe impact of the chosen variable ordering\nThe size of the OBDD\nrepresenting the parity functions is independent of the chosen variable or-\ndering. This is because the parity functions are themselves independent of\nthe order of variables: swapping the values of any two variables does not\nchange the value of the function; such functions are called symmetric.\nHowever, in general the chosen variable ordering makes a signiﬁcant dif-\nference to the size of the OBDD representing a given function. Consider\nthe boolean function (x1 + x2) · (x3 + x4) · · · · · (x2n−1 + x2n); it corresponds\nto a propositional formula in conjunctive normal form. If we choose the\n1 In an implementation this will amount to checking whether two pointers are equal.\n370\n6 Binary decision diagrams\n1\n0\nx1\nx2\nx3\nx4\nx3\nx2\nx4\nFigure 6.11. An OBDD for the even parity function for four bits.\n‘natural’ ordering [x1, x2, x3, x4, . . . ], then we can represent this function as\n1 In an implementation this will amount to checking whether two pointers are equal.\n370\n6 Binary decision diagrams\n1\n0\nx1\nx2\nx3\nx4\nx3\nx2\nx4\nFigure 6.11. An OBDD for the even parity function for four bits.\n‘natural’ ordering [x1, x2, x3, x4, . . . ], then we can represent this function as\nan OBDD with 2n + 2 nodes. Figure 6.12 shows the resulting OBDD for\nn = 3. Unfortunately, if we choose instead the ordering\n[x1, x3, . . . , x2n−1, x2, x4, . . . , x2n]\nthe resulting OBDD requires 2n+1 nodes; the OBDD for n = 3 can be seen\nin Figure 6.13.\nThe sensitivity of the size of an OBDD to the particular variable order-\ning is a price we pay for all the advantages that OBDDs have over BDDs.\nAlthough ﬁnding the optimal ordering is itself a computationally expensive\nproblem, there are good heuristics which will usually produce a fairly good\nordering. Later on we return to this issue in discussions of applications.\nThe importance of canonical representation\nThe importance of\nhaving a canonical form for OBDDs in conjunction with an eﬃcient test for\ndeciding whether two reduced OBDDs are isomorphic cannot be overesti-\nmated. It allows us to perform the following tests:\nAbsence of redundant variables. If the value of the boolean function\nf(x1, x2, . . . , xn) does not depend on the value of xi, then any reduced\nOBDD which represents f does not contain any xi-node.\nTest for semantic equivalence. If two functions f(x1, x2, . . . , xn) and\ng(x1, x2, . . . , xn) are represented by OBDDs Bf, respectively Bg, with a\ncompatible ordering of variables, then we can eﬃciently decide whether f\nand g are semantically equivalent. We reduce Bf and Bg (if necessary); f\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\nsize of an OBDD: the OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with\nvariable ordering [x1, x3, x5, x2, x4, x6].\n372\n6 Binary decision diagrams\nand g denote the same boolean functions if, and only if, the reduced OBDDs\nhave identical structure.\nTest for validity. We can test a function f(x1, x2, . . . , xn) for validity (i.e.\nf always computes 1) in the following way. Compute a reduced OBDD for\nf. Then f is valid if, and only if, its reduced OBDD is B1.\nTest for implication. We can test whether f(x1, x2, . . . , xn) implies g(x1,\nx2, . . . , xn) (i.e. whenever f computes 1, then so does g) by computing the\nreduced OBDD for f · g. This is B0 iﬀthe implication holds.\nTest for satisﬁability. We can test a function f(x1, x2, . . . , xn) for satis-\nﬁability (f computes 1 for at least one assignment of 0 and 1 values to its\nvariables). The function f is satisﬁable iﬀits reduced OBDD is not B0.\n6.2 Algorithms for reduced OBDDs\n6.2.1 The algorithm reduce\nThe reductions C1–C3 are at the core of any serious use of OBDDs, for\nwhenever we construct a BDD we will want to convert it to its reduced form.\nIn this section, we describe an algorithm reduce which does this eﬃciently\nfor ordered BDDs.\nIf the ordering of B is [x1, x2, . . . , xl], then B has at most l + 1 layers. The\nalgorithm reduce now traverses B layer by layer in a bottom-up fashion,\nbeginning with the terminal nodes. In traversing B, it assigns an integer\nlabel id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\n(R1, S1)\nx1\nx2\nx3\n(R3, S3)\n(R2, S3)\n(R3, S2)\nx4\nx3\n(R5, S4)\n(R6, S5)\n(R4, S3)\n(R6, S3)\n(R4, S3)\n(R4, S3)\nx4\n(R5, S4)\n(R6, S5)\n(R6, S5)\nx4\n(R6, S5)\nx4\n(R5, S4)\n(R6, S4)\n(R6, S5)\nFigure 6.16. The recursive call structure of apply for the example in\nFigure 6.15 (without memoisation).\n0\n1\nx4\nx3\nx2\nx1\nFigure 6.17. The result of apply (+, Bf, Bg), where Bf and Bg are given\nin Figure 6.15.\n6.2 Algorithms for reduced OBDDs\n377\nthe ﬁrst time and the result remembered for future calls. This program-\nming technique is known as memoisation. As well as being more eﬃcient,\nit has the advantage that the resulting OBDD requires less reduction. (In\nthis example, using memoisation eliminates the need for the ﬁnal call to\nreduce altogether.) Without memoisation, apply is exponential in the size\nof its arguments, since each non-leaf call generates a further two calls. With\nmemoisation, the number of calls to apply is bounded by 2 · |Bf| · |Bg|, where\n|B| is the size of the BDD. This is a worst-time complexity; the actual per-\nformance is often much better than this.\n6.2.3 The algorithm restrict\nGiven an OBDD Bf representing a boolean formula f, we need an algo-\nrithm restrict such that the call restrict(0, x, Bf) computes the reduced\nOBDD representing f[0/x] using the same variable ordering as Bf. The al-\ngorithm for restrict(0, x, Bf) works as follows. For each node n labelled\nwith x, incoming edges are redirected to lo(n) and n is removed. Then we\ncall reduce on the resulting OBDD. The call restrict (1, x, Bf) proceeds\nsimilarly, only we now redirect incoming edges to hi(n).\n6.2.4 The algorithm exists\nA boolean function can be thought of as putting a constraint on the values\nof its argument variables. For example, the function x + (y · z) evaluates to 1\nonly if x is 1; or y is 0 and z is 1 – this is a constraint on x, y, and z.\nIt is useful to be able to express the relaxation of the constraint on a subset\nof the variables concerned. To allow this, we write ∃x. f for the boolean alone must take responsibility for those.\nAdded for second edition\nMany people have helped improve this text by pointing out typos and\nmaking other useful comments after the publication date. Among them,\nxiii\nxiv\nAcknowledgements\nwe mention Wolfgang Ahrendt, Yasuhiro Ajiro, Torben Amtoft, Stephan\nAndrei, Bernhard Beckert, Jonathan Brown, James Caldwell, Ruchira Datta,\nAmy Felty, Dimitar Guelev, Hirotsugu Kakugawa, Kamran Kashef, Markus\nKr¨otzsch, Jagun Kwon, Ranko Lazic, David Makinson, Alexander Miczo,\nAart Middeldorp, Robert Morelli, Prakash Panangaden, Aileen Paraguya,\nFrank Pfenning, Shekhar Pradhan, Koichi Takahashi, Kazunori Ueda,\nHiroshi Watanabe, Fuzhi Wang and Reinhard Wilhelm.\n1\nPropositional logic\nThe aim of logic in computer science is to develop languages to model the\nsituations we encounter as computer science professionals, in such a way\nthat we can reason about them formally. Reasoning about situations means\nconstructing arguments about them; we want to do this formally, so that\nthe arguments are valid and can be defended rigorously, or executed on a\nmachine.\nConsider the following argument:\nExample 1.1 If the train arrives late and there are no taxis at the station,\nthen John is late for his meeting. John is not late for his meeting. The train\ndid arrive late. Therefore, there were taxis at the station.\nIntuitively, the argument is valid, since if we put the ﬁrst sentence and\nthe third sentence together, they tell us that if there are no taxis, then John\nwill be late. The second sentence tells us that he was not late, so it must be\nthe case that there were taxis.\nMuch of this book will be concerned with arguments that have this struc-\nture, namely, that consist of a number of sentences followed by the word\n‘therefore’ and then another sentence. The argument is valid if the sentence\nafter the ‘therefore’ logically follows from the sentences before it. Exactly\nwhat we mean by ‘follows from’ is the subject of this chapter and the next\none.\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nexamples, as are variables such as x and v. Function symbols also allow us\nto refer to objects: thus, m(a) and g(x, y) are also objects. Expressions in\npredicate logic which denote objects are called terms.\nThe other sort of things in predicate logic denotes truth values; expres-\nsions of this kind are formulas: Y (x, m(x)) is a formula, though x and m(x)\nare terms.\nA predicate vocabulary consists of three sets: a set of predicate symbols\nP, a set of function symbols F and a set of constant symbols C. Each pred-\nicate symbol and each function symbol comes with an arity, the number of\narguments it expects. In fact, constants can be thought of as functions which\ndon’t take any arguments (and we even drop the argument brackets) – there-\nfore, constants live in the set F together with the ‘true’ functions which do\ntake arguments. From now on, we will drop the set C, since it is convenient to\ndo so, and stipulate that constants are 0-arity, so-called nullary, functions.\n2.2.1 Terms\nThe terms of our language are made up of variables, constant symbols\nand functions applied to those. Functions may be nested, as in m(m(x))\nor g(m(a), c): the grade obtained by Andy’s mother in the course c.\nDeﬁnition 2.1 Terms are deﬁned as follows.\nr Any variable is a term.\nr If c ∈F is a nullary function, then c is a term.\nr If t1, t2, . . . , tn are terms and f ∈F has arity n > 0, then f(t1, t2, . . . , tn) is a\nterm.\nr Nothing else is a term.\nIn Backus Naur form we may write\nt ::= x | c | f(t, . . . , t)\nwhere x ranges over a set of variables var, c over nullary function symbols\nin F, and f over those elements of F with arity n > 0.\nIt is important to note that\nr the ﬁrst building blocks of terms are constants (nullary functions) and variables;\nr more complex terms are built from function symbols using as many previously\nbuilt terms as required by such function symbols; and\nr the notion of terms is dependent on the set F. If you change it, you change the\nset of terms.\n100\nreplaced by every student’s name in turn. Similarly, when trying to codify\na sentence having to do with the execution of a program, it would be rather\nlaborious to have to write down every state of the computer. Therefore,\nwe employ the concept of a variable. Variables are written u, v, w, x, y, z, . . .\nor x1, y3, u5, . . . and can be thought of as place holders for concrete values\n(like a student, or a program state). Using variables, we can now specify the\nmeanings of S, I and Y more formally:\nS(x) :\nx is a student\nI(x) :\nx is an instructor\nY (x, y) :\nx is younger than y.\nNote that the names of the variables are not important, provided that we\nuse them consistently. We can state the intended meaning of I by writing\nI(y) :\ny is an instructor\nor, equivalently, by writing\nI(z) :\nz is an instructor.\nVariables are mere place holders for objects. The availability of variables is\nstill not suﬃcient for capturing the essence of the example sentence above.\nWe need to convey the meaning of ‘Every student x is younger than some\ninstructor y.’ This is where we need to introduce quantiﬁers ∀(read: ‘for\nall’) and ∃(read: ‘there exists’ or ‘for some’) which always come attached\nto a variable, as in ∀x (‘for all x’) or in ∃z (‘there exists z’, or ‘there is some\nz’). Now we can write the example sentence in an entirely symbolic way as\n∀x (S(x) →(∃y (I(y) ∧Y (x, y)))).\n2.1 The need for a richer language\n95\nActually, this encoding is rather a paraphrase of the original sentence. In\nour example, the re-translation results in\nFor every x, if x is a student, then there is some y which is an\ninstructor such that x is younger than y.\nDiﬀerent predicates can have a diﬀerent number of arguments. The predi-\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\n312\n5 Modal logics and agents\n→\nφ\nφ\n3\n2\nFigure 5.4. The parse tree of the formula scheme φ →23φ.\nbelow. Even 2⊥is true in x6. If you wanted to convince someone that 2⊥\nwas not true in x6, you’d have to show that there is a world accessible from\nx6 in which ⊥is not true; but you can’t do this, for there are no worlds\naccessible from x6. So again, although ⊥is false in every world, 2⊥might\nnot be false. In fact, x ⊩2⊥holds iﬀx has no accessible worlds.\nFormulas and formula schemes\nThe grammar in (5.1) speciﬁes ex-\nactly the formulas of basic modal logic, given a set of atomic formulas. For\nexample, p →23p is such a formula. It is sometimes useful to talk about\na whole family of formulas which have the same ‘shape;’ these are called\nformula schemes. For example, φ →23φ is a formula scheme. Any formula\nwhich has the shape of a certain formula scheme is called an instance of the\nscheme. For example,\nr p →23p\nr q →23q\nr (p ∧3q) →23(p ∧3q)\nare all instances of the scheme φ →23φ. An example of a formula scheme\nof propositional logic is φ ∧ψ →ψ. We may think of a formula scheme as\nan under-speciﬁed parse tree, where certain portions of the tree still need to\nbe supplied – e.g. the tree of φ →23φ is found in Figure 5.4.\n5.2 Basic modal logic\n313\nSemantically, a scheme can be thought of as the conjunction of all its\ninstances – since there are generally inﬁnitely many such instances, this\ncannot be carried out syntactically! We say that a world/model satisﬁes a\nscheme if it satisﬁes all its instances. Note that an instance being satisﬁed\nin a Kripke model does not imply that the whole scheme is satisﬁed. For\nexample, we may have a Kripke model in which all worlds satisfy ¬p ∨q,\nbut at least one world does not satisfy ¬q ∨p; the scheme ¬φ ∨ψ is not\nsatisﬁed.\nEquivalences between modal formulas\nDeﬁnition 5.7 1.\nWe say that a set of formulas Γ of basic modal logic seman-\ntically entails a formula ψ of basic modal logic if, in any world x of any model\n9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional\nto predicate logic, let’s now look at how the semantics of predicate logic\nworks. Just like in the propositional case, the semantics should provide a\nseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-\nrate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent\nway; in proof theory, they were deﬁned by proof rules providing an oper-\native explanation. In semantics, we expect something like truth tables. By\n‘equivalent,’ we mean that we should be able to prove soundness and com-\npleteness, as we did for propositional logic – although a fully ﬂedged proof\nof soundness and completeness for predicate logic is beyond the scope of this\nbook.\nBefore we begin describing the semantics of predicate logic, let us look\nmore closely at the real diﬀerence between a semantic and a proof-theoretic\naccount. In proof theory, the basic object which is constructed is a proof.\nLet us write Γ as a shorthand for lists of formulas φ1, φ2, . . . , φn. Thus, to\nshow that Γ ⊢ψ is valid, we need to provide a proof of ψ from Γ. Yet,\nhow can we show that ψ is not a consequence of Γ? Intuitively, this is\nharder; how can you possibly show that there is no proof of something?\nYou would have to consider every ‘candidate’ proof and show it is not one.\nThus, proof theory gives a ‘positive’ characterisation of the logic; it pro-\nvides convincing evidence for assertions like ‘Γ ⊢ψ is valid,’ but it is not\nvery useful for establishing evidence for assertions of the form ‘Γ ⊢φ is not\nvalid.’\n2.4 Semantics of predicate logic\n123\nSemantics, on the other hand, works in the opposite way. To show that ψ\nis not a consequence of Γ is the ‘easy’ bit: ﬁnd a model in which all φi are\ntrue, but ψ isn’t. Showing that ψ is a consequence of Γ, on the other hand,\nis harder in principle. For propositional logic, you need to show that every\nvaluation (an assignment of truth values to all atoms involved) that makes ‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula",
            "summary": "If we combine declarative sentences p and q with a logical connective, say                , the truth value of p is determined by three things. The meaning of  is captured by the observation that p is true iﬀp and q are both true; otherwise p is false. As far as  is concerned, it needs only to know whether p andQ are true, it does not need to know what p andq are actually saying about the world out there.  A valuation or model of a formula φ is an assignment of each propositional atom in φ to a truth value. The set of truth values contains two elements T and F, where T represents 'true' and F represents 'false' This is also the case for all the other logical connectives and is the reason why we can compute the truth value of a Formula just by knowing the truth values of the atomic propositions occurring in it. In the ﬁrst column, labelled φ, we list all possible valuations for a formula. We can think of the meaning of φ as a function of two arguments; each argument is a truthvalue. Wespecify this function in a table, called the truth The truth table for conjunction, the logical connective, is shown in Figure 1. The possible number of combinations of truthvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of ω and ωmeans F, so the disjunction of F and F is still F. We have to take that result,                F, and compute its conjunction with the meaning of p which is T. The result is that T is the right subtree of the right subree of F. The truth tables for all logical connectives discussed so far are shown in Figures 1.6 and 1.7. For example, the table for the conjunction of T with F is given by the formula Figure 1.7 shows how the truth values propagate upwards to reach the root. The associated truth value is the truth value of φ given the meanings of p, q and r above. Figure 1.8 contains a truth table for the formula (p →¬q) →                (q ∨¬p), which is T. To evaluate the meaning of χ, we compute F →F which is F. The truth table can be used to build atruth table for more com-                plex formulas. For example, we can use the table to compute the column of p → q for a formula that has the meaning (p, q, r) as the root of the formula. Column 6 works similarly, only we need to look up the truth table for. Column 2 and 3 as input. Propositional logic is a logical formula under a given valuation. Figure 1.8 is a simplified version of the logical formula in the original version of this article. For more information, see the book, The Logic of Proposalitional Logic, and the book’s online version, which is published by Oxford University Press, priced £16.99. Given a formula φ which contains the propositional atoms p1, p2, . . . , pn, we can construct a truth table for φ, at least in principle. Using the truth tables for ¬ and ∨you can check that φ → ω evaluates. This means that ω and φ are semantically equivalent; more on that in Section 1.5. In section 1.4.2 Mathematical induction we will look at the inductive part of propositional logic. We will also look at logical induction in section 2.2 of the book. The final section will be about the logical consequences of the inductions we have already seen. For large n this task is impossible tocomplete. Our aim is to compute the value of φ for each of these 2ncases for moderately small values of n. The beauty of our semantics is that we know the meaning of the subformulas ¬p, q and r. Therefore, we can do the calculation by traversing the parse treeof φ in a bottom-up fashion. The result is that φ is an implication of these two sub-formulas. It involves three propositional atoms (n = 3) so we have 23 = 8774cases to consider. We illustrate how things go for one particular case, namely for the val-                uation in which q evaluates to F; and p and We know what its leaves evaluate to since westated what the atoms p, q and r evaluated to. Because the meaning of p is T, we see that ¬p computes to F. Now q is assumed to represent F and theconjunction of F and F is F. Thus, the left subtree of the node →evaluates                to F. As for the right subtrees of →, r stands for T so ¬r compute to F and q                means F. We have to take that result,                F, and compute its conjunction with the meaning, p which is T. Since the conjunction of T and F, F, is F, we get F as themeaning of the In Figure 1.6 you can see the truth tables for all logical connectives of propo-                sitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the mirror image of conjunction if we swap T and F, namely, a disjunction re-turns F iﬀboth arguments are equal to F. The behaviour of implication is not quite intuitive. Think of the meaning of →as checking whether truth is beingpreserved. For example, in the second entry in the column φ → ψ equals F, while in the third column the result is T, which is the same for all other lines. If at least one of the two arguments equals T, If you feel slightly uncomfortable with the semantics (= the meaning) of φ, then it might be good to think of it as an abbreviation of the formula ¬φ ∨ψ. The two formulas are very syntactically and natural deduction treats them diﬀerently as well. For example, using the truth tables for ¬ and ∨you can check that φ →ψ evaluates T iﬄ¬ φ i ﬀ¬  φ  does so. In Section 1.5.4 Semantics of propositional logic we will look at the meaning of the words T, F, T, and F. CNF's formula for a formula φ will be false if at least one of its conjuncts is false. That conjunct is now obtained by a disjunction of literals. The resulting formula in CNF is thus ¬p ∨q which is readily seen to be in C NF and to be equivalent to (p →¬q) →(q ∨¬p).Why does this always work for any formula? Well, the constructed                formula will be true if all the disjuncts in such a ψi must be F. Using the de Morgan5858 Propositional logic rule, we infer that the con- autoimmunejunction The truth table is really just a speciﬁcation of φ. It does not tell us what φ looks like syntactically, but it does tell us how it ought to ‘behave’ Since this truth table has four entries which compute F, we construct four con-                juncts ψi (1 ≤i ≤4) The resulting φ in CNF is therefore φ(¬p ∨¬q ∨r)  (p  ‘q’ ’r’)  (‘p’ ‘’’, ‘p.’  ’‘”, � The formula for φ is well-formed and can be used to construct a full truth table of φ and an equivalent formula in the form: p ∧¬(p ∨¬q) →(r →s) Figure 1.3 on page 34 is a parse tree of a negated implication. The formula is represented by the parse tree in Figures 1.1 and 1.2 on the same page. The truth table for ¬p  q can be constructed by constructing the table for p  p q and verifying that the columns of T and F values are the same. The formulas for the truth table and the formula can be combined to produce a full table of the formula in Given a valuation and a parsetree of a formula, compute the truth value of the                formula for that valuation. Compute thetruth value on the formula’s parse tree, or specify the corresponding line of a truth table. Is the formula of the parse tree in Figure 1.10 on page 44 valid? Is it satisﬁable? Is the truthvalue of the truth table of the formula valid? The formula is valid iﬀit computes T for all its valuations. The truth table is valid for at least one of the valuations that it is valid to compute. It is valid if and only if the formula can be proved to be true. Let φ and ψ be formulas of propositional logic. We say that they are semantically equivalent if they hold. We call φ valid if it holds. Let p and q be a new logical connective such that p does not hold iﬀp and q are either both false or both true. The truth table for p is four lines long, whereas the one for r is only two lines long. This suggests that we deﬁne the equivalence of formulas χ and ω via ⊨. We could also have said that φ is valid if ω is valid, but this amounts to the same thing. We conclude that the formulas are valid as far as our truth- Because of soundness and completeness, semantic equivalence is identical to provable equivalence. The lemma says that any decisionprocedure for tautologies is in fact a decision procedure for the validity of                sequents as well. Examples of equivalent formulas are                p →q ≡¬q →¬p                p ⊨¬r ≡p →(q →r)                p   p  q  Q  P   Q   P  P 1.5 Normal forms                55                (Deﬁnition 1.25) 2. Normal forms                 55                                       P 1.1. We want to transform formulas into ones which don’t contain →at all. The occurrences of  and are conﬁned to bind most closely. This convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. In basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when we apply modal logics to express various modes of truth, we may read them appropriately. We have already shown that ⊨φ1 →( φ2 →(φ3 →) follows in step 1 of our completeness proof. We cannot omit the remaining brackets, however, for For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. A model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W →P(Atoms) These models are often called Kripke models, in honour of S. Kripk who invented them in the 1950s and 1960s. For example, consider the BDD inFigure 6.7. The parse tree for 23q ∧¬r →2p. The labels on each node are the result of f for that particular assignment of truth values. A BDD represents a satisﬁable function if a 1-terminal node is reachable from the root along a consistent path in a BDD which represents it. A consistent path is one which, for every variable, has only dashed lines or only solid lines leaving nodes labelled by that variable. The solid link from the left-most x to the 1-Terminal is never taken, for example, because one can only get to that x-node when x has value 0.Thanks to the reductions C1–C3, BDDs can often be quite compact rep-resentations of boolean functions. The operations · and + can be performed by ‘surgery’ on the componentBDDs. Given BDDs Bf and Bg representing boolean functions f and g, a BDD representing f · g can be obtained by taking the BDD f and replacing all its 1-terminals by Bg. Since f’s truth table has 2n lines, we see that decision trees as such are not a more compact representation of boolean functions.    A BDD where some boolean variables occur more than once on an evaluation path is called a ‘decision tree’ and can be found in the ‘Decision Tree’ section of this article. Binary decision trees often contain some redun-                dancy which we can exploit. Since 0 and 1 are the only terminal nodes of binary decision trees, we canoptimise the representation. For example, the binary decision tree in Figure 6.2 can beoptimised in this way. A second optimisation we can do is to remove unnecessary decision points in the tree. In Figure.3(a), the right-hand y is unnecessary, because we go to the same place whether it is 0 or 1.Figure 6.4. A BDD with duplicated subBDDs. The resulting structure is depicted in Figure.6.1 Representing boolean functions. Binary decision diagrams (BDDs) are more general than binary decision trees. The sharing of the leaves means that they are not trees. There are three ways of reducing a BDD to a more compact form:C1. Removal of duplicate terminals. C2. Sharing of subBDDs. C3. Reducing the number of nodes in the BDD from one to two or three to one or more. The BDD in Figure 6.5(a) could be further reduced to the one shown on the right, (b), by removing one of the y-nodes above the left-most y-node and merging it with the middle-most one. For example, in Figure. 6.4, Every variable occurs exactly once as one travels down any path of the tree T. Use mathematical induction to show that T has                2n+1 −1 nodes. Find a BDD for that function which does not have multiple occurrences of                variables along any path. Find an equivalent reduced BDD with ordering [z, y, x].    Find the truth table for the function f(x, y,. z) represented by the BDD of Figure 6.3(b)   The BDDs representing the B0, B1 and Bx are illustrated in Figures 6.6, 6.7 and 6.8. Use these diagrams to understand how to reduce a tree to a tree of n Consider the BDDs in Figures 6.4–6.10. Determine which of them are OBDDs. Compute their unique reduced OBDD with respect to the ordering [x, y, z]. It is advisable to compute a binary decision tree and then to perform the removal of redundancies. Recall the derived connective φ from Chapter 1 saying that for all valuations φ is true if, and only if, ψ is true. Consider the following boolean formulas: f(x), f(y), f (x),f (y),f(x, z) and f (y, z), f(\"x\"),f (\"y\"),f \"x\",f \"y\",f The OBDD for (x1 + x2) · (x3 + x4) ·  (x5 + x6) with a variable ordering is called a 'reduced OBDDs' It can be used to test whether a function f is valid, valid, or not. Changing the ordering may have dramatic effects on the size of an OBDd. The following diagram shows how this can be done for a number of different types of functions. For example, a function called f(x1, x2, . . . , xn) is valid if it always computes 1. It is not valid if its reduced OBD d is B1, which is B0. The reductions C1–C3 are at the core of any serious use of OBDDs. The function f is satisﬁable iﬀits reduced OBDD is not B0. The algorithm reduce traverses B layer by layer in a bottom-up fashion, beginning with the terminal nodes. In traversing B, it assigns an integerlabel id(n) to each node n of B, in such a way that the subOBDDs withroot nodes n and m denote the same boolean function if, and only if, id(m) and id( n) are equal. The reduce algorithm starts with the layer of terminal nodes, and it assigns the ﬁrst integer Exercises 6.1.2 and 6.3. Write down a BNF for the syntax of boolean formulas based on the operations in Deﬁnition 6.2 on page 359. The BNF is a list of the truth tables for the formulas in the binary decision tree of Fig-                ure 6. 2. The final exercise is to write down the truth table for the formula f(x, y) in terms of ·, +, ¯, 0 and 1, such that f (x) has the same truth table as p (y) (F) (Q) (T) (A) (B) (C) (D) (E) Exercises: Construct a binary decision tree for a boolean function f(x1, x2, . . . , xn) of nolean variables. Write out the truth table of the resulting binary decisionTree and ﬁnd a formula for it. Exercises 4.2-4.5 Exercise 6.1-6.1 Exercising 6.2.5 Exercise 7.3-8 Exercised 6.4-9 Exercisable 6.5-8 Exercise 8.9-10 Exerciser: Exercizer: Figure 8.1. Figure 9.2 Exercisers: Figure 10.1, Figure 11, Figure 12. A simple CTL model (Example 6.12) can be used to prove that every variable occurs exactly once as one travels down the tree. The OBDD of the OBDS represents state si. The tree T can be shown to have T has T has 2n+1 + 1 + 1 - 1 nodes. The CTL can also be used as a basis for other CTL models, such as the CTL-T model (Figure 6.13) and the C TL-T-L model (Figures 6.14, 6.15, and 6.16) CTL is a simple tree with nodes T, L, M, N, R, S, and S. The key point which makes this representation interesting is that the OBDD representing a set of states may be quite small. For all states s1 and s2, L(s1) = L (s2)implies s1 = s2. Sets of states can be represented by boolean values and by booleanformulas with the ordering [x1, x2] Figure 6.25. The vector (1, 1) and the corresponding function x1 · x2 are not used in the model. Therefore, we are free to include it in the representation of a subset of the set. Figure.6.3 Symbolic model checking for the size of a set. In order to justify the claim that the representation of subsets of S asOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need to find an ordering of variables for which the resulting reduced OBDD Bf has a minimal number of edges. (How many possible orderings for x, y and z are there?) For example, the subset {s0, s1} is better represented by the boolean function x1 + x2, since its O BDD is smaller than that for                x1 · x2 + x1 · X2 (Figure 6.26). The algorithm is then applied to all possible reductions of S. Consider the BDD in Figure 6.11 (page 370). Construct its truth table. Compute its conjunctive normal form. Compare the length of that normal form with the size of the B DD. compute the reduced BDDs for p and q and explain why they are identical. Given the ordering [p, q, r], compute the reductions for p (p) (q (q) (r) ( p) ( r) and (p q) (p r) ( q r (p p) p (q p) r (r p) 6.6.1. Perform the execution of reduce on the following OBDDs: The binary decision tree for x. x ⊕y The Shannon expansion is used to deﬁne formally how BDDs determineBoolean functions. Let B be a BDD. It is intuitively clear that B determines a unique boolean function. Formally, we compute a function fn inductively(bottom-up) for all nodes n of B. If n is a terminal node labelled 0, then fn is the constant 0 function. Given an assignment of 0s and 1s to the variables, f and g are semantically equivalent if, and only if, f + g computes 1 for all possible assignments of 1s and 0s to their variables. The Shannon expansion can be used to show that the Shannon expansion determines auniqueBoolean function. The binary decision tree of Figure 6.2 represents a booleanfunction f(x, y) To compute f(0, 1), start at the root of the tree. Since the value of x is 0, we follow the dashed line out of the node labelled x and arrive at the leftmost node labelled y. Since y’s value is 1, we following the solidline out of that y-node and arriving at the rightmost terminal node labelled 0. In computing f( 0, 0), we similarly travel down the tree, but now following two dashed lines to obtain 1 as a result. You can see that the two other possibilities result in reaching the remaining two terminal nodes labelled 0 and 0. Binary decision trees are quite close to the representation of boolean functions as far as their sizes are concerned. If the root of a binarydecision tree is an x-node then it has two subtrees (one for the value of x being 0 and another one for x having value 1) So if f depends on n booleanvariables, the corresponding binary decision tree will have at least 2n+1 −1                nodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we                see that decision trees as such are not a more compact representation of functions. However, binary decision trees often contain some redun- ring along any path. An ordered BDD (OBDD) is a BDD which has an ordering for some list of variables. The BDDs of Figures 6.3(a,b) and 6.9 are ordered (with ordering[x, y]. We don’t insist that every variable in the list is used in the paths. A BDD that does not have an ordering of variables is not an OBDD. Even the B DDs B0 and B1 in Figure 6.6 are OBDDs, a suitable ordering list being the empty list (there are no variables), or indeed any list. To see why this is so, consider the path taken if the values of x and y are 0. We cannot have multiple occurrences of any variable along a path. The path for (x, y, z) shows that y needs to occur before x in such a list. No matter what list arrangement we choose, this path violates the ordering condition. Since reduce starts with the layer of terminal nodes, it assigns the ﬁrstlabel (say #0) to the 0-node it encounters. The subOBDDs with root nodes n and m denote the same boolean function if, and only if, id(n)                equals id(m). The OBDDs that are not ordered can be seen in Figures 6.10 and 6.11. For example, we begin with the root, an x Let us inductively assume that reduce has already assigned integer.labels to all nodes of a layer > i. We describe how nodes of layer i (i.e. xi-nodes) are being handled. Given a non-terminal node n in a BDD, we deﬁne lo(n) to be the node pointed to via the dashed line from n. Dually, hi( n) is the node that is pointed to by lo (n) via the solid line fromn. There are three ways in which a node may get its label, depending on its function. We call these three ways of labelling the nodes the OBDDs are based on. If the label id(lo(n)) is the same as id(hi(n), then we set id(n) to be that label. In other words, node n performs a redundant test and can be eliminated by reduction C2. If there is another node m such that n and m have the same variable xi, then we use id(m) instead of id( n) This is because the nodes n andm compute the same boolean function (compare with reduction C3). Otherwise, we set n to the next unused integer label.Note that only the last case creates a new label. The algorithm is called reduce and is based on the OBDD algorithm. Algorithm reduce is an eﬃcient operation in the number of nodes of anOBDD. The algorithm apply is used to implement operations on boolean functions such as +, · , ⊕and F. The call apply (op, Bf, Bg) computes the reduced OBDD of the boolean formula f op g, where op denotes any function from {0, 1} to 0.6.2 The algorithm reduce then redirects the OBDDs bottom-up as outlined in C1–C3. Figure 6.14 is an example of an OBDD with a number of different nodes. The resulting reduced O BDD is in the left side of the Figure. The algorithm is based on the structure of the two OBDDs: Bf and Bg. The result will usually have to be reduced to make it into an OBDD. Somereduction can be done ‘on the ﬂy’ in step 2, by avoiding the creation of a new node if both branches are equal (in which case return the common result) or if an equivalent node already exists. The algorithm can also be used to solve problems for two subproblems for v being 0 and v being 1 and solve them recursively. For example, the algorithm can be used for solving the problem for the variable v being the leftmost in the list. Consider the BDD in Figure 6.11 (page 370) Construct its truth table. Compute its conjunctive normal form. Compare the length of that normal form with the size of the OBDD. Given the truth table, compute the reduced BDDs for p, q, r and explain why they are identical. The expressions f[0/x] and f[1/x) are called restrictions of f. The reduced O BDD Bf can be found by applying all possible reductions of f[ 0/x, f[ 1/x], f[ 2/x), f[ 3/x or f[ 4/x]. The BDD Bf has a minimal number of edges. 6. Perform the execution of reduce on the following OBDDs: The binary decision tree for x, y, and z. 7. Show that f and g are semantically equivalent if, and only if, the formula (f + g) computes 1 for all possible assignments of 1s and 1s to their variables. 9. Use the Shannon expansion to deﬁne formally how BDDs determineolean functions. 10. Use these exercises to understand how to use the binary decision diagrams in a real-life situation. 11. Use this information to help you understand the use of the OBDD in the real world. 12. Use it to develop your own understanding of the decision tree. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that this upper bound is hard, i.e. it cannot be improved. Describe informally how apply can be optimised when op has a controlling value. Compute the sum-of-product form of f (x1, x2, . . . , x2n+2m) and g (x2n-2m, x1-x2-x3m), and choose the ordering [x1,. x2,. x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, 6.5 Exercises: Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation. 6.8 Exercise: Compute the reduced OBDD for the restrictions: f[0/x] f[1/y] f [0/z]. 2.3 Exercised: compute the OBDDs Bf and Bg for a general composition f[g/x]. 3. The algorithm is now ready to be used in the next section of the book. The book is published by Oxford University Press, London, UK, priced £9.99 (including p&p) and £14.99 for non-UK copies. Every OBDD is a read-1-BDD; but not every read-2-BDC is an OBDC. We show that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that this upper bound is hard, i.e. it cannot be improved. Show that apply can be optimised when op has a left- or right-controlling value. We say that v is a controlling value if and only if it is a left or right value. And we show how this can be done in terms of the functions f (x1, x2, . . . , x2n+2m) and g (x 1, x 6.5 Exercises: Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation. 6.8 Exercise: Compute the reduced OBDD for the restrictions: f[0/x] f[1/y] f [0/z]. 2.3 Exercised: compute the OBDDs Bf and Bg for a general composition f[g/x]. 3. The algorithm is now ready to be used in the next section of the book. The book is published by Oxford University Press, London, UK, priced £9.99 (including p&p) and £14.99 for non-UK copies. Every OBDD is a read-1-BDD; but not all OBDDs are. The path for (x, y, z) ‘reads’ the                only if x is 1; or y is 0 and z is 1. It is useful to be able to express the relaxation of the constraint on a subset of the variables concerned. To allow this, we write ∃x. f for the function f with a relaxed constraint on x. The exists algorithm can be implemented in terms of the algorithms apply and restrict as follows: apply (+, restrict (0, x, Bf), restrict (1, x,. Bf) . The result of applying + to them is the same as applying The apply algorithm works on two BDDs which are identical all the way down to the level of the x-nodes. We can improve the eﬃciency of this algorithm by taking the OBDD for f and replacing eachnode labelled with x by the result of calling apply on + and its two branches. This can easily be generalised to a sequence of exists operations. For example, we can write f to mean ∃x1.∃x2. . . .          . .   .   .  —   —  — — —— — —– — —- — — –— —— – — —­ — — There are 2n boolean vectors (v1, v2, . . . , vn) of length n. N should be chosen such that 2n−1 < |S| ≤2n, where |S is the number of elements in S. The labelling function L : S →P(Atoms) gives us the encoding. f, where ˆx denotes (x1, x2,. . ., xn).                6.2.2 Algorithms for reduced OBDDs. The algorithm is based on the OBDD-2 algorithm, which has been used for many years in computer science. The algorithms are based on a number of different algorithms. We assume an ordering on the set Atoms, say x1, x2, . . . , xn. We then represent a state s by the vector (v1, v2,  vn), where, for each i, vi equals 1 if xi equals 1 and 0 otherwise. For all s1, s2, L(s1) = L (s2) implies s1 = s2. If this is not the case, perhaps because 2|Atoms| < |S|, we can add extra atomic propositions in order to make enough distinctions. The set of states is represented by the OBDD of the boolean function l1, l2, ln. Figure 6.24. A simple CTL model (Example 6.12). Figure 6.25. An OBDD of the boolean function. Figure 7. A binary decision diagram. Figure 8. A series of binary decision diagrams. Figure 9. A set of Binary Decision Diagrams (BDCs) Figure 10. A group of Binary Decisions (BCS) Figure 11. A pair of BinaryDecisions (BNCs)Figure 12. A single BinaryDecision (BCC) Figure 13. A BinaryDec decision (BCD) Figure 14. A Single BinaryDecoration (BCDC) Figure 15. A Pair of Binarydecisions (CCD)Figure 16. A Simple Decision ( The key point which makes this representation interesting is that the OBDD representing a set of states may be quite small. For all states s1 and s2, L(s1) = L (s2)implies s1 = s2. Sets of states can be represented by boolean values and by booleanformulas with the ordering [x1, x2] Figure 6.25. The vector (1, 1) and the corresponding function x1 · x2 are not used in the model. Therefore, we are free to include it in the representation of a subset of the set. Figure.6.3 Symbolic model checking for the size of a set. In order to justify the claim that the representation of subsets of S asOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need to explain how OBDDs were developed in the early 1990s. For example, the subset {s0, s1} is better represented by the boolean function x1 + x2, since its OBDD is smaller than that forx1 · x2 + x1 ·x2 (Figure 6.26). In this section, we describe in detail how the model-checking algorithm can be implemented using OBDds as the basic data structure. The pseudo-code presented in Figure 3.28 on page 227 takes as input Model checking using OBDDs is called symbolic model checking. The term purposefullyemphasises that individual states are not represented. Instead, sets of states are represented symbolically, namely, those which satisfy the formula beingchecked. We show in this section how the model and the intermediate sets ofStates can be stored as OBDD. We also show how the operations required in that pseudo-code can be implemented in terms of the operations on OBDDS which we have seen in this chapter. We conclude with a discussion of the implications of the model checking scheme for computer science. We hope that this will help you to understand the theory of computer science more fully. Back to the page you came from. There are 2n boolean vectors (v1, v2, . . . , vn) of length n. N should be chosen such that 2n−1 < |S| ≤2n, where |S | is the number of x. The truth table for the transition relation of Figure 6.24 is shown in the next section of the book. The book is published by Oxford University Press in the US and the UK at a cost of $1.99 per book. For more information, see the book’s official website and the book's English-language version at http://www.oxford.co.uk/books/book/features/book-notes/Book-notes-Book- The OBDD for the transition relation of Fig. 6.24 is shown as a truth table (Figure 6.27) Each 1 in the ﬁnal column corresponds to a link in the relation. Each 0 in the truth table corresponds to the absence of a link. As anOBDD, the link is represented by the OBD D for the boolean function (v1, v2, . . . , vn), where vi is 1 if pi ∈L(s) and 0 otherwise. For example, the entire relation → is a set of links (for example,  v1 v2 vn) with vi 1, vi 0, and so on. The model is free of states that deadlock: all states have a transition to some state. Figure 6.27 (right) shows the truth table redrawn with the interleaved ordering of the columns and the rowsreordered lexicographically. The resulting OBDD is shown in Figures 6.28 (left) and 6.3 (center) The formula for the transition relation of Example 6.13.4 is: R(x, y) P(x) R(y) P (x) P. (y) R (x), P (y), P. P (X) P, P (Y), P(Y),P (X),P. (Y,Y) P., The model M we have in mind has as set A all binary strings, including the empty string denoted by ϵ. The interpretation ·M of · is                the concatenation of words. For example, 0110 ·M 1110 equals 01101110. We say that s1 is a preﬁx of s2 if there is a binary word s3 such that  s1 ·M s3 equals s2. This is true in our model: a can move to a, b or c; and b and c                can move to c. The model M has a set A of words over the alphabet {0, 1}. The interpretation eM of e is just the empty word � In our model, every word is a preﬁx of itself concatenated with the empty word and vice versa. We use directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. Thus, ≤M is the set {(s1, s2) |                s1 is a prior of s2}. Here are again some informal model checks for our model. For example, the formula for a word s is true, for s ·M ϵ is just s and every word  is a Pre-Pre-Pre of itself. For a word  we may chose ϵ as such a word (there is no other choice in this case). The requirement in Deﬁnition 3.4 that for every s ∈S there is at least one s′ ∉S such that s →s′ means that no state of the system can ‘dead-lock’ is a technical convenience. If a system did deadlock, we could always add an extra state sd representing deadlock. We prefer to present models by means of such pictures whenever that is feasible. For example, if our system has only three states s0, s1 and s2, then we can condense this information into Figure 3.3.2. We label state s with l iff l ∉L(s) as a directed graph. A path in a model M = (S, →, L) is an inﬁnite sequence ofstates s1, s2, s3, . . . in S such that, for each i ≥1, si →si+1. We write the path as s1 →s2 →. . . and it represents a possible future of our system. See Figure 3.4 for such an example. The operations apply, restrict, etc.    to further optimisation techniques, such as parallelisation. For example, we could write a system with a state s4 that does not have any further transitions. On the right, we expand that system to have a state sd such that no Theorem 6.11: Any OBDD representation of fn−1 has at least a number of vertices proportional to 1.09n, i.e. are only eﬃcient in the size of the input OBDDs. So if a function f does not have a compact repre-sentation as an O BDD, then computing with it will not be e ﬁcient. The following negative result, due to R. E. Bryant, shows that O BDDs cannot be used for implementing integer multiplication. For example, multiplication of two n-bit integers results in a 2n-bit integer, where bn−1 and an−1an−2 are the most signi There are many variations and extensions to the OBDD data structure. Many of them can implement cer-                tain operations more eﬃciently than their OBDDs counterparts. But none of them perform as well as O BDDs overall. In particular, one fea-                ture which many of the variations lack is the canonical form; therefore they don't have an e-cient algorithm for deciding when two objects denote the same function. Another NP-complete problem is to decide the satisﬁability of formulas of propositional logic. For more information, see the Wikipedia article on OBDd data structures, and the Wikipedia entry for OBDs. 6.3.3 Implementing the functions pre∃and pre∀. Figure 6.27 (right) shows the truth                table redrawn with the interleaved ordering of the columns and the rowsreordered lexicographically. The resulting OBDD is shown in Figures 6.28 (left) and 6.29 (respectively) The meaning is that the function represented by                 is rather than [x1, x2, x′                ] rather than  x′                1, X′                2. The meaning of the word                 is that it is the term used to refer to a function. The method used in Example. 6.13 for producing an OBDD for the transi-portion relation was to compute ﬁrst the truth table and then an O.BDD which might not be in its fully reduced form. Now (6.4) suggests that one should proceed as follows: 1. rename the variables in BX to their primed versions; 2. compute the OBDDs for exists(ˆx′, apply(·, B→, BX′), and 3. Synthesise the results using the apply and exists algorithms (Sections 6.2.2 The idea of applying OBDDs to ﬁnite systems is to take a system description in a language such as SMV and to synthesise theOBDD directly. SMV allows us to deﬁne the next value of a variable in terms of the current values of variables (see the examples of code in Section 3.3.2) This can be compiled into a set of boolean functions fi, one for each variable xi, xi.f (reduced) and xn, n (increased) Figure 6.23.23 gives upper bounds for the running time of our algorithms needed in our implementa- hyperttion of boolean formulas. All the operations except nested boolean quantiﬁ-cation are practically eﬃcient in the size of the participating OBDDs. It has already been shown that OBDD modelling certain classes of systems and networks don’t grow excessively. The expensive computational operations are the nested Boolean quanti-cation. If we can control the size by using good heuristics for the choice of variable ordering, then these operations are computationally feasible. The table in Figure 6.23 summarises the upper bounds of these upper bounds. Some of those upper bounds may require more sophisticated versions of the algorithms than the versionspresented in this chapter. For example, the table on page 406, the com-                putation f, given the OBDD for f, is an NP-complete problem2; thus, it is unlikely that there exists an algorithm with                a feasible worst-time complexity. This is not to say that practical systems may not have eﬃcient nested boolean quan-                tiﬁcations. The performance of our algorithms can be improved by using further optimisation techniques, such as parallelisation. The operations apply, restrict, etc. are only e-cient in the size of the input OBDDs. So if a function f does not have a compact repre-                sentation as an OBD d, then computing with its OBDd will not be e-scientific. The OBDD for f is obtained by replacing every node labelled with an xi by the + of its two branches. F could be made false by putting x to 0 or to 1. The translation of boolean formulas into OBDDs using the algorithms of                this section is summarised in Figure 6.22. For f, f is the dual of f (which is the equivalent to x1 · y1 + y2 + y3) and f (f is the opposite of f) is the same as f(x1) (Fig. 6.6) FBDDs for f and f are shown in Figures 6.1, 6.2, and 6.3. Algorithm Input OBDD(s) Output OBDDs (reduced) O(|Bf| · log |Bf) Bf op g (red reduced) O (|Bg| · |Bg) Bg op op f (reducing) B f op op b (reduce) B g op op c (reduces) Bop g op Bg (red Reduced) Bp gop Bf (Reduced) Gop gop C (Reduce) Cop B (Reducing) Cops Bf [0/x] or Bf[1/x]. Cops O(Bf, Bg) Puts Bf on the 0- and The algorithms for · and + for BDDs, presented in Section 6.1.2, won’t work for OBDDs as they may introduce multiple occurrences of the samevariable on a path. We will soon develop more sophisticated algorithms for these operations on OBDD, which exploit the compatible ordering ofvariables in paths.OBDDs allow compact representations of certain classes of boolean func-tions which only have exponential representations in other systems, such astruth tables and conjunctive normal forms. As an example consider the evenparity function feven(x1, x2, . . . , xn) which is deﬁned to be The size of the OBDDrepresenting the parity functions is independent of the chosen variable or-dering. The chosen variable ordering makes a signiﬁcant dif-                ference to the size of a given function. In an implementation this will amount to checking whether two pointers are equal. If we choose the                1 In an Implementation this will Amount to Checking Whether Two pointers are Equal. The impact of the choosing variable ordering can be seen in Figure 6.11.7. The size of an even parity function for four bits can be found in Figure 7.1 in the ‘Even Parity Function’ section of this article. It is the same size as an even-parity function for The sensitivity of the size of an OBDD to the particular variable order is a price we pay for all the advantages that OBDDs have over BDDs. Although ﬁnding the optimal ordering is itself a computationally expensiveproblem, there are good heuristics which will usually produce a fairly good ordering. The resulting OBD D for n = 3 can be seen in Figure 6.13. The optimal ordering can be found at the bottom of the page by searching for the word ‘optimal’ in the ‘OBDD’ section of this article. The word “optimal ordering” is a term used to refer to the order in which two pointers are equal. Having a canonical form for OBDDs in conjunction with an eﬃcient test for                deciding whether two reduced OBDD are isomorphic cannot be overesti-                mated. It allows us to perform the following tests:Absence of redundant variables. If the value of the boolean function.f(x1, x2, . . . , xn) does not depend on the value. of xi, then any reducedOBDD which represents f does not contain any xi-node.Test for semantic equivalence. We reduce Bf and Bg (if necessary); f and g are semantically equivalent. Later on we return to this issue in discussions of applications. The OBDD for (x1 + x2) · (x3 + x4) ·. (x5 + x6) with. Variable ordering [x1, x2, x3, x4, x5, x6]. Changing the ordering may have dramatic effects on the size of the OBDDs. We can test a function f(x1,. x2,. . . , xn) for validity (i.e. f always computes 1) in the following way. Compute a reduced OBDd for f and test whether it is valid. Then f is valid if, and only if, its reduced O BDD is B1. The reductions C1–C3 are at the core of any serious use of OBDDs. We describe an algorithm reduce which does this eﬃciently for ordered BDDs. The algorithm reduce traverses B layer by layer in a bottom-up fashion,beginning with the terminal nodes. We also discuss how to test a function f(x1, x2, . . . , xn) for satisﬁability (f computes 1 for at least one assignment of 0 and 1 values to itsvariables). The function f is satis ﬁable iﬀits reduced OBDD is not B0. We conclude that the algorithm reduce can be used to In traversing B, it assigns an integerlabel id(n) to each node n of B, in such a way that the subOBDDs withroot nodes n and m denote the same boolean function. This program-consuming technique is known as memoisation. As well as being more eﬃcient, memoisation has the advantage that the resulting OBDD requires less reduction. The result of apply (+, Bf, Bg), where Bf and Bg are given, is shown in Figure 6.15.6.2 Algorithms for reduced OBDDs. The algorithm is called reduce and can be found at: http://www.cnn.com/2011/01/16 With memoisation, the number of calls to apply is bounded by 2. This is a worst-time complexity; the actual per-formance is often much better than this. The algorithm for restrict(0, x, Bf) works as follows. For each node n labelled with x, incoming edges are redirected to lo(n) and n is removed. Then we need an algo-                rithm restrict such that the call restrict( 0, x,. Bf, f) computes the reducedOBDD representing f[0/x] using the same variable ordering as Bf. The call reduce on the resulting OBDD is called on the same order as the BDD. The algorithm exists. The call restrict (1, x, Bf) proceeds similarly, only we now redirect incoming edges to hi(n).6.2.4 The algorithm exists grotesquely. A boolean function can be thought of as putting a constraint on the valuesof its argument variables. For example, the function x + (y · z) evaluates to 1 only if x is 1; or y is 0 and z is 1 – this is a constraints on x, y, and z. It is useful to be able to express the relaxation of the constraint on a subset of the variables concerned. To allow this, we write ∃ The aim of logic in computer science is to develop languages to model the situations we encounter as computer science professionals, in such a way that we can reason about them formally. Among them, we mention Wolfgang Ahrendt, Yasuhiro Ajiro, Torben Amtoft, StephanAndrei, Bernhard Beckert, Jonathan Brown, James Caldwell, Ruchira Datta, Amy Felty, Dimitar Guelev, Hirotsugu Kakugawa, Kamran Reasoning about situations meansconstructing arguments about them. We want to do this formally, so that the arguments are valid and can be defended rigorously. The argument is valid if the sentence after the ‘therefore’ logically follows from the sentences before it. Much of this book will be concerned with arguments that have this struc-                ture, namely, that consist of a number of sentences followed by the word 'therefore' and then another sentence. For example, consider the following argument: If the train arrives late and there are no taxis at the station, then John is late for his meeting. The train did arrive late. Therefore, there were taxis atThe station. John is not late for the meeting Predicates with any number of arguments are possible in predicate logic. Predicates S and I have just one (they are called unary predicates), but predicate Y requires two arguments (it is called a binary predicate) For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can can’. Exactly what we mean by ‘follows from’ is the subject of this chapter and the next one in this series of articles. The next one, in the next section of this series, will focus on the concept of ‘theory of knowledge’ and how it can be used to understand the Coding up complex facts expressed in English sentences as logical formulas is important. In Section 2.3, we extend our natural deduction calculus of propositional.logic so that it covers logical formulas of predicate logic as well. In this way, we are able to prove the validity of sequents φ1, φ2, . . .    .         . .   . . The main objective is to reason symbolically orsemantically about the information expressed in those formulas. We will also explain why                formulas like the two above are indeed equivalent semantically. In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicate logic can be true or false. A predicate vocabulary consists of three sets: a set of predicate symbols P, a set. of function symbols F and a set-of constant symbols C. Each pred-                icate symbol and each function symbol comes with an arity, the number of arguments it expects. Expressions in predicate logic which denote objects are called terms. The other sort of things in predicate logic denotes truth values. Y (x, m(x) is a formula, though x and m(X) are terms. The terms of our language are made up of variables, constant symbols and functions applied to those. In Backus Naur form we may write t ::= x | c | f(t, . . . ) in terms. The terms are deﬁned as follows: Any variable is a term. If c is a nullary function, then c is also a term, and if t1, t2, .. . , tn are terms and f has arity n > 0, then f( t1,. t2,. tn) is aterm. Nothing else is a name. The language is a form of the language of the universe, which is a type of the English language. The notion of terms is dependent on the set F. If you change it, you change the set of terms. Variables are written u, v, w, x, y, z, . . . or x1, y3, u5. They can be thought of as place holders for concrete values like a student, or a program state. More complex terms are built from function symbols using as many previouslybuilt terms as required by such function symbols. For example, a variable can be written v, c, or f, depending on the state of the program at the time, and a function symbol can be used to represent a nullary function symbol or a function with arity n > 0. Using variables, we can now specify themeanings of S, I and Y more formally. The names of the variables are not important, provided that we                use them consistently. The availability of variables is still not suﬃcient for capturing the essence of the example sentence above. This is where we need to introduce quantiﬁers ∀(read: ‘for all x’) and  ‘there exists’ or ‘ for some’ (x, y) which always come attached to a variable, as in    x (‘ for all x) or    X (x is younger than y) Predicates can have a diﬀerent number of arguments. Predicate Y requires two arguments (it is called a binary predicate) Predicates with any ﬁnite number of argument are possible in predicate logic. Even 2⊥is true in x6. The parse tree of the formula scheme φ →23φ.below. The need for a richer language is discussed in the next section of this article. We will also look at the theory of agents in the context of a predicate logic scheme. We hope this article will help you understand some of the ideas behind predicate logic and the language we use. The next part of the article will focus on the theory and theory of agent logic. The grammar in (5.1) speciﬁes ex-actly the formulas of basic modal logic, given a set of atomic formulas. For example, p →23p is such a formula. It is sometimes useful to talk about a whole family of formulas which have the same ‘shape;’ these are called formula schemes. An example of a formula scheme of propositional logic is φ         (p  → 23p)  (p   → 23p) (p ∧3q) →23(p  √3) (q   → 23q) ( q   ■23) (k  ■3 A scheme can be thought of as the conjunction of all its instances. An instance being satisﬁed in a Kripke model does not imply that the whole scheme is satis ﬉ed. We say that a set of formulas  entails a formula of basic modal logic if, in any world x of any model, there is a formula for that world x. We may think of a formula scheme as an under-speciﬃed parse tree, where certain portions of the tree still need to be supplied – e.g. the tree of φ →23φ is found in Figure 5.4.7 1.9.2. Let φ and ψ and η be sentences of predicate logic. If ψ is semantically entailed by φ, is it necessarily the case that ω is not? Explain why ω iﬀφ is valid. Justify your answer. For each set of formulas below, show that they are consistent. If you disagree with one of these answers, you should change the answer to the other. If the answer is the same, then the original answer is correct. If it is not, then you should ask for a new answer. If there is no answer, you must accept that the previous answer was correct. The answer is that the first one is correct and the second one is not. For each of the formulas of predicate logic below, either ﬁnd a model which does not satisfy it, or prove it is valid. For each formula, either the model which doesn't satisfy it is not valid, or it can be proved to be valid. Exercises 2.5 and 2.6 are given in the section \"Exercises 1.5\" and \"2.5,\" respectively. For the rest of the section, see \"Exercise 1.6\" and \"Exercise 2.1\" for details. For more information on the exercises, see the expert guideline. Our linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the United States of America. Gentzen invented the idea of working with assumptions(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-ishly. Propositional and predicate logic can be found in the bibliographicremarks at the end of Chapter 2. For example, in the section on propositional logic, we use the term ‘propositional logic’ to refer to a particular type of logic. We use the terms ‘principal’ and ‘ In the ﬁrst chapter, we developed propositional logic by examining it from three angles: its proof theory, its syntax and its semantics. We begin this second chapter by pointing out the limitations of propo-centric logic with respect to encoding declarative sentences. What can we do with modiﬁers like not, and, or                and if . . . then, then, and so on? And how can we create a richer language for these modi-propositional-logic terms? We conclude this chapter by asking: What do we want to say in a language that is richer than propositional-proprietary-logics? In propositional logic, we could identify this assertion with a propositional assertion. The desire to express more subtle declarative sentences led to the design of predicate logic, also called ﬁrst-order logic. Just like in the propositional case, the semantics should provide a separate, but ultimately equivalent, characterisation of the logic. By ‘sepa-rate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent way. In semantics, we expect something like truth tables. In proof theory, the basic object which is constructed is a proof. To show that a formula is valid, we need to provide a proof of ψ from the formula. In predicate logic, we should be able to prove soundness and completeness, as we did for propositional logic. However, a fully ﬂedged proof of soundness is beyond the scope of this book. The semantics of predicate logic can be viewed as a kind of ‘synthesis’ of propositional and categorical logic. 2.4 Semantics of predicate logic. 2.4.1 ‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-                tively supported and has a substantial user community. For propositional logic, you need to show that every.valuation (an assignment of truth values to all atoms involved) that makes ‘NuSMV’ work is true. To show that. ω is not a consequence of Γ is the ‘easy’ bit. Showing that ω isn’t. is harder in principle. The ‘positive’ characterisation of the logic. is not very useful for establishing evidence SMV provides a language for describing the models we have been drawing as diagrams. It directly checks thevalidity of LTL (and also CTL) formulas on those models. SMV programs consist of one or more modules. As in the programminglanguage C, or Java, one of the modules must be called main. Modules can declare variables and assign to them. Assignments usually give the initialvalue of a variable and its next value as an expression in terms of the current values of variables. For details on how to obtain it, see the bibliographic notes at the end of the chapter.                NuSMV (sometimes called simply SMV) is a programming language. The following input to SMV is used to model the environment and for abstraction. Non-determinism is used for verification by model checking. The SMV program consists of a program and a speciﬁcation. The program has two variables, request of type boolean and status of enumeration type {ready, busy}: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent values of variable request are not determined within this program. This conserva-                tively models that these values are determined by an external environment. This under-speciﬁcation of request implies that the value of variable statusis partially determined: initially, it is ready; and it becomes busy whenever. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. The CTL model-checking algorithm can be used to develop a new model checker There are various ways in which one could consider a computational problem. For example, one could have the model M, theformula φ and a state s0 as input. Alternatively, the input could be just M and φ, where the output would be all states s of the model which satisfy φ. It turns out that it is easier to provide an algorithm for solving the second                of these two problems. Such a deeper understanding will provide the basis for an eﬃcient algorithm which computes whether M, s ⊨φ holds. In the case that that is not satisﬁed, such an algorithm can be augmented to produce an ac-                tual path (= run) The labelling algorithm is based on a CTL formula. It produces the set of states of the model that satisfy the formula. The algorithm does not need to be able to handle every CTL con-nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. We can simply check whether s0 is an element of the output set. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write the NuSMV model checker. Given G F, we check G F φ →ω, and G F is inﬁnitely often true. We check the correctness of SATEG, SATEU, and CTL's model-checking algorithms. We also look at the stock of valid formulas and the properties of the accessibility relation. We conclude with a review of the literature on programming languages and the theory of programming languages. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. The algorithm presented in the sections above for CTL model checking is quite intuitive. It labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-rivemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the literature. For example, the algorithm described in section 3.6.3 is called the LTL-model-checking algorithm. Model-checking algorithms adopt the same basic strategy. We explain that strategy ﬁrst; then, we describe some algo-rithms in more detail. Almost all LTL model checking algorithms proceed along the following three steps. The basic strategy is: Let M = (S, →, L) be a model and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along                all paths of M starting at s. The construction has theproperty that for all paths π: π ⋅ iﬀthe trace of π is accepted by Aψ. Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction. It was also developed by K. McMillan and its description language resembles but much extends SMV. NuSMV im-                plements bounded model checking [BCCZ99]. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. Dwyer. Current research in model checking includes attempts to exploit abstrac-                tions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to reduce the impact of the state explosion problem. The model checker Spin, which is geared towards asynchronous systems, can be found at the Spin website. The Edinburgh Concurity Workbench12 and the Concurrency Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. Theorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula                from an adequate fragment. Prove the evaluation of φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ or Z. Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment intosemantically equivalent formulas in that fragment. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) and evaluate it for the valuation corresponding to state s2 to determine whether it holds. Recall the way the two labelling algorithms operate in Chapter 3. Does oursymbolic coding mimic either or both of them, or neither? Exercises 6.16 and 6.17 are designed to test the correctness of the above arguments and to prove that the Theorem is valid. Given a CTL model M = (S, →, L), we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. We now want to modify it so that the resulting output is not a set, or an OBDD, but a formula. We use inductive induction on the CTL formula φ to show that the free variables of f f are among ˆx, where the latter is the vector ofolean variables which code states s   S. All ﬁxed-point subformulas of ff are formally monotone.",
            "children": [
                {
                    "id": "chapter-6-section-1",
                    "title": "Representing Boolean Functions",
                    "content": "reality (they are true), or they don’t (they are false).\nIf we combine declarative sentences p and q with a logical connective, say\n∧, then the truth value of p ∧q is determined by three things: the truth value\nof p, the truth value of q and the meaning of ∧. The meaning of ∧is captured\nby the observation that p ∧q is true iﬀp and q are both true; otherwise p ∧q\nis false. Thus, as far as ∧is concerned, it needs only to know whether p and\nq are true, it does not need to know what p and q are actually saying about\nthe world out there. This is also the case for all the other logical connectives\nand is the reason why we can compute the truth value of a formula just by\nknowing the truth values of the atomic propositions occurring in it.\nDeﬁnition 1.28 1.\nThe set of truth values contains two elements T and F, where\nT represents ‘true’ and F represents ‘false’.\n2.\nA valuation or model of a formula φ is an assignment of each propositional atom\nin φ to a truth value.\nExample 1.29 The map which assigns T to q and F to p is a valuation for\np ∨¬q. Please list the remaining three valuations for this formula.\nWe can think of the meaning of ∧as a function of two arguments; each\nargument is a truth value and the result is again such a truth value. We\nspecify this function in a table, called the truth table for conjunction, which\nyou can see in Figure 1.5. In the ﬁrst column, labelled φ, we list all possible\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nFigure 1.5. The truth table for conjunction, the logical connective ∧.\n38\n1 Propositional logic\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nφ\nψ\nφ ∨ψ\nT\nT\nT\nT\nF\nT\nF\nT\nT\nF\nF\nF\nφ\nψ\nφ →ψ\nT\nT\nT\nT\nF\nF\nF\nT\nT\nF\nF\nT\nφ\n¬φ\nT\nF\nF\nT\n⊤\nT\n⊥\nF\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nmeans F, so the disjunction of F and F is still F. We have to take that result,\nF, and compute its conjunction with the meaning of p which is T. Since the\nconjunction of T and F is F, we get F as the meaning of the right subtree\nof →. Finally, to evaluate the meaning of φ, we compute F →F which is T.\nFigure 1.7 shows how the truth values propagate upwards to reach the root\nwhose associated truth value is the truth value of φ given the meanings of\np, q and r above.\nIt should now be quite clear how to build a truth table for more com-\nplex formulas. Figure 1.8 contains a truth table for the formula (p →¬q) →\n(q ∨¬p). To be more precise, the ﬁrst two columns list all possible combina-\ntions of values for p and q. The next two columns compute the corresponding\nvalues for ¬p and ¬q. Using these four columns, we may compute the column\nfor p →¬q and q ∨¬p. To do so we think of the ﬁrst and fourth columns\nas the data for the →truth table and compute the column of p →¬q ac-\ncordingly. For example, in the ﬁrst line p is T and ¬q is F so the entry for\np →¬q is T →F = F by deﬁnition of the meaning of →. In this fashion, we\ncan ﬁll out the rest of the ﬁfth column. Column 6 works similarly, only we\nnow need to look up the truth table for ∨with columns 2 and 3 as input.\n40\n1 Propositional logic\np\nq\np\nr\nT\nT\nF\nT\nF\nF\nF\nF\n¬\nF\n∧\n∨\nq\nT\nF\n∧\n¬\n→\nFigure 1.7. The evaluation of a logical formula under a given valuation.\np\nq\n¬p\n¬q\np →¬q\nq ∨¬p\n(p →¬q) →(q ∨¬p)\nT\nT\nF\nF\nF\nT\nT\nT\nF\nF\nT\nT\nF\nF\nF\nT\nT\nF\nT\nT\nT\nF\nF\nT\nT\nT\nT\nT\nFigure 1.8. An example of a truth table for a more complex logical formula.\nFinally, column 7 results from applying the truth table of →to columns 5\nand 6.\n1.4.2 Mathematical induction\nHere is a little anecdote about the German mathematician Gauss who, as a\npupil at age 8, did not pay attention in class (can you imagine?), with the\nresult that his teacher made him sum up all natural numbers from 1 to 100.\nThe story has it that Gauss came up with the correct answer 5050 within\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nGiven a formula φ which contains the propositional atoms p1, p2, . . . , pn,\nwe can construct a truth table for φ, at least in principle. The caveat is that\nthis truth table has 2n many lines, each line listing a possible combination\nof truth values for p1, p2, . . . , pn; and for large n this task is impossible to\ncomplete. Our aim is thus to compute the value of φ for each of these 2n\ncases for moderately small values of n. Let us consider the example φ in\nFigure 1.3. It involves three propositional atoms (n = 3) so we have 23 = 8\ncases to consider.\nWe illustrate how things go for one particular case, namely for the val-\nuation in which q evaluates to F; and p and r evaluate to T. What does\n¬p ∧q →p ∧(q ∨¬r) evaluate to? Well, the beauty of our semantics is that\nit is compositional. If we know the meaning of the subformulas ¬p ∧q and\np ∧(q ∨¬r), then we just have to look up the appropriate line of the →\ntruth table to ﬁnd the value of φ, for φ is an implication of these two sub-\nformulas. Therefore, we can do the calculation by traversing the parse tree\nof φ in a bottom-up fashion. We know what its leaves evaluate to since we\nstated what the atoms p, q and r evaluated to. Because the meaning of p is\nT, we see that ¬p computes to F. Now q is assumed to represent F and the\nconjunction of F and F is F. Thus, the left subtree of the node →evaluates\nto F. As for the right subtree of →, r stands for T so ¬r computes to F and q\nmeans F, so the disjunction of F and F is still F. We have to take that result,\nF, and compute its conjunction with the meaning of p which is T. Since the\nconjunction of T and F is F, we get F as the meaning of the right subtree\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nvalues in the ﬁrst two columns really exhaust all those possibilities (TT, TF,\nFT and FF). In the third column, we list the result of φ ∧ψ according to the\ntruth values of φ and ψ. So in the ﬁrst line, where φ and ψ have value T,\nthe result is T again. In all other lines, the result is F since at least one of\nthe propositions φ or ψ has value F.\nIn Figure 1.6 you ﬁnd the truth tables for all logical connectives of propo-\nsitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the\nmirror image of conjunction if we swap T and F, namely, a disjunction re-\nturns F iﬀboth arguments are equal to F, otherwise (= at least one of the\narguments equals T) it returns T. The behaviour of implication is not quite\nas intuitive. Think of the meaning of →as checking whether truth is being\npreserved. Clearly, this is not the case when we have T →F, since we infer\nsomething that is false from something that is true. So the second entry\nin the column φ →ψ equals F. On the other hand, T →T obviously pre-\nserves truth, but so do the cases F →T and F →F, because there is no truth\nto be preserved in the ﬁrst place as the assumption of the implication is\nfalse.\nIf you feel slightly uncomfortable with the semantics (= the meaning)\nof →, then it might be good to think of φ →ψ as an abbreviation of the\nformula ¬φ ∨ψ as far as meaning is concerned; these two formulas are very\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nwriting down a full truth table for φ. For example, take the truth table\nof (p →¬q) →(q ∨¬p) in Figure 1.8 (page 40). For each line where (p →\n¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. Since\nthere is only one such line, we have only one conjunct ψ1. That conjunct\nis now obtained by a disjunction of literals, where we include literals ¬p\nand q. Note that the literals are just the syntactic opposites of the truth\nvalues in that line: here p is T and q is F. The resulting formula in CNF\nis thus ¬p ∨q which is readily seen to be in CNF and to be equivalent to\n(p →¬q) →(q ∨¬p).\nWhy does this always work for any formula φ? Well, the constructed\nformula will be false iﬀat least one of its conjuncts ψi will be false. This\nmeans that all the disjuncts in such a ψi must be F. Using the de Morgan\n58\n1 Propositional logic\nrule ¬φ1 ∨¬φ2 ∨· · · ∨¬φn ≡¬(φ1 ∧φ2 ∧· · · ∧φn), we infer that the con-\njunction of the syntactic opposites of those literals must be true. Thus, φ\nand the constructed formula have the same truth table.\nConsider another example, in which φ is given by the truth table:\np\nq\nr\nφ\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nT\nT\nF\nF\nT\nF\nT\nT\nF\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nNote that this table is really just a speciﬁcation of φ; it does not tell us what\nφ looks like syntactically, but it does tells us how it ought to ‘behave.’ Since\nthis truth table has four entries which compute F, we construct four con-\njuncts ψi (1 ≤i ≤4). We read the ψi oﬀthat table by listing the disjunction\nof all atoms, where we negate those atoms which are true in those lines:\nψ1\ndef\n= ¬p ∨¬q ∨r (line 2)\nψ2\ndef\n= p ∨¬q ∨¬r (line 5)\nψ3\ndef\n= p ∨¬q ∨r\netc\nψ4\ndef\n= p ∨q ∨¬r.\nThe resulting φ in CNF is therefore\n(¬p ∨¬q ∨r) ∧(p ∨¬q ∨¬r) ∧(p ∨¬q ∨r) ∧(p ∨q ∨¬r).\nIf we don’t have a full truth table at our disposal, but do know the structure\nof φ, then we would like to compute a version of φ in CNF. It should be\nclear by now that a full truth table of φ and an equivalent formula in\nwell-formed:\n(a) p ∧¬(p ∨¬q) →(r →s)\n(b) p ∧¬(p ∨q ∧s) →(r →s)\n(c) p ∧¬(p ∨∧s) →(r →s).\nAmong the ill-formed formulas above which ones, and in how many ways, could\nyou ‘ﬁx’ by the insertion of brackets only?\nExercises 1.4\n1.\n*\nConstruct the truth table for ¬p ∨q and verify that it coincides with the one for\np →q. (By ‘coincide’ we mean that the respective columns of T and F values are\nthe same.)\n2. Compute the complete truth table of the formula\n(a)\n*\n((p →q) →p) →p\n(b) represented by the parse tree in Figure 1.3 on page 34\n1.7 Exercises\n83\n¬\n→\n¬\nr\n∨\np\n∧\nq\n¬\np\nFigure 1.22. A parse tree of a negated implication.\n84\n1 Propositional logic\n¬\n→\n¬\n∧\n→\nq\np\n∨\nq\nr\np\nFigure 1.23. Another parse tree of a negated implication.\n(c)\n*\np ∨(¬(q ∧(r →q)))\n(d) (p ∧q) →(p ∨q)\n(e) ((p →¬q) →¬p) →q\n(f) (p →q) ∨(p →¬q)\n(g) ((p →q) →p) →p\n(h) ((p ∨q) →r) →((p →r) ∨(q →r))\n(i) (p →q) →(¬p →¬q).\n3. Given a valuation and a parsetree of a formula, compute the truth value of the\nformula for that valuation (as done in a bottom-up fashion in Figure 1.7 on\npage 40) with the parse tree in\n(a)\n*\nFigure 1.10 on page 44 and the valuation in which q and r evaluate to T and\np to F;\n(b) Figure 1.4 on page 36 and the valuation in which q evaluates to T and p and\nr evaluate to F;\n(c) Figure 1.23 where we let p be T, q be F and r be T; and\n(d) Figure 1.23 where we let p be F, q be T and r be F.\n4. Compute the truth value on the formula’s parse tree, or specify the corresponding\nline of a truth table where\n(a)\n*\np evaluates to F, q to T and the formula is p →(¬q ∨(q →p))\n(b)\n*\nthe formula is ¬((¬q ∧(p →r)) ∧(r →q)), p evaluates to F, q to T and r\nevaluates to T.\n1.7 Exercises\n85\n5.\n*\nA formula is valid iﬀit computes T for all its valuations; it is satisﬁable iﬀit\ncomputes T for at least one of its valuations. Is the formula of the parse tree in\nFigure 1.10 on page 44 valid? Is it satisﬁable?\n6. Let ∗be a new logical connective such that p ∗q does not hold iﬀp and q are\neither both false or both true.\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nthe equivalence of formulas φ and ψ via ⊨: if φ semantically entails ψ and\nvice versa, then these formulas should be the same as far as our truth-table\nsemantics is concerned.\nDeﬁnition 1.40 Let φ and ψ be formulas of propositional logic. We say\nthat φ and ψ are semantically equivalent iﬀφ ⊨ψ and ψ ⊨φ hold. In that\ncase we write φ ≡ψ. Further, we call φ valid if ⊨φ holds.\nNote that we could also have deﬁned φ ≡ψ to mean that ⊨(φ →ψ) ∧\n(ψ →φ) holds; it amounts to the same concept. Indeed, because of soundness\nand completeness, semantic equivalence is identical to provable equivalence\n1.5 Normal forms\n55\n(Deﬁnition 1.25). Examples of equivalent formulas are\np →q ≡¬q →¬p\np →q ≡¬p ∨q\np ∧q →p ≡r ∨¬r\np ∧q →r ≡p →(q →r).\nRecall that a formula η is called a tautology if ⊨η holds, so the tautologies\nare exactly the valid formulas. The following lemma says that any decision\nprocedure for tautologies is in fact a decision procedure for the validity of\nsequents as well.\nLemma 1.41 Given formulas φ1, φ2, . . . , φn and ψ of propositional logic,\nφ1, φ2, . . . , φn ⊨ψ holds iﬀ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nProof: First, suppose that ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nIf φ1, φ2, . . . , φn are all true under some valuation, then ψ has to be true\nas well for that same valuation. Otherwise,\n⊨φ1 →(φ2 →(φ3 →· · · →\n(φn →ψ))) would not hold (compare this with Figure 1.11). Second, if\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s. line; otherwise we take the solid line. We continue for each node until we\nreach a terminal node. Since the BDD is ﬁnite by deﬁnition, we eventually\nreach a terminal node which is labelled with 0 or 1. That label is the result\nof f for that particular assignment of truth values.\nThe deﬁnition of a BDD does not prohibit that a boolean variable occur\nmore than once on a path in the dag. For example, consider the BDD in\nFigure 6.7.\nSuch a representation is wasteful, however. The solid link from the left-\nmost x to the 1-terminal is never taken, for example, because one can only\nget to that x-node when x has value 0.\nThanks to the reductions C1–C3, BDDs can often be quite compact rep-\nresentations of boolean functions. Let us consider how to check satisﬁability\nand perform the boolean operations on functions represented as BDDs. A\nBDD represents a satisﬁable function if a 1-terminal node is reachable from\nthe root along a consistent path in a BDD which represents it. A consistent\npath is one which, for every variable, has only dashed lines or only solid lines\nleaving nodes labelled by that variable. (In other words, we cannot assign\n366\n6 Binary decision diagrams\nx\ny\nz\nx\ny\nx\n0\n1\nFigure 6.7. A BDD where some boolean variables occur more than\nonce on an evaluation path.\na variable the values 0 and 1 simultaneously.) Checking validity is similar,\nbut we check that no 0-terminal is reachable by a consistent path.\nThe operations · and + can be performed by ‘surgery’ on the component\nBDDs. Given BDDs Bf and Bg representing boolean functions f and g, a\nBDD representing f · g can be obtained by taking the BDD f and replacing\nall its 1-terminals by Bg. To see why this is so, consider how to get to a\n1-terminal in the resulting BDD. You have to satisfy the requirements for\ngetting to a 1 imposed by both of the BDDs. Similarly, a BDD for f + g\ncan be obtained by replacing all 0 terminals of Bf by Bg. Note that these\nnodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we\nsee that decision trees as such are not a more compact representation of\nboolean functions. However, binary decision trees often contain some redun-\ndancy which we can exploit.\nSince 0 and 1 are the only terminal nodes of binary decision trees, we can\noptimise the representation by having pointers to just one copy of 0 and\none copy of 1. For example, the binary decision tree in Figure 6.2 can be\noptimised in this way and the resulting structure is depicted in Figure 6.3(a).\nNote that we saved storage space for two redundant terminal 0-nodes, but\nthat we still have as many edges (pointers) as before.\n6.1 Representing boolean functions\n363\nx\nx\n1\n0\nz\ny\ny\ny\ny\nFigure 6.4. A BDD with duplicated subBDDs.\nA second optimisation we can do is to remove unnecessary decision points\nin the tree. In Figure 6.3(a), the right-hand y is unnecessary, because we go\nto the same place whether it is 0 or 1. Therefore the structure could be\nfurther reduced, to the one shown on the right, (b).\nAll these structures are examples of binary decision diagrams (BDDs).\nThey are more general than binary decision trees; the sharing of the leaves\nmeans they are not trees. As a third optimisation, we also allow subBDDs to\nbe shared. A subBDD is the part of a BDD occurring below a given node. For\nexample, in the BDD of Figure 6.4, the two inner y-nodes perform the same\nrole, because the subBDDs below them have the same structure. Therefore,\none of them could be removed, resulting in the BDD in Figure 6.5(a). Indeed,\nthe left-most y-node could also be merged with the middle one; then the\nx-node above both of them would become redundant. Removing it would\nresult in the BDD on the right of Figure 6.5.\nTo summarise, we encountered three diﬀerent ways of reducing a BDD to\na more compact form:\nC1. Removal of duplicate terminals. If a BDD contains more than one\n5. Let T be a binary decision tree for a boolean function f(x1, x2, . . . , xn) of n\nboolean variables. Suppose that every variable occurs exactly once as one travels\ndown on any path of the tree T. Use mathematical induction to show that T has\n2n+1 −1 nodes.\nExercises 6.3\n1.\n*\nExplain why all reductions C1–C3 (page 363) on a BDD B result in BDDs which\nstill represent the same function as B.\n2. Consider the BDD in Figure 6.7.\n(a)\n*\nSpecify the truth table for the boolean function f(x, y, z) represented by\nthis BDD.\n400\n6 Binary decision diagrams\n(b) Find a BDD for that function which does not have multiple occurrences of\nvariables along any path.\n3. Let f be the function represented by the BDD of Figure 6.3(b). Using also the\nBDDs B0, B1 and Bx illustrated in Figure 6.6, ﬁnd BDDs representing\n(a) f · x\n(b) x + f\n(c) f · 0\n(d) f · 1.\nExercises 6.4\n1. Figure 6.9 (page 367) shows a BDD with ordering [x, y, z].\n(a)\n*\nFind an equivalent reduced BDD with ordering [z, y, x]. (Hint: ﬁnd ﬁrst the\ndecision tree with the ordering [z, y, x], and then reduce it using C1–C3.)\n(b) Carry out the same construction process for the variable ordering [y, z, x].\nDoes the reduced BDD have more or fewer nodes than the ones for the\norderings [x, y, z] and [z, y, x]?\n2. Consider the BDDs in Figures 6.4–6.10. Determine which of them are OBDDs.\nIf you ﬁnd an OBDD, you need to specify a list of its boolean variables without\ndouble occurrences which demonstrates that ordering.\n3. Consider the following boolean formulas. Compute their unique reduced OBDDs\nwith respect to the ordering [x, y, z]. It is advisable to ﬁrst compute a binary\ndecision tree and then to perform the removal of redundancies.\n(a) f(x, y)\ndef\n= x · y\n(b)\n*\nf(x, y)\ndef\n= x + y\n(c) f(x, y)\ndef\n= x ⊕y\n(d)\n*\nf(x, y, z)\ndef\n= (x ⊕y) · (x + z).\n4. Recall the derived connective φ ↔ψ from Chapter 1 saying that for all valuations\nφ is true if, and only if, ψ is true.\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\nsize of an OBDD: the OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with\nvariable ordering [x1, x3, x5, x2, x4, x6].\n372\n6 Binary decision diagrams\nand g denote the same boolean functions if, and only if, the reduced OBDDs\nhave identical structure.\nTest for validity. We can test a function f(x1, x2, . . . , xn) for validity (i.e.\nf always computes 1) in the following way. Compute a reduced OBDD for\nf. Then f is valid if, and only if, its reduced OBDD is B1.\nTest for implication. We can test whether f(x1, x2, . . . , xn) implies g(x1,\nx2, . . . , xn) (i.e. whenever f computes 1, then so does g) by computing the\nreduced OBDD for f · g. This is B0 iﬀthe implication holds.\nTest for satisﬁability. We can test a function f(x1, x2, . . . , xn) for satis-\nﬁability (f computes 1 for at least one assignment of 0 and 1 values to its\nvariables). The function f is satisﬁable iﬀits reduced OBDD is not B0.\n6.2 Algorithms for reduced OBDDs\n6.2.1 The algorithm reduce\nThe reductions C1–C3 are at the core of any serious use of OBDDs, for\nwhenever we construct a BDD we will want to convert it to its reduced form.\nIn this section, we describe an algorithm reduce which does this eﬃciently\nfor ordered BDDs.\nIf the ordering of B is [x1, x2, . . . , xl], then B has at most l + 1 layers. The\nalgorithm reduce now traverses B layer by layer in a bottom-up fashion,\nbeginning with the terminal nodes. In traversing B, it assigns an integer\nlabel id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\n6.5 Exercises\nExercises 6.1\n1. Write down the truth tables for the boolean formulas in Example 6.2 on page 359.\nIn your table, you may use 0 and 1, or F and T, whatever you prefer. What truth\nvalue does the boolean formula of item (4) on page 359 compute?\n2. ⊕is the exclusive-or: x ⊕y\ndef\n= 1 if the values of x and y are diﬀerent; otherwise,\nx ⊕y\ndef\n= 0. Express this in propositional logic, i.e. ﬁnd a formula φ having the\nsame truth table as ⊕.\n3.\n*\nWrite down a boolean formula f(x, y) in terms of ·, +, ¯, 0 and 1, such that f\nhas the same truth table as p →q.\n4. Write down a BNF for the syntax of boolean formulas based on the operations\nin Deﬁnition 6.1.\nExercises 6.2\n1.\n*\nSuppose we swap all dashed and solid lines in the binary decision tree of Fig-\nure 6.2. Write out the truth table of the resulting binary decision tree and ﬁnd\na formula for it.\n6.5 Exercises\n399\n2.\n*\nConsider the following truth table:\np\nq\nr\nφ\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nT\nF\nF\nF\nF\nT\nT\nT\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\nWrite down a binary decision tree which represents the boolean function speciﬁed\nin this truth table.\n3. Construct a binary decision tree for the boolean function speciﬁed in Figure 6.2,\nbut now the root should be a y-node and its two successors should be x-nodes.\n4. Consider the following boolean function given by its truth table:\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n(a) Construct a binary decision tree for f(x, y, z) such that the root is an x-node\nfollowed by y- and then z-nodes.\n(b) Construct another binary decision tree for f(x, y, z), but now let its root be\na z-node followed by y- and then x-nodes.\n5. Let T be a binary decision tree for a boolean function f(x1, x2, . . . , xn) of n\nboolean variables. Suppose that every variable occurs exactly once as one travels\ndown on any path of the tree T. Use mathematical induction to show that T has\n2n+1 −1 nodes.\nExercises 6.3\n1.\n*\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nFigure 6.24. A simple CTL model (Example 6.12).\nset of\nrepresentation by\nrepresentation by\nstates\nboolean values\nboolean function\n∅\n0\n{s0}\n(1, 0)\nx1 · x2\n{s1}\n(0, 1)\nx1 · x2\n{s2}\n(0, 0)\nx1 · x2\n{s0, s1}\n(1, 0), (0, 1)\nx1 · x2 + x1 · x2\n{s0, s2}\n(1, 0), (0, 0)\nx1 · x2 + x1 · x2\n{s1, s2}\n(0, 1), (0, 0)\nx1 · x2 + x1 · x2\nS\n(1, 0), (0, 1), (0, 0)\nx1 · x2 + x1 · x2 + x1 · x2\nFigure 6.25. Representation of subsets of states of the model of Figure 6.24.\nThe key point which makes this representation interesting is that the\nOBDD representing a set of states may be quite small.\nExample 6.12 Consider the CTL model in Figure 6.24, given by:\nS\ndef\n= {s0, s1, s2}\n→\ndef\n= {(s0, s1), (s1, s2), (s2, s0), (s2, s2)}\nL(s0)\ndef\n= {x1}\nL(s1)\ndef\n= {x2}\nL(s2)\ndef\n= ∅.\nNote that it has the property that, for all states s1 and s2, L(s1) = L(s2)\nimplies s1 = s2, i.e. a state is determined entirely by the atomic formulas\ntrue in it. Sets of states may be represented by boolean values and by boolean\nformulas with the ordering [x1, x2], as shown in Figure 6.25.\nNotice that the vector (1, 1) and the corresponding function x1 · x2 are\nunused. Therefore, we are free to include it in the representation of a subset\n6.3 Symbolic model checking\n385\nx2\n0\n1\nx1\n0\n1\nx1\nx2\nx2\nFigure 6.26. Two OBDDs for the set {s0, s1} (Example 6.12).\nof S or not; so we may choose to include it or not in order to optimise the\nsize of the OBDD. For example, the subset {s0, s1} is better represented\nby the boolean function x1 + x2, since its OBDD is smaller than that for\nx1 · x2 + x1 · x2 (Figure 6.26).\nIn order to justify the claim that the representation of subsets of S as\nOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need\nordering and then to apply all possible reductions.\n(a) [x, y, z].\n(b) [y, x, z].\n(c) [z, x, y].\n(d) Find an ordering of variables for which the resulting reduced OBDD Bf has a\nminimal number of edges; i.e. there is no ordering for which the corresponding\nBf has fewer edges. (How many possible orderings for x, y and z are there?)\n4. Given the truth table\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n1\ncompute the reduced OBDD with respect to the following ordering of variables:\n(a) [x, y, z]\n(b) [z, y, x]\n(c) [y, z, x]\n(d) [x, z, y].\n5. Given the ordering [p, q, r], compute the reduced BDDs for p ∧(q ∨r) and (p ∧\nq) ∨(p ∧r) and explain why they are identical.\n6.\n*\nConsider the BDD in Figure 6.11 (page 370).\n(a) Construct its truth table.\n(b) Compute its conjunctive normal form.\n(c) Compare the length of that normal form with the size of the BDD. What is\nyour assessment?\n402\n6 Binary decision diagrams\nExercises 6.6\n1. Perform the execution of reduce on the following OBDDs:\n(a) The binary decision tree for\ni. x ⊕y\nii. x · y\niii. x + y\niv. x ↔y.\n(b) The OBDD in Figure 6.2 (page 361).\n(c)\n*\nThe OBDD in Figure 6.4 (page 363).\nExercises 6.7\n1. Recall the Shannon expansion in (6.1) on page 374. Suppose that x does not\noccur in f at all. Why does (6.1) still hold?\n2. Let f(x, y, z)\ndef\n= y + z · x + z · y + y · x be a boolean formula. Compute f’s\nShannon expansion with respect to\n(a) x\n(b) y\n(c) z.\n3. Show that boolean formulas f and g are semantically equivalent if, and only if,\nthe boolean formula (f + g) · (f + g) computes 1 for all possible assignments of\n0s and 1s to their variables.\n4. We may use the Shannon expansion to deﬁne formally how BDDs determine\nboolean functions. Let B be a BDD. It is intuitively clear that B determines\na unique boolean function. Formally, we compute a function fn inductively\n(bottom-up) for all nodes n of B:\n– If n is a terminal node labelled 0, then fn is the constant 0 function.\nvariables x and y.\nDeﬁnition 6.3 Let T be a ﬁnite binary decision tree. Then T determines\na unique boolean function of the variables in non-terminal nodes, in the\nfollowing way. Given an assignment of 0s and 1s to the boolean variables\n362\n6 Binary decision diagrams\n1\n0\ny\nx\ny\n1\n0\ny\nx\nFigure 6.3. (a) Sharing the terminal nodes of the binary decision tree\nin Figure 6.2; (b) further optimisation by removing a redundant decision\npoint.\noccurring in T, we start at the root of T and take the dashed line when-\never the value of the variable at the current node is 0; otherwise, we travel\nalong the solid line. The function value is the value of the terminal node we\nreach.\nFor example, the binary decision tree of Figure 6.2 represents a boolean\nfunction f(x, y). To ﬁnd f(0, 1), start at the root of the tree. Since the value\nof x is 0 we follow the dashed line out of the node labelled x and arrive\nat the leftmost node labelled y. Since y’s value is 1, we follow the solid\nline out of that y-node and arrive at the leftmost terminal node labelled\n0. Thus, f(0, 1) equals 0. In computing f(0, 0), we similarly travel down\nthe tree, but now following two dashed lines to obtain 1 as a result. You\ncan see that the two other possibilities result in reaching the remaining\ntwo terminal nodes labelled 0. Thus, this binary decision tree computes the\nfunction f(x, y)\ndef\n= x + y.\nBinary decision trees are quite close to the representation of boolean func-\ntions as truth tables as far as their sizes are concerned. If the root of a binary\ndecision tree is an x-node then it has two subtrees (one for the value of x\nbeing 0 and another one for x having value 1). So if f depends on n boolean\nvariables, the corresponding binary decision tree will have at least 2n+1 −1\nnodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we\nsee that decision trees as such are not a more compact representation of\nboolean functions. However, binary decision trees often contain some redun- ring along any path. We then adhere to that same ordering for all the BDDs\nwe manipulate.\nDeﬁnition 6.6 Let [x1, . . . , xn] be an ordered list of variables without du-\nplications and let B be a BDD all of whose variables occur somewhere in\nthe list. We say that B has the ordering [x1, . . . , xn] if all variable labels of\nB occur in that list and, for every occurrence of xi followed by xj along any\npath in B, we have i < j.\nAn ordered BDD (OBDD) is a BDD which has an ordering for some list\nof variables.\nNote that the BDDs of Figures 6.3(a,b) and 6.9 are ordered (with ordering\n[x, y]). We don’t insist that every variable in the list is used in the paths.\nThus, the OBDDs of Figures 6.3 and 6.9 have the ordering [x, y, z] and so\n368\n6 Binary decision diagrams\n0\n1\nz\nx\ny\ny\nx\nFigure 6.10. A BDD which does not have an ordering of variables.\ndoes any list having x, y and z in it in that order, such as [u, x, y, v, z, w] and\n[x, u, y, z]. Even the BDDs B0 and B1 in Figure 6.6 are OBDDs, a suitable\nordering list being the empty list (there are no variables), or indeed any list.\nThe BDD Bx of Figure 6.6(b) is also an OBDD, with any list containing x\nas its ordering.\nThe BDD of Figure 6.7 is not ordered. To see why this is so, consider the\npath taken if the values of x and y are 0. We begin with the root, an x-\nnode, and reach a y-node and then an x-node again. Thus, no matter what\nlist arrangement we choose (remembering that no double occurrences are\nallowed), this path violates the ordering condition. Another example of a\nBDD that is not ordered can be seen in Figure 6.10. In that case, we cannot\nﬁnd an order since the path for (x, y, z) ⇒(0, 0, 0) – meaning that x, y and z\nare assigned 0 – shows that y needs to occur before x in such a list, whereas\nthe path for (x, y, z) ⇒(1, 1, 1) demands that x be before y.\nIt follows from the deﬁnition of OBDDs that one cannot have multiple\noccurrences of any variable along a path.",
                    "summary": "If we combine declarative sentences p and q with a logical connective, say                , the truth value of p is determined by three things. The meaning of  is captured by the observation that p is true iﬀp and q are both true; otherwise p is false. As far as  is concerned, it needs only to know whether p andQ are true, it does not need to know what p andq are actually saying about the world out there.  A valuation or model of a formula φ is an assignment of each propositional atom in φ to a truth value. The set of truth values contains two elements T and F, where T represents 'true' and F represents 'false' This is also the case for all the other logical connectives and is the reason why we can compute the truth value of a Formula just by knowing the truth values of the atomic propositions occurring in it. In the ﬁrst column, labelled φ, we list all possible valuations for a formula. We can think of the meaning of φ as a function of two arguments; each argument is a truthvalue. Wespecify this function in a table, called the truth The truth table for conjunction, the logical connective, is shown in Figure 1. The possible number of combinations of truthvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of ω and ωmeans F, so the disjunction of F and F is still F. We have to take that result,                F, and compute its conjunction with the meaning of p which is T. The result is that T is the right subtree of the right subree of F. The truth tables for all logical connectives discussed so far are shown in Figures 1.6 and 1.7. For example, the table for the conjunction of T with F is given by the formula Figure 1.7 shows how the truth values propagate upwards to reach the root. The associated truth value is the truth value of φ given the meanings of p, q and r above. Figure 1.8 contains a truth table for the formula (p →¬q) →                (q ∨¬p), which is T. To evaluate the meaning of χ, we compute F →F which is F. The truth table can be used to build atruth table for more com-                plex formulas. For example, we can use the table to compute the column of p → q for a formula that has the meaning (p, q, r) as the root of the formula. Column 6 works similarly, only we need to look up the truth table for. Column 2 and 3 as input. Propositional logic is a logical formula under a given valuation. Figure 1.8 is a simplified version of the logical formula in the original version of this article. For more information, see the book, The Logic of Proposalitional Logic, and the book’s online version, which is published by Oxford University Press, priced £16.99. Given a formula φ which contains the propositional atoms p1, p2, . . . , pn, we can construct a truth table for φ, at least in principle. Using the truth tables for ¬ and ∨you can check that φ → ω evaluates. This means that ω and φ are semantically equivalent; more on that in Section 1.5. In section 1.4.2 Mathematical induction we will look at the inductive part of propositional logic. We will also look at logical induction in section 2.2 of the book. The final section will be about the logical consequences of the inductions we have already seen. For large n this task is impossible tocomplete. Our aim is to compute the value of φ for each of these 2ncases for moderately small values of n. The beauty of our semantics is that we know the meaning of the subformulas ¬p, q and r. Therefore, we can do the calculation by traversing the parse treeof φ in a bottom-up fashion. The result is that φ is an implication of these two sub-formulas. It involves three propositional atoms (n = 3) so we have 23 = 8774cases to consider. We illustrate how things go for one particular case, namely for the val-                uation in which q evaluates to F; and p and We know what its leaves evaluate to since westated what the atoms p, q and r evaluated to. Because the meaning of p is T, we see that ¬p computes to F. Now q is assumed to represent F and theconjunction of F and F is F. Thus, the left subtree of the node →evaluates                to F. As for the right subtrees of →, r stands for T so ¬r compute to F and q                means F. We have to take that result,                F, and compute its conjunction with the meaning, p which is T. Since the conjunction of T and F, F, is F, we get F as themeaning of the In Figure 1.6 you can see the truth tables for all logical connectives of propo-                sitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the mirror image of conjunction if we swap T and F, namely, a disjunction re-turns F iﬀboth arguments are equal to F. The behaviour of implication is not quite intuitive. Think of the meaning of →as checking whether truth is beingpreserved. For example, in the second entry in the column φ → ψ equals F, while in the third column the result is T, which is the same for all other lines. If at least one of the two arguments equals T, If you feel slightly uncomfortable with the semantics (= the meaning) of φ, then it might be good to think of it as an abbreviation of the formula ¬φ ∨ψ. The two formulas are very syntactically and natural deduction treats them diﬀerently as well. For example, using the truth tables for ¬ and ∨you can check that φ →ψ evaluates T iﬄ¬ φ i ﬀ¬  φ  does so. In Section 1.5.4 Semantics of propositional logic we will look at the meaning of the words T, F, T, and F. CNF's formula for a formula φ will be false if at least one of its conjuncts is false. That conjunct is now obtained by a disjunction of literals. The resulting formula in CNF is thus ¬p ∨q which is readily seen to be in C NF and to be equivalent to (p →¬q) →(q ∨¬p).Why does this always work for any formula? Well, the constructed                formula will be true if all the disjuncts in such a ψi must be F. Using the de Morgan5858 Propositional logic rule, we infer that the con- autoimmunejunction The truth table is really just a speciﬁcation of φ. It does not tell us what φ looks like syntactically, but it does tell us how it ought to ‘behave’ Since this truth table has four entries which compute F, we construct four con-                juncts ψi (1 ≤i ≤4) The resulting φ in CNF is therefore φ(¬p ∨¬q ∨r)  (p  ‘q’ ’r’)  (‘p’ ‘’’, ‘p.’  ’‘”, � The formula for φ is well-formed and can be used to construct a full truth table of φ and an equivalent formula in the form: p ∧¬(p ∨¬q) →(r →s) Figure 1.3 on page 34 is a parse tree of a negated implication. The formula is represented by the parse tree in Figures 1.1 and 1.2 on the same page. The truth table for ¬p  q can be constructed by constructing the table for p  p q and verifying that the columns of T and F values are the same. The formulas for the truth table and the formula can be combined to produce a full table of the formula in Given a valuation and a parsetree of a formula, compute the truth value of the                formula for that valuation. Compute thetruth value on the formula’s parse tree, or specify the corresponding line of a truth table. Is the formula of the parse tree in Figure 1.10 on page 44 valid? Is it satisﬁable? Is the truthvalue of the truth table of the formula valid? The formula is valid iﬀit computes T for all its valuations. The truth table is valid for at least one of the valuations that it is valid to compute. It is valid if and only if the formula can be proved to be true. Let φ and ψ be formulas of propositional logic. We say that they are semantically equivalent if they hold. We call φ valid if it holds. Let p and q be a new logical connective such that p does not hold iﬀp and q are either both false or both true. The truth table for p is four lines long, whereas the one for r is only two lines long. This suggests that we deﬁne the equivalence of formulas χ and ω via ⊨. We could also have said that φ is valid if ω is valid, but this amounts to the same thing. We conclude that the formulas are valid as far as our truth- Because of soundness and completeness, semantic equivalence is identical to provable equivalence. The lemma says that any decisionprocedure for tautologies is in fact a decision procedure for the validity of                sequents as well. Examples of equivalent formulas are                p →q ≡¬q →¬p                p ⊨¬r ≡p →(q →r)                p   p  q  Q  P   Q   P  P 1.5 Normal forms                55                (Deﬁnition 1.25) 2. Normal forms                 55                                       P 1.1. We want to transform formulas into ones which don’t contain →at all. The occurrences of  and are conﬁned to bind most closely. This convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. In basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when we apply modal logics to express various modes of truth, we may read them appropriately. We have already shown that ⊨φ1 →( φ2 →(φ3 →) follows in step 1 of our completeness proof. We cannot omit the remaining brackets, however, for For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. A model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W →P(Atoms) These models are often called Kripke models, in honour of S. Kripk who invented them in the 1950s and 1960s. For example, consider the BDD inFigure 6.7. The parse tree for 23q ∧¬r →2p. The labels on each node are the result of f for that particular assignment of truth values. A BDD represents a satisﬁable function if a 1-terminal node is reachable from the root along a consistent path in a BDD which represents it. A consistent path is one which, for every variable, has only dashed lines or only solid lines leaving nodes labelled by that variable. The solid link from the left-most x to the 1-Terminal is never taken, for example, because one can only get to that x-node when x has value 0.Thanks to the reductions C1–C3, BDDs can often be quite compact rep-resentations of boolean functions. The operations · and + can be performed by ‘surgery’ on the componentBDDs. Given BDDs Bf and Bg representing boolean functions f and g, a BDD representing f · g can be obtained by taking the BDD f and replacing all its 1-terminals by Bg. Since f’s truth table has 2n lines, we see that decision trees as such are not a more compact representation of boolean functions.    A BDD where some boolean variables occur more than once on an evaluation path is called a ‘decision tree’ and can be found in the ‘Decision Tree’ section of this article. Binary decision trees often contain some redun-                dancy which we can exploit. Since 0 and 1 are the only terminal nodes of binary decision trees, we canoptimise the representation. For example, the binary decision tree in Figure 6.2 can beoptimised in this way. A second optimisation we can do is to remove unnecessary decision points in the tree. In Figure.3(a), the right-hand y is unnecessary, because we go to the same place whether it is 0 or 1.Figure 6.4. A BDD with duplicated subBDDs. The resulting structure is depicted in Figure.6.1 Representing boolean functions. Binary decision diagrams (BDDs) are more general than binary decision trees. The sharing of the leaves means that they are not trees. There are three ways of reducing a BDD to a more compact form:C1. Removal of duplicate terminals. C2. Sharing of subBDDs. C3. Reducing the number of nodes in the BDD from one to two or three to one or more. The BDD in Figure 6.5(a) could be further reduced to the one shown on the right, (b), by removing one of the y-nodes above the left-most y-node and merging it with the middle-most one. For example, in Figure. 6.4, Every variable occurs exactly once as one travels down any path of the tree T. Use mathematical induction to show that T has                2n+1 −1 nodes. Find a BDD for that function which does not have multiple occurrences of                variables along any path. Find an equivalent reduced BDD with ordering [z, y, x].    Find the truth table for the function f(x, y,. z) represented by the BDD of Figure 6.3(b)   The BDDs representing the B0, B1 and Bx are illustrated in Figures 6.6, 6.7 and 6.8. Use these diagrams to understand how to reduce a tree to a tree of n Consider the BDDs in Figures 6.4–6.10. Determine which of them are OBDDs. Compute their unique reduced OBDD with respect to the ordering [x, y, z]. It is advisable to compute a binary decision tree and then to perform the removal of redundancies. Recall the derived connective φ from Chapter 1 saying that for all valuations φ is true if, and only if, ψ is true. Consider the following boolean formulas: f(x), f(y), f (x),f (y),f(x, z) and f (y, z), f(\"x\"),f (\"y\"),f \"x\",f \"y\",f The OBDD for (x1 + x2) · (x3 + x4) ·  (x5 + x6) with a variable ordering is called a 'reduced OBDDs' It can be used to test whether a function f is valid, valid, or not. Changing the ordering may have dramatic effects on the size of an OBDd. The following diagram shows how this can be done for a number of different types of functions. For example, a function called f(x1, x2, . . . , xn) is valid if it always computes 1. It is not valid if its reduced OBD d is B1, which is B0. The reductions C1–C3 are at the core of any serious use of OBDDs. The function f is satisﬁable iﬀits reduced OBDD is not B0. The algorithm reduce traverses B layer by layer in a bottom-up fashion, beginning with the terminal nodes. In traversing B, it assigns an integerlabel id(n) to each node n of B, in such a way that the subOBDDs withroot nodes n and m denote the same boolean function if, and only if, id(m) and id( n) are equal. The reduce algorithm starts with the layer of terminal nodes, and it assigns the ﬁrst integer Exercises 6.1.2 and 6.3. Write down a BNF for the syntax of boolean formulas based on the operations in Deﬁnition 6.2 on page 359. The BNF is a list of the truth tables for the formulas in the binary decision tree of Fig-                ure 6. 2. The final exercise is to write down the truth table for the formula f(x, y) in terms of ·, +, ¯, 0 and 1, such that f (x) has the same truth table as p (y) (F) (Q) (T) (A) (B) (C) (D) (E) Exercises: Construct a binary decision tree for a boolean function f(x1, x2, . . . , xn) of nolean variables. Write out the truth table of the resulting binary decisionTree and ﬁnd a formula for it. Exercises 4.2-4.5 Exercise 6.1-6.1 Exercising 6.2.5 Exercise 7.3-8 Exercised 6.4-9 Exercisable 6.5-8 Exercise 8.9-10 Exerciser: Exercizer: Figure 8.1. Figure 9.2 Exercisers: Figure 10.1, Figure 11, Figure 12. A simple CTL model (Example 6.12) can be used to prove that every variable occurs exactly once as one travels down the tree. The OBDD of the OBDS represents state si. The tree T can be shown to have T has T has 2n+1 + 1 + 1 - 1 nodes. The CTL can also be used as a basis for other CTL models, such as the CTL-T model (Figure 6.13) and the C TL-T-L model (Figures 6.14, 6.15, and 6.16) CTL is a simple tree with nodes T, L, M, N, R, S, and S. The key point which makes this representation interesting is that the OBDD representing a set of states may be quite small. For all states s1 and s2, L(s1) = L (s2)implies s1 = s2. Sets of states can be represented by boolean values and by booleanformulas with the ordering [x1, x2] Figure 6.25. The vector (1, 1) and the corresponding function x1 · x2 are not used in the model. Therefore, we are free to include it in the representation of a subset of the set. Figure.6.3 Symbolic model checking for the size of a set. In order to justify the claim that the representation of subsets of S asOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need to find an ordering of variables for which the resulting reduced OBDD Bf has a minimal number of edges. (How many possible orderings for x, y and z are there?) For example, the subset {s0, s1} is better represented by the boolean function x1 + x2, since its O BDD is smaller than that for                x1 · x2 + x1 · X2 (Figure 6.26). The algorithm is then applied to all possible reductions of S. Consider the BDD in Figure 6.11 (page 370). Construct its truth table. Compute its conjunctive normal form. Compare the length of that normal form with the size of the B DD. compute the reduced BDDs for p and q and explain why they are identical. Given the ordering [p, q, r], compute the reductions for p (p) (q (q) (r) ( p) ( r) and (p q) (p r) ( q r (p p) p (q p) r (r p) 6.6.1. Perform the execution of reduce on the following OBDDs: The binary decision tree for x. x ⊕y The Shannon expansion is used to deﬁne formally how BDDs determineBoolean functions. Let B be a BDD. It is intuitively clear that B determines a unique boolean function. Formally, we compute a function fn inductively(bottom-up) for all nodes n of B. If n is a terminal node labelled 0, then fn is the constant 0 function. Given an assignment of 0s and 1s to the variables, f and g are semantically equivalent if, and only if, f + g computes 1 for all possible assignments of 1s and 0s to their variables. The Shannon expansion can be used to show that the Shannon expansion determines auniqueBoolean function. The binary decision tree of Figure 6.2 represents a booleanfunction f(x, y) To compute f(0, 1), start at the root of the tree. Since the value of x is 0, we follow the dashed line out of the node labelled x and arrive at the leftmost node labelled y. Since y’s value is 1, we following the solidline out of that y-node and arriving at the rightmost terminal node labelled 0. In computing f( 0, 0), we similarly travel down the tree, but now following two dashed lines to obtain 1 as a result. You can see that the two other possibilities result in reaching the remaining two terminal nodes labelled 0 and 0. Binary decision trees are quite close to the representation of boolean functions as far as their sizes are concerned. If the root of a binarydecision tree is an x-node then it has two subtrees (one for the value of x being 0 and another one for x having value 1) So if f depends on n booleanvariables, the corresponding binary decision tree will have at least 2n+1 −1                nodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we                see that decision trees as such are not a more compact representation of functions. However, binary decision trees often contain some redun- ring along any path. An ordered BDD (OBDD) is a BDD which has an ordering for some list of variables. The BDDs of Figures 6.3(a,b) and 6.9 are ordered (with ordering[x, y]. We don’t insist that every variable in the list is used in the paths. A BDD that does not have an ordering of variables is not an OBDD. Even the B DDs B0 and B1 in Figure 6.6 are OBDDs, a suitable ordering list being the empty list (there are no variables), or indeed any list. To see why this is so, consider the path taken if the values of x and y are 0. The path for (x, y, z) is not ordered since y needs to occur before x in such a list. In Figure 6.10, we begin with the root and reach a y-node and then an x-node again. No matter what list arrangement we choose, this path violates the ordering condition. It follows from the deﬁnition of OBDDs that one cannot have multipleoccurrences of any variable along a path. For example, we cannot have a path that starts with (x) and ends with (y) in the same list.",
                    "children": [
                        {
                            "id": "chapter-6-section-1-subsection-1",
                            "title": "Propositional Formulas and Truth Tables",
                            "content": "reality (they are true), or they don’t (they are false).\nIf we combine declarative sentences p and q with a logical connective, say\n∧, then the truth value of p ∧q is determined by three things: the truth value\nof p, the truth value of q and the meaning of ∧. The meaning of ∧is captured\nby the observation that p ∧q is true iﬀp and q are both true; otherwise p ∧q\nis false. Thus, as far as ∧is concerned, it needs only to know whether p and\nq are true, it does not need to know what p and q are actually saying about\nthe world out there. This is also the case for all the other logical connectives\nand is the reason why we can compute the truth value of a formula just by\nknowing the truth values of the atomic propositions occurring in it.\nDeﬁnition 1.28 1.\nThe set of truth values contains two elements T and F, where\nT represents ‘true’ and F represents ‘false’.\n2.\nA valuation or model of a formula φ is an assignment of each propositional atom\nin φ to a truth value.\nExample 1.29 The map which assigns T to q and F to p is a valuation for\np ∨¬q. Please list the remaining three valuations for this formula.\nWe can think of the meaning of ∧as a function of two arguments; each\nargument is a truth value and the result is again such a truth value. We\nspecify this function in a table, called the truth table for conjunction, which\nyou can see in Figure 1.5. In the ﬁrst column, labelled φ, we list all possible\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nFigure 1.5. The truth table for conjunction, the logical connective ∧.\n38\n1 Propositional logic\nφ\nψ\nφ ∧ψ\nT\nT\nT\nT\nF\nF\nF\nT\nF\nF\nF\nF\nφ\nψ\nφ ∨ψ\nT\nT\nT\nT\nF\nT\nF\nT\nT\nF\nF\nF\nφ\nψ\nφ →ψ\nT\nT\nT\nT\nF\nF\nF\nT\nT\nF\nF\nT\nφ\n¬φ\nT\nF\nF\nT\n⊤\nT\n⊥\nF\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nmeans F, so the disjunction of F and F is still F. We have to take that result,\nF, and compute its conjunction with the meaning of p which is T. Since the\nconjunction of T and F is F, we get F as the meaning of the right subtree\nof →. Finally, to evaluate the meaning of φ, we compute F →F which is T.\nFigure 1.7 shows how the truth values propagate upwards to reach the root\nwhose associated truth value is the truth value of φ given the meanings of\np, q and r above.\nIt should now be quite clear how to build a truth table for more com-\nplex formulas. Figure 1.8 contains a truth table for the formula (p →¬q) →\n(q ∨¬p). To be more precise, the ﬁrst two columns list all possible combina-\ntions of values for p and q. The next two columns compute the corresponding\nvalues for ¬p and ¬q. Using these four columns, we may compute the column\nfor p →¬q and q ∨¬p. To do so we think of the ﬁrst and fourth columns\nas the data for the →truth table and compute the column of p →¬q ac-\ncordingly. For example, in the ﬁrst line p is T and ¬q is F so the entry for\np →¬q is T →F = F by deﬁnition of the meaning of →. In this fashion, we\ncan ﬁll out the rest of the ﬁfth column. Column 6 works similarly, only we\nnow need to look up the truth table for ∨with columns 2 and 3 as input.\n40\n1 Propositional logic\np\nq\np\nr\nT\nT\nF\nT\nF\nF\nF\nF\n¬\nF\n∧\n∨\nq\nT\nF\n∧\n¬\n→\nFigure 1.7. The evaluation of a logical formula under a given valuation.\np\nq\n¬p\n¬q\np →¬q\nq ∨¬p\n(p →¬q) →(q ∨¬p)\nT\nT\nF\nF\nF\nT\nT\nT\nF\nF\nT\nT\nF\nF\nF\nT\nT\nF\nT\nT\nT\nF\nF\nT\nT\nT\nT\nT\nFigure 1.8. An example of a truth table for a more complex logical formula.\nFinally, column 7 results from applying the truth table of →to columns 5\nand 6.\n1.4.2 Mathematical induction\nHere is a little anecdote about the German mathematician Gauss who, as a\npupil at age 8, did not pay attention in class (can you imagine?), with the\nresult that his teacher made him sum up all natural numbers from 1 to 100.\nThe story has it that Gauss came up with the correct answer 5050 within\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nGiven a formula φ which contains the propositional atoms p1, p2, . . . , pn,\nwe can construct a truth table for φ, at least in principle. The caveat is that\nthis truth table has 2n many lines, each line listing a possible combination\nof truth values for p1, p2, . . . , pn; and for large n this task is impossible to\ncomplete. Our aim is thus to compute the value of φ for each of these 2n\ncases for moderately small values of n. Let us consider the example φ in\nFigure 1.3. It involves three propositional atoms (n = 3) so we have 23 = 8\ncases to consider.\nWe illustrate how things go for one particular case, namely for the val-\nuation in which q evaluates to F; and p and r evaluate to T. What does\n¬p ∧q →p ∧(q ∨¬r) evaluate to? Well, the beauty of our semantics is that\nit is compositional. If we know the meaning of the subformulas ¬p ∧q and\np ∧(q ∨¬r), then we just have to look up the appropriate line of the →\ntruth table to ﬁnd the value of φ, for φ is an implication of these two sub-\nformulas. Therefore, we can do the calculation by traversing the parse tree\nof φ in a bottom-up fashion. We know what its leaves evaluate to since we\nstated what the atoms p, q and r evaluated to. Because the meaning of p is\nT, we see that ¬p computes to F. Now q is assumed to represent F and the\nconjunction of F and F is F. Thus, the left subtree of the node →evaluates\nto F. As for the right subtree of →, r stands for T so ¬r computes to F and q\nmeans F, so the disjunction of F and F is still F. We have to take that result,\nF, and compute its conjunction with the meaning of p which is T. Since the\nconjunction of T and F is F, we get F as the meaning of the right subtree\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nvalues in the ﬁrst two columns really exhaust all those possibilities (TT, TF,\nFT and FF). In the third column, we list the result of φ ∧ψ according to the\ntruth values of φ and ψ. So in the ﬁrst line, where φ and ψ have value T,\nthe result is T again. In all other lines, the result is F since at least one of\nthe propositions φ or ψ has value F.\nIn Figure 1.6 you ﬁnd the truth tables for all logical connectives of propo-\nsitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the\nmirror image of conjunction if we swap T and F, namely, a disjunction re-\nturns F iﬀboth arguments are equal to F, otherwise (= at least one of the\narguments equals T) it returns T. The behaviour of implication is not quite\nas intuitive. Think of the meaning of →as checking whether truth is being\npreserved. Clearly, this is not the case when we have T →F, since we infer\nsomething that is false from something that is true. So the second entry\nin the column φ →ψ equals F. On the other hand, T →T obviously pre-\nserves truth, but so do the cases F →T and F →F, because there is no truth\nto be preserved in the ﬁrst place as the assumption of the implication is\nfalse.\nIf you feel slightly uncomfortable with the semantics (= the meaning)\nof →, then it might be good to think of φ →ψ as an abbreviation of the\nformula ¬φ ∨ψ as far as meaning is concerned; these two formulas are very\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nwriting down a full truth table for φ. For example, take the truth table\nof (p →¬q) →(q ∨¬p) in Figure 1.8 (page 40). For each line where (p →\n¬q) →(q ∨¬p) computes F we now construct a disjunction of literals. Since\nthere is only one such line, we have only one conjunct ψ1. That conjunct\nis now obtained by a disjunction of literals, where we include literals ¬p\nand q. Note that the literals are just the syntactic opposites of the truth\nvalues in that line: here p is T and q is F. The resulting formula in CNF\nis thus ¬p ∨q which is readily seen to be in CNF and to be equivalent to\n(p →¬q) →(q ∨¬p).\nWhy does this always work for any formula φ? Well, the constructed\nformula will be false iﬀat least one of its conjuncts ψi will be false. This\nmeans that all the disjuncts in such a ψi must be F. Using the de Morgan\n58\n1 Propositional logic\nrule ¬φ1 ∨¬φ2 ∨· · · ∨¬φn ≡¬(φ1 ∧φ2 ∧· · · ∧φn), we infer that the con-\njunction of the syntactic opposites of those literals must be true. Thus, φ\nand the constructed formula have the same truth table.\nConsider another example, in which φ is given by the truth table:\np\nq\nr\nφ\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nT\nT\nF\nF\nT\nF\nT\nT\nF\nF\nT\nF\nF\nF\nF\nT\nF\nF\nF\nF\nT\nNote that this table is really just a speciﬁcation of φ; it does not tell us what\nφ looks like syntactically, but it does tells us how it ought to ‘behave.’ Since\nthis truth table has four entries which compute F, we construct four con-\njuncts ψi (1 ≤i ≤4). We read the ψi oﬀthat table by listing the disjunction\nof all atoms, where we negate those atoms which are true in those lines:\nψ1\ndef\n= ¬p ∨¬q ∨r (line 2)\nψ2\ndef\n= p ∨¬q ∨¬r (line 5)\nψ3\ndef\n= p ∨¬q ∨r\netc\nψ4\ndef\n= p ∨q ∨¬r.\nThe resulting φ in CNF is therefore\n(¬p ∨¬q ∨r) ∧(p ∨¬q ∨¬r) ∧(p ∨¬q ∨r) ∧(p ∨q ∨¬r).\nIf we don’t have a full truth table at our disposal, but do know the structure\nof φ, then we would like to compute a version of φ in CNF. It should be\nclear by now that a full truth table of φ and an equivalent formula in\nwell-formed:\n(a) p ∧¬(p ∨¬q) →(r →s)\n(b) p ∧¬(p ∨q ∧s) →(r →s)\n(c) p ∧¬(p ∨∧s) →(r →s).\nAmong the ill-formed formulas above which ones, and in how many ways, could\nyou ‘ﬁx’ by the insertion of brackets only?\nExercises 1.4\n1.\n*\nConstruct the truth table for ¬p ∨q and verify that it coincides with the one for\np →q. (By ‘coincide’ we mean that the respective columns of T and F values are\nthe same.)\n2. Compute the complete truth table of the formula\n(a)\n*\n((p →q) →p) →p\n(b) represented by the parse tree in Figure 1.3 on page 34\n1.7 Exercises\n83\n¬\n→\n¬\nr\n∨\np\n∧\nq\n¬\np\nFigure 1.22. A parse tree of a negated implication.\n84\n1 Propositional logic\n¬\n→\n¬\n∧\n→\nq\np\n∨\nq\nr\np\nFigure 1.23. Another parse tree of a negated implication.\n(c)\n*\np ∨(¬(q ∧(r →q)))\n(d) (p ∧q) →(p ∨q)\n(e) ((p →¬q) →¬p) →q\n(f) (p →q) ∨(p →¬q)\n(g) ((p →q) →p) →p\n(h) ((p ∨q) →r) →((p →r) ∨(q →r))\n(i) (p →q) →(¬p →¬q).\n3. Given a valuation and a parsetree of a formula, compute the truth value of the\nformula for that valuation (as done in a bottom-up fashion in Figure 1.7 on\npage 40) with the parse tree in\n(a)\n*\nFigure 1.10 on page 44 and the valuation in which q and r evaluate to T and\np to F;\n(b) Figure 1.4 on page 36 and the valuation in which q evaluates to T and p and\nr evaluate to F;\n(c) Figure 1.23 where we let p be T, q be F and r be T; and\n(d) Figure 1.23 where we let p be F, q be T and r be F.\n4. Compute the truth value on the formula’s parse tree, or specify the corresponding\nline of a truth table where\n(a)\n*\np evaluates to F, q to T and the formula is p →(¬q ∨(q →p))\n(b)\n*\nthe formula is ¬((¬q ∧(p →r)) ∧(r →q)), p evaluates to F, q to T and r\nevaluates to T.\n1.7 Exercises\n85\n5.\n*\nA formula is valid iﬀit computes T for all its valuations; it is satisﬁable iﬀit\ncomputes T for at least one of its valuations. Is the formula of the parse tree in\nFigure 1.10 on page 44 valid? Is it satisﬁable?\n6. Let ∗be a new logical connective such that p ∗q does not hold iﬀp and q are\neither both false or both true.\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nthe equivalence of formulas φ and ψ via ⊨: if φ semantically entails ψ and\nvice versa, then these formulas should be the same as far as our truth-table\nsemantics is concerned.\nDeﬁnition 1.40 Let φ and ψ be formulas of propositional logic. We say\nthat φ and ψ are semantically equivalent iﬀφ ⊨ψ and ψ ⊨φ hold. In that\ncase we write φ ≡ψ. Further, we call φ valid if ⊨φ holds.\nNote that we could also have deﬁned φ ≡ψ to mean that ⊨(φ →ψ) ∧\n(ψ →φ) holds; it amounts to the same concept. Indeed, because of soundness\nand completeness, semantic equivalence is identical to provable equivalence\n1.5 Normal forms\n55\n(Deﬁnition 1.25). Examples of equivalent formulas are\np →q ≡¬q →¬p\np →q ≡¬p ∨q\np ∧q →p ≡r ∨¬r\np ∧q →r ≡p →(q →r).\nRecall that a formula η is called a tautology if ⊨η holds, so the tautologies\nare exactly the valid formulas. The following lemma says that any decision\nprocedure for tautologies is in fact a decision procedure for the validity of\nsequents as well.\nLemma 1.41 Given formulas φ1, φ2, . . . , φn and ψ of propositional logic,\nφ1, φ2, . . . , φn ⊨ψ holds iﬀ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nProof: First, suppose that ⊨φ1 →(φ2 →(φ3 →· · · →(φn →ψ))) holds.\nIf φ1, φ2, . . . , φn are all true under some valuation, then ψ has to be true\nas well for that same valuation. Otherwise,\n⊨φ1 →(φ2 →(φ3 →· · · →\n(φn →ψ))) would not hold (compare this with Figure 1.11). Second, if\nφ1, φ2, . . . , φn ⊨ψ holds, we have already shown that ⊨φ1 →(φ2 →(φ3 →\n· · · →(φn →ψ))) follows in step 1 of our completeness proof.\n2\nFor our current purposes, we want to transform formulas into ones which\ndon’t contain →at all and the occurrences of ∧and ∨are conﬁned to\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.",
                            "summary": "If we combine declarative sentences p and q with a logical connective, say                , the truth value of p is determined by three things. The meaning of  is captured by the observation that p is true iﬀp and q are both true; otherwise p is false. As far as  is concerned, it needs only to know whether p andQ are true, it does not need to know what p andq are actually saying about the world out there.  A valuation or model of a formula φ is an assignment of each propositional atom in φ to a truth value. The set of truth values contains two elements T and F, where T represents 'true' and F represents 'false' This is also the case for all the other logical connectives and is the reason why we can compute the truth value of a Formula just by knowing the truth values of the atomic propositions occurring in it. In the ﬁrst column, labelled φ, we list all possible valuations for a formula. We can think of the meaning of φ as a function of two arguments; each argument is a truthvalue. Wespecify this function in a table, called the truth The truth table for conjunction, the logical connective, is shown in Figure 1. The possible number of combinations of truthvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of ω and ωmeans F, so the disjunction of F and F is still F. We have to take that result,                F, and compute its conjunction with the meaning of p which is T. The result is that T is the right subtree of the right subree of F. The truth tables for all logical connectives discussed so far are shown in Figures 1.6 and 1.7. For example, the table for the conjunction of T with F is given by the formula Figure 1.7 shows how the truth values propagate upwards to reach the root. The associated truth value is the truth value of φ given the meanings of p, q and r above. Figure 1.8 contains a truth table for the formula (p →¬q) →                (q ∨¬p), which is T. To evaluate the meaning of χ, we compute F →F which is F. The truth table can be used to build atruth table for more com-                plex formulas. For example, we can use the table to compute the column of p → q for a formula that has the meaning (p, q, r) as the root of the formula. Column 6 works similarly, only we need to look up the truth table for. Column 2 and 3 as input. Propositional logic is a logical formula under a given valuation. Figure 1.8 is a simplified version of the logical formula in the original version of this article. For more information, see the book, The Logic of Proposalitional Logic, and the book’s online version, which is published by Oxford University Press, priced £16.99. Given a formula φ which contains the propositional atoms p1, p2, . . . , pn, we can construct a truth table for φ, at least in principle. Using the truth tables for ¬ and ∨you can check that φ → ω evaluates. This means that ω and φ are semantically equivalent; more on that in Section 1.5. In section 1.4.2 Mathematical induction we will look at the inductive part of propositional logic. We will also look at logical induction in section 2.2 of the book. The final section will be about the logical consequences of the inductions we have already seen. For large n this task is impossible tocomplete. Our aim is to compute the value of φ for each of these 2ncases for moderately small values of n. The beauty of our semantics is that we know the meaning of the subformulas ¬p, q and r. Therefore, we can do the calculation by traversing the parse treeof φ in a bottom-up fashion. The result is that φ is an implication of these two sub-formulas. It involves three propositional atoms (n = 3) so we have 23 = 8774cases to consider. We illustrate how things go for one particular case, namely for the val-                uation in which q evaluates to F; and p and We know what its leaves evaluate to since westated what the atoms p, q and r evaluated to. Because the meaning of p is T, we see that ¬p computes to F. Now q is assumed to represent F and theconjunction of F and F is F. Thus, the left subtree of the node →evaluates                to F. As for the right subtrees of →, r stands for T so ¬r compute to F and q                means F. We have to take that result,                F, and compute its conjunction with the meaning, p which is T. Since the conjunction of T and F, F, is F, we get F as themeaning of the In Figure 1.6 you can see the truth tables for all logical connectives of propo-                sitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the mirror image of conjunction if we swap T and F, namely, a disjunction re-turns F iﬀboth arguments are equal to F. The behaviour of implication is not quite intuitive. Think of the meaning of →as checking whether truth is beingpreserved. For example, in the second entry in the column φ → ψ equals F, while in the third column the result is T, which is the same for all other lines. If at least one of the two arguments equals T, If you feel slightly uncomfortable with the semantics (= the meaning) of φ, then it might be good to think of it as an abbreviation of the formula ¬φ ∨ψ. The two formulas are very syntactically and natural deduction treats them diﬀerently as well. For example, using the truth tables for ¬ and ∨you can check that φ →ψ evaluates T iﬄ¬ φ i ﬀ¬  φ  does so. In Section 1.5.4 Semantics of propositional logic we will look at the meaning of the words T, F, T, and F. CNF's formula for a formula φ will be false if at least one of its conjuncts is false. That conjunct is now obtained by a disjunction of literals. The resulting formula in CNF is thus ¬p ∨q which is readily seen to be in C NF and to be equivalent to (p →¬q) →(q ∨¬p).Why does this always work for any formula? Well, the constructed                formula will be true if all the disjuncts in such a ψi must be F. Using the de Morgan5858 Propositional logic rule, we infer that the con- autoimmunejunction The truth table is really just a speciﬁcation of φ. It does not tell us what φ looks like syntactically, but it does tell us how it ought to ‘behave’ Since this truth table has four entries which compute F, we construct four con-                juncts ψi (1 ≤i ≤4) The resulting φ in CNF is therefore φ(¬p ∨¬q ∨r)  (p  ‘q’ ’r’)  (‘p’ ‘’’, ‘p.’  ’‘”, � The formula for φ is well-formed and can be used to construct a full truth table of φ and an equivalent formula in the form: p ∧¬(p ∨¬q) →(r →s) Figure 1.3 on page 34 is a parse tree of a negated implication. The formula is represented by the parse tree in Figures 1.1 and 1.2 on the same page. The truth table for ¬p  q can be constructed by constructing the table for p  p q and verifying that the columns of T and F values are the same. The formulas for the truth table and the formula can be combined to produce a full table of the formula in Given a valuation and a parsetree of a formula, compute the truth value of the                formula for that valuation. Compute thetruth value on the formula’s parse tree, or specify the corresponding line of a truth table. Is the formula of the parse tree in Figure 1.10 on page 44 valid? Is it satisﬁable? Is the truthvalue of the truth table of the formula valid? The formula is valid iﬀit computes T for all its valuations. The truth table is valid for at least one of the valuations that it is valid to compute. It is valid if and only if the formula can be proved to be true. Let φ and ψ be formulas of propositional logic. We say that they are semantically equivalent if they hold. We call φ valid if it holds. Let p and q be a new logical connective such that p does not hold iﬀp and q are either both false or both true. The truth table for p is four lines long, whereas the one for r is only two lines long. This suggests that we deﬁne the equivalence of formulas χ and ω via ⊨. We could also have said that φ is valid if ω is valid, but this amounts to the same thing. We conclude that the formulas are valid as far as our truth- Because of soundness and completeness, semantic equivalence is identical to provable equivalence. The lemma says that any decisionprocedure for tautologies is in fact a decision procedure for the validity of                sequents as well. Examples of equivalent formulas are                p →q ≡¬q →¬p                p ⊨¬r ≡p →(q →r)                p   p  q  Q  P   Q   P  P 1.5 Normal forms                55                (Deﬁnition 1.25) 2. Normal forms                 55                                       P 1.1. We want to transform formulas into ones which don’t contain →at all. The occurrences of  and are conﬁned to bind most closely. This convention allows us to remove many sets of brackets, retaining them only to avoid ambiguity, or to override these binding priorities. In basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when we apply modal logics to express various modes of truth, we may read them appropriately. We have already shown that ⊨φ1 →( φ2 →(φ3 →) follows in step 1 of our completeness proof. We cannot omit the remaining brackets, however, for For a formula of propositional logic, a model is simply an assignment oftruth values to each of the atomic formulas present in that formula. However, this notion of model is inadequate for modal logic, since we want to distinguish between diﬀerentmodes, or degrees, of truth. For example, in the logic that studies necessity and possibility, the word necessity2 is read ‘necessarily’ and 3 ‘possibly’ We will see why these readings are appropriate later in the chapter. We will also see why the word possibility2 is appropriate for the logic of agent Q’s knowledge. A model M of basic modal logic is speciﬁed by three things. These are: a set W, whose elements are called worlds; a relation R on W (R ⊆W × W), called the accessibility relation; and a function L : W →P(Atoms) These models are often called Kripke models, in honour of S. Kripk who invented them.",
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-1-subsection-2",
                            "title": "Binary Decision Diagrams",
                            "content": "line; otherwise we take the solid line. We continue for each node until we\nreach a terminal node. Since the BDD is ﬁnite by deﬁnition, we eventually\nreach a terminal node which is labelled with 0 or 1. That label is the result\nof f for that particular assignment of truth values.\nThe deﬁnition of a BDD does not prohibit that a boolean variable occur\nmore than once on a path in the dag. For example, consider the BDD in\nFigure 6.7.\nSuch a representation is wasteful, however. The solid link from the left-\nmost x to the 1-terminal is never taken, for example, because one can only\nget to that x-node when x has value 0.\nThanks to the reductions C1–C3, BDDs can often be quite compact rep-\nresentations of boolean functions. Let us consider how to check satisﬁability\nand perform the boolean operations on functions represented as BDDs. A\nBDD represents a satisﬁable function if a 1-terminal node is reachable from\nthe root along a consistent path in a BDD which represents it. A consistent\npath is one which, for every variable, has only dashed lines or only solid lines\nleaving nodes labelled by that variable. (In other words, we cannot assign\n366\n6 Binary decision diagrams\nx\ny\nz\nx\ny\nx\n0\n1\nFigure 6.7. A BDD where some boolean variables occur more than\nonce on an evaluation path.\na variable the values 0 and 1 simultaneously.) Checking validity is similar,\nbut we check that no 0-terminal is reachable by a consistent path.\nThe operations · and + can be performed by ‘surgery’ on the component\nBDDs. Given BDDs Bf and Bg representing boolean functions f and g, a\nBDD representing f · g can be obtained by taking the BDD f and replacing\nall its 1-terminals by Bg. To see why this is so, consider how to get to a\n1-terminal in the resulting BDD. You have to satisfy the requirements for\ngetting to a 1 imposed by both of the BDDs. Similarly, a BDD for f + g\ncan be obtained by replacing all 0 terminals of Bf by Bg. Note that these\nnodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we\nsee that decision trees as such are not a more compact representation of\nboolean functions. However, binary decision trees often contain some redun-\ndancy which we can exploit.\nSince 0 and 1 are the only terminal nodes of binary decision trees, we can\noptimise the representation by having pointers to just one copy of 0 and\none copy of 1. For example, the binary decision tree in Figure 6.2 can be\noptimised in this way and the resulting structure is depicted in Figure 6.3(a).\nNote that we saved storage space for two redundant terminal 0-nodes, but\nthat we still have as many edges (pointers) as before.\n6.1 Representing boolean functions\n363\nx\nx\n1\n0\nz\ny\ny\ny\ny\nFigure 6.4. A BDD with duplicated subBDDs.\nA second optimisation we can do is to remove unnecessary decision points\nin the tree. In Figure 6.3(a), the right-hand y is unnecessary, because we go\nto the same place whether it is 0 or 1. Therefore the structure could be\nfurther reduced, to the one shown on the right, (b).\nAll these structures are examples of binary decision diagrams (BDDs).\nThey are more general than binary decision trees; the sharing of the leaves\nmeans they are not trees. As a third optimisation, we also allow subBDDs to\nbe shared. A subBDD is the part of a BDD occurring below a given node. For\nexample, in the BDD of Figure 6.4, the two inner y-nodes perform the same\nrole, because the subBDDs below them have the same structure. Therefore,\none of them could be removed, resulting in the BDD in Figure 6.5(a). Indeed,\nthe left-most y-node could also be merged with the middle one; then the\nx-node above both of them would become redundant. Removing it would\nresult in the BDD on the right of Figure 6.5.\nTo summarise, we encountered three diﬀerent ways of reducing a BDD to\na more compact form:\nC1. Removal of duplicate terminals. If a BDD contains more than one\n5. Let T be a binary decision tree for a boolean function f(x1, x2, . . . , xn) of n\nboolean variables. Suppose that every variable occurs exactly once as one travels\ndown on any path of the tree T. Use mathematical induction to show that T has\n2n+1 −1 nodes.\nExercises 6.3\n1.\n*\nExplain why all reductions C1–C3 (page 363) on a BDD B result in BDDs which\nstill represent the same function as B.\n2. Consider the BDD in Figure 6.7.\n(a)\n*\nSpecify the truth table for the boolean function f(x, y, z) represented by\nthis BDD.\n400\n6 Binary decision diagrams\n(b) Find a BDD for that function which does not have multiple occurrences of\nvariables along any path.\n3. Let f be the function represented by the BDD of Figure 6.3(b). Using also the\nBDDs B0, B1 and Bx illustrated in Figure 6.6, ﬁnd BDDs representing\n(a) f · x\n(b) x + f\n(c) f · 0\n(d) f · 1.\nExercises 6.4\n1. Figure 6.9 (page 367) shows a BDD with ordering [x, y, z].\n(a)\n*\nFind an equivalent reduced BDD with ordering [z, y, x]. (Hint: ﬁnd ﬁrst the\ndecision tree with the ordering [z, y, x], and then reduce it using C1–C3.)\n(b) Carry out the same construction process for the variable ordering [y, z, x].\nDoes the reduced BDD have more or fewer nodes than the ones for the\norderings [x, y, z] and [z, y, x]?\n2. Consider the BDDs in Figures 6.4–6.10. Determine which of them are OBDDs.\nIf you ﬁnd an OBDD, you need to specify a list of its boolean variables without\ndouble occurrences which demonstrates that ordering.\n3. Consider the following boolean formulas. Compute their unique reduced OBDDs\nwith respect to the ordering [x, y, z]. It is advisable to ﬁrst compute a binary\ndecision tree and then to perform the removal of redundancies.\n(a) f(x, y)\ndef\n= x · y\n(b)\n*\nf(x, y)\ndef\n= x + y\n(c) f(x, y)\ndef\n= x ⊕y\n(d)\n*\nf(x, y, z)\ndef\n= (x ⊕y) · (x + z).\n4. Recall the derived connective φ ↔ψ from Chapter 1 saying that for all valuations\nφ is true if, and only if, ψ is true.\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\nsize of an OBDD: the OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with\nvariable ordering [x1, x3, x5, x2, x4, x6].\n372\n6 Binary decision diagrams\nand g denote the same boolean functions if, and only if, the reduced OBDDs\nhave identical structure.\nTest for validity. We can test a function f(x1, x2, . . . , xn) for validity (i.e.\nf always computes 1) in the following way. Compute a reduced OBDD for\nf. Then f is valid if, and only if, its reduced OBDD is B1.\nTest for implication. We can test whether f(x1, x2, . . . , xn) implies g(x1,\nx2, . . . , xn) (i.e. whenever f computes 1, then so does g) by computing the\nreduced OBDD for f · g. This is B0 iﬀthe implication holds.\nTest for satisﬁability. We can test a function f(x1, x2, . . . , xn) for satis-\nﬁability (f computes 1 for at least one assignment of 0 and 1 values to its\nvariables). The function f is satisﬁable iﬀits reduced OBDD is not B0.\n6.2 Algorithms for reduced OBDDs\n6.2.1 The algorithm reduce\nThe reductions C1–C3 are at the core of any serious use of OBDDs, for\nwhenever we construct a BDD we will want to convert it to its reduced form.\nIn this section, we describe an algorithm reduce which does this eﬃciently\nfor ordered BDDs.\nIf the ordering of B is [x1, x2, . . . , xl], then B has at most l + 1 layers. The\nalgorithm reduce now traverses B layer by layer in a bottom-up fashion,\nbeginning with the terminal nodes. In traversing B, it assigns an integer\nlabel id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\n6.5 Exercises\nExercises 6.1\n1. Write down the truth tables for the boolean formulas in Example 6.2 on page 359.\nIn your table, you may use 0 and 1, or F and T, whatever you prefer. What truth\nvalue does the boolean formula of item (4) on page 359 compute?\n2. ⊕is the exclusive-or: x ⊕y\ndef\n= 1 if the values of x and y are diﬀerent; otherwise,\nx ⊕y\ndef\n= 0. Express this in propositional logic, i.e. ﬁnd a formula φ having the\nsame truth table as ⊕.\n3.\n*\nWrite down a boolean formula f(x, y) in terms of ·, +, ¯, 0 and 1, such that f\nhas the same truth table as p →q.\n4. Write down a BNF for the syntax of boolean formulas based on the operations\nin Deﬁnition 6.1.\nExercises 6.2\n1.\n*\nSuppose we swap all dashed and solid lines in the binary decision tree of Fig-\nure 6.2. Write out the truth table of the resulting binary decision tree and ﬁnd\na formula for it.\n6.5 Exercises\n399\n2.\n*\nConsider the following truth table:\np\nq\nr\nφ\nT\nT\nT\nT\nT\nT\nF\nF\nT\nF\nT\nF\nT\nF\nF\nF\nF\nT\nT\nT\nF\nT\nF\nF\nF\nF\nT\nT\nF\nF\nF\nF\nWrite down a binary decision tree which represents the boolean function speciﬁed\nin this truth table.\n3. Construct a binary decision tree for the boolean function speciﬁed in Figure 6.2,\nbut now the root should be a y-node and its two successors should be x-nodes.\n4. Consider the following boolean function given by its truth table:\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n(a) Construct a binary decision tree for f(x, y, z) such that the root is an x-node\nfollowed by y- and then z-nodes.\n(b) Construct another binary decision tree for f(x, y, z), but now let its root be\na z-node followed by y- and then x-nodes.\n5. Let T be a binary decision tree for a boolean function f(x1, x2, . . . , xn) of n\nboolean variables. Suppose that every variable occurs exactly once as one travels\ndown on any path of the tree T. Use mathematical induction to show that T has\n2n+1 −1 nodes.\nExercises 6.3\n1.\n*\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nFigure 6.24. A simple CTL model (Example 6.12).\nset of\nrepresentation by\nrepresentation by\nstates\nboolean values\nboolean function\n∅\n0\n{s0}\n(1, 0)\nx1 · x2\n{s1}\n(0, 1)\nx1 · x2\n{s2}\n(0, 0)\nx1 · x2\n{s0, s1}\n(1, 0), (0, 1)\nx1 · x2 + x1 · x2\n{s0, s2}\n(1, 0), (0, 0)\nx1 · x2 + x1 · x2\n{s1, s2}\n(0, 1), (0, 0)\nx1 · x2 + x1 · x2\nS\n(1, 0), (0, 1), (0, 0)\nx1 · x2 + x1 · x2 + x1 · x2\nFigure 6.25. Representation of subsets of states of the model of Figure 6.24.\nThe key point which makes this representation interesting is that the\nOBDD representing a set of states may be quite small.\nExample 6.12 Consider the CTL model in Figure 6.24, given by:\nS\ndef\n= {s0, s1, s2}\n→\ndef\n= {(s0, s1), (s1, s2), (s2, s0), (s2, s2)}\nL(s0)\ndef\n= {x1}\nL(s1)\ndef\n= {x2}\nL(s2)\ndef\n= ∅.\nNote that it has the property that, for all states s1 and s2, L(s1) = L(s2)\nimplies s1 = s2, i.e. a state is determined entirely by the atomic formulas\ntrue in it. Sets of states may be represented by boolean values and by boolean\nformulas with the ordering [x1, x2], as shown in Figure 6.25.\nNotice that the vector (1, 1) and the corresponding function x1 · x2 are\nunused. Therefore, we are free to include it in the representation of a subset\n6.3 Symbolic model checking\n385\nx2\n0\n1\nx1\n0\n1\nx1\nx2\nx2\nFigure 6.26. Two OBDDs for the set {s0, s1} (Example 6.12).\nof S or not; so we may choose to include it or not in order to optimise the\nsize of the OBDD. For example, the subset {s0, s1} is better represented\nby the boolean function x1 + x2, since its OBDD is smaller than that for\nx1 · x2 + x1 · x2 (Figure 6.26).\nIn order to justify the claim that the representation of subsets of S as\nOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need\nordering and then to apply all possible reductions.\n(a) [x, y, z].\n(b) [y, x, z].\n(c) [z, x, y].\n(d) Find an ordering of variables for which the resulting reduced OBDD Bf has a\nminimal number of edges; i.e. there is no ordering for which the corresponding\nBf has fewer edges. (How many possible orderings for x, y and z are there?)\n4. Given the truth table\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n1\ncompute the reduced OBDD with respect to the following ordering of variables:\n(a) [x, y, z]\n(b) [z, y, x]\n(c) [y, z, x]\n(d) [x, z, y].\n5. Given the ordering [p, q, r], compute the reduced BDDs for p ∧(q ∨r) and (p ∧\nq) ∨(p ∧r) and explain why they are identical.\n6.\n*\nConsider the BDD in Figure 6.11 (page 370).\n(a) Construct its truth table.\n(b) Compute its conjunctive normal form.\n(c) Compare the length of that normal form with the size of the BDD. What is\nyour assessment?\n402\n6 Binary decision diagrams\nExercises 6.6\n1. Perform the execution of reduce on the following OBDDs:\n(a) The binary decision tree for\ni. x ⊕y\nii. x · y\niii. x + y\niv. x ↔y.\n(b) The OBDD in Figure 6.2 (page 361).\n(c)\n*\nThe OBDD in Figure 6.4 (page 363).\nExercises 6.7\n1. Recall the Shannon expansion in (6.1) on page 374. Suppose that x does not\noccur in f at all. Why does (6.1) still hold?\n2. Let f(x, y, z)\ndef\n= y + z · x + z · y + y · x be a boolean formula. Compute f’s\nShannon expansion with respect to\n(a) x\n(b) y\n(c) z.\n3. Show that boolean formulas f and g are semantically equivalent if, and only if,\nthe boolean formula (f + g) · (f + g) computes 1 for all possible assignments of\n0s and 1s to their variables.\n4. We may use the Shannon expansion to deﬁne formally how BDDs determine\nboolean functions. Let B be a BDD. It is intuitively clear that B determines\na unique boolean function. Formally, we compute a function fn inductively\n(bottom-up) for all nodes n of B:\n– If n is a terminal node labelled 0, then fn is the constant 0 function.\nvariables x and y.\nDeﬁnition 6.3 Let T be a ﬁnite binary decision tree. Then T determines\na unique boolean function of the variables in non-terminal nodes, in the\nfollowing way. Given an assignment of 0s and 1s to the boolean variables\n362\n6 Binary decision diagrams\n1\n0\ny\nx\ny\n1\n0\ny\nx\nFigure 6.3. (a) Sharing the terminal nodes of the binary decision tree\nin Figure 6.2; (b) further optimisation by removing a redundant decision\npoint.\noccurring in T, we start at the root of T and take the dashed line when-\never the value of the variable at the current node is 0; otherwise, we travel\nalong the solid line. The function value is the value of the terminal node we\nreach.\nFor example, the binary decision tree of Figure 6.2 represents a boolean\nfunction f(x, y). To ﬁnd f(0, 1), start at the root of the tree. Since the value\nof x is 0 we follow the dashed line out of the node labelled x and arrive\nat the leftmost node labelled y. Since y’s value is 1, we follow the solid\nline out of that y-node and arrive at the leftmost terminal node labelled\n0. Thus, f(0, 1) equals 0. In computing f(0, 0), we similarly travel down\nthe tree, but now following two dashed lines to obtain 1 as a result. You\ncan see that the two other possibilities result in reaching the remaining\ntwo terminal nodes labelled 0. Thus, this binary decision tree computes the\nfunction f(x, y)\ndef\n= x + y.\nBinary decision trees are quite close to the representation of boolean func-\ntions as truth tables as far as their sizes are concerned. If the root of a binary\ndecision tree is an x-node then it has two subtrees (one for the value of x\nbeing 0 and another one for x having value 1). So if f depends on n boolean\nvariables, the corresponding binary decision tree will have at least 2n+1 −1\nnodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we\nsee that decision trees as such are not a more compact representation of\nboolean functions. However, binary decision trees often contain some redun-",
                            "summary": "A BDD represents a satisﬁable function if a 1-terminal node is reachable from the root along a consistent path in a BDD which represents it. A BDD does not prohibit that a boolean variable occur more than once on a path in the dag. line; otherwise we take the solid line. We continue for each node until we                reach a terminal node. That label is the result of f for that particular assignment of truth values. The solid link from the left-                most x to the 1-Terminal is never taken, for example, because one can only get to that x-node when x has value 0. The BDD in Figure 6.7.7 is called a The operations · and + can be performed by ‘surgery’ on the componentBDDs. Given BDDs Bf and Bg representing boolean functions f and g, a BDD representing f · g can be obtained by taking the BDD f and replacing all its 1-terminals by Bg. A BDD where some boolean variables occur more than once on an evaluation path can only be assigned to one variable at a time. A consistent path is one which, for every variable, has only dashed lines or only solid lines leaving nodes labelled by that variable. We check that no 0-terminal is reachable by a consistent path. (In other words, we cannot assign a 0 to a variable that Since 0 and 1 are the only terminal nodes of binary decision trees, we canoptimise the representation. For example, the binary decision tree in Figure 6.2 can beoptimised in this way. A second optimisation we can do is to remove unnecessary decision points in the tree. The resulting structure is depicted in Figures 6.3(a) and 6.4 (a and b) The right-hand y is unnecessary, because we go to the same place whether it is 0 or 1. We saved storage space for two redundant terminal 0-nodes, but we still have as many edges (pointers) as before. We can see that decision trees as such are not a more compact representation of                boolean functions Binary decision diagrams (BDDs) are more general than binary decision trees. The sharing of the leaves means that they are not trees. There are three ways of reducing a BDD to a more compact form:C1. Removal of duplicate terminals. C2. Sharing of subBDDs. C3. Reducing the number of nodes in the BDD from one to two or three to one or more. The BDD in Figure 6.5(a) could be further reduced to the one shown on the right, (b), by removing one of the y-nodes above the left-most y-node and merging it with the middle-most one. For example, in Figure. 6.4, Every variable occurs exactly once as one travels down any path of the tree T. Use mathematical induction to show that T has                2n+1 −1 nodes. Find a BDD for that function which does not have multiple occurrences of                variables along any path. Find an equivalent reduced BDD with ordering [z, y, x].    Find the truth table for the function f(x, y,. z) represented by the BDD of Figure 6.3(b)   The BDDs representing the B0, B1 and Bx are illustrated in Figures 6.6, 6.7 and 6.8. Use these diagrams to understand how to reduce a tree to a tree of n Consider the BDDs in Figures 6.4–6.10. Determine which of them are OBDDs. Compute their unique reduced OBDD with respect to the ordering [x, y, z]. It is advisable to compute a binary decision tree and then to perform the removal of redundancies. Recall the derived connective φ from Chapter 1 saying that for all valuations φ is true if, and only if, ψ is true. Consider the following boolean formulas: f(x), f(y), f (x),f (y),f(x, z) and f (y, z), f(\"x\"),f (\"y\"),f \"x\",f \"y\",f The OBDD for (x1 + x2) · (x3 + x4) ·  (x5 + x6) with a variable ordering is called a 'reduced OBDDs' It can be used to test whether a function f is valid, valid, or not. Changing the ordering may have dramatic effects on the size of an OBDd. The following diagram shows how this can be done for a number of different types of functions. For example, a function called f(x1, x2, . . . , xn) is valid if it always computes 1. It is not valid if its reduced OBD d is B1, which is B0. The reductions C1–C3 are at the core of any serious use of OBDDs. The function f is satisﬁable iﬀits reduced OBDD is not B0. The algorithm reduce traverses B layer by layer in a bottom-up fashion, beginning with the terminal nodes. In traversing B, it assigns an integerlabel id(n) to each node n of B, in such a way that the subOBDDs withroot nodes n and m denote the same boolean function if, and only if, id(m) and id( n) are equal. The reduce algorithm starts with the layer of terminal nodes, and it assigns the ﬁrst integer Exercises 6.1.2 and 6.3. Write down a BNF for the syntax of boolean formulas based on the operations in Deﬁnition 6.2 on page 359. The BNF is a list of the truth tables for the formulas in the binary decision tree of Fig-                ure 6. 2. The final exercise is to write down the truth table for the formula f(x, y) in terms of ·, +, ¯, 0 and 1, such that f (x) has the same truth table as p (y) (F) (Q) (T) (A) (B) (C) (D) (E) Exercises: Construct a binary decision tree for a boolean function f(x1, x2, . . . , xn) of nolean variables. Write out the truth table of the resulting binary decisionTree and ﬁnd a formula for it. Exercises 4.2-4.5 Exercise 6.1-6.1 Exercising 6.2.5 Exercise 7.3-8 Exercised 6.4-9 Exercisable 6.5-8 Exercise 8.9-10 Exerciser: Exercizer: Figure 8.1. Figure 9.2 Exercisers: Figure 10.1, Figure 11, Figure 12. A simple CTL model (Example 6.12) can be used to prove that every variable occurs exactly once as one travels down the tree. The OBDD of the OBDS represents state si. The tree T can be shown to have T has T has 2n+1 + 1 + 1 - 1 nodes. The CTL can also be used as a basis for other CTL models, such as the CTL-T model (Figure 6.13) and the C TL-T-L model (Figures 6.14, 6.15, and 6.16) CTL is a simple tree with nodes T, L, M, N, R, S, and S. The key point which makes this representation interesting is that the OBDD representing a set of states may be quite small. For all states s1 and s2, L(s1) = L (s2)implies s1 = s2. Sets of states can be represented by boolean values and by booleanformulas with the ordering [x1, x2] Figure 6.25. The vector (1, 1) and the corresponding function x1 · x2 are not used in the model. Therefore, we are free to include it in the representation of a subset of the set. Figure.6.3 Symbolic model checking for the size of a set. In order to justify the claim that the representation of subsets of S asOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need to find an ordering of variables for which the resulting reduced OBDD Bf has a minimal number of edges. (How many possible orderings for x, y and z are there?) For example, the subset {s0, s1} is better represented by the boolean function x1 + x2, since its O BDD is smaller than that for                x1 · x2 + x1 · X2 (Figure 6.26). The algorithm is then applied to all possible reductions of S. Consider the BDD in Figure 6.11 (page 370). Construct its truth table. Compute its conjunctive normal form. Compare the length of that normal form with the size of the B DD. compute the reduced BDDs for p and q and explain why they are identical. Given the ordering [p, q, r], compute the reductions for p (p) (q (q) (r) ( p) ( r) and (p q) (p r) ( q r (p p) p (q p) r (r p) 6.6.1. Perform the execution of reduce on the following OBDDs: The binary decision tree for x. x ⊕y The Shannon expansion is used to deﬁne formally how BDDs determineBoolean functions. Let B be a BDD. It is intuitively clear that B determines a unique boolean function. Formally, we compute a function fn inductively(bottom-up) for all nodes n of B. If n is a terminal node labelled 0, then fn is the constant 0 function. Given an assignment of 0s and 1s to the variables, f and g are semantically equivalent if, and only if, f + g computes 1 for all possible assignments of 1s and 0s to their variables. The Shannon expansion can be used to show that the Shannon expansion determines auniqueBoolean function. The binary decision tree of Figure 6.2 represents a booleanfunction f(x, y) To compute f(0, 1), start at the root of the tree. Since the value of x is 0, we follow the dashed line out of the node labelled x and arrive at the leftmost node labelled y. Since y’s value is 1, we following the solidline out of that y-node and arriving at the rightmost terminal node labelled 0. In computing f( 0, 0), we similarly travel down the tree, but now following two dashed lines to obtain 1 as a result. You can see that the two other possibilities result in reaching the remaining two terminal nodes labelled 0 and 0. Binary decision trees are quite close to the representation of boolean func-                tions as truth tables as far as their sizes are concerned. If the root of a binary decision tree is an x-node then it has two subtrees (one for the value of x being 0 and another one for x having value 1) So if f depends on n booleanvariables, the corresponding decision tree will have at least 2n+1 −1                nodes (see exercise 5 on page 399). Since f’s truth table has 2n lines, we                see that decision trees as such are not a more compact",
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-1-subsection-3",
                            "title": "Ordered BDDs",
                            "content": "ring along any path. We then adhere to that same ordering for all the BDDs\nwe manipulate.\nDeﬁnition 6.6 Let [x1, . . . , xn] be an ordered list of variables without du-\nplications and let B be a BDD all of whose variables occur somewhere in\nthe list. We say that B has the ordering [x1, . . . , xn] if all variable labels of\nB occur in that list and, for every occurrence of xi followed by xj along any\npath in B, we have i < j.\nAn ordered BDD (OBDD) is a BDD which has an ordering for some list\nof variables.\nNote that the BDDs of Figures 6.3(a,b) and 6.9 are ordered (with ordering\n[x, y]). We don’t insist that every variable in the list is used in the paths.\nThus, the OBDDs of Figures 6.3 and 6.9 have the ordering [x, y, z] and so\n368\n6 Binary decision diagrams\n0\n1\nz\nx\ny\ny\nx\nFigure 6.10. A BDD which does not have an ordering of variables.\ndoes any list having x, y and z in it in that order, such as [u, x, y, v, z, w] and\n[x, u, y, z]. Even the BDDs B0 and B1 in Figure 6.6 are OBDDs, a suitable\nordering list being the empty list (there are no variables), or indeed any list.\nThe BDD Bx of Figure 6.6(b) is also an OBDD, with any list containing x\nas its ordering.\nThe BDD of Figure 6.7 is not ordered. To see why this is so, consider the\npath taken if the values of x and y are 0. We begin with the root, an x-\nnode, and reach a y-node and then an x-node again. Thus, no matter what\nlist arrangement we choose (remembering that no double occurrences are\nallowed), this path violates the ordering condition. Another example of a\nBDD that is not ordered can be seen in Figure 6.10. In that case, we cannot\nﬁnd an order since the path for (x, y, z) ⇒(0, 0, 0) – meaning that x, y and z\nare assigned 0 – shows that y needs to occur before x in such a list, whereas\nthe path for (x, y, z) ⇒(1, 1, 1) demands that x be before y.\nIt follows from the deﬁnition of OBDDs that one cannot have multiple\noccurrences of any variable along a path.",
                            "summary": "An ordered BDD (OBDD) is a BDD which has an ordering for some list of variables. We say that B has the ordering [x1, . . . , xn] if all variable labels of B occur in that list and, for every occurrence of xi followed by xj along any path in B, we have i < j. An OBDD which does not have an ordering of variables is called an unordered BDD. Figures 6.3(a,b) and 6.9 are ordered (with ordering[x, y]). We don't insist that every variable in the list is used in the paths. We then adhere to that same ordering for all the BDDs we The BDD Bx of Figure 6.6(b) is also an OBDD, with any list containing x as its ordering. Even the BDDs B0 and B1 are OBDDs, a suitableordering list being the empty list (there are no variables), or indeed any list. The path for (x, y, z) ⇒(0, 0, 0) – meaning that x, y and z are assigned 0 – shows that y needs to occur before x in such a list. Another example of a BDD that is not ordered can be seen in Figures 6.7 and 6.10. It follows that one cannot have multipleoccurrences of any variable along a path.",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-6-section-2",
                    "title": "Algorithms for Reduced OBDDs",
                    "content": "label id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\nlabel (say #0) to the ﬁrst 0-node it encounters. All other terminal 0-nodes\ndenote the same function as the ﬁrst 0-node and therefore get the same label\n(compare with reduction C1). Similarly, the 1-nodes all get the next label,\nsay #1.\nNow let us inductively assume that reduce has already assigned integer\nlabels to all nodes of a layer > i (i.e. all terminal nodes and xj-nodes with\nj > i). We describe how nodes of layer i (i.e. xi-nodes) are being handled.\nDeﬁnition 6.8 Given a non-terminal node n in a BDD, we deﬁne lo(n) to\nbe the node pointed to via the dashed line from n. Dually, hi(n) is the node\npointed to via the solid line from n.\nLet us describe how the labelling is done. Given an xi-node n, there are\nthree ways in which it may get its label:\n6.2 Algorithms for reduced OBDDs\n373\n0\n1\n#0\n#1\n0\n1\n0\n1\nx3\nx3\nx2\nx2\nx1\n#0\n#1\n#0\n#1\n#2\n#2\n#3\n#2\n#4\n=⇒\nx3\nx2\nx1\n#2\n#3\n#4\nReduce\nFigure 6.14. An example execution of the algorithm reduce.\nr If the label id(lo(n)) is the same as id(hi(n)), then we set id(n) to be that label.\nThat is because the boolean function represented at n is the same function as the\none represented at lo(n) and hi(n). In other words, node n performs a redundant\ntest and can be eliminated by reduction C2.\nr If there is another node m such that n and m have the same variable xi, and\nid(lo(n)) = id(lo(m)) and id(hi(n)) = id(hi(m)), then we set id(n) to be id(m).\nThis is because the nodes n and m compute the same boolean function (compare\nwith reduction C3).\nr Otherwise, we set id(n) to the next unused integer label.\nNote that only the last case creates a new label. Consider the OBDD\nin left side of Figure 6.14; each node has an integer label obtained in the\nwith reduction C3).\nr Otherwise, we set id(n) to the next unused integer label.\nNote that only the last case creates a new label. Consider the OBDD\nin left side of Figure 6.14; each node has an integer label obtained in the\nmanner just described. The algorithm reduce then ﬁnishes by redirecting\nedges bottom-up as outlined in C1–C3. The resulting reduced OBDD is in\nright of Figure 6.14. Since there are eﬃcient bottom-up traversal algorithms\nfor dags, reduce is an eﬃcient operation in the number of nodes of an\nOBDD.\n6.2.2 The algorithm apply\nAnother procedure at the heart of OBDDs is the algorithm apply. It is\nused to implement operations on boolean functions such as +, · , ⊕and\ncomplementation (via f ⊕1). Given OBDDs Bf and Bg for boolean formulas\nf and g, the call apply (op, Bf, Bg) computes the reduced OBDD of the\nboolean formula f op g, where op denotes any function from {0, 1} × {0, 1}\nto {0, 1}.\n374\n6 Binary decision diagrams\nThe intuition behind the apply algorithm is fairly simple. The algorithm\noperates recursively on the structure of the two OBDDs:\n1.\nlet v be the variable highest in the ordering (=leftmost in the list) which occurs\nin Bf or Bg.\n2.\nsplit the problem into two subproblems for v being 0 and v being 1 and solve\nrecursively;\n3.\nat the leaves, apply the boolean operation op directly.\nThe result will usually have to be reduced to make it into an OBDD. Some\nreduction can be done ‘on the ﬂy’ in step 2, by avoiding the creation of a new\nnode if both branches are equal (in which case return the common result),\nor if an equivalent node already exists (in which case, use it).\nLet us make all this more precise and detailed.\nDeﬁnition 6.9 Let f be a boolean formula and x a variable.\n1.\nWe denote by f[0/x] the boolean formula obtained by replacing all occurrences\nof x in f by 0. The formula f[1/x] is deﬁned similarly. The expressions f[0/x]\nand f[1/x] are called restrictions of f.\n2.\nordering and then to apply all possible reductions.\n(a) [x, y, z].\n(b) [y, x, z].\n(c) [z, x, y].\n(d) Find an ordering of variables for which the resulting reduced OBDD Bf has a\nminimal number of edges; i.e. there is no ordering for which the corresponding\nBf has fewer edges. (How many possible orderings for x, y and z are there?)\n4. Given the truth table\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n1\ncompute the reduced OBDD with respect to the following ordering of variables:\n(a) [x, y, z]\n(b) [z, y, x]\n(c) [y, z, x]\n(d) [x, z, y].\n5. Given the ordering [p, q, r], compute the reduced BDDs for p ∧(q ∨r) and (p ∧\nq) ∨(p ∧r) and explain why they are identical.\n6.\n*\nConsider the BDD in Figure 6.11 (page 370).\n(a) Construct its truth table.\n(b) Compute its conjunctive normal form.\n(c) Compare the length of that normal form with the size of the BDD. What is\nyour assessment?\n402\n6 Binary decision diagrams\nExercises 6.6\n1. Perform the execution of reduce on the following OBDDs:\n(a) The binary decision tree for\ni. x ⊕y\nii. x · y\niii. x + y\niv. x ↔y.\n(b) The OBDD in Figure 6.2 (page 361).\n(c)\n*\nThe OBDD in Figure 6.4 (page 363).\nExercises 6.7\n1. Recall the Shannon expansion in (6.1) on page 374. Suppose that x does not\noccur in f at all. Why does (6.1) still hold?\n2. Let f(x, y, z)\ndef\n= y + z · x + z · y + y · x be a boolean formula. Compute f’s\nShannon expansion with respect to\n(a) x\n(b) y\n(c) z.\n3. Show that boolean formulas f and g are semantically equivalent if, and only if,\nthe boolean formula (f + g) · (f + g) computes 1 for all possible assignments of\n0s and 1s to their variables.\n4. We may use the Shannon expansion to deﬁne formally how BDDs determine\nboolean functions. Let B be a BDD. It is intuitively clear that B determines\na unique boolean function. Formally, we compute a function fn inductively\n(bottom-up) for all nodes n of B:\n– If n is a terminal node labelled 0, then fn is the constant 0 function.\nv op x = 1 or v op x = 0 for all values of x. We say that v is a controlling value\nif it is a left- and right-controlling value.\n(a) Deﬁne the notion of a right-controlling value.\n(b) Give examples of operations with controlling values.\n(c) Describe informally how apply can be optimised when op has a controlling\nvalue.\n(d) Could one still do some optimisation if op had only a left- or right-controlling\nvalue?\n12. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that\nthis upper bound is hard, i.e. it cannot be improved:\n(a) Consider the functions f(x1, x2, . . . , x2n+2m)\ndef\n= x1 · xn+m+1 + · · · + xn ·\nx2n+m and g(x1, x2, . . . , x2n+2m)\ndef\n= xn+1 · x2n+m+1 + · · · + xn+m · x2n+2m\nwhich are in sum-of-product form. Compute the sum-of-product form of\nf + g.\n(b) Choose the ordering [x1, x2, . . . , x2n+2m] and argue that the OBDDs Bf\nand Bg have 2n+1 and 2m+1 edges, respectively.\n(c) Use the result from part (a) to conclude that Bf+g has 2n+m+1 edges, i.e.\n0.5 · |Bf| · |Bg|.\nExercises 6.8\n1. Let f be the reduced OBDD represented in Figure 6.5(b) (page 364). Compute\nthe reduced OBDD for the restrictions:\n(a) f[0/x]\n(b)\n*\nf[1/x]\n6.5 Exercises\n405\n(c) f[1/y]\n(d)\n*\nf[0/z].\n2.\n*\nSuppose that we intend to modify the algorithm restrict so that it is capable\nof computing reduced OBDDs for a general composition f[g/x].\n(a) Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation\n[g/x].\n(b) What fact about OBDDs causes problems for computing this composition\ndirectly?\n(c) How can we compute this composition given the algorithms discussed so far?\n3. We deﬁne read-1-BDDs as BDDs B where each boolean variable occurs at most\nonce on any evaluation path of B. In particular, read-1-BDDs need not possess\nan ordering on their boolean variables. Clearly, every OBDD is a read-1-BDD;\nbut not every read-1-BDD is an OBDD (see Figure 6.10). In Figure 6.18 we see\na BDD which is not a read-1-BDD; the path for (x, y, z) ⇒(1, 0, 1) ‘reads’ the v op x = 1 or v op x = 0 for all values of x. We say that v is a controlling value\nif it is a left- and right-controlling value.\n(a) Deﬁne the notion of a right-controlling value.\n(b) Give examples of operations with controlling values.\n(c) Describe informally how apply can be optimised when op has a controlling\nvalue.\n(d) Could one still do some optimisation if op had only a left- or right-controlling\nvalue?\n12. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that\nthis upper bound is hard, i.e. it cannot be improved:\n(a) Consider the functions f(x1, x2, . . . , x2n+2m)\ndef\n= x1 · xn+m+1 + · · · + xn ·\nx2n+m and g(x1, x2, . . . , x2n+2m)\ndef\n= xn+1 · x2n+m+1 + · · · + xn+m · x2n+2m\nwhich are in sum-of-product form. Compute the sum-of-product form of\nf + g.\n(b) Choose the ordering [x1, x2, . . . , x2n+2m] and argue that the OBDDs Bf\nand Bg have 2n+1 and 2m+1 edges, respectively.\n(c) Use the result from part (a) to conclude that Bf+g has 2n+m+1 edges, i.e.\n0.5 · |Bf| · |Bg|.\nExercises 6.8\n1. Let f be the reduced OBDD represented in Figure 6.5(b) (page 364). Compute\nthe reduced OBDD for the restrictions:\n(a) f[0/x]\n(b)\n*\nf[1/x]\n6.5 Exercises\n405\n(c) f[1/y]\n(d)\n*\nf[0/z].\n2.\n*\nSuppose that we intend to modify the algorithm restrict so that it is capable\nof computing reduced OBDDs for a general composition f[g/x].\n(a) Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation\n[g/x].\n(b) What fact about OBDDs causes problems for computing this composition\ndirectly?\n(c) How can we compute this composition given the algorithms discussed so far?\n3. We deﬁne read-1-BDDs as BDDs B where each boolean variable occurs at most\nonce on any evaluation path of B. In particular, read-1-BDDs need not possess\nan ordering on their boolean variables. Clearly, every OBDD is a read-1-BDD;\nbut not every read-1-BDD is an OBDD (see Figure 6.10). In Figure 6.18 we see\na BDD which is not a read-1-BDD; the path for (x, y, z) ⇒(1, 0, 1) ‘reads’ the\nonly if x is 1; or y is 0 and z is 1 – this is a constraint on x, y, and z.\nIt is useful to be able to express the relaxation of the constraint on a subset\nof the variables concerned. To allow this, we write ∃x. f for the boolean\nfunction f with the constraint on x relaxed. Formally, ∃x. f is deﬁned as\nf[0/x] + f[1/x]; that is, ∃x. f is true if f could be made true by putting x\nto 0 or to 1. Given that ∃x. f\ndef\n= f[0/x] + f[1/x] the exists algorithm can\nbe implemented in terms of the algorithms apply and restrict as\napply (+, restrict (0, x, Bf), restrict (1, x, Bf)) .\n(6.3)\nConsider, for example, the OBDD Bf for the function f\ndef\n= x1 · y1 + x2 ·\ny2 + x3 · y3, shown in Figure 6.19. Figure 6.20 shows restrict(0, x3, Bf)\nand restrict(1, x3, Bf) and the result of applying + to them. (In this case\nthe apply function happens to return its second argument.)\nWe can improve the eﬃciency of this algorithm. Consider what happens\nduring the apply stage of (6.3). In that case, the apply algorithm works on\ntwo BDDs which are identical all the way down to the level of the x-nodes;\n378\n6 Binary decision diagrams\n1\n0\nx\nx\nx\nz\ny\nFigure 6.18. An example of a BDD which is not a read-1-BDD.\n1\n0\nx1\nx2\nx3\ny1\ny2\ny3\nFigure 6.19. A BDD Bf to illustrate the exists algorithm.\ntherefore the returned BDD also has that structure down to the x-nodes.\nAt the x-nodes, the two argument BDDs diﬀer, so the apply algorithm\nwill compute the apply of + to these two subBDDs and return that as the\nsubBDD of the result. This is illustrated in Figure 6.20. Therefore, we can\ncompute the OBDD for ∃x. f by taking the OBDD for f and replacing each\nnode labelled with x by the result of calling apply on + and its two branches.\nThis can easily be generalised to a sequence of exists operations. We\nwrite ∃ˆx. f to mean ∃x1.∃x2. . . . ∃xn. f, where ˆx denotes (x1, x2, . . . , xn).\n6.2 Algorithms for reduced OBDDs\n379\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\n1\n0\nx1\nx2\ny1\ny2\nx1\nx2\ny1\ny2\ny3",
                    "summary": "Let us describe how the labelling is done. Given a non-terminal node n in a BDD, we deﬁne lo(n) to                be the node pointed to via the dashed line from n. Dually, hi( n) is the node vehementlypointed to via a solid line. We describe how nodes of layer i (i.e. xi-nodes) are being handled. We assume that reduce has already assigned integerlabels to all nodes of a layer > i. All other terminal 0-Nodesdenote the same function as the ﬁrst 0-node and therefore get the same label(compare with reduction C1). Similarly, the 1 Given an xi-node n, there are three ways in which it may get its label. In other words, node n performs a redundant test and can be eliminated by reduction C2. If the label id(lo(n)) is the same as id(hi(n), then we set id(n) to be that label. If there is another node m such that n and m have the same variable xi, we set n to be id(m) This is because the nodes n andm compute the same boolean function (compare with reduction C3). Otherwise, weSet id( n) to the next unused integer label.Note that only the last case creates a new label.  reduce is an eﬃcient operation in the number of nodes of anOBDD. Consider the OBDD                in left side of Figure 6.14; each node has an integer label obtained in the                with reduction C3). Otherwise, we set id(n) to the next unused integer label. The algorithm reduce then redirects                edges bottom-up as outlined in C1–C3. The resulting reduced OBDDs is in the right side of the figure.6.2.2 The algorithm apply is used to implement operations on boolean functions such as +, · , ⊕and ⊉. The apply algorithm is fairly simple. Given OBDDs Bf and Bg for boolean formulasf and g, the call apply (op, Bf, Bg) computes the reduced OBDD of the formula f op g. The algorithm operates recursively on the structure of the two O BDDs. The result will usually have to be reduced to make it into an OBDC. The algorithms can also be used to solve problems in binary decision diagrams. For example, the apply algorithm can solve the problem of choosing between a binary decision and a binary binary decision. Deﬁnition 6.9 lets f be a boolean formula and x a variable. Find an ordering of variables for which the resulting reduced OBDD Bf has a minimal number of edges. Some reductions can be done ‘on the ﬂy’ in step 2, by avoiding the creation of a newnode if both branches are equal (in which case return the common result) or if an equivalent node already exists. The expressions f[0/x] and f[1/x) are called restrictions of f. The formula f[2/x], f[3/x), f[4/x, f[5/X] andf[6/X) are also Given the ordering [p, q, r], compute the reduced BDDs for p and q. Compute the reduced OBDD with respect to the following ordering of variables: [x, y, z] and [y, z, x]. Compute its conjunctive normal form. Compare the length of that normal form with the size of the BDD. Perform the execution of reduce on the following OBDDs: The binary decision tree for x, y and y + y + x + y. The O BDD in Figure 6.2 (page 361). The OBD D in Figure.4 (page 363). The binary Decision Tree for X, Y and Y. Let B be a BDD. Compute f’s Shannon expansion with respect to x. Show that f and g are semantically equivalent if, and only if, the formula (f + g) computes 1 for all possible assignments of                0s and 1s to their variables. We may use the Shannon expansion to deﬁne formally how BDDs determine functions. It is intuitively clear that B determines a unique boolean function. Formally, we compute a function fn inductively(bottom-up) for all nodes n of B. If n is a terminal node labelled 0, then fn is the constant 0 function. If v op x = 0 for all values of x, then v op We say that v is a controlling value if it is a left- and right-controlling value. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that this upper bound is hard, i.e. it cannot be improved. Describe informally how apply can be optimised when op has a controllingvalue. Exercises 6.8.1.1: The OBDDs Bf and Bg have 2n+1 and 2m+1 edges, respectively, and are in sum-of-product form. We show that Bf+g has 2n-1 and2m-1 edges. Every OBDD is a read-1-BDD; but not every read-2-BDDs are OBDDs. In Figure 6.18 we see a BDD which is not a read. The path for (x, y, z) ‘reads’ the v op x = 1 or v op X = 0 for all values of x. We deﬁne read-4-BDs as BDDs B where each boolean variable occurs at most once on any evaluation path of B. We use the Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation f[g/x]. We say that v is a controlling value if it is a left- and right-controlling value. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that this upper bound is hard, i.e. it cannot be improved. Describe informally how apply can be optimised when op has a controllingvalue. Exercises 6.8.1.1: The OBDDs Bf and Bg have 2n+1 and 2m+1 edges, respectively, and are in sum-of-product form. We show that Bf+g has 2n-1 and2m-1 edges. The reduced OBDD is represented in Figure 6.5(b) (page 364) We deﬁne read-1-BDDs as BDDs B where each boolean variable occurs at most once on any evaluation path of B. We use the Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation f[g/x] (see 6.10) (see also 6.9 and 6.11) for more details on the algorithms discussed so far. We also use the Exercises section of the paper to show how to use the exercises to compute OBDDs for a general composition. In Figure 6.18 we see a BDD which is not a read-1-BDD. The path for (x, y, z) ‘reads’ the variables only if x is 1; or y is 0 and z is 1. It is useful to be able to express the relaxation of the constraint on a subset of the variables concerned. To allow this, we write ∃x. f for the boolean function f with a constraint on x relaxed. The exists algorithm can be implemented in terms of the algorithms apply and restrict as follows: apply (+, restrict (0, x, Bf), restrict (1, x,. Bf) .                (6.3) The apply algorithm works on two BDDs which are identical all the way down to the level of the x-nodes. It can easily be generalised to a sequence of exists operations. We can compute the OBDD for f by replacing eachnode labelled with x by the result of calling apply on + and its two branches. This is illustrated in Figure 6.20. The BDD Bf is used to illustrate the exists algorithm. It is also used to show the structure of a BDD which is not a read-1-BDD. For more information, see the BDD Diagrams section of the book. The book is published by Oxford University Press, priced £16.99. 6.2 Algorithms for reduced OBDDs. The algorithm is based on a series of algorithms for reducing",
                    "children": [
                        {
                            "id": "chapter-6-section-2-subsection-1",
                            "title": "The Algorithm Reduce",
                            "content": "label id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\nlabel (say #0) to the ﬁrst 0-node it encounters. All other terminal 0-nodes\ndenote the same function as the ﬁrst 0-node and therefore get the same label\n(compare with reduction C1). Similarly, the 1-nodes all get the next label,\nsay #1.\nNow let us inductively assume that reduce has already assigned integer\nlabels to all nodes of a layer > i (i.e. all terminal nodes and xj-nodes with\nj > i). We describe how nodes of layer i (i.e. xi-nodes) are being handled.\nDeﬁnition 6.8 Given a non-terminal node n in a BDD, we deﬁne lo(n) to\nbe the node pointed to via the dashed line from n. Dually, hi(n) is the node\npointed to via the solid line from n.\nLet us describe how the labelling is done. Given an xi-node n, there are\nthree ways in which it may get its label:\n6.2 Algorithms for reduced OBDDs\n373\n0\n1\n#0\n#1\n0\n1\n0\n1\nx3\nx3\nx2\nx2\nx1\n#0\n#1\n#0\n#1\n#2\n#2\n#3\n#2\n#4\n=⇒\nx3\nx2\nx1\n#2\n#3\n#4\nReduce\nFigure 6.14. An example execution of the algorithm reduce.\nr If the label id(lo(n)) is the same as id(hi(n)), then we set id(n) to be that label.\nThat is because the boolean function represented at n is the same function as the\none represented at lo(n) and hi(n). In other words, node n performs a redundant\ntest and can be eliminated by reduction C2.\nr If there is another node m such that n and m have the same variable xi, and\nid(lo(n)) = id(lo(m)) and id(hi(n)) = id(hi(m)), then we set id(n) to be id(m).\nThis is because the nodes n and m compute the same boolean function (compare\nwith reduction C3).\nr Otherwise, we set id(n) to the next unused integer label.\nNote that only the last case creates a new label. Consider the OBDD\nin left side of Figure 6.14; each node has an integer label obtained in the\nwith reduction C3).\nr Otherwise, we set id(n) to the next unused integer label.\nNote that only the last case creates a new label. Consider the OBDD\nin left side of Figure 6.14; each node has an integer label obtained in the\nmanner just described. The algorithm reduce then ﬁnishes by redirecting\nedges bottom-up as outlined in C1–C3. The resulting reduced OBDD is in\nright of Figure 6.14. Since there are eﬃcient bottom-up traversal algorithms\nfor dags, reduce is an eﬃcient operation in the number of nodes of an\nOBDD.\n6.2.2 The algorithm apply\nAnother procedure at the heart of OBDDs is the algorithm apply. It is\nused to implement operations on boolean functions such as +, · , ⊕and\ncomplementation (via f ⊕1). Given OBDDs Bf and Bg for boolean formulas\nf and g, the call apply (op, Bf, Bg) computes the reduced OBDD of the\nboolean formula f op g, where op denotes any function from {0, 1} × {0, 1}\nto {0, 1}.\n374\n6 Binary decision diagrams\nThe intuition behind the apply algorithm is fairly simple. The algorithm\noperates recursively on the structure of the two OBDDs:\n1.\nlet v be the variable highest in the ordering (=leftmost in the list) which occurs\nin Bf or Bg.\n2.\nsplit the problem into two subproblems for v being 0 and v being 1 and solve\nrecursively;\n3.\nat the leaves, apply the boolean operation op directly.\nThe result will usually have to be reduced to make it into an OBDD. Some\nreduction can be done ‘on the ﬂy’ in step 2, by avoiding the creation of a new\nnode if both branches are equal (in which case return the common result),\nor if an equivalent node already exists (in which case, use it).\nLet us make all this more precise and detailed.\nDeﬁnition 6.9 Let f be a boolean formula and x a variable.\n1.\nWe denote by f[0/x] the boolean formula obtained by replacing all occurrences\nof x in f by 0. The formula f[1/x] is deﬁned similarly. The expressions f[0/x]\nand f[1/x] are called restrictions of f.\n2.\nordering and then to apply all possible reductions.\n(a) [x, y, z].\n(b) [y, x, z].\n(c) [z, x, y].\n(d) Find an ordering of variables for which the resulting reduced OBDD Bf has a\nminimal number of edges; i.e. there is no ordering for which the corresponding\nBf has fewer edges. (How many possible orderings for x, y and z are there?)\n4. Given the truth table\nx\ny\nz\nf(x, y, z)\n1\n1\n1\n0\n1\n1\n0\n1\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n1\ncompute the reduced OBDD with respect to the following ordering of variables:\n(a) [x, y, z]\n(b) [z, y, x]\n(c) [y, z, x]\n(d) [x, z, y].\n5. Given the ordering [p, q, r], compute the reduced BDDs for p ∧(q ∨r) and (p ∧\nq) ∨(p ∧r) and explain why they are identical.\n6.\n*\nConsider the BDD in Figure 6.11 (page 370).\n(a) Construct its truth table.\n(b) Compute its conjunctive normal form.\n(c) Compare the length of that normal form with the size of the BDD. What is\nyour assessment?\n402\n6 Binary decision diagrams\nExercises 6.6\n1. Perform the execution of reduce on the following OBDDs:\n(a) The binary decision tree for\ni. x ⊕y\nii. x · y\niii. x + y\niv. x ↔y.\n(b) The OBDD in Figure 6.2 (page 361).\n(c)\n*\nThe OBDD in Figure 6.4 (page 363).\nExercises 6.7\n1. Recall the Shannon expansion in (6.1) on page 374. Suppose that x does not\noccur in f at all. Why does (6.1) still hold?\n2. Let f(x, y, z)\ndef\n= y + z · x + z · y + y · x be a boolean formula. Compute f’s\nShannon expansion with respect to\n(a) x\n(b) y\n(c) z.\n3. Show that boolean formulas f and g are semantically equivalent if, and only if,\nthe boolean formula (f + g) · (f + g) computes 1 for all possible assignments of\n0s and 1s to their variables.\n4. We may use the Shannon expansion to deﬁne formally how BDDs determine\nboolean functions. Let B be a BDD. It is intuitively clear that B determines\na unique boolean function. Formally, we compute a function fn inductively\n(bottom-up) for all nodes n of B:\n– If n is a terminal node labelled 0, then fn is the constant 0 function.\nv op x = 1 or v op x = 0 for all values of x. We say that v is a controlling value\nif it is a left- and right-controlling value.\n(a) Deﬁne the notion of a right-controlling value.\n(b) Give examples of operations with controlling values.\n(c) Describe informally how apply can be optimised when op has a controlling\nvalue.\n(d) Could one still do some optimisation if op had only a left- or right-controlling\nvalue?\n12. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that\nthis upper bound is hard, i.e. it cannot be improved:\n(a) Consider the functions f(x1, x2, . . . , x2n+2m)\ndef\n= x1 · xn+m+1 + · · · + xn ·\nx2n+m and g(x1, x2, . . . , x2n+2m)\ndef\n= xn+1 · x2n+m+1 + · · · + xn+m · x2n+2m\nwhich are in sum-of-product form. Compute the sum-of-product form of\nf + g.\n(b) Choose the ordering [x1, x2, . . . , x2n+2m] and argue that the OBDDs Bf\nand Bg have 2n+1 and 2m+1 edges, respectively.\n(c) Use the result from part (a) to conclude that Bf+g has 2n+m+1 edges, i.e.\n0.5 · |Bf| · |Bg|.\nExercises 6.8\n1. Let f be the reduced OBDD represented in Figure 6.5(b) (page 364). Compute\nthe reduced OBDD for the restrictions:\n(a) f[0/x]\n(b)\n*\nf[1/x]\n6.5 Exercises\n405\n(c) f[1/y]\n(d)\n*\nf[0/z].\n2.\n*\nSuppose that we intend to modify the algorithm restrict so that it is capable\nof computing reduced OBDDs for a general composition f[g/x].\n(a) Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation\n[g/x].\n(b) What fact about OBDDs causes problems for computing this composition\ndirectly?\n(c) How can we compute this composition given the algorithms discussed so far?\n3. We deﬁne read-1-BDDs as BDDs B where each boolean variable occurs at most\nonce on any evaluation path of B. In particular, read-1-BDDs need not possess\nan ordering on their boolean variables. Clearly, every OBDD is a read-1-BDD;\nbut not every read-1-BDD is an OBDD (see Figure 6.10). In Figure 6.18 we see\na BDD which is not a read-1-BDD; the path for (x, y, z) ⇒(1, 0, 1) ‘reads’ the",
                            "summary": "Let us describe how the labelling is done. Given a non-terminal node n in a BDD, we deﬁne lo(n) to                be the node pointed to via the dashed line from n. Dually, hi( n) is the node vehementlypointed to via a solid line. We describe how nodes of layer i (i.e. xi-nodes) are being handled. We assume that reduce has already assigned integerlabels to all nodes of a layer > i. All other terminal 0-Nodesdenote the same function as the ﬁrst 0-node and therefore get the same label(compare with reduction C1). Similarly, the 1 Given an xi-node n, there are three ways in which it may get its label. In other words, node n performs a redundant test and can be eliminated by reduction C2. If the label id(lo(n)) is the same as id(hi(n), then we set id(n) to be that label. If there is another node m such that n and m have the same variable xi, we set n to be id(m) This is because the nodes n andm compute the same boolean function (compare with reduction C3). Otherwise, weSet id( n) to the next unused integer label.Note that only the last case creates a new label.  reduce is an eﬃcient operation in the number of nodes of anOBDD. Consider the OBDD                in left side of Figure 6.14; each node has an integer label obtained in the                with reduction C3). Otherwise, we set id(n) to the next unused integer label. The algorithm reduce then redirects                edges bottom-up as outlined in C1–C3. The resulting reduced OBDDs is in the right side of the figure.6.2.2 The algorithm apply is used to implement operations on boolean functions such as +, · , ⊕and ⊉. The apply algorithm is fairly simple. Given OBDDs Bf and Bg for boolean formulasf and g, the call apply (op, Bf, Bg) computes the reduced OBDD of the formula f op g. The algorithm operates recursively on the structure of the two O BDDs. The result will usually have to be reduced to make it into an OBDC. The algorithms can also be used to solve problems in binary decision diagrams. For example, the apply algorithm can solve the problem of choosing between a binary decision and a binary binary decision. Deﬁnition 6.9 lets f be a boolean formula and x a variable. Find an ordering of variables for which the resulting reduced OBDD Bf has a minimal number of edges. Some reductions can be done ‘on the ﬂy’ in step 2, by avoiding the creation of a newnode if both branches are equal (in which case return the common result) or if an equivalent node already exists. The expressions f[0/x] and f[1/x) are called restrictions of f. The formula f[2/x], f[3/x), f[4/x, f[5/X] andf[6/X) are also Given the ordering [p, q, r], compute the reduced BDDs for p and q. Compute the reduced OBDD with respect to the following ordering of variables: [x, y, z] and [y, z, x]. Compute its conjunctive normal form. Compare the length of that normal form with the size of the BDD. Perform the execution of reduce on the following OBDDs: The binary decision tree for x, y and y + y + x + y. The O BDD in Figure 6.2 (page 361). The OBD D in Figure.4 (page 363). The binary Decision Tree for X, Y and Y. Let B be a BDD. Compute f’s Shannon expansion with respect to x. Show that f and g are semantically equivalent if, and only if, the formula (f + g) computes 1 for all possible assignments of                0s and 1s to their variables. We may use the Shannon expansion to deﬁne formally how BDDs determine functions. It is intuitively clear that B determines a unique boolean function. Formally, we compute a function fn inductively(bottom-up) for all nodes n of B. If n is a terminal node labelled 0, then fn is the constant 0 function. If v op x = 0 for all values of x, then v op We say that v is a controlling value if it is a left- and right-controlling value. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that this upper bound is hard, i.e. it cannot be improved. Describe informally how apply can be optimised when op has a controllingvalue. Exercises 6.8.1.1: The OBDDs Bf and Bg have 2n+1 and 2m+1 edges, respectively, and are in sum-of-product form. We show that Bf+g has 2n-1 and2m-1 edges. Every OBDD is a read-1-BDD; but not every read-2-BDDs are OBDDs. In Figure 6.18 we see a BDD which is not a read. The path for (x, y, z) ‘reads’ the. path for    ‘ reads’ (1, 0, 1) (see 6.10). We deﬁne read-4-BDs as BDDs B where each. boolean variable occurs at most once on any evaluation path of B. (6.1.1) to reﬂect the intuitive meaning of the operation f[g/x] (page 364) 6.",
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-2-subsection-2",
                            "title": "The Algorithm Apply",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-2-subsection-3",
                            "title": "The Algorithm Restrict",
                            "content": "v op x = 1 or v op x = 0 for all values of x. We say that v is a controlling value\nif it is a left- and right-controlling value.\n(a) Deﬁne the notion of a right-controlling value.\n(b) Give examples of operations with controlling values.\n(c) Describe informally how apply can be optimised when op has a controlling\nvalue.\n(d) Could one still do some optimisation if op had only a left- or right-controlling\nvalue?\n12. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that\nthis upper bound is hard, i.e. it cannot be improved:\n(a) Consider the functions f(x1, x2, . . . , x2n+2m)\ndef\n= x1 · xn+m+1 + · · · + xn ·\nx2n+m and g(x1, x2, . . . , x2n+2m)\ndef\n= xn+1 · x2n+m+1 + · · · + xn+m · x2n+2m\nwhich are in sum-of-product form. Compute the sum-of-product form of\nf + g.\n(b) Choose the ordering [x1, x2, . . . , x2n+2m] and argue that the OBDDs Bf\nand Bg have 2n+1 and 2m+1 edges, respectively.\n(c) Use the result from part (a) to conclude that Bf+g has 2n+m+1 edges, i.e.\n0.5 · |Bf| · |Bg|.\nExercises 6.8\n1. Let f be the reduced OBDD represented in Figure 6.5(b) (page 364). Compute\nthe reduced OBDD for the restrictions:\n(a) f[0/x]\n(b)\n*\nf[1/x]\n6.5 Exercises\n405\n(c) f[1/y]\n(d)\n*\nf[0/z].\n2.\n*\nSuppose that we intend to modify the algorithm restrict so that it is capable\nof computing reduced OBDDs for a general composition f[g/x].\n(a) Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation\n[g/x].\n(b) What fact about OBDDs causes problems for computing this composition\ndirectly?\n(c) How can we compute this composition given the algorithms discussed so far?\n3. We deﬁne read-1-BDDs as BDDs B where each boolean variable occurs at most\nonce on any evaluation path of B. In particular, read-1-BDDs need not possess\nan ordering on their boolean variables. Clearly, every OBDD is a read-1-BDD;\nbut not every read-1-BDD is an OBDD (see Figure 6.10). In Figure 6.18 we see\na BDD which is not a read-1-BDD; the path for (x, y, z) ⇒(1, 0, 1) ‘reads’ the\nonly if x is 1; or y is 0 and z is 1 – this is a constraint on x, y, and z.\nIt is useful to be able to express the relaxation of the constraint on a subset\nof the variables concerned. To allow this, we write ∃x. f for the boolean\nfunction f with the constraint on x relaxed. Formally, ∃x. f is deﬁned as\nf[0/x] + f[1/x]; that is, ∃x. f is true if f could be made true by putting x\nto 0 or to 1. Given that ∃x. f\ndef\n= f[0/x] + f[1/x] the exists algorithm can\nbe implemented in terms of the algorithms apply and restrict as\napply (+, restrict (0, x, Bf), restrict (1, x, Bf)) .\n(6.3)\nConsider, for example, the OBDD Bf for the function f\ndef\n= x1 · y1 + x2 ·\ny2 + x3 · y3, shown in Figure 6.19. Figure 6.20 shows restrict(0, x3, Bf)\nand restrict(1, x3, Bf) and the result of applying + to them. (In this case\nthe apply function happens to return its second argument.)\nWe can improve the eﬃciency of this algorithm. Consider what happens\nduring the apply stage of (6.3). In that case, the apply algorithm works on\ntwo BDDs which are identical all the way down to the level of the x-nodes;\n378\n6 Binary decision diagrams\n1\n0\nx\nx\nx\nz\ny\nFigure 6.18. An example of a BDD which is not a read-1-BDD.\n1\n0\nx1\nx2\nx3\ny1\ny2\ny3\nFigure 6.19. A BDD Bf to illustrate the exists algorithm.\ntherefore the returned BDD also has that structure down to the x-nodes.\nAt the x-nodes, the two argument BDDs diﬀer, so the apply algorithm\nwill compute the apply of + to these two subBDDs and return that as the\nsubBDD of the result. This is illustrated in Figure 6.20. Therefore, we can\ncompute the OBDD for ∃x. f by taking the OBDD for f and replacing each\nnode labelled with x by the result of calling apply on + and its two branches.\nThis can easily be generalised to a sequence of exists operations. We\nwrite ∃ˆx. f to mean ∃x1.∃x2. . . . ∃xn. f, where ˆx denotes (x1, x2, . . . , xn).\n6.2 Algorithms for reduced OBDDs\n379\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\n1\n0\nx1\nx2\ny1\ny2\nx1\nx2\ny1\ny2\ny3",
                            "summary": "We say that v is a controlling value if it is a left- and right-controlling value. We showed that the worst-time complexity of apply is O(|Bf| · |Bg|). Show that this upper bound is hard, i.e. it cannot be improved. Describe informally how apply can be optimised when op has a controllingvalue. We show that the sum-of-product form of f (x1, x2, . . . , x2n+2m) and g (x2n + 2m) can be used to compute the upper bound of O(Bf | Bg) for apply. 6.5 Exercises: Generalise Equation (6.1) to reﬂect the intuitive meaning of the operation. 6.8 Exercise: Compute the reduced OBDD for the restrictions: f[0/x] f[1/y] f [0/z]. 2.3 Exercised: compute the OBDDs Bf and Bg for a general composition f[g/x]. 3. The algorithm is now ready to be used in the next section of the book. The book is published by Oxford University Press, London, UK, priced £9.99 (including p&p) and £14.99 for non-UK copies. Every OBDD is a read-1-BDD; but not all OBDDs are. The path for (x, y, z) ‘reads’ the                only if x is 1; or y is 0 and z is 1. It is useful to be able to express the relaxation of the constraint on a subset of the variables concerned. To allow this, we write ∃x. f for the function f with a relaxed constraint on x. The exists algorithm can be implemented in terms of the algorithms apply and restrict as follows: apply (+, restrict (0, x, Bf), restrict (1, x,. Bf) . The result of applying + to them is the same as applying The apply algorithm works on two BDDs which are identical all the way down to the level of the x-nodes. We can improve the eﬃciency of this algorithm by taking the OBDD for f and replacing eachnode labelled with x by the result of calling apply on + and its two branches. This can easily be generalised to a sequence of exists operations. For example, we can write f to mean ∃x1.∃x2. . . .          . .   .   .  —   —  — — —— — —– — —- — — –— —— – — —­ — — 6.2 Algorithms for reduced OBDDs. ˆx denotes (x1, x2, . . . , xn), where ",
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-2-subsection-4",
                            "title": "The Algorithm Exists",
                            "content": "",
                            "summary": null,
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-6-section-3",
                    "title": "Symbolic Model Checking",
                    "content": "represent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nelements in S. If |S| is not an exact power of 2, there will be some vec-\ntors which do not correspond to any element of S; they are just ignored.\nThe function fT : {0, 1}n →{0, 1} which tells us, for each s, represented by\n(v1, v2, . . . , vn), whether it is in the set T or not, is called the characteristic\nfunction of T.\nIn the case that S is the set of states of a transition system M = (S, →, L)\n(see Deﬁnition 3.4), there is a natural way of choosing the representation\nof S as boolean vectors. The labelling function L : S →P(Atoms) (where\nP(Atoms) is the set of subsets of Atoms) gives us the encoding. We assume\na ﬁxed ordering on the set Atoms, say x1, x2, . . . , xn, and then represent\ns ∈S by the vector (v1, v2, . . . , vn), where, for each i, vi equals 1 if xi ∈\nL(s) and vi is 0 otherwise. In order to guarantee that each s has a unique\nrepresentation as a boolean vector, we require that, for all s1, s2 ∈S, L(s1) =\nL(s2) implies s1 = s2. If this is not the case, perhaps because 2|Atoms| < |S|,\nwe can add extra atomic propositions in order to make enough distinctions\n(Cf. introduction of the turn variable for mutual exclusion in Section 3.3.4.)\nFrom now on, we refer to a state s ∈S by its representing boolean vector\n(v1, v2, . . . , vn), where vi is 1 if xi ∈L(s) and 0 otherwise. As an OBDD,\nthis state is represented by the OBDD of the boolean function l1 · l2 · · · · · ln,\nwhere li is xi if xi ∈L(s) and xi otherwise. The set of states {s1, s2, . . . , sm}\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nFigure 6.24. A simple CTL model (Example 6.12).\nset of\nrepresentation by\nrepresentation by\nstates\nboolean values\nboolean function\n∅\n0\n{s0}\n(1, 0)\nx1 · x2\n{s1}\n(0, 1)\nx1 · x2\n{s2}\n(0, 0)\nx1 · x2\n{s0, s1}\n(1, 0), (0, 1)\nx1 · x2 + x1 · x2\n{s0, s2}\n(1, 0), (0, 0)\nx1 · x2 + x1 · x2\n{s1, s2}\n(0, 1), (0, 0)\nx1 · x2 + x1 · x2\nS\n(1, 0), (0, 1), (0, 0)\nx1 · x2 + x1 · x2 + x1 · x2\nFigure 6.25. Representation of subsets of states of the model of Figure 6.24.\nThe key point which makes this representation interesting is that the\nOBDD representing a set of states may be quite small.\nExample 6.12 Consider the CTL model in Figure 6.24, given by:\nS\ndef\n= {s0, s1, s2}\n→\ndef\n= {(s0, s1), (s1, s2), (s2, s0), (s2, s2)}\nL(s0)\ndef\n= {x1}\nL(s1)\ndef\n= {x2}\nL(s2)\ndef\n= ∅.\nNote that it has the property that, for all states s1 and s2, L(s1) = L(s2)\nimplies s1 = s2, i.e. a state is determined entirely by the atomic formulas\ntrue in it. Sets of states may be represented by boolean values and by boolean\nformulas with the ordering [x1, x2], as shown in Figure 6.25.\nNotice that the vector (1, 1) and the corresponding function x1 · x2 are\nunused. Therefore, we are free to include it in the representation of a subset\n6.3 Symbolic model checking\n385\nx2\n0\n1\nx1\n0\n1\nx1\nx2\nx2\nFigure 6.26. Two OBDDs for the set {s0, s1} (Example 6.12).\nof S or not; so we may choose to include it or not in order to optimise the\nsize of the OBDD. For example, the subset {s0, s1} is better represented\nby the boolean function x1 + x2, since its OBDD is smaller than that for\nx1 · x2 + x1 · x2 (Figure 6.26).\nIn order to justify the claim that the representation of subsets of S as\nOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of x1\nx2\nx′\n1\nx′\n2\n→\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\nx1\nx′\n1\nx2\nx′\n2\n→\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\nFigure 6.27. The truth table for the transition relation of Figure 6.24\n(see Example 6.13). The left version shows the ordering of variables\n[x1, x2, x′\n1, x′\n2], while the right one orders the variables [x1, x′\n1, x2, x′\n2] (the\nrows are ordered lexicographically).\nboolean vectors ((v1, v2, . . . , vn), (v′\n1, v′\n2, . . . , v′\nn)), where vi is 1 if pi ∈L(s)\nand 0 otherwise; and similarly, v′\ni is 1 if pi ∈L(s′) and 0 otherwise. As an\nOBDD, the link is represented by the OBDD for the boolean function\n(l1 · l2 · · · · · ln) · (l′\n1 · l′\n2 · · · · · l′\nn)\nand a set of links (for example, the entire relation →) is the OBDD for the\n+ of such formulas.\nExample 6.13 To compute the OBDD for the transition relation of Fig-\nure 6.24, we ﬁrst show it as a truth table (Figure 6.27 (left)). Each 1 in\nthe ﬁnal column corresponds to a link in the transition relation and each 0\ncorresponds to the absence of a link. The boolean function is obtained by\ntaking the disjunction of the rows having 1 in the last column and is\nf→def\n= x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2.\n(6.5)\nIt turns out that it is usually more eﬃcient to interleave unprimed and\nprimed variables in the OBDD variable ordering for →. We therefore use\n6.3 Symbolic model checking\n387\n0\n1\nx2\nx2\nx′\n2\nx′\n2\nx1\nx′\n1\nx′\n1\nFigure 6.28. An OBDD for the transition relation of Example 6.13.\n[x1, x′\n1, x2, x′\n2] rather than [x1, x2, x′\n1, x′\n2]. Figure 6.27 (right) shows the truth\ntable redrawn with the interleaved ordering of the columns and the rows\nreordered lexicographically. The resulting OBDD is shown in Figure 6.28.\n4.\nThe formula\n∀x∃y R(x, y)\nstates that the model is free of states that deadlock: all states have a transition\nto some state. This is true in our model: a can move to a, b or c; and b and c\ncan move to c.\nExample 2.16 Let F\ndef\n= {e, ·} and P\ndef\n= {≤}, where e is a constant, · is a\nfunction of two arguments and ≤is a predicate in need of two arguments as\nwell. Again, we write · and ≤in inﬁx notation as in (t1 · t2) ≤(t · t).\n126\n2 Predicate logic\nThe model M we have in mind has as set A all binary strings, ﬁnite\nwords over the alphabet {0, 1}, including the empty string denoted by ϵ. The\ninterpretation eM of e is just the empty word ϵ. The interpretation ·M of · is\nthe concatenation of words. For example, 0110 ·M 1110 equals 01101110. In\ngeneral, if a1a2 . . . ak and b1b2 . . . bn are such words with ai, bj ∈{0, 1}, then\na1a2 . . . ak ·M b1b2 . . . bn equals a1a2 . . . akb1b2 . . . bn. Finally, we interpret ≤\nas the preﬁx ordering of words. We say that s1 is a preﬁx of s2 if there is\na binary word s3 such that s1 ·M s3 equals s2. For example, 011 is a preﬁx\nof 011001 and of 011, but 010 is neither. Thus, ≤M is the set {(s1, s2) |\ns1 is a preﬁx of s2}. Here are again some informal model checks:\n1.\nIn our model, the formula\n∀x ((x ≤x · e) ∧(x · e ≤x))\nsays that every word is a preﬁx of itself concatenated with the empty word and\nconversely. Clearly, this holds in our model, for s ·M ϵ is just s and every word\nis a preﬁx of itself.\n2.\nIn our model, the formula\n∃y ∀x (y ≤x)\nsays that there exists a word s that is a preﬁx of every other word. This is true,\nfor we may chose ϵ as such a word (there is no other choice in this case).\n3.\nIn our model, the formula\n∀x ∃y (y ≤x)\nsays that every word has a preﬁx. This is clearly the case and there are in\ngeneral multiple choices for y, which are dependent on x.\n4.\nIn our model, the formula ∀x ∀y ∀z ((x ≤y) →(x · z ≤y · z)) says that when-\never a word s1 is a preﬁx of s2, then s1s has to be a preﬁx of s2s for every word\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;\nand if L(s0) = {p, q}, L(s1) = {q, r} and L(s2) = {r}, then we can condense\nall this information into Figure 3.3. We prefer to present models by means\nof such pictures whenever that is feasible.\nThe requirement in Deﬁnition 3.4 that for every s ∈S there is at least\none s′ ∈S such that s →s′ means that no state of the system can ‘dead-\nlock.’ This is a technical convenience, and in fact it does not represent any\nreal restriction on the systems we can model. If a system did deadlock, we\ncould always add an extra state sd representing deadlock, together with new\n3.2 Linear-time temporal logic\n179\ns0\np, q\ns1\nq, r\ns2\nr\nFigure 3.3. A concise representation of a transition system M =\n(S, →,L) as a directed graph. We label state s with l iff l ∈L(s).\ns1\ns3\ns0\ns2\ns4\ns1\ns3\ns0\ns2\ns4\nsd\nFigure 3.4. On the left, we have a system with a state s4 that does not\nhave any further transitions. On the right, we expand that system with a\n‘deadlock’ state sd such that no state can deadlock; of course, it is then\nour understanding that reaching the ‘deadlock’ state sd corresponds to\ndeadlock in the original system.\ntransitions s →sd for each s which was a deadlock in the old system, as well\nas sd →sd. See Figure 3.4 for such an example.\nDeﬁnition 3.5 A path in a model M = (S, →, L) is an inﬁnite sequence of\nstates s1, s2, s3, . . . in S such that, for each i ≥1, si →si+1. We write the\npath as s1 →s2 →. . . .\nConsider the path π = s1 →s2 →. . . . It represents a possible future of\nour system: ﬁrst it is in state s1, then it is in state s2, and so on. We write\nπi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .\n180\n3 Verification by model checking\np, q\nr\nr\nr\nq, r\np, q\nq, r\ns0\ns2\ns2\ns2\ns0\ns1 further optimisation techniques, such as parallelisation.\nNote that the operations apply, restrict, etc. are only eﬃcient in the\nsize of the input OBDDs. So if a function f does not have a compact repre-\nsentation as an OBDD, then computing with its OBDD will not be eﬃcient.\nThere are such nasty functions; indeed, one of them is integer multiplication.\nLet bn−1bn−2 . . . b0 and an−1an−2 . . . a0 be two n-bit integers, where bn−1 and\nan−1 are the most signiﬁcant bits and b0 and a0 are the least signiﬁcant bits.\nThe multiplication of these two integers results in a 2n-bit integer. Thus, we\nmay think of multiplication as 2n many boolean functions fi in 2n variables\n(n bits for input b and n bits for input a), where fi denotes the ith output\nbit of the multiplication. The following negative result, due to R. E. Bryant,\nshows that OBDDs cannot be used for implementing integer multiplication.\nTheorem 6.11 Any OBDD representation of fn−1 has at least a number\nof vertices proportional to 1.09n, i.e. its size is exponential in n.\nExtensions and variations of OBDDs\nThere are many variations and\nextensions to the OBDD data structure. Many of them can implement cer-\ntain operations more eﬃciently than their OBDD counterparts, but it seems\nthat none of them perform as well as OBDDs overall. In particular, one fea-\nture which many of the variations lack is the canonical form; therefore they\nlack an eﬃcient algorithm for deciding when two objects denote the same\nboolean function.\nOne kind of variation allows non-terminal nodes to be labelled with bi-\nnary operators as well as boolean variables. Parity OBDDs are like OBDDs\nin that there is an ordering on variables and every variable may occur at\n2 Another NP-complete problem is to decide the satisﬁability of formulas of propositional logic.\n382\n6 Binary decision diagrams\nmost once on a path; but some non-terminal nodes may be labelled with ⊕,\nthe exclusive-or operation. The meaning is that the function represented by\n[x1, x′\n1, x2, x′\n2] rather than [x1, x2, x′\n1, x′\n2]. Figure 6.27 (right) shows the truth\ntable redrawn with the interleaved ordering of the columns and the rows\nreordered lexicographically. The resulting OBDD is shown in Figure 6.28.\n6.3.3 Implementing the functions pre∃and pre∀\nIt remains to show how an OBDD for pre∃(X) and pre∀(X) can be com-\nputed, given OBDDs BX for X and B→for the transition relation →. First\nwe observe that pre∀can be expressed in terms of complementation and\npre∃, as follows: pre∀(X) = S −pre∃(S −X), where we write S −Y for the\nset of all s ∈S which are not in Y . Therefore, we need only explain how to\ncompute the OBDD for pre∃(X) in terms of BX and B→. Now (6.4) suggests\nthat one should proceed as follows:\n1.\nRename the variables in BX to their primed versions; call the resulting OBDD\nBX′.\n2.\nCompute the OBDD for exists(ˆx′, apply(·, B→, BX′)) using the apply and\nexists algorithms (Sections 6.2.2 and 6.2.4).\n6.3.4 Synthesising OBDDs\nThe method used in Example 6.13 for producing an OBDD for the transi-\ntion relation was to compute ﬁrst the truth table and then an OBDD which\nmight not be in its fully reduced form; hence the need for a ﬁnal call to\n388\n6 Binary decision diagrams\nthe reduce function. However, this procedure would be unacceptable if ap-\nplied to realistically sized systems with a large number of variables, for the\ntruth table’s size is exponential in the number of boolean variables. The\nkey idea and attraction of applying OBDDs to ﬁnite systems is therefore to\ntake a system description in a language such as SMV and to synthesise the\nOBDD directly, without having to go via intermediate representations (such\nas binary decision trees or truth tables) which are exponential in size.\nSMV allows us to deﬁne the next value of a variable in terms of the\ncurrent values of variables (see the examples of code in Section 3.3.2)3. This\ncan be compiled into a set of boolean functions fi, one for each variable xi,\nBf (reduced)\nB∃x1.∃x2....∃xn.f (reduced)\nNP-complete\nFigure 6.23. Upper bounds in terms of the input OBDD(s) for the\nworst-case running times of our algorithms needed in our implementa-\ntion of boolean formulas.\n6.2.5 Assessment of OBDDs\nTime complexities for computing OBDDs\nWe can measure the com-\nplexity of the algorithms of the preceding section by giving upper bounds\nfor the running time in terms of the sizes of the input OBDDs. The table\nin Figure 6.23 summarises these upper bounds (some of those upper bounds\nmay require more sophisticated versions of the algorithms than the versions\npresented in this chapter). All the operations except nested boolean quantiﬁ-\ncation are practically eﬃcient in the size of the participating OBDDs. Thus,\nmodelling very large systems with this approach will work if the OBDDs\n6.2 Algorithms for reduced OBDDs\n381\nwhich represent the systems don’t grow too large too fast. If we can some-\nhow control the size of OBDDs, e.g. by using good heuristics for the choice\nof variable ordering, then these operations are computationally feasible. It\nhas already been shown that OBDDs modelling certain classes of systems\nand networks don’t grow excessively.\nThe expensive computational operations are the nested boolean quantiﬁ-\ncations ∃z1. . . . ∃zn.f and ∀z1. . . . ∀zn.f. By exercise 1 on page 406, the com-\nputation of the OBDD for ∃z1. . . . ∃zn.f, given the OBDD for f, is an NP-\ncomplete problem2; thus, it is unlikely that there exists an algorithm with\na feasible worst-time complexity. This is not to say that boolean functions\nmodelling practical systems may not have eﬃcient nested boolean quan-\ntiﬁcations. The performance of our algorithms can be improved by using\nfurther optimisation techniques, such as parallelisation.\nNote that the operations apply, restrict, etc. are only eﬃcient in the\nsize of the input OBDDs. So if a function f does not have a compact repre-\nsentation as an OBDD, then computing with its OBDD will not be eﬃcient.\nThis can easily be generalised to a sequence of exists operations. We\nwrite ∃ˆx. f to mean ∃x1.∃x2. . . . ∃xn. f, where ˆx denotes (x1, x2, . . . , xn).\n6.2 Algorithms for reduced OBDDs\n379\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\n1\n0\nx1\nx2\ny1\ny2\nx1\nx2\ny1\ny2\ny3\nFigure 6.20. restrict(0, x3, Bf) and restrict(1, x3, Bf) and the result\nof applying + to them.\n1\n0\nx1\nx2\nx3\ny1\ny2\ny3\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\nx1\ny1\ny2\ny3\n∃x3\n⇒\n∃x2\n⇒\nFigure 6.21. OBDDs for f, ∃x3. f and ∃x2.∃x3. f.\nThe OBDD for this boolean function is obtained from the OBDD for f by\nreplacing every node labelled with an xi by the + of its two branches.\nFigure 6.21 shows the computation of ∃x3. f and ∃x2.∃x3. f (which is\nsemantically equivalent to x1 · y1 + y2 + y3) in this way.\nThe boolean quantiﬁer ∀is the dual of ∃:\n∀x.f\ndef\n= f[0/x] · f[1/x]\nasserting that f could be made false by putting x to 0 or to 1.\nThe translation of boolean formulas into OBDDs using the algorithms of\nthis section is summarised in Figure 6.22.\n380\n6 Binary decision diagrams\nBoolean formula f\nRepresenting OBDD Bf\n0\nB0 (Fig. 6.6)\n1\nB1 (Fig. 6.6)\nx\nBx (Fig. 6.6)\nf\nswap the 0- and 1-nodes in Bf\nf + g\napply (+, Bf, Bg)\nf · g\napply (· , Bf, Bg)\nf ⊕g\napply (⊕, Bf, Bg)\nf[1/x]\nrestrict (1, x, Bf)\nf[0/x]\nrestrict (0, x, Bf)\n∃x.f\napply (+, Bf[0/x], Bf[1/x])\n∀x.f\napply (· , Bf[0/x], Bf[1/x])\nFigure 6.22. Translating boolean formulas f to OBDDs Bf, given a\nfixed, global ordering on boolean variables.\nAlgorithm Input OBDD(s)\nOutput OBDD\nTime-complexity\nreduce\nB\nreduced B\nO(|B| · log |B|)\napply\nBf, Bg (reduced) Bf op g (reduced)\nO(|Bf| · |Bg|)\nrestrict Bf (reduced)\nBf[0/x] or Bf[1/x] (reduced) O(|Bf| · log |Bf|)\n∃\nBf (reduced)\nB∃x1.∃x2....∃xn.f (reduced)\nNP-complete\nFigure 6.23. Upper bounds in terms of the input OBDD(s) for the\nworst-case running times of our algorithms needed in our implementa-\ntion of boolean formulas.\n6.2.5 Assessment of OBDDs\nTime complexities for computing OBDDs\nWe can measure the com-\nin which we applied the reductions does not matter. We therefore say that\nOBDDs have a canonical form, namely their unique reduced OBDD. Most\nother representations (conjunctive normal forms, etc.) do not have canonical\nforms.\nThe algorithms for · and + for BDDs, presented in Section 6.1.2, won’t\nwork for OBDDs as they may introduce multiple occurrences of the same\nvariable on a path. We will soon develop more sophisticated algorithms\nfor these operations on OBDDs, which exploit the compatible ordering of\nvariables in paths.\nOBDDs allow compact representations of certain classes of boolean func-\ntions which only have exponential representations in other systems, such as\ntruth tables and conjunctive normal forms. As an example consider the even\nparity function feven(x1, x2, . . . , xn) which is deﬁned to be 1 if there is an\neven number of variables xi with value 1; otherwise, it is deﬁned to be 0.\nIts representation as an OBDD requires only 2n + 1 nodes. Its OBDD for\nn = 4 and the ordering [x1, x2, x3, x4] can be found in Figure 6.11.\nThe impact of the chosen variable ordering\nThe size of the OBDD\nrepresenting the parity functions is independent of the chosen variable or-\ndering. This is because the parity functions are themselves independent of\nthe order of variables: swapping the values of any two variables does not\nchange the value of the function; such functions are called symmetric.\nHowever, in general the chosen variable ordering makes a signiﬁcant dif-\nference to the size of the OBDD representing a given function. Consider\nthe boolean function (x1 + x2) · (x3 + x4) · · · · · (x2n−1 + x2n); it corresponds\nto a propositional formula in conjunctive normal form. If we choose the\n1 In an implementation this will amount to checking whether two pointers are equal.\n370\n6 Binary decision diagrams\n1\n0\nx1\nx2\nx3\nx4\nx3\nx2\nx4\nFigure 6.11. An OBDD for the even parity function for four bits.\n‘natural’ ordering [x1, x2, x3, x4, . . . ], then we can represent this function as\n1 In an implementation this will amount to checking whether two pointers are equal.\n370\n6 Binary decision diagrams\n1\n0\nx1\nx2\nx3\nx4\nx3\nx2\nx4\nFigure 6.11. An OBDD for the even parity function for four bits.\n‘natural’ ordering [x1, x2, x3, x4, . . . ], then we can represent this function as\nan OBDD with 2n + 2 nodes. Figure 6.12 shows the resulting OBDD for\nn = 3. Unfortunately, if we choose instead the ordering\n[x1, x3, . . . , x2n−1, x2, x4, . . . , x2n]\nthe resulting OBDD requires 2n+1 nodes; the OBDD for n = 3 can be seen\nin Figure 6.13.\nThe sensitivity of the size of an OBDD to the particular variable order-\ning is a price we pay for all the advantages that OBDDs have over BDDs.\nAlthough ﬁnding the optimal ordering is itself a computationally expensive\nproblem, there are good heuristics which will usually produce a fairly good\nordering. Later on we return to this issue in discussions of applications.\nThe importance of canonical representation\nThe importance of\nhaving a canonical form for OBDDs in conjunction with an eﬃcient test for\ndeciding whether two reduced OBDDs are isomorphic cannot be overesti-\nmated. It allows us to perform the following tests:\nAbsence of redundant variables. If the value of the boolean function\nf(x1, x2, . . . , xn) does not depend on the value of xi, then any reduced\nOBDD which represents f does not contain any xi-node.\nTest for semantic equivalence. If two functions f(x1, x2, . . . , xn) and\ng(x1, x2, . . . , xn) are represented by OBDDs Bf, respectively Bg, with a\ncompatible ordering of variables, then we can eﬃciently decide whether f\nand g are semantically equivalent. We reduce Bf and Bg (if necessary); f\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\nsize of an OBDD: the OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with\nvariable ordering [x1, x3, x5, x2, x4, x6].\n372\n6 Binary decision diagrams\nand g denote the same boolean functions if, and only if, the reduced OBDDs\nhave identical structure.\nTest for validity. We can test a function f(x1, x2, . . . , xn) for validity (i.e.\nf always computes 1) in the following way. Compute a reduced OBDD for\nf. Then f is valid if, and only if, its reduced OBDD is B1.\nTest for implication. We can test whether f(x1, x2, . . . , xn) implies g(x1,\nx2, . . . , xn) (i.e. whenever f computes 1, then so does g) by computing the\nreduced OBDD for f · g. This is B0 iﬀthe implication holds.\nTest for satisﬁability. We can test a function f(x1, x2, . . . , xn) for satis-\nﬁability (f computes 1 for at least one assignment of 0 and 1 values to its\nvariables). The function f is satisﬁable iﬀits reduced OBDD is not B0.\n6.2 Algorithms for reduced OBDDs\n6.2.1 The algorithm reduce\nThe reductions C1–C3 are at the core of any serious use of OBDDs, for\nwhenever we construct a BDD we will want to convert it to its reduced form.\nIn this section, we describe an algorithm reduce which does this eﬃciently\nfor ordered BDDs.\nIf the ordering of B is [x1, x2, . . . , xl], then B has at most l + 1 layers. The\nalgorithm reduce now traverses B layer by layer in a bottom-up fashion,\nbeginning with the terminal nodes. In traversing B, it assigns an integer\nlabel id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\n(R1, S1)\nx1\nx2\nx3\n(R3, S3)\n(R2, S3)\n(R3, S2)\nx4\nx3\n(R5, S4)\n(R6, S5)\n(R4, S3)\n(R6, S3)\n(R4, S3)\n(R4, S3)\nx4\n(R5, S4)\n(R6, S5)\n(R6, S5)\nx4\n(R6, S5)\nx4\n(R5, S4)\n(R6, S4)\n(R6, S5)\nFigure 6.16. The recursive call structure of apply for the example in\nFigure 6.15 (without memoisation).\n0\n1\nx4\nx3\nx2\nx1\nFigure 6.17. The result of apply (+, Bf, Bg), where Bf and Bg are given\nin Figure 6.15.\n6.2 Algorithms for reduced OBDDs\n377\nthe ﬁrst time and the result remembered for future calls. This program-\nming technique is known as memoisation. As well as being more eﬃcient,\nit has the advantage that the resulting OBDD requires less reduction. (In\nthis example, using memoisation eliminates the need for the ﬁnal call to\nreduce altogether.) Without memoisation, apply is exponential in the size\nof its arguments, since each non-leaf call generates a further two calls. With\nmemoisation, the number of calls to apply is bounded by 2 · |Bf| · |Bg|, where\n|B| is the size of the BDD. This is a worst-time complexity; the actual per-\nformance is often much better than this.\n6.2.3 The algorithm restrict\nGiven an OBDD Bf representing a boolean formula f, we need an algo-\nrithm restrict such that the call restrict(0, x, Bf) computes the reduced\nOBDD representing f[0/x] using the same variable ordering as Bf. The al-\ngorithm for restrict(0, x, Bf) works as follows. For each node n labelled\nwith x, incoming edges are redirected to lo(n) and n is removed. Then we\ncall reduce on the resulting OBDD. The call restrict (1, x, Bf) proceeds\nsimilarly, only we now redirect incoming edges to hi(n).\n6.2.4 The algorithm exists\nA boolean function can be thought of as putting a constraint on the values\nof its argument variables. For example, the function x + (y · z) evaluates to 1\nonly if x is 1; or y is 0 and z is 1 – this is a constraint on x, y, and z.\nIt is useful to be able to express the relaxation of the constraint on a subset\nof the variables concerned. To allow this, we write ∃x. f for the boolean",
                    "summary": "There are 2n boolean vectors (v1, v2, . . . , vn) of length n. represent a subset T by the boolean function fT which maps ( v1,. v2,. . ., vn ) onto 1 if s is in T and 0 otherwise. The labelling function L : S →P(Atoms) gives us the encoding. We assume a ﬁxed ordering on the set Atoms, say x1, x2,  xn, and then represents  by the vector (V1, V2, Vn) (see Deﬁnition 3.4 for more details) The characteristicfunction of T is called the characteristicfunction The set of states {s1, s2, . . .    vn), where, for each i, vi equals 1 if xi equals 0 otherwise. L(s1) =                L(s2) implies s1 = s2. If this is not the case, perhaps because 2|Atoms| < |S|, we can add extra atomic propositions in order to make enough distinctions. We refer to a state s ∈S by its representing boolean vector, where vi is 1 if Xi is 0 and xi is 1 otherwise. This state is represented by the OBDD of the function l1 · l2 · · · ln. Figure 6.24. A simple CTL model (Example 6.12). Figure 6.25. An OBDD of the boolean function. Figure 7. A binary decision diagram. Figure 8. A series of binary decision diagrams. Figure 9. A set of Binary Decision Diagrams (BDCs) Figure 10. A group of Binary Decisions (BCS) Figure 11. A pair of BinaryDecisions (BNCs)Figure 12. A single BinaryDecision (BCC) Figure 13. A BinaryDec decision (BCD) Figure 14. A Single BinaryDecoration (BCDC) Figure 15. A Pair of Binarydecisions (CCD)Figure 16. A Simple Decision ( The key point which makes this representation interesting is that the OBDD representing a set of states may be quite small. For all states s1 and s2, L(s1) = L (s2)implies s1 = s2. Sets of states can be represented by boolean values and by booleanformulas with the ordering [x1, x2] Figure 6.25. The vector (1, 1) and the corresponding function x1 · x2 are not used in the model. Therefore, we are free to include it in the representation of a subset of the set. Figure.6.3 Symbolic model checking for the size of a set. In order to justify the claim that the representation of subsets of S asOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need to explain how OBDDs were developed in the early 1990s. For example, the subset {s0, s1} is better represented by the boolean function x1 + x2, since its OBDD is smaller than that forx1 · x2 + x1 ·x2 (Figure 6.26). In this section, we describe in detail how the model-checking algorithm can be implemented using OBDds as the basic data structure. The pseudo-code presented in Figure 3.28 on page 227 takes as input Model checking using OBDDs is called symbolic model checking. The term purposefullyemphasises that individual states are not represented. Instead, sets of states are represented symbolically, namely, those which satisfy the formula beingchecked. We show in this section how the model and the intermediate sets ofStates can be stored as OBDD. We also show how the operations required in that pseudo-code can be implemented in terms of the operations on OBDDS which we have seen in this chapter. We conclude with a discussion of the implications of the model checking scheme for computer science. We hope that this will help you to understand the theory of computer science more fully. Back to the page you came from. There are 2n boolean vectors (v1, v2, . . . , vn) of length n. N should be chosen such that 2n−1 < |S| ≤2n, where |S | is the number of x. The truth table for the transition relation of Figure 6.24 is shown in the next section of the book. The book is published by Oxford University Press in the US and the UK at a cost of $1.99 per book. For more information, see the book’s official website and the book's English-language version at http://www.oxford.co.uk/books/book/features/book-notes/Book-notes-Book- The OBDD for the transition relation of Fig. 6.24 is shown as a truth table (Figure 6.27) Each 1 in the ﬁnal column corresponds to a link in the relation. Each 0 in the truth table corresponds to the absence of a link. As anOBDD, the link is represented by the OBD D for the boolean function (v1, v2, . . . , vn), where vi is 1 if pi ∈L(s) and 0 otherwise. For example, the entire relation → is a set of links (for example,  v1 v2 vn) with vi 1, vi 0, and so on. The model is free of states that deadlock: all states have a transition to some state. Figure 6.27 (right) shows the truth table redrawn with the interleaved ordering of the columns and the rowsreordered lexicographically. The resulting OBDD is shown in Figures 6.28 (left) and 6.3 (center) The formula for the transition relation of Example 6.13.4 is: R(x, y) P(x) R(y) P (x) P. (y) R (x), P (y), P. P (X) P, P (Y), P(Y),P (X),P. (Y,Y) P., The model M we have in mind has as set A all binary strings, including the empty string denoted by ϵ. The interpretation ·M of · is                the concatenation of words. For example, 0110 ·M 1110 equals 01101110. We say that s1 is a preﬁx of s2 if there is a binary word s3 such that  s1 ·M s3 equals s2. This is true in our model: a can move to a, b or c; and b and c                can move to c. The model M has a set A of words over the alphabet {0, 1}. The interpretation eM of e is just the empty word � In our model, every word is a preﬁx of itself concatenated with the empty word and vice versa. We use directed graphs whose nodes (which we call states) contain all propositional atoms that are true in that state. Thus, ≤M is the set {(s1, s2) |                s1 is a prior of s2}. Here are again some informal model checks for our model. For example, the formula for a word s is true, for s ·M ϵ is just s and every word  is a Pre-Pre-Pre of itself. For a word  we may chose ϵ as such a word (there is no other choice in this case). The requirement in Deﬁnition 3.4 that for every s ∈S there is at least one s′ ∉S such that s →s′ means that no state of the system can ‘dead-lock’ is a technical convenience. If a system did deadlock, we could always add an extra state sd representing deadlock. We prefer to present models by means of such pictures whenever that is feasible. For example, if our system has only three states s0, s1 and s2, then we can condense this information into Figure 3.3.2. We label state s with l iff l ∉L(s) as a directed graph. A path in a model M = (S, →, L) is an inﬁnite sequence ofstates s1, s2, s3, . . . in S such that, for each i ≥1, si →si+1. We write the path as s1 →s2 →. . . and it represents a possible future of our system. See Figure 3.4 for such an example. The operations apply, restrict, etc.    to further optimisation techniques, such as parallelisation. For example, we could write a system with a state s4 that does not have any further transitions. On the right, we expand that system to have a state sd such that no Theorem 6.11: Any OBDD representation of fn−1 has at least a number of vertices proportional to 1.09n, i.e. are only eﬃcient in the size of the input OBDDs. So if a function f does not have a compact repre-sentation as an O BDD, then computing with it will not be e ﬁcient. The following negative result, due to R. E. Bryant, shows that O BDDs cannot be used for implementing integer multiplication. For example, multiplication of two n-bit integers results in a 2n-bit integer, where bn−1 and an−1an−2 are the most signi There are many variations and extensions to the OBDD data structure. Many of them can implement cer-                tain operations more eﬃciently than their OBDDs counterparts. But none of them perform as well as O BDDs overall. In particular, one fea-                ture which many of the variations lack is the canonical form; therefore they don't have an e-cient algorithm for deciding when two objects denote the same function. Another NP-complete problem is to decide the satisﬁability of formulas of propositional logic. For more information, see the Wikipedia article on OBDd data structures, and the Wikipedia entry for OBDs. 6.3.3 Implementing the functions pre∃and pre∀. Figure 6.27 (right) shows the truth                table redrawn with the interleaved ordering of the columns and the rowsreordered lexicographically. The resulting OBDD is shown in Figures 6.28 (left) and 6.29 (respectively) The meaning is that the function represented by                 is rather than [x1, x2, x′                ] rather than  x′                1, X′                2. The meaning of the word                 is that it is the term used to refer to a function. The method used in Example. 6.13 for producing an OBDD for the transi-portion relation was to compute ﬁrst the truth table and then an O.BDD which might not be in its fully reduced form. Now (6.4) suggests that one should proceed as follows: 1. rename the variables in BX to their primed versions; 2. compute the OBDDs for exists(ˆx′, apply(·, B→, BX′), and 3. Synthesise the results using the apply and exists algorithms (Sections 6.2.2 The idea of applying OBDDs to ﬁnite systems is to take a system description in a language such as SMV and to synthesise theOBDD directly. SMV allows us to deﬁne the next value of a variable in terms of the current values of variables (see the examples of code in Section 3.3.2) This can be compiled into a set of boolean functions fi, one for each variable xi, xi.f (reduced) and xn, n (increased) Figure 6.23.23 gives upper bounds for the running time of our algorithms needed in our implementa- hyperttion of boolean formulas. All the operations except nested boolean quantiﬁ-cation are practically eﬃcient in the size of the participating OBDDs. It has already been shown that OBDD modelling certain classes of systems and networks don’t grow excessively. The expensive computational operations are the nested Boolean quanti-cation. If we can control the size by using good heuristics for the choice of variable ordering, then these operations are computationally feasible. The table in Figure 6.23 summarises the upper bounds of these upper bounds. Some of those upper bounds may require more sophisticated versions of the algorithms than the versionspresented in this chapter. For example, the table on page 406, the com-                putation f, given the OBDD for f, is an NP-complete problem2; thus, it is unlikely that there exists an algorithm with                a feasible worst-time complexity. This is not to say that practical systems may not have eﬃcient nested boolean quan-                tiﬁcations. The performance of our algorithms can be improved by using further optimisation techniques, such as parallelisation. The operations apply, restrict, etc. are only e-cient in the size of the input OBDDs. So if a function f does not have a compact repre-                sentation as an OBD d, then computing with its OBDd will not be e-scientific. The OBDD for f is obtained by replacing every node labelled with an xi by the + of its two branches. F could be made false by putting x to 0 or to 1. The translation of boolean formulas into OBDDs using the algorithms of                this section is summarised in Figure 6.22. For f, f is the dual of f (which is the equivalent to x1 · y1 + y2 + y3) and f (f is the opposite of f) is the same as f(x1) (Fig. 6.6) FBDDs for f and f are shown in Figures 6.1, 6.2, and 6.3. Algorithm Input OBDD(s) Output OBDDs (reduced) O(|Bf| · log |Bf) Bf op g (red reduced) O (|Bg| · |Bg) Bg op op f (reducing) B f op op b (reduce) B g op op c (reduces) Bop g op Bg (red Reduced) Bp gop Bf (Reduced) Gop gop C (Reduce) Cop B (Reducing) Cops Bf [0/x] or Bf[1/x]. Cops O(Bf, Bg) Puts Bf on the 0- and The algorithms for · and + for BDDs, presented in Section 6.1.2, won’t work for OBDDs as they may introduce multiple occurrences of the samevariable on a path. We will soon develop more sophisticated algorithms for these operations on OBDD, which exploit the compatible ordering ofvariables in paths.OBDDs allow compact representations of certain classes of boolean func-tions which only have exponential representations in other systems, such astruth tables and conjunctive normal forms. As an example consider the evenparity function feven(x1, x2, . . . , xn) which is deﬁned to be The size of the OBDDrepresenting the parity functions is independent of the chosen variable or-dering. The chosen variable ordering makes a signiﬁcant dif-                ference to the size of a given function. In an implementation this will amount to checking whether two pointers are equal. If we choose the                1 In an Implementation this will Amount to Checking Whether Two pointers are Equal. The impact of the choosing variable ordering can be seen in Figure 6.11.7. The size of an even parity function for four bits can be found in Figure 7.1 in the ‘Even Parity Function’ section of this article. It is the same size as an even-parity function for The sensitivity of the size of an OBDD to the particular variable order is a price we pay for all the advantages that OBDDs have over BDDs. Although ﬁnding the optimal ordering is itself a computationally expensiveproblem, there are good heuristics which will usually produce a fairly good ordering. The resulting OBD D for n = 3 can be seen in Figure 6.13. The optimal ordering can be found at the bottom of the page by searching for the word ‘optimal’ in the ‘OBDD’ section of this article. The word “optimal ordering” is a term used to refer to the order in which two pointers are equal. Having a canonical form for OBDDs in conjunction with an eﬃcient test for                deciding whether two reduced OBDD are isomorphic cannot be overesti-                mated. It allows us to perform the following tests:Absence of redundant variables. If the value of the boolean function.f(x1, x2, . . . , xn) does not depend on the value. of xi, then any reducedOBDD which represents f does not contain any xi-node.Test for semantic equivalence. We reduce Bf and Bg (if necessary); f and g are semantically equivalent. Later on we return to this issue in discussions of applications. The OBDD for (x1 + x2) · (x3 + x4) ·. (x5 + x6) with. Variable ordering [x1, x2, x3, x4, x5, x6]. Changing the ordering may have dramatic effects on the size of the OBDDs. We can test a function f(x1,. x2,. . . , xn) for validity (i.e. f always computes 1) in the following way. Compute a reduced OBDd for f and test whether it is valid. Then f is valid if, and only if, its reduced O BDD is B1. The reductions C1–C3 are at the core of any serious use of OBDDs. We describe an algorithm reduce which does this eﬃciently for ordered BDDs. The algorithm reduce traverses B layer by layer in a bottom-up fashion,beginning with the terminal nodes. We also discuss how to test a function f(x1, x2, . . . , xn) for satisﬁability (f computes 1 for at least one assignment of 0 and 1 values to itsvariables). The function f is satis ﬁable iﬀits reduced OBDD is not B0. We conclude that the algorithm reduce can be used to In traversing B, it assigns an integerlabel id(n) to each node n of B, in such a way that the subOBDDs withroot nodes n and m denote the same boolean function. This program-consuming technique is known as memoisation. As well as being more eﬃcient, memoisation has the advantage that the resulting OBDD requires less reduction. The result of apply (+, Bf, Bg), where Bf and Bg are given, is shown in Figure 6.15.6.2 Algorithms for reduced OBDDs. The algorithm is called reduce and can be found at: http://www.cnn.com/2011/01/16 With memoisation, the number of calls to apply is bounded by 2. This is a worst-time complexity; the actual per-formance is often much better than this. The algorithm for restrict(0, x, Bf) works as follows. For each node n labelled with x, incoming edges are redirected to lo(n) and n is removed. Then we need an algo-                rithm restrict such that the call restrict( 0, x,. Bf, f) computes the reducedOBDD representing f[0/x] using the same variable ordering as Bf. The call reduce on the resulting OBDD is called on the same order as the BDD. A boolean function can be thought of as putting a constraint on the values of its argument variables. For example, the function x + (y · z) evaluates to 1 only if x is 1; or y is 0 and z is 1. It is useful to be able to express the relaxation of the constraint on a subsetof the variables concerned. To allow this, we write ∃x. f for the boolean. The call restrict (1, x, Bf) proceeds similarly, only",
                    "children": [
                        {
                            "id": "chapter-6-section-3-subsection-1",
                            "title": "Representing Subsets of the Set of States",
                            "content": "represent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of\nelements in S. If |S| is not an exact power of 2, there will be some vec-\ntors which do not correspond to any element of S; they are just ignored.\nThe function fT : {0, 1}n →{0, 1} which tells us, for each s, represented by\n(v1, v2, . . . , vn), whether it is in the set T or not, is called the characteristic\nfunction of T.\nIn the case that S is the set of states of a transition system M = (S, →, L)\n(see Deﬁnition 3.4), there is a natural way of choosing the representation\nof S as boolean vectors. The labelling function L : S →P(Atoms) (where\nP(Atoms) is the set of subsets of Atoms) gives us the encoding. We assume\na ﬁxed ordering on the set Atoms, say x1, x2, . . . , xn, and then represent\ns ∈S by the vector (v1, v2, . . . , vn), where, for each i, vi equals 1 if xi ∈\nL(s) and vi is 0 otherwise. In order to guarantee that each s has a unique\nrepresentation as a boolean vector, we require that, for all s1, s2 ∈S, L(s1) =\nL(s2) implies s1 = s2. If this is not the case, perhaps because 2|Atoms| < |S|,\nwe can add extra atomic propositions in order to make enough distinctions\n(Cf. introduction of the turn variable for mutual exclusion in Section 3.3.4.)\nFrom now on, we refer to a state s ∈S by its representing boolean vector\n(v1, v2, . . . , vn), where vi is 1 if xi ∈L(s) and 0 otherwise. As an OBDD,\nthis state is represented by the OBDD of the boolean function l1 · l2 · · · · · ln,\nwhere li is xi if xi ∈L(s) and xi otherwise. The set of states {s1, s2, . . . , sm}\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nis represented by the OBDD of the boolean function\n(l11 · l12 · · · · · l1n) + (l21 · l22 · · · · · l2n) + · · · + (lm1 · lm2 · · · · · lmn)\nwhere li1 · li2 · · · · · lin represents state si.\n384\n6 Binary decision diagrams\ns2\nx1\ns0\nx2\ns1\nFigure 6.24. A simple CTL model (Example 6.12).\nset of\nrepresentation by\nrepresentation by\nstates\nboolean values\nboolean function\n∅\n0\n{s0}\n(1, 0)\nx1 · x2\n{s1}\n(0, 1)\nx1 · x2\n{s2}\n(0, 0)\nx1 · x2\n{s0, s1}\n(1, 0), (0, 1)\nx1 · x2 + x1 · x2\n{s0, s2}\n(1, 0), (0, 0)\nx1 · x2 + x1 · x2\n{s1, s2}\n(0, 1), (0, 0)\nx1 · x2 + x1 · x2\nS\n(1, 0), (0, 1), (0, 0)\nx1 · x2 + x1 · x2 + x1 · x2\nFigure 6.25. Representation of subsets of states of the model of Figure 6.24.\nThe key point which makes this representation interesting is that the\nOBDD representing a set of states may be quite small.\nExample 6.12 Consider the CTL model in Figure 6.24, given by:\nS\ndef\n= {s0, s1, s2}\n→\ndef\n= {(s0, s1), (s1, s2), (s2, s0), (s2, s2)}\nL(s0)\ndef\n= {x1}\nL(s1)\ndef\n= {x2}\nL(s2)\ndef\n= ∅.\nNote that it has the property that, for all states s1 and s2, L(s1) = L(s2)\nimplies s1 = s2, i.e. a state is determined entirely by the atomic formulas\ntrue in it. Sets of states may be represented by boolean values and by boolean\nformulas with the ordering [x1, x2], as shown in Figure 6.25.\nNotice that the vector (1, 1) and the corresponding function x1 · x2 are\nunused. Therefore, we are free to include it in the representation of a subset\n6.3 Symbolic model checking\n385\nx2\n0\n1\nx1\n0\n1\nx1\nx2\nx2\nFigure 6.26. Two OBDDs for the set {s0, s1} (Example 6.12).\nof S or not; so we may choose to include it or not in order to optimise the\nsize of the OBDD. For example, the subset {s0, s1} is better represented\nby the boolean function x1 + x2, since its OBDD is smaller than that for\nx1 · x2 + x1 · x2 (Figure 6.26).\nIn order to justify the claim that the representation of subsets of S as\nOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need\nveriﬁcation in the early 1990s, because they have allowed systems with much\nlarger state spaces to be veriﬁed. In this section, we describe in detail how\nthe model-checking algorithm presented in Chapter 3 can be implemented\nusing OBDDs as the basic data structure.\nThe pseudo-code presented in Figure 3.28 on page 227 takes as input a\nCTL formula φ and returns the set of states of the given model which satisfy\nφ. Inspection of the code shows that the algorithm consists of manipulating\nintermediate sets of states. We show in this section how the model and the\nintermediate sets of states can be stored as OBDDs; and how the operations\nrequired in that pseudo-code can be implemented in terms of the operations\non OBDDs which we have seen in this chapter.\nWe start by showing how sets of states are represented with OBDDs,\ntogether with some of the operations required. Then, we extend that to\nthe representation of the transition system; and ﬁnally, we show how the\nremainder of the required operations is implemented.\n6.3 Symbolic model checking\n383\nModel checking using OBDDs is called symbolic model checking. The term\nemphasises that individual states are not represented; rather, sets of states\nare represented symbolically, namely, those which satisfy the formula being\nchecked.\n6.3.1 Representing subsets of the set of states\nLet S be a ﬁnite set (we forget for the moment that it is a set of states). The\ntask is to represent the various subsets of S as OBDDs. Since OBDDs encode\nboolean functions, we need somehow to code the elements of S as boolean\nvalues. The way to do this in general is to assign to each element s ∈S a\nunique vector of boolean values (v1, v2, . . . , vn), each vi ∈{0, 1}. Then, we\nrepresent a subset T by the boolean function fT which maps (v1, v2, . . . , vn)\nonto 1 if s ∈T and maps it onto 0 otherwise.\nThere are 2n boolean vectors (v1, v2, . . . , vn) of length n. Therefore, n\nshould be chosen such that 2n−1 < |S| ≤2n, where |S| is the number of",
                            "summary": "There are 2n boolean vectors (v1, v2, . . . , vn) of length n. represent a subset T by the boolean function fT which maps ( v1,. v2,. . ., vn ) onto 1 if s is in T and 0 otherwise. The labelling function L : S →P(Atoms) gives us the encoding. We assume a ﬁxed ordering on the set Atoms, say x1, x2,  xn, and then represents  by the vector (V1, V2, Vn) (see Deﬁnition 3.4 for more details) The characteristicfunction of T is called the characteristicfunction The set of states {s1, s2, . . .    vn), where, for each i, vi equals 1 if xi equals 0 otherwise. L(s1) =                L(s2) implies s1 = s2. If this is not the case, perhaps because 2|Atoms| < |S|, we can add extra atomic propositions in order to make enough distinctions. We refer to a state s ∈S by its representing boolean vector, where vi is 1 if Xi is 0 and xi is 1 otherwise. This state is represented by the OBDD of the function l1 · l2 · · · ln. Figure 6.24. A simple CTL model (Example 6.12). Figure 6.25. An OBDD of the boolean function. Figure 7. A binary decision diagram. Figure 8. A series of binary decision diagrams. Figure 9. A set of Binary Decision Diagrams (BDCs) Figure 10. A group of Binary Decisions (BCS) Figure 11. A pair of BinaryDecisions (BNCs)Figure 12. A single BinaryDecision (BCC) Figure 13. A BinaryDec decision (BCD) Figure 14. A Single BinaryDecoration (BCDC) Figure 15. A Pair of Binarydecisions (CCD)Figure 16. A Simple Decision ( The key point which makes this representation interesting is that the OBDD representing a set of states may be quite small. For all states s1 and s2, L(s1) = L (s2)implies s1 = s2. Sets of states can be represented by boolean values and by booleanformulas with the ordering [x1, x2] Figure 6.25. The vector (1, 1) and the corresponding function x1 · x2 are not used in the model. Therefore, we are free to include it in the representation of a subset of the set. Figure.6.3 Symbolic model checking for the size of a set. In order to justify the claim that the representation of subsets of S asOBDDs will be suitable for the algorithm presented in Section 3.6.1, we need to explain how OBDDs were developed in the early 1990s. For example, the subset {s0, s1} is better represented by the boolean function x1 + x2, since its OBDD is smaller than that forx1 · x2 + x1 ·x2 (Figure 6.26). In this section, we describe in detail how the model-checking algorithm can be implemented using OBDds as the basic data structure. The pseudo-code presented in Figure 3.28 on page 227 takes as input Model checking using OBDDs is called symbolic model checking. The term purposefullyemphasises that individual states are not represented. Instead, sets of states are represented symbolically, namely, those which satisfy the formula beingchecked. We show in this section how the model and the intermediate sets ofStates can be stored as OBDD. We also show how the operations required in that pseudo-code can be implemented in terms of the operations on OBDDS which we have seen in this chapter. We conclude with a discussion of the implications of the model checking scheme for computer science. We hope that this will help you to understand the theory of computer science more fully. Back to the page you came from. There are 2n boolean vectors (v1, v2, . . . , vn) of length n. n should be chosen such that 2n−1 < |S| ≤2n, where |S is the number of elements in S. The way to do this in general is to assign to each element s aunique vector of boolean values. Each vi ∈{0, 1}. Then, werepresent a subset T by the boolean function fT which maps v1,v2, vn onto 1 if",
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-3-subsection-2",
                            "title": "Representing the Transition Relation",
                            "content": "x1\nx2\nx′\n1\nx′\n2\n→\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\nx1\nx′\n1\nx2\nx′\n2\n→\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\n1\n1\n0\n0\n1\n1\n1\n1\n0\nFigure 6.27. The truth table for the transition relation of Figure 6.24\n(see Example 6.13). The left version shows the ordering of variables\n[x1, x2, x′\n1, x′\n2], while the right one orders the variables [x1, x′\n1, x2, x′\n2] (the\nrows are ordered lexicographically).\nboolean vectors ((v1, v2, . . . , vn), (v′\n1, v′\n2, . . . , v′\nn)), where vi is 1 if pi ∈L(s)\nand 0 otherwise; and similarly, v′\ni is 1 if pi ∈L(s′) and 0 otherwise. As an\nOBDD, the link is represented by the OBDD for the boolean function\n(l1 · l2 · · · · · ln) · (l′\n1 · l′\n2 · · · · · l′\nn)\nand a set of links (for example, the entire relation →) is the OBDD for the\n+ of such formulas.\nExample 6.13 To compute the OBDD for the transition relation of Fig-\nure 6.24, we ﬁrst show it as a truth table (Figure 6.27 (left)). Each 1 in\nthe ﬁnal column corresponds to a link in the transition relation and each 0\ncorresponds to the absence of a link. The boolean function is obtained by\ntaking the disjunction of the rows having 1 in the last column and is\nf→def\n= x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2 + x1 · x2 · x′\n1 · x′\n2.\n(6.5)\nIt turns out that it is usually more eﬃcient to interleave unprimed and\nprimed variables in the OBDD variable ordering for →. We therefore use\n6.3 Symbolic model checking\n387\n0\n1\nx2\nx2\nx′\n2\nx′\n2\nx1\nx′\n1\nx′\n1\nFigure 6.28. An OBDD for the transition relation of Example 6.13.\n[x1, x′\n1, x2, x′\n2] rather than [x1, x2, x′\n1, x′\n2]. Figure 6.27 (right) shows the truth\ntable redrawn with the interleaved ordering of the columns and the rows\nreordered lexicographically. The resulting OBDD is shown in Figure 6.28.\n4.\nThe formula\n∀x∃y R(x, y)\nstates that the model is free of states that deadlock: all states have a transition\nto some state. This is true in our model: a can move to a, b or c; and b and c\ncan move to c.\nExample 2.16 Let F\ndef\n= {e, ·} and P\ndef\n= {≤}, where e is a constant, · is a\nfunction of two arguments and ≤is a predicate in need of two arguments as\nwell. Again, we write · and ≤in inﬁx notation as in (t1 · t2) ≤(t · t).\n126\n2 Predicate logic\nThe model M we have in mind has as set A all binary strings, ﬁnite\nwords over the alphabet {0, 1}, including the empty string denoted by ϵ. The\ninterpretation eM of e is just the empty word ϵ. The interpretation ·M of · is\nthe concatenation of words. For example, 0110 ·M 1110 equals 01101110. In\ngeneral, if a1a2 . . . ak and b1b2 . . . bn are such words with ai, bj ∈{0, 1}, then\na1a2 . . . ak ·M b1b2 . . . bn equals a1a2 . . . akb1b2 . . . bn. Finally, we interpret ≤\nas the preﬁx ordering of words. We say that s1 is a preﬁx of s2 if there is\na binary word s3 such that s1 ·M s3 equals s2. For example, 011 is a preﬁx\nof 011001 and of 011, but 010 is neither. Thus, ≤M is the set {(s1, s2) |\ns1 is a preﬁx of s2}. Here are again some informal model checks:\n1.\nIn our model, the formula\n∀x ((x ≤x · e) ∧(x · e ≤x))\nsays that every word is a preﬁx of itself concatenated with the empty word and\nconversely. Clearly, this holds in our model, for s ·M ϵ is just s and every word\nis a preﬁx of itself.\n2.\nIn our model, the formula\n∃y ∀x (y ≤x)\nsays that there exists a word s that is a preﬁx of every other word. This is true,\nfor we may chose ϵ as such a word (there is no other choice in this case).\n3.\nIn our model, the formula\n∀x ∃y (y ≤x)\nsays that every word has a preﬁx. This is clearly the case and there are in\ngeneral multiple choices for y, which are dependent on x.\n4.\nIn our model, the formula ∀x ∀y ∀z ((x ≤y) →(x · z ≤y · z)) says that when-\never a word s1 is a preﬁx of s2, then s1s has to be a preﬁx of s2s for every word\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;\nand if L(s0) = {p, q}, L(s1) = {q, r} and L(s2) = {r}, then we can condense\nall this information into Figure 3.3. We prefer to present models by means\nof such pictures whenever that is feasible.\nThe requirement in Deﬁnition 3.4 that for every s ∈S there is at least\none s′ ∈S such that s →s′ means that no state of the system can ‘dead-\nlock.’ This is a technical convenience, and in fact it does not represent any\nreal restriction on the systems we can model. If a system did deadlock, we\ncould always add an extra state sd representing deadlock, together with new\n3.2 Linear-time temporal logic\n179\ns0\np, q\ns1\nq, r\ns2\nr\nFigure 3.3. A concise representation of a transition system M =\n(S, →,L) as a directed graph. We label state s with l iff l ∈L(s).\ns1\ns3\ns0\ns2\ns4\ns1\ns3\ns0\ns2\ns4\nsd\nFigure 3.4. On the left, we have a system with a state s4 that does not\nhave any further transitions. On the right, we expand that system with a\n‘deadlock’ state sd such that no state can deadlock; of course, it is then\nour understanding that reaching the ‘deadlock’ state sd corresponds to\ndeadlock in the original system.\ntransitions s →sd for each s which was a deadlock in the old system, as well\nas sd →sd. See Figure 3.4 for such an example.\nDeﬁnition 3.5 A path in a model M = (S, →, L) is an inﬁnite sequence of\nstates s1, s2, s3, . . . in S such that, for each i ≥1, si →si+1. We write the\npath as s1 →s2 →. . . .\nConsider the path π = s1 →s2 →. . . . It represents a possible future of\nour system: ﬁrst it is in state s1, then it is in state s2, and so on. We write\nπi for the suﬃx starting at si, e.g., π3 is s3 →s4 →. . . .\n180\n3 Verification by model checking\np, q\nr\nr\nr\nq, r\np, q\nq, r\ns0\ns2\ns2\ns2\ns0\ns1",
                            "summary": "Figure 6.27. The truth table for the transition relation of Figure 6.24(see Example 6.13) The left version shows the ordering of variables. The right one orders the variables [x1, x′. grotesque1, X2, x’sian, x″ ’’  ”’, x–’.’] (the variables are ordered lexicographically). The left one shows the variables[x1,. x2,. x′’Sian, X″’; x‚’: “Sian”, “”: ‘sian’), while the right one. orders the The OBDD for the transition relation of Fig. 6.24 is a truth table (Figure 6.27) Each 1 in the truth table corresponds to a link in the relation and each 0corresponds to the absence of a link. The link is represented by the OBD D for the boolean function (6.5) for a set of links (for example, the entire relation of Example 6.13) We therefore use the model checking tool (6-3) to check for links in a relation that is not a transition relation. For example, we check that the relation is not the same as [x1, x2, x′ grotesque1, X′ grotesque2] rather than the other way The formula is free of states that deadlock: all states have a transition to some state. This is true in our model: a can move to a, b or c; and b and c                can move to c. The model M we have in mind has as set A all binary strings, including the empty string denoted by ϵ. The interpretation ·M of · is the concatenation of words. For example, 0110 ·M 1110 equals 01101110. In general, if a1a2 . . . ak and b1b2 .. . bn are such words with ai, bj ∈{0, 1}, then bj    a1a We say that s1 is a preﬁx of s2 if there is a binary word s3 such that  s1 ·M s3 equals s2. For example, 011  is a. pre�aryx of 011001 and of 011, but 010 is neither. We interpret ≤ as the pre�ariesx ordering of words. Here are again some informal model checks:. ak ·M b1b2 . . . bn equals a1a2 .. . . akb1b 2 . . ... bn. . ak · m b1a1 equals a 1a1b1, and a 1b1b is a 1.1b. In our model, the formula says that when-ever a word s1 is a preﬁx of s2, then s1s has to be a pre-œx of s2s. This is clearly the case and there are in general multiple choices for y, which are dependent on x. For example, ifour system has only three states s0, s1 and s2; if the only possible transi-culartions between states are s0 →s1, s0→s2; and if L(s0) = {p, q,. L( s1) = q, r, L(S2) =  r. A model M = (S, →, L) is an inﬁnite sequence ofstates s1, s2, s3, . . . in S such that, for each i ≥1, si →si+1. If a system did deadlock, we could always add an extra state sd representing deadlock. See Figure 3.4 for an example of such an example. The ‘deadlock’ state sd corresponds to the original system, as well as the new one. We write the path as s1 →s2, and the path π = s1–s2. The model is called a linear-time temporal logic. We write                πi for the suﬃx starting at si, e.g., π3 is s3 →s4. It represents a possible future of                our system: ﬁrst it is in state s1, then it's in s2, and so",
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-3-subsection-3",
                            "title": "Implementing the Functions pre∃ and pre∀",
                            "content": "",
                            "summary": null,
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-3-subsection-4",
                            "title": "Synthesising OBDDs",
                            "content": "further optimisation techniques, such as parallelisation.\nNote that the operations apply, restrict, etc. are only eﬃcient in the\nsize of the input OBDDs. So if a function f does not have a compact repre-\nsentation as an OBDD, then computing with its OBDD will not be eﬃcient.\nThere are such nasty functions; indeed, one of them is integer multiplication.\nLet bn−1bn−2 . . . b0 and an−1an−2 . . . a0 be two n-bit integers, where bn−1 and\nan−1 are the most signiﬁcant bits and b0 and a0 are the least signiﬁcant bits.\nThe multiplication of these two integers results in a 2n-bit integer. Thus, we\nmay think of multiplication as 2n many boolean functions fi in 2n variables\n(n bits for input b and n bits for input a), where fi denotes the ith output\nbit of the multiplication. The following negative result, due to R. E. Bryant,\nshows that OBDDs cannot be used for implementing integer multiplication.\nTheorem 6.11 Any OBDD representation of fn−1 has at least a number\nof vertices proportional to 1.09n, i.e. its size is exponential in n.\nExtensions and variations of OBDDs\nThere are many variations and\nextensions to the OBDD data structure. Many of them can implement cer-\ntain operations more eﬃciently than their OBDD counterparts, but it seems\nthat none of them perform as well as OBDDs overall. In particular, one fea-\nture which many of the variations lack is the canonical form; therefore they\nlack an eﬃcient algorithm for deciding when two objects denote the same\nboolean function.\nOne kind of variation allows non-terminal nodes to be labelled with bi-\nnary operators as well as boolean variables. Parity OBDDs are like OBDDs\nin that there is an ordering on variables and every variable may occur at\n2 Another NP-complete problem is to decide the satisﬁability of formulas of propositional logic.\n382\n6 Binary decision diagrams\nmost once on a path; but some non-terminal nodes may be labelled with ⊕,\nthe exclusive-or operation. The meaning is that the function represented by\n[x1, x′\n1, x2, x′\n2] rather than [x1, x2, x′\n1, x′\n2]. Figure 6.27 (right) shows the truth\ntable redrawn with the interleaved ordering of the columns and the rows\nreordered lexicographically. The resulting OBDD is shown in Figure 6.28.\n6.3.3 Implementing the functions pre∃and pre∀\nIt remains to show how an OBDD for pre∃(X) and pre∀(X) can be com-\nputed, given OBDDs BX for X and B→for the transition relation →. First\nwe observe that pre∀can be expressed in terms of complementation and\npre∃, as follows: pre∀(X) = S −pre∃(S −X), where we write S −Y for the\nset of all s ∈S which are not in Y . Therefore, we need only explain how to\ncompute the OBDD for pre∃(X) in terms of BX and B→. Now (6.4) suggests\nthat one should proceed as follows:\n1.\nRename the variables in BX to their primed versions; call the resulting OBDD\nBX′.\n2.\nCompute the OBDD for exists(ˆx′, apply(·, B→, BX′)) using the apply and\nexists algorithms (Sections 6.2.2 and 6.2.4).\n6.3.4 Synthesising OBDDs\nThe method used in Example 6.13 for producing an OBDD for the transi-\ntion relation was to compute ﬁrst the truth table and then an OBDD which\nmight not be in its fully reduced form; hence the need for a ﬁnal call to\n388\n6 Binary decision diagrams\nthe reduce function. However, this procedure would be unacceptable if ap-\nplied to realistically sized systems with a large number of variables, for the\ntruth table’s size is exponential in the number of boolean variables. The\nkey idea and attraction of applying OBDDs to ﬁnite systems is therefore to\ntake a system description in a language such as SMV and to synthesise the\nOBDD directly, without having to go via intermediate representations (such\nas binary decision trees or truth tables) which are exponential in size.\nSMV allows us to deﬁne the next value of a variable in terms of the\ncurrent values of variables (see the examples of code in Section 3.3.2)3. This\ncan be compiled into a set of boolean functions fi, one for each variable xi,\nBf (reduced)\nB∃x1.∃x2....∃xn.f (reduced)\nNP-complete\nFigure 6.23. Upper bounds in terms of the input OBDD(s) for the\nworst-case running times of our algorithms needed in our implementa-\ntion of boolean formulas.\n6.2.5 Assessment of OBDDs\nTime complexities for computing OBDDs\nWe can measure the com-\nplexity of the algorithms of the preceding section by giving upper bounds\nfor the running time in terms of the sizes of the input OBDDs. The table\nin Figure 6.23 summarises these upper bounds (some of those upper bounds\nmay require more sophisticated versions of the algorithms than the versions\npresented in this chapter). All the operations except nested boolean quantiﬁ-\ncation are practically eﬃcient in the size of the participating OBDDs. Thus,\nmodelling very large systems with this approach will work if the OBDDs\n6.2 Algorithms for reduced OBDDs\n381\nwhich represent the systems don’t grow too large too fast. If we can some-\nhow control the size of OBDDs, e.g. by using good heuristics for the choice\nof variable ordering, then these operations are computationally feasible. It\nhas already been shown that OBDDs modelling certain classes of systems\nand networks don’t grow excessively.\nThe expensive computational operations are the nested boolean quantiﬁ-\ncations ∃z1. . . . ∃zn.f and ∀z1. . . . ∀zn.f. By exercise 1 on page 406, the com-\nputation of the OBDD for ∃z1. . . . ∃zn.f, given the OBDD for f, is an NP-\ncomplete problem2; thus, it is unlikely that there exists an algorithm with\na feasible worst-time complexity. This is not to say that boolean functions\nmodelling practical systems may not have eﬃcient nested boolean quan-\ntiﬁcations. The performance of our algorithms can be improved by using\nfurther optimisation techniques, such as parallelisation.\nNote that the operations apply, restrict, etc. are only eﬃcient in the\nsize of the input OBDDs. So if a function f does not have a compact repre-\nsentation as an OBDD, then computing with its OBDD will not be eﬃcient.\nThis can easily be generalised to a sequence of exists operations. We\nwrite ∃ˆx. f to mean ∃x1.∃x2. . . . ∃xn. f, where ˆx denotes (x1, x2, . . . , xn).\n6.2 Algorithms for reduced OBDDs\n379\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\n1\n0\nx1\nx2\ny1\ny2\nx1\nx2\ny1\ny2\ny3\nFigure 6.20. restrict(0, x3, Bf) and restrict(1, x3, Bf) and the result\nof applying + to them.\n1\n0\nx1\nx2\nx3\ny1\ny2\ny3\n1\n0\nx1\nx2\ny1\ny2\ny3\n1\n0\nx1\ny1\ny2\ny3\n∃x3\n⇒\n∃x2\n⇒\nFigure 6.21. OBDDs for f, ∃x3. f and ∃x2.∃x3. f.\nThe OBDD for this boolean function is obtained from the OBDD for f by\nreplacing every node labelled with an xi by the + of its two branches.\nFigure 6.21 shows the computation of ∃x3. f and ∃x2.∃x3. f (which is\nsemantically equivalent to x1 · y1 + y2 + y3) in this way.\nThe boolean quantiﬁer ∀is the dual of ∃:\n∀x.f\ndef\n= f[0/x] · f[1/x]\nasserting that f could be made false by putting x to 0 or to 1.\nThe translation of boolean formulas into OBDDs using the algorithms of\nthis section is summarised in Figure 6.22.\n380\n6 Binary decision diagrams\nBoolean formula f\nRepresenting OBDD Bf\n0\nB0 (Fig. 6.6)\n1\nB1 (Fig. 6.6)\nx\nBx (Fig. 6.6)\nf\nswap the 0- and 1-nodes in Bf\nf + g\napply (+, Bf, Bg)\nf · g\napply (· , Bf, Bg)\nf ⊕g\napply (⊕, Bf, Bg)\nf[1/x]\nrestrict (1, x, Bf)\nf[0/x]\nrestrict (0, x, Bf)\n∃x.f\napply (+, Bf[0/x], Bf[1/x])\n∀x.f\napply (· , Bf[0/x], Bf[1/x])\nFigure 6.22. Translating boolean formulas f to OBDDs Bf, given a\nfixed, global ordering on boolean variables.\nAlgorithm Input OBDD(s)\nOutput OBDD\nTime-complexity\nreduce\nB\nreduced B\nO(|B| · log |B|)\napply\nBf, Bg (reduced) Bf op g (reduced)\nO(|Bf| · |Bg|)\nrestrict Bf (reduced)\nBf[0/x] or Bf[1/x] (reduced) O(|Bf| · log |Bf|)\n∃\nBf (reduced)\nB∃x1.∃x2....∃xn.f (reduced)\nNP-complete\nFigure 6.23. Upper bounds in terms of the input OBDD(s) for the\nworst-case running times of our algorithms needed in our implementa-\ntion of boolean formulas.\n6.2.5 Assessment of OBDDs\nTime complexities for computing OBDDs\nWe can measure the com-\nin which we applied the reductions does not matter. We therefore say that\nOBDDs have a canonical form, namely their unique reduced OBDD. Most\nother representations (conjunctive normal forms, etc.) do not have canonical\nforms.\nThe algorithms for · and + for BDDs, presented in Section 6.1.2, won’t\nwork for OBDDs as they may introduce multiple occurrences of the same\nvariable on a path. We will soon develop more sophisticated algorithms\nfor these operations on OBDDs, which exploit the compatible ordering of\nvariables in paths.\nOBDDs allow compact representations of certain classes of boolean func-\ntions which only have exponential representations in other systems, such as\ntruth tables and conjunctive normal forms. As an example consider the even\nparity function feven(x1, x2, . . . , xn) which is deﬁned to be 1 if there is an\neven number of variables xi with value 1; otherwise, it is deﬁned to be 0.\nIts representation as an OBDD requires only 2n + 1 nodes. Its OBDD for\nn = 4 and the ordering [x1, x2, x3, x4] can be found in Figure 6.11.\nThe impact of the chosen variable ordering\nThe size of the OBDD\nrepresenting the parity functions is independent of the chosen variable or-\ndering. This is because the parity functions are themselves independent of\nthe order of variables: swapping the values of any two variables does not\nchange the value of the function; such functions are called symmetric.\nHowever, in general the chosen variable ordering makes a signiﬁcant dif-\nference to the size of the OBDD representing a given function. Consider\nthe boolean function (x1 + x2) · (x3 + x4) · · · · · (x2n−1 + x2n); it corresponds\nto a propositional formula in conjunctive normal form. If we choose the\n1 In an implementation this will amount to checking whether two pointers are equal.\n370\n6 Binary decision diagrams\n1\n0\nx1\nx2\nx3\nx4\nx3\nx2\nx4\nFigure 6.11. An OBDD for the even parity function for four bits.\n‘natural’ ordering [x1, x2, x3, x4, . . . ], then we can represent this function as\n1 In an implementation this will amount to checking whether two pointers are equal.\n370\n6 Binary decision diagrams\n1\n0\nx1\nx2\nx3\nx4\nx3\nx2\nx4\nFigure 6.11. An OBDD for the even parity function for four bits.\n‘natural’ ordering [x1, x2, x3, x4, . . . ], then we can represent this function as\nan OBDD with 2n + 2 nodes. Figure 6.12 shows the resulting OBDD for\nn = 3. Unfortunately, if we choose instead the ordering\n[x1, x3, . . . , x2n−1, x2, x4, . . . , x2n]\nthe resulting OBDD requires 2n+1 nodes; the OBDD for n = 3 can be seen\nin Figure 6.13.\nThe sensitivity of the size of an OBDD to the particular variable order-\ning is a price we pay for all the advantages that OBDDs have over BDDs.\nAlthough ﬁnding the optimal ordering is itself a computationally expensive\nproblem, there are good heuristics which will usually produce a fairly good\nordering. Later on we return to this issue in discussions of applications.\nThe importance of canonical representation\nThe importance of\nhaving a canonical form for OBDDs in conjunction with an eﬃcient test for\ndeciding whether two reduced OBDDs are isomorphic cannot be overesti-\nmated. It allows us to perform the following tests:\nAbsence of redundant variables. If the value of the boolean function\nf(x1, x2, . . . , xn) does not depend on the value of xi, then any reduced\nOBDD which represents f does not contain any xi-node.\nTest for semantic equivalence. If two functions f(x1, x2, . . . , xn) and\ng(x1, x2, . . . , xn) are represented by OBDDs Bf, respectively Bg, with a\ncompatible ordering of variables, then we can eﬃciently decide whether f\nand g are semantically equivalent. We reduce Bf and Bg (if necessary); f\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\n6.1 Representing boolean functions\n371\n0\n1\nx1\nx6\nx5\nx3\nx4\nx2\nFigure 6.12. The OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with vari-\nable ordering [x1, x2, x3, x4, x5, x6].\nx1\nx3\nx3\nx5\nx5\nx5\nx2\nx2\nx2\nx4\nx4\n1\nx6\n0\nx2\nx5\nFigure 6.13. Changing the ordering may have dramatic effects on the\nsize of an OBDD: the OBDD for (x1 + x2) · (x3 + x4) · (x5 + x6) with\nvariable ordering [x1, x3, x5, x2, x4, x6].\n372\n6 Binary decision diagrams\nand g denote the same boolean functions if, and only if, the reduced OBDDs\nhave identical structure.\nTest for validity. We can test a function f(x1, x2, . . . , xn) for validity (i.e.\nf always computes 1) in the following way. Compute a reduced OBDD for\nf. Then f is valid if, and only if, its reduced OBDD is B1.\nTest for implication. We can test whether f(x1, x2, . . . , xn) implies g(x1,\nx2, . . . , xn) (i.e. whenever f computes 1, then so does g) by computing the\nreduced OBDD for f · g. This is B0 iﬀthe implication holds.\nTest for satisﬁability. We can test a function f(x1, x2, . . . , xn) for satis-\nﬁability (f computes 1 for at least one assignment of 0 and 1 values to its\nvariables). The function f is satisﬁable iﬀits reduced OBDD is not B0.\n6.2 Algorithms for reduced OBDDs\n6.2.1 The algorithm reduce\nThe reductions C1–C3 are at the core of any serious use of OBDDs, for\nwhenever we construct a BDD we will want to convert it to its reduced form.\nIn this section, we describe an algorithm reduce which does this eﬃciently\nfor ordered BDDs.\nIf the ordering of B is [x1, x2, . . . , xl], then B has at most l + 1 layers. The\nalgorithm reduce now traverses B layer by layer in a bottom-up fashion,\nbeginning with the terminal nodes. In traversing B, it assigns an integer\nlabel id(n) to each node n of B, in such a way that the subOBDDs with\nroot nodes n and m denote the same boolean function if, and only if, id(n)\nequals id(m).\nSince reduce starts with the layer of terminal nodes, it assigns the ﬁrst\n(R1, S1)\nx1\nx2\nx3\n(R3, S3)\n(R2, S3)\n(R3, S2)\nx4\nx3\n(R5, S4)\n(R6, S5)\n(R4, S3)\n(R6, S3)\n(R4, S3)\n(R4, S3)\nx4\n(R5, S4)\n(R6, S5)\n(R6, S5)\nx4\n(R6, S5)\nx4\n(R5, S4)\n(R6, S4)\n(R6, S5)\nFigure 6.16. The recursive call structure of apply for the example in\nFigure 6.15 (without memoisation).\n0\n1\nx4\nx3\nx2\nx1\nFigure 6.17. The result of apply (+, Bf, Bg), where Bf and Bg are given\nin Figure 6.15.\n6.2 Algorithms for reduced OBDDs\n377\nthe ﬁrst time and the result remembered for future calls. This program-\nming technique is known as memoisation. As well as being more eﬃcient,\nit has the advantage that the resulting OBDD requires less reduction. (In\nthis example, using memoisation eliminates the need for the ﬁnal call to\nreduce altogether.) Without memoisation, apply is exponential in the size\nof its arguments, since each non-leaf call generates a further two calls. With\nmemoisation, the number of calls to apply is bounded by 2 · |Bf| · |Bg|, where\n|B| is the size of the BDD. This is a worst-time complexity; the actual per-\nformance is often much better than this.\n6.2.3 The algorithm restrict\nGiven an OBDD Bf representing a boolean formula f, we need an algo-\nrithm restrict such that the call restrict(0, x, Bf) computes the reduced\nOBDD representing f[0/x] using the same variable ordering as Bf. The al-\ngorithm for restrict(0, x, Bf) works as follows. For each node n labelled\nwith x, incoming edges are redirected to lo(n) and n is removed. Then we\ncall reduce on the resulting OBDD. The call restrict (1, x, Bf) proceeds\nsimilarly, only we now redirect incoming edges to hi(n).\n6.2.4 The algorithm exists\nA boolean function can be thought of as putting a constraint on the values\nof its argument variables. For example, the function x + (y · z) evaluates to 1\nonly if x is 1; or y is 0 and z is 1 – this is a constraint on x, y, and z.\nIt is useful to be able to express the relaxation of the constraint on a subset\nof the variables concerned. To allow this, we write ∃x. f for the boolean",
                            "summary": "Theorem 6.11: Any OBDD representation of fn−1 has at least a number of vertices proportional to 1.09n, i.e. further optimisation techniques, such as parallelisation. Note that the operations apply, restrict, etc. are only eﬃcient in the size of the input OBDDs. So if a function f does not have a compact repre-sentation as an O BDD, then computing with its OBDC will not be e�â€¬cient. The following negative result, due to R. E. Bryant, demonstrates that OBDBs cannot be used for implementing integer multiplication. For example, multiplication of two n-bit integers results There are many variations and extensions to the OBDD data structure. Many of them can implement cer-                tain operations more eﬃciently than their OBDDs counterparts. But none of them perform as well as O BDDs overall. In particular, one fea-                ture which many of the variations lack is the canonical form; therefore they don't have an e-cient algorithm for deciding when two objects denote the same function. Another NP-complete problem is to decide the satisﬁability of formulas of propositional logic. For more information, see the Wikipedia article on OBDd data structures, and the Wikipedia entry for OBDs. 6.3.3 Implementing the functions pre∃and pre∀. Figure 6.27 (right) shows the truth                table redrawn with the interleaved ordering of the columns and the rowsreordered lexicographically. The resulting OBDD is shown in Figures 6.28 (left) and 6.29 (respectively) The meaning is that the function represented by                 is rather than [x1, x2, x′                ] rather than  x′                1, X′                2. The meaning of the word                 is that it is the term used to refer to a function. The method used in Example. 6.13 for producing an OBDD for the transi-portion relation was to compute ﬁrst the truth table and then an O.BDD which might not be in its fully reduced form. Now (6.4) suggests that one should proceed as follows: 1. rename the variables in BX to their primed versions; 2. compute the OBDDs for exists(ˆx′, apply(·, B→, BX′), and 3. Synthesise the results using the apply and exists algorithms (Sections 6.2.2 The idea of applying OBDDs to ﬁnite systems is to take a system description in a language such as SMV and to synthesise theOBDD directly. SMV allows us to deﬁne the next value of a variable in terms of the current values of variables (see the examples of code in Section 3.3.2) This can be compiled into a set of boolean functions fi, one for each variable xi, xi.f (reduced) and xn, n (increased) Figure 6.23.23 gives upper bounds for the running time of our algorithms needed in our implementa- hyperttion of boolean formulas. All the operations except nested boolean quantiﬁ-cation are practically eﬃcient in the size of the participating OBDDs. It has already been shown that OBDD modelling certain classes of systems and networks don’t grow excessively. The expensive computational operations are the nested Boolean quanti-cation. If we can control the size by using good heuristics for the choice of variable ordering, then these operations are computationally feasible. The table in Figure 6.23 summarises the upper bounds of these upper bounds. Some of those upper bounds may require more sophisticated versions of the algorithms than the versionspresented in this chapter. For example, the table on page 406, the com-                putation f, given the OBDD for f, is an NP-complete problem2; thus, it is unlikely that there exists an algorithm with                a feasible worst-time complexity. This is not to say that practical systems may not have eﬃcient nested boolean quan-                tiﬁcations. The performance of our algorithms can be improved by using further optimisation techniques, such as parallelisation. The operations apply, restrict, etc. are only e-cient in the size of the input OBDDs. So if a function f does not have a compact repre-                sentation as an OBD d, then computing with its OBDd will not be e-scientific. The OBDD for f is obtained by replacing every node labelled with an xi by the + of its two branches. F could be made false by putting x to 0 or to 1. The translation of boolean formulas into OBDDs using the algorithms of                this section is summarised in Figure 6.22. For f, f is the dual of f (which is the equivalent to x1 · y1 + y2 + y3) and f (f is the opposite of f) is the same as f(x1) (Fig. 6.6) FBDDs for f and f are shown in Figures 6.1, 6.2, and 6.3. Algorithm Input OBDD(s) Output OBDDs (reduced) O(|Bf| · log |Bf) Bf op g (red reduced) O (|Bg| · |Bg) Bg op op f (reducing) B f op op b (reduce) B g op op c (reduces) Bop g op Bg (red Reduced) Bp gop Bf (Reduced) Gop gop C (Reduce) Cop B (Reducing) Cops Bf [0/x] or Bf[1/x]. Cops O(Bf, Bg) Puts Bf on the 0- and The algorithms for · and + for BDDs, presented in Section 6.1.2, won’t work for OBDDs as they may introduce multiple occurrences of the samevariable on a path. We will soon develop more sophisticated algorithms for these operations on OBDD, which exploit the compatible ordering ofvariables in paths.OBDDs allow compact representations of certain classes of boolean func-tions which only have exponential representations in other systems, such astruth tables and conjunctive normal forms. As an example consider the evenparity function feven(x1, x2, . . . , xn) which is deﬁned to be The size of the OBDDrepresenting the parity functions is independent of the chosen variable or-dering. The chosen variable ordering makes a signiﬁcant dif-                ference to the size of a given function. In an implementation this will amount to checking whether two pointers are equal. If we choose the                1 In an Implementation this will Amount to Checking Whether Two pointers are Equal. The impact of the choosing variable ordering can be seen in Figure 6.11.7. The size of an even parity function for four bits can be found in Figure 7.1 in the ‘Even Parity Function’ section of this article. It is the same size as an even-parity function for The sensitivity of the size of an OBDD to the particular variable order is a price we pay for all the advantages that OBDDs have over BDDs. Although ﬁnding the optimal ordering is itself a computationally expensiveproblem, there are good heuristics which will usually produce a fairly good ordering. The resulting OBD D for n = 3 can be seen in Figure 6.13. The optimal ordering can be found at the bottom of the page by searching for the word ‘optimal’ in the ‘OBDD’ section of this article. The word “optimal ordering” is a term used to refer to the order in which two pointers are equal. Having a canonical form for OBDDs in conjunction with an eﬃcient test for                deciding whether two reduced OBDD are isomorphic cannot be overesti-                mated. It allows us to perform the following tests:Absence of redundant variables. If the value of the boolean function.f(x1, x2, . . . , xn) does not depend on the value. of xi, then any reducedOBDD which represents f does not contain any xi-node.Test for semantic equivalence. We reduce Bf and Bg (if necessary); f and g are semantically equivalent. Later on we return to this issue in discussions of applications. The OBDD for (x1 + x2) · (x3 + x4) ·. (x5 + x6) with. Variable ordering [x1, x2, x3, x4, x5, x6]. Changing the ordering may have dramatic effects on the size of the OBDDs. We can test a function f(x1,. x2,. . . , xn) for validity (i.e. f always computes 1) in the following way. Compute a reduced OBDd for f and test whether it is valid. Then f is valid if, and only if, its reduced O BDD is B1. The reductions C1–C3 are at the core of any serious use of OBDDs. We describe an algorithm reduce which does this eﬃciently for ordered BDDs. The algorithm reduce traverses B layer by layer in a bottom-up fashion,beginning with the terminal nodes. We also discuss how to test a function f(x1, x2, . . . , xn) for satisﬁability (f computes 1 for at least one assignment of 0 and 1 values to itsvariables). The function f is satis ﬁable iﬀits reduced OBDD is not B0. We conclude that the algorithm reduce can be used to In traversing B, it assigns an integerlabel id(n) to each node n of B, in such a way that the subOBDDs withroot nodes n and m denote the same boolean function. This program-consuming technique is known as memoisation. As well as being more eﬃcient, memoisation has the advantage that the resulting OBDD requires less reduction. The result of apply (+, Bf, Bg), where Bf and Bg are given, is shown in Figure 6.15.6.2 Algorithms for reduced OBDDs. The algorithm is called reduce and can be found at: http://www.cnn.com/2011/01/16 With memoisation, the number of calls to apply is bounded by 2. This is a worst-time complexity; the actual per-formance is often much better than this. The algorithm for restrict(0, x, Bf) works as follows. For each node n labelled with x, incoming edges are redirected to lo(n) and n is removed. Then we need an algo-                rithm restrict such that the call restrict( 0, x,. Bf, f) computes the reducedOBDD representing f[0/x] using the same variable ordering as Bf. The call reduce on the resulting OBDD is called on the same order as the BDD. A boolean function can be thought of as putting a constraint on the values of its argument variables. For example, the function x + (y · z) evaluates to 1 only if x is 1; or y is 0 and z is 1. It is useful to be able to express the relaxation of the constraint on a subsetof the variables concerned. To allow this, we write ∃x. f for the boolean. The call restrict (1, x, Bf) proceeds similarly, only",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-6-section-4",
                    "title": "A Relational Mu-Calculus",
                    "content": "alone must take responsibility for those.\nAdded for second edition\nMany people have helped improve this text by pointing out typos and\nmaking other useful comments after the publication date. Among them,\nxiii\nxiv\nAcknowledgements\nwe mention Wolfgang Ahrendt, Yasuhiro Ajiro, Torben Amtoft, Stephan\nAndrei, Bernhard Beckert, Jonathan Brown, James Caldwell, Ruchira Datta,\nAmy Felty, Dimitar Guelev, Hirotsugu Kakugawa, Kamran Kashef, Markus\nKr¨otzsch, Jagun Kwon, Ranko Lazic, David Makinson, Alexander Miczo,\nAart Middeldorp, Robert Morelli, Prakash Panangaden, Aileen Paraguya,\nFrank Pfenning, Shekhar Pradhan, Koichi Takahashi, Kazunori Ueda,\nHiroshi Watanabe, Fuzhi Wang and Reinhard Wilhelm.\n1\nPropositional logic\nThe aim of logic in computer science is to develop languages to model the\nsituations we encounter as computer science professionals, in such a way\nthat we can reason about them formally. Reasoning about situations means\nconstructing arguments about them; we want to do this formally, so that\nthe arguments are valid and can be defended rigorously, or executed on a\nmachine.\nConsider the following argument:\nExample 1.1 If the train arrives late and there are no taxis at the station,\nthen John is late for his meeting. John is not late for his meeting. The train\ndid arrive late. Therefore, there were taxis at the station.\nIntuitively, the argument is valid, since if we put the ﬁrst sentence and\nthe third sentence together, they tell us that if there are no taxis, then John\nwill be late. The second sentence tells us that he was not late, so it must be\nthe case that there were taxis.\nMuch of this book will be concerned with arguments that have this struc-\nture, namely, that consist of a number of sentences followed by the word\n‘therefore’ and then another sentence. The argument is valid if the sentence\nafter the ‘therefore’ logically follows from the sentences before it. Exactly\nwhat we mean by ‘follows from’ is the subject of this chapter and the next\none.\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nexamples, as are variables such as x and v. Function symbols also allow us\nto refer to objects: thus, m(a) and g(x, y) are also objects. Expressions in\npredicate logic which denote objects are called terms.\nThe other sort of things in predicate logic denotes truth values; expres-\nsions of this kind are formulas: Y (x, m(x)) is a formula, though x and m(x)\nare terms.\nA predicate vocabulary consists of three sets: a set of predicate symbols\nP, a set of function symbols F and a set of constant symbols C. Each pred-\nicate symbol and each function symbol comes with an arity, the number of\narguments it expects. In fact, constants can be thought of as functions which\ndon’t take any arguments (and we even drop the argument brackets) – there-\nfore, constants live in the set F together with the ‘true’ functions which do\ntake arguments. From now on, we will drop the set C, since it is convenient to\ndo so, and stipulate that constants are 0-arity, so-called nullary, functions.\n2.2.1 Terms\nThe terms of our language are made up of variables, constant symbols\nand functions applied to those. Functions may be nested, as in m(m(x))\nor g(m(a), c): the grade obtained by Andy’s mother in the course c.\nDeﬁnition 2.1 Terms are deﬁned as follows.\nr Any variable is a term.\nr If c ∈F is a nullary function, then c is a term.\nr If t1, t2, . . . , tn are terms and f ∈F has arity n > 0, then f(t1, t2, . . . , tn) is a\nterm.\nr Nothing else is a term.\nIn Backus Naur form we may write\nt ::= x | c | f(t, . . . , t)\nwhere x ranges over a set of variables var, c over nullary function symbols\nin F, and f over those elements of F with arity n > 0.\nIt is important to note that\nr the ﬁrst building blocks of terms are constants (nullary functions) and variables;\nr more complex terms are built from function symbols using as many previously\nbuilt terms as required by such function symbols; and\nr the notion of terms is dependent on the set F. If you change it, you change the\nset of terms.\n100\nreplaced by every student’s name in turn. Similarly, when trying to codify\na sentence having to do with the execution of a program, it would be rather\nlaborious to have to write down every state of the computer. Therefore,\nwe employ the concept of a variable. Variables are written u, v, w, x, y, z, . . .\nor x1, y3, u5, . . . and can be thought of as place holders for concrete values\n(like a student, or a program state). Using variables, we can now specify the\nmeanings of S, I and Y more formally:\nS(x) :\nx is a student\nI(x) :\nx is an instructor\nY (x, y) :\nx is younger than y.\nNote that the names of the variables are not important, provided that we\nuse them consistently. We can state the intended meaning of I by writing\nI(y) :\ny is an instructor\nor, equivalently, by writing\nI(z) :\nz is an instructor.\nVariables are mere place holders for objects. The availability of variables is\nstill not suﬃcient for capturing the essence of the example sentence above.\nWe need to convey the meaning of ‘Every student x is younger than some\ninstructor y.’ This is where we need to introduce quantiﬁers ∀(read: ‘for\nall’) and ∃(read: ‘there exists’ or ‘for some’) which always come attached\nto a variable, as in ∀x (‘for all x’) or in ∃z (‘there exists z’, or ‘there is some\nz’). Now we can write the example sentence in an entirely symbolic way as\n∀x (S(x) →(∃y (I(y) ∧Y (x, y)))).\n2.1 The need for a richer language\n95\nActually, this encoding is rather a paraphrase of the original sentence. In\nour example, the re-translation results in\nFor every x, if x is a student, then there is some y which is an\ninstructor such that x is younger than y.\nDiﬀerent predicates can have a diﬀerent number of arguments. The predi-\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\n312\n5 Modal logics and agents\n→\nφ\nφ\n3\n2\nFigure 5.4. The parse tree of the formula scheme φ →23φ.\nbelow. Even 2⊥is true in x6. If you wanted to convince someone that 2⊥\nwas not true in x6, you’d have to show that there is a world accessible from\nx6 in which ⊥is not true; but you can’t do this, for there are no worlds\naccessible from x6. So again, although ⊥is false in every world, 2⊥might\nnot be false. In fact, x ⊩2⊥holds iﬀx has no accessible worlds.\nFormulas and formula schemes\nThe grammar in (5.1) speciﬁes ex-\nactly the formulas of basic modal logic, given a set of atomic formulas. For\nexample, p →23p is such a formula. It is sometimes useful to talk about\na whole family of formulas which have the same ‘shape;’ these are called\nformula schemes. For example, φ →23φ is a formula scheme. Any formula\nwhich has the shape of a certain formula scheme is called an instance of the\nscheme. For example,\nr p →23p\nr q →23q\nr (p ∧3q) →23(p ∧3q)\nare all instances of the scheme φ →23φ. An example of a formula scheme\nof propositional logic is φ ∧ψ →ψ. We may think of a formula scheme as\nan under-speciﬁed parse tree, where certain portions of the tree still need to\nbe supplied – e.g. the tree of φ →23φ is found in Figure 5.4.\n5.2 Basic modal logic\n313\nSemantically, a scheme can be thought of as the conjunction of all its\ninstances – since there are generally inﬁnitely many such instances, this\ncannot be carried out syntactically! We say that a world/model satisﬁes a\nscheme if it satisﬁes all its instances. Note that an instance being satisﬁed\nin a Kripke model does not imply that the whole scheme is satisﬁed. For\nexample, we may have a Kripke model in which all worlds satisfy ¬p ∨q,\nbut at least one world does not satisfy ¬q ∨p; the scheme ¬φ ∨ψ is not\nsatisﬁed.\nEquivalences between modal formulas\nDeﬁnition 5.7 1.\nWe say that a set of formulas Γ of basic modal logic seman-\ntically entails a formula ψ of basic modal logic if, in any world x of any model\n9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional\nto predicate logic, let’s now look at how the semantics of predicate logic\nworks. Just like in the propositional case, the semantics should provide a\nseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-\nrate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent\nway; in proof theory, they were deﬁned by proof rules providing an oper-\native explanation. In semantics, we expect something like truth tables. By\n‘equivalent,’ we mean that we should be able to prove soundness and com-\npleteness, as we did for propositional logic – although a fully ﬂedged proof\nof soundness and completeness for predicate logic is beyond the scope of this\nbook.\nBefore we begin describing the semantics of predicate logic, let us look\nmore closely at the real diﬀerence between a semantic and a proof-theoretic\naccount. In proof theory, the basic object which is constructed is a proof.\nLet us write Γ as a shorthand for lists of formulas φ1, φ2, . . . , φn. Thus, to\nshow that Γ ⊢ψ is valid, we need to provide a proof of ψ from Γ. Yet,\nhow can we show that ψ is not a consequence of Γ? Intuitively, this is\nharder; how can you possibly show that there is no proof of something?\nYou would have to consider every ‘candidate’ proof and show it is not one.\nThus, proof theory gives a ‘positive’ characterisation of the logic; it pro-\nvides convincing evidence for assertions like ‘Γ ⊢ψ is valid,’ but it is not\nvery useful for establishing evidence for assertions of the form ‘Γ ⊢φ is not\nvalid.’\n2.4 Semantics of predicate logic\n123\nSemantics, on the other hand, works in the opposite way. To show that ψ\nis not a consequence of Γ is the ‘easy’ bit: ﬁnd a model in which all φi are\ntrue, but ψ isn’t. Showing that ψ is a consequence of Γ, on the other hand,\nis harder in principle. For propositional logic, you need to show that every\nvaluation (an assignment of truth values to all atoms involved) that makes ‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula",
                    "summary": "Many people have helped improve this text by pointing out typos and making other useful comments after the publication date. Among them are Wolfgang Ahrendt, Torben Amtoft, Bernhard Beckert, James Caldwell, Ruchira Datta, Amy Felty, Kamran Kashef, Jagun Kwon, Ranko Lazic, Alexander Miczo, Prakash Panangaden, Aileen Paraguya, Shekhar Pradhan, Koichi Takahashi, Fuzhi Wang and Reinhard Wilhelm. The aim of logic in computer science is to develop languages to model the situations we encounter. Reasoning about situations meansconstructing arguments about them. We want to do this formally, so that the arguments are valid and can be defended rigorously. The argument is valid if the sentence after the ‘therefore’ logically follows from the sentences before it. Much of this book will be concerned with arguments that have this struc-                ture, namely, that consist of a number of sentences followed by the word 'therefore' and then another sentence. For example, consider the following argument: If the train arrives late and there are no taxis at the station, then John is late for his meeting. The train did arrive late. Therefore, there were taxis atThe station. John is not late for the meeting Predicates with any number of arguments are possible in predicate logic. Predicates S and I have just one (they are called unary predicates), but predicate Y requires two arguments (it is called a binary predicate) For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can can’. Exactly what we mean by ‘follows from’ is the subject of this chapter and the next one in this series of articles. The next one, in the next section of this series, will focus on the concept of ‘theory of knowledge’ and how it can be used to understand the Coding up complex facts expressed in English sentences as logical formulas is important. In Section 2.3, we extend our natural deduction calculus of propositional.logic so that it covers logical formulas of predicate logic as well. In this way, we are able to prove the validity of sequents φ1, φ2, . . .    .         . .   . . The main objective is to reason symbolically orsemantically about the information expressed in those formulas. We will also explain why                formulas like the two above are indeed equivalent semantically. In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicate logic can be true or false. A predicate vocabulary consists of three sets: a set of predicate symbols P, a set. of function symbols F and a set-of constant symbols C. Each pred-                icate symbol and each function symbol comes with an arity, the number of arguments it expects. Expressions in predicate logic which denote objects are called terms. The other sort of things in predicate logic denotes truth values. Y (x, m(x) is a formula, though x and m(X) are terms. The terms of our language are made up of variables, constant symbols and functions applied to those. In Backus Naur form we may write t ::= x | c | f(t, . . . ) in terms. The terms are deﬁned as follows: Any variable is a term. If c is a nullary function, then c is also a term, and if t1, t2, .. . , tn are terms and f has arity n > 0, then f( t1,. t2,. tn) is aterm. Nothing else is a name. The language is a form of the language of the universe, which is a type of the English language. The notion of terms is dependent on the set F. If you change it, you change the set of terms. Variables are written u, v, w, x, y, z, . . . or x1, y3, u5. They can be thought of as place holders for concrete values like a student, or a program state. More complex terms are built from function symbols using as many previouslybuilt terms as required by such function symbols. For example, a variable can be written v, c, or f, depending on the state of the program at the time, and a function symbol can be used to represent a nullary function symbol or a function with arity n > 0. Using variables, we can now specify themeanings of S, I and Y more formally. The names of the variables are not important, provided that we                use them consistently. The availability of variables is still not suﬃcient for capturing the essence of the example sentence above. This is where we need to introduce quantiﬁers ∀(read: ‘for all x’) and  ‘there exists’ or ‘ for some’ (x, y) which always come attached to a variable, as in    x (‘ for all x) or    X (x is younger than y) Predicates can have a diﬀerent number of arguments. Predicate Y requires two arguments (it is called a binary predicate) Predicates with any ﬁnite number of argument are possible in predicate logic. Even 2⊥is true in x6. The parse tree of the formula scheme φ →23φ.below. The need for a richer language is discussed in the next section of this article. We will also look at the theory of agents in the context of a predicate logic scheme. We hope this article will help you understand some of the ideas behind predicate logic and the language we use. The next part of the article will focus on the theory and theory of agent logic. The grammar in (5.1) speciﬁes ex-actly the formulas of basic modal logic, given a set of atomic formulas. For example, p →23p is such a formula. It is sometimes useful to talk about a whole family of formulas which have the same ‘shape;’ these are called formula schemes. An example of a formula scheme of propositional logic is φ         (p  → 23p)  (p   → 23p) (p ∧3q) →23(p  √3) (q   → 23q) ( q   ■23) (k  ■3 A scheme can be thought of as the conjunction of all its instances. An instance being satisﬁed in a Kripke model does not imply that the whole scheme is satis ﬉ed. We say that a set of formulas  entails a formula of basic modal logic if, in any world x of any model, there is a formula for that world x. We may think of a formula scheme as an under-speciﬃed parse tree, where certain portions of the tree still need to be supplied – e.g. the tree of φ →23φ is found in Figure 5.4.7 1.9.2. Let φ and ψ and η be sentences of predicate logic. If ψ is semantically entailed by φ, is it necessarily the case that ω is not? Explain why ω iﬀφ is valid. Justify your answer. For each set of formulas below, show that they are consistent. If you disagree with one of these answers, you should change the answer to the other. If the answer is the same, then the original answer is correct. If it is not, then you should ask for a new answer. If there is no answer, you must accept that the previous answer was correct. The answer is that the first one is correct and the second one is not. For each of the formulas of predicate logic below, either ﬁnd a model which does not satisfy it, or prove it is valid. For each formula, either the model which doesn't satisfy it is not valid, or it can be proved to be valid. Exercises 2.5 and 2.6 are given in the section \"Exercises 1.5\" and \"2.5,\" respectively. For the rest of the section, see \"Exercise 1.6\" and \"Exercise 2.1\" for details. For more information on the exercises, see the expert guideline. Our linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the United States of America. Gentzen invented the idea of working with assumptions(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-ishly. Propositional and predicate logic can be found in the bibliographicremarks at the end of Chapter 2. For example, in the section on propositional logic, we use the term ‘propositional logic’ to refer to a particular type of logic. We use the terms ‘principal’ and ‘ In the ﬁrst chapter, we developed propositional logic by examining it from three angles: its proof theory, its syntax and its semantics. We begin this second chapter by pointing out the limitations of propo-centric logic with respect to encoding declarative sentences. What can we do with modiﬁers like not, and, or                and if . . . then, then, and so on? And how can we create a richer language for these modi-propositional-logic terms? We conclude this chapter by asking: What do we want to say in a language that is richer than propositional-proprietary-logics? In propositional logic, we could identify this assertion with a propositional assertion. The desire to express more subtle declarative sentences led to the design of predicate logic, also called ﬁrst-order logic. Just like in the propositional case, the semantics should provide a separate, but ultimately equivalent, characterisation of the logic. By ‘sepa-rate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent way. In semantics, we expect something like truth tables. In proof theory, the basic object which is constructed is a proof. To show that a formula is valid, we need to provide a proof of ψ from the formula. In predicate logic, we should be able to prove soundness and completeness, as we did for propositional logic. However, a fully ﬂedged proof of soundness is beyond the scope of this book. The semantics of predicate logic can be viewed as a kind of ‘synthesis’ of propositional and categorical logic. 2.4 Semantics of predicate logic. 2.4.1 ‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-                tively supported and has a substantial user community. For propositional logic, you need to show that every.valuation (an assignment of truth values to all atoms involved) that makes ‘NuSMV’ work is true. To show that. ω is not a consequence of Γ is the ‘easy’ bit. Showing that ω isn’t. is harder in principle. The ‘positive’ characterisation of the logic. is not very useful for establishing evidence SMV provides a language for describing the models we have been drawing as diagrams. It directly checks thevalidity of LTL (and also CTL) formulas on those models. SMV programs consist of one or more modules. As in the programminglanguage C, or Java, one of the modules must be called main. Modules can declare variables and assign to them. Assignments usually give the initialvalue of a variable and its next value as an expression in terms of the current values of variables. For details on how to obtain it, see the bibliographic notes at the end of the chapter.                NuSMV (sometimes called simply SMV) is a programming language. The following input to SMV is used to model the environment and for abstraction. Non-determinism is used for verification by model checking. The SMV program consists of a program and a speciﬁcation. The program has two variables, request of type boolean and status of enumeration type {ready, busy}: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent values of variable request are not determined within this program. This conserva-                tively models that these values are determined by an external environment. This under-speciﬁcation of request implies that the value of variable statusis partially determined: initially, it is ready; and it becomes busy whenever. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. The CTL model-checking algorithm can be used to develop a new model checker There are various ways in which one could consider a computational problem. For example, one could have the model M, theformula φ and a state s0 as input. Alternatively, the input could be just M and φ, where the output would be all states s of the model which satisfy φ. It turns out that it is easier to provide an algorithm for solving the second                of these two problems. Such a deeper understanding will provide the basis for an eﬃcient algorithm which computes whether M, s ⊨φ holds. In the case that that is not satisﬁed, such an algorithm can be augmented to produce an ac-                tual path (= run) The labelling algorithm is based on a CTL formula. It produces the set of states of the model that satisfy the formula. The algorithm does not need to be able to handle every CTL con-nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. We can simply check whether s0 is an element of the output set. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write the NuSMV model checker. Given G F, we check G F φ →ω, and G F is inﬁnitely often true. We check the correctness of SATEG, SATEU, and CTL's model-checking algorithms. We also look at the stock of valid formulas and the properties of the accessibility relation. We conclude with a review of the literature on programming languages and the theory of programming languages. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. The algorithm presented in the sections above for CTL model checking is quite intuitive. It labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-rivemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the literature. For example, the algorithm described in section 3.6.3 is called the LTL-model-checking algorithm. Model-checking algorithms adopt the same basic strategy. We explain that strategy ﬁrst; then, we describe some algo-rithms in more detail. Almost all LTL model checking algorithms proceed along the following three steps. The basic strategy is: Let M = (S, →, L) be a model and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along                all paths of M starting at s. The construction has theproperty that for all paths π: π ⋅ iﬀthe trace of π is accepted by Aψ. Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction. It was also developed by K. McMillan and its description language resembles but much extends SMV. NuSMV im-                plements bounded model checking [BCCZ99]. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. Dwyer. Current research in model checking includes attempts to exploit abstrac-                tions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to reduce the impact of the state explosion problem. The model checker Spin, which is geared towards asynchronous systems, can be found at the Spin website. The Edinburgh Concurity Workbench12 and the Concurrency Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. Theorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula                from an adequate fragment. Prove the evaluation of φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ or Z. Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment intosemantically equivalent formulas in that fragment. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) and evaluate it for the valuation corresponding to state s2 to determine whether it holds. Recall the way the two labelling algorithms operate in Chapter 3. Does oursymbolic coding mimic either or both of them, or neither? Exercises 6.16 and 6.17 are designed to test the correctness of the above arguments and to prove that the Theorem is valid. Given a CTL model M = (S, →, L), we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. We now want to modify it so that the resulting output is not a set, or an OBDD, but a formula. We use inductive induction on the CTL formula φ to show that the free variables of f f are among ˆx, where the latter is the vector ofolean variables which code states s   S. All ﬁxed-point subformulas of ff are formally monotone.",
                    "children": [
                        {
                            "id": "chapter-6-section-4-subsection-1",
                            "title": "Syntax and Semantics",
                            "content": "alone must take responsibility for those.\nAdded for second edition\nMany people have helped improve this text by pointing out typos and\nmaking other useful comments after the publication date. Among them,\nxiii\nxiv\nAcknowledgements\nwe mention Wolfgang Ahrendt, Yasuhiro Ajiro, Torben Amtoft, Stephan\nAndrei, Bernhard Beckert, Jonathan Brown, James Caldwell, Ruchira Datta,\nAmy Felty, Dimitar Guelev, Hirotsugu Kakugawa, Kamran Kashef, Markus\nKr¨otzsch, Jagun Kwon, Ranko Lazic, David Makinson, Alexander Miczo,\nAart Middeldorp, Robert Morelli, Prakash Panangaden, Aileen Paraguya,\nFrank Pfenning, Shekhar Pradhan, Koichi Takahashi, Kazunori Ueda,\nHiroshi Watanabe, Fuzhi Wang and Reinhard Wilhelm.\n1\nPropositional logic\nThe aim of logic in computer science is to develop languages to model the\nsituations we encounter as computer science professionals, in such a way\nthat we can reason about them formally. Reasoning about situations means\nconstructing arguments about them; we want to do this formally, so that\nthe arguments are valid and can be defended rigorously, or executed on a\nmachine.\nConsider the following argument:\nExample 1.1 If the train arrives late and there are no taxis at the station,\nthen John is late for his meeting. John is not late for his meeting. The train\ndid arrive late. Therefore, there were taxis at the station.\nIntuitively, the argument is valid, since if we put the ﬁrst sentence and\nthe third sentence together, they tell us that if there are no taxis, then John\nwill be late. The second sentence tells us that he was not late, so it must be\nthe case that there were taxis.\nMuch of this book will be concerned with arguments that have this struc-\nture, namely, that consist of a number of sentences followed by the word\n‘therefore’ and then another sentence. The argument is valid if the sentence\nafter the ‘therefore’ logically follows from the sentences before it. Exactly\nwhat we mean by ‘follows from’ is the subject of this chapter and the next\none.\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nexamples, as are variables such as x and v. Function symbols also allow us\nto refer to objects: thus, m(a) and g(x, y) are also objects. Expressions in\npredicate logic which denote objects are called terms.\nThe other sort of things in predicate logic denotes truth values; expres-\nsions of this kind are formulas: Y (x, m(x)) is a formula, though x and m(x)\nare terms.\nA predicate vocabulary consists of three sets: a set of predicate symbols\nP, a set of function symbols F and a set of constant symbols C. Each pred-\nicate symbol and each function symbol comes with an arity, the number of\narguments it expects. In fact, constants can be thought of as functions which\ndon’t take any arguments (and we even drop the argument brackets) – there-\nfore, constants live in the set F together with the ‘true’ functions which do\ntake arguments. From now on, we will drop the set C, since it is convenient to\ndo so, and stipulate that constants are 0-arity, so-called nullary, functions.\n2.2.1 Terms\nThe terms of our language are made up of variables, constant symbols\nand functions applied to those. Functions may be nested, as in m(m(x))\nor g(m(a), c): the grade obtained by Andy’s mother in the course c.\nDeﬁnition 2.1 Terms are deﬁned as follows.\nr Any variable is a term.\nr If c ∈F is a nullary function, then c is a term.\nr If t1, t2, . . . , tn are terms and f ∈F has arity n > 0, then f(t1, t2, . . . , tn) is a\nterm.\nr Nothing else is a term.\nIn Backus Naur form we may write\nt ::= x | c | f(t, . . . , t)\nwhere x ranges over a set of variables var, c over nullary function symbols\nin F, and f over those elements of F with arity n > 0.\nIt is important to note that\nr the ﬁrst building blocks of terms are constants (nullary functions) and variables;\nr more complex terms are built from function symbols using as many previously\nbuilt terms as required by such function symbols; and\nr the notion of terms is dependent on the set F. If you change it, you change the\nset of terms.\n100\nreplaced by every student’s name in turn. Similarly, when trying to codify\na sentence having to do with the execution of a program, it would be rather\nlaborious to have to write down every state of the computer. Therefore,\nwe employ the concept of a variable. Variables are written u, v, w, x, y, z, . . .\nor x1, y3, u5, . . . and can be thought of as place holders for concrete values\n(like a student, or a program state). Using variables, we can now specify the\nmeanings of S, I and Y more formally:\nS(x) :\nx is a student\nI(x) :\nx is an instructor\nY (x, y) :\nx is younger than y.\nNote that the names of the variables are not important, provided that we\nuse them consistently. We can state the intended meaning of I by writing\nI(y) :\ny is an instructor\nor, equivalently, by writing\nI(z) :\nz is an instructor.\nVariables are mere place holders for objects. The availability of variables is\nstill not suﬃcient for capturing the essence of the example sentence above.\nWe need to convey the meaning of ‘Every student x is younger than some\ninstructor y.’ This is where we need to introduce quantiﬁers ∀(read: ‘for\nall’) and ∃(read: ‘there exists’ or ‘for some’) which always come attached\nto a variable, as in ∀x (‘for all x’) or in ∃z (‘there exists z’, or ‘there is some\nz’). Now we can write the example sentence in an entirely symbolic way as\n∀x (S(x) →(∃y (I(y) ∧Y (x, y)))).\n2.1 The need for a richer language\n95\nActually, this encoding is rather a paraphrase of the original sentence. In\nour example, the re-translation results in\nFor every x, if x is a student, then there is some y which is an\ninstructor such that x is younger than y.\nDiﬀerent predicates can have a diﬀerent number of arguments. The predi-\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\n312\n5 Modal logics and agents\n→\nφ\nφ\n3\n2\nFigure 5.4. The parse tree of the formula scheme φ →23φ.\nbelow. Even 2⊥is true in x6. If you wanted to convince someone that 2⊥\nwas not true in x6, you’d have to show that there is a world accessible from\nx6 in which ⊥is not true; but you can’t do this, for there are no worlds\naccessible from x6. So again, although ⊥is false in every world, 2⊥might\nnot be false. In fact, x ⊩2⊥holds iﬀx has no accessible worlds.\nFormulas and formula schemes\nThe grammar in (5.1) speciﬁes ex-\nactly the formulas of basic modal logic, given a set of atomic formulas. For\nexample, p →23p is such a formula. It is sometimes useful to talk about\na whole family of formulas which have the same ‘shape;’ these are called\nformula schemes. For example, φ →23φ is a formula scheme. Any formula\nwhich has the shape of a certain formula scheme is called an instance of the\nscheme. For example,\nr p →23p\nr q →23q\nr (p ∧3q) →23(p ∧3q)\nare all instances of the scheme φ →23φ. An example of a formula scheme\nof propositional logic is φ ∧ψ →ψ. We may think of a formula scheme as\nan under-speciﬁed parse tree, where certain portions of the tree still need to\nbe supplied – e.g. the tree of φ →23φ is found in Figure 5.4.\n5.2 Basic modal logic\n313\nSemantically, a scheme can be thought of as the conjunction of all its\ninstances – since there are generally inﬁnitely many such instances, this\ncannot be carried out syntactically! We say that a world/model satisﬁes a\nscheme if it satisﬁes all its instances. Note that an instance being satisﬁed\nin a Kripke model does not imply that the whole scheme is satisﬁed. For\nexample, we may have a Kripke model in which all worlds satisfy ¬p ∨q,\nbut at least one world does not satisfy ¬q ∨p; the scheme ¬φ ∨ψ is not\nsatisﬁed.\nEquivalences between modal formulas\nDeﬁnition 5.7 1.\nWe say that a set of formulas Γ of basic modal logic seman-\ntically entails a formula ψ of basic modal logic if, in any world x of any model\n9. Let φ and ψ and η be sentences of predicate logic.\n(a) If ψ is semantically entailed by φ, is it necessarily the case that ψ is not\nsemantically entailed by ¬φ?\n(b)\n*\nIf ψ is semantically entailed by φ ∧η, is it necessarily the case that ψ is\nsemantically entailed by φ and semantically entailed by η?\n(c) If ψ is semantically entailed by φ or by η, is it necessarily the case that ψ\nis semantically entailed by φ ∨η?\n(d) Explain why ψ is semantically entailed by φ iﬀφ →ψ is valid.\n10. Is ∀x (P(x) ∨Q(x)) ⊨∀x P(x) ∨∀x Q(x) a semantic entailment? Justify your\nanswer.\n11. For each set of formulas below show that they are consistent:\n(a) ∀x ¬S(x, x), ∃x P(x), ∀x ∃y S(x, y), ∀x (P(x) →∃y S(y, x))\n(b)\n*\n∀x ¬S(x, x), ∀x ∃y S(x, y),\n∀x ∀y ∀z ((S(x, y) ∧S(y, z)) →S(x, z))\n(c) (∀x (P(x) ∨Q(x))) →∃y R(y), ∀x (R(x) →Q(x)), ∃y (¬Q(y) ∧P(y))\n(d)\n*\n∃x S(x, x), ∀x ∀y (S(x, y) →(x = y)).\n12. For each of the formulas of predicate logic below, either ﬁnd a model which\ndoes not satisfy it, or prove it is valid:\n(a) (∀x ∀y (S(x, y) →S(y, x))) →(∀x ¬S(x, x))\n(b)\n*\n∃y ((∀x P(x)) →P(y))\n(c) (∀x (P(x) →∃y Q(y))) →(∀x ∃y (P(x) →Q(y)))\n(d) (∀x ∃y (P(x) →Q(y))) →(∀x (P(x) →∃y Q(y)))\n(e) ∀x ∀y (S(x, y) →(∃z (S(x, z) ∧S(z, y))))\n(f) (∀x ∀y (S(x, y) →(x = y))) →(∀z ¬S(z, z))\n(g)\n*\n(∀x ∃y (S(x, y) ∧((S(x, y) ∧S(y, x)) →(x = y)))) →\n(¬∃z ∀w (S(z, w))).\n(h) ∀x ∀y ((P(x) →P(y)) ∧(P(y) →P(x)))\n(i) (∀x ((P(x) →Q(x)) ∧(Q(x) →P(x)))) →((∀x P(x)) →(∀x Q(x)))\n(j) ((∀x P(x)) →(∀x Q(x))) →(∀x ((P(x) →Q(x)) ∧(Q(x) →P(x))))\n(k) Diﬃcult: (∀x ∃y (P(x) →Q(y))) →(∃y ∀x (P(x) →Q(y))).\nExercises 2.5\n1. Assuming that our proof calculus for predicate logic is sound (see exercise 3\nbelow), show that the validity of the following sequents cannot be proved by\nﬁnding for each sequent a model such that all formulas to the left of ⊢evaluate\nto T and the sole formula to the right of ⊢evaluates to F (explain why this\nguarantees the non-existence of a proof):\n2.8 Exercises\n165\n(a) ∀x (P(x) ∨Q(x)) ⊢∀x P(x) ∨∀x Q(x)\n(b)\n*\nnectives such as →and ¬. This makes them hard to use in practice. Gentzen\nimproved the situation by inventing the idea of working with assumptions\n(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-\nrately.\n92\n1 Propositional logic\nOur linear and cubic SAT solvers are variants of St˚almarck’s method\n[SS90], a SAT solver which is patented in Sweden and in the United States\nof America.\nFurther historical remarks, and also pointers to other contemporary books\nabout propositional and predicate logic, can be found in the bibliographic\nremarks at the end of Chapter 2. For an introduction to algorithms and data\nstructures see e.g. [Wei98].\n2\nPredicate logic\n2.1 The need for a richer language\nIn the ﬁrst chapter, we developed propositional logic by examining it from\nthree diﬀerent angles: its proof theory (the natural deduction calculus), its\nsyntax (the tree-like nature of formulas) and its semantics (what these for-\nmulas actually mean). From the outset, this enterprise was guided by the\nstudy of declarative sentences, statements about the world which can, for\nevery valuation or model, be given a truth value.\nWe begin this second chapter by pointing out the limitations of propo-\nsitional logic with respect to encoding declarative sentences. Propositional\nlogic dealt quite satisfactorily with sentence components like not, and, or\nand if . . . then, but the logical aspects of natural and artiﬁcial languages\nare much richer than that. What can we do with modiﬁers like there exists\n. . . , all . . . , among . . . and only . . . ? Here, propositional logic shows clear\nlimitations and the desire to express more subtle declarative sentences led\nto the design of predicate logic, which is also called ﬁrst-order logic.\nLet us consider the declarative sentence\nEvery student is younger than some instructor.\n(2.1)\nIn propositional logic, we could identify this assertion with a propositional\nto predicate logic, let’s now look at how the semantics of predicate logic\nworks. Just like in the propositional case, the semantics should provide a\nseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-\nrate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent\nway; in proof theory, they were deﬁned by proof rules providing an oper-\native explanation. In semantics, we expect something like truth tables. By\n‘equivalent,’ we mean that we should be able to prove soundness and com-\npleteness, as we did for propositional logic – although a fully ﬂedged proof\nof soundness and completeness for predicate logic is beyond the scope of this\nbook.\nBefore we begin describing the semantics of predicate logic, let us look\nmore closely at the real diﬀerence between a semantic and a proof-theoretic\naccount. In proof theory, the basic object which is constructed is a proof.\nLet us write Γ as a shorthand for lists of formulas φ1, φ2, . . . , φn. Thus, to\nshow that Γ ⊢ψ is valid, we need to provide a proof of ψ from Γ. Yet,\nhow can we show that ψ is not a consequence of Γ? Intuitively, this is\nharder; how can you possibly show that there is no proof of something?\nYou would have to consider every ‘candidate’ proof and show it is not one.\nThus, proof theory gives a ‘positive’ characterisation of the logic; it pro-\nvides convincing evidence for assertions like ‘Γ ⊢ψ is valid,’ but it is not\nvery useful for establishing evidence for assertions of the form ‘Γ ⊢φ is not\nvalid.’\n2.4 Semantics of predicate logic\n123\nSemantics, on the other hand, works in the opposite way. To show that ψ\nis not a consequence of Γ is the ‘easy’ bit: ﬁnd a model in which all φi are\ntrue, but ψ isn’t. Showing that ψ is a consequence of Γ, on the other hand,\nis harder in principle. For propositional logic, you need to show that every\nvaluation (an assignment of truth values to all atoms involved) that makes",
                            "summary": "Many people have helped improve this text by pointing out typos and making other useful comments after the publication date. Among them are Wolfgang Ahrendt, Torben Amtoft, Bernhard Beckert, James Caldwell, Ruchira Datta, Amy Felty, Kamran Kashef, Jagun Kwon, Ranko Lazic, Alexander Miczo, Prakash Panangaden, Aileen Paraguya, Shekhar Pradhan, Koichi Takahashi, Fuzhi Wang and Reinhard Wilhelm. The aim of logic in computer science is to develop languages to model the situations we encounter. Reasoning about situations meansconstructing arguments about them. We want to do this formally, so that the arguments are valid and can be defended rigorously. The argument is valid if the sentence after the ‘therefore’ logically follows from the sentences before it. Much of this book will be concerned with arguments that have this struc-                ture, namely, that consist of a number of sentences followed by the word 'therefore' and then another sentence. For example, consider the following argument: If the train arrives late and there are no taxis at the station, then John is late for his meeting. The train did arrive late. Therefore, there were taxis atThe station. John is not late for the meeting Predicates with any number of arguments are possible in predicate logic. Predicates S and I have just one (they are called unary predicates), but predicate Y requires two arguments (it is called a binary predicate) For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can can’. Exactly what we mean by ‘follows from’ is the subject of this chapter and the next one in this series of articles. The next one, in the next section of this series, will focus on the concept of ‘theory of knowledge’ and how it can be used to understand the Coding up complex facts expressed in English sentences as logical formulas is important. In Section 2.3, we extend our natural deduction calculus of propositional.logic so that it covers logical formulas of predicate logic as well. In this way, we are able to prove the validity of sequents φ1, φ2, . . .    .         . .   . . The main objective is to reason symbolically orsemantically about the information expressed in those formulas. We will also explain why                formulas like the two above are indeed equivalent semantically. In Section 2.4, we generalize the valuations of Chapter 1 to a propernotion of models, real or artiﬁcial worlds in which formulas of predicate logic can be true or false. A predicate vocabulary consists of three sets: a set of predicate symbols P, a set. of function symbols F and a set-of constant symbols C. Each pred-                icate symbol and each function symbol comes with an arity, the number of arguments it expects. Expressions in predicate logic which denote objects are called terms. The other sort of things in predicate logic denotes truth values. Y (x, m(x) is a formula, though x and m(X) are terms. The terms of our language are made up of variables, constant symbols and functions applied to those. In Backus Naur form we may write t ::= x | c | f(t, . . . ) in terms. The terms are deﬁned as follows: Any variable is a term. If c is a nullary function, then c is also a term, and if t1, t2, .. . , tn are terms and f has arity n > 0, then f( t1,. t2,. tn) is aterm. Nothing else is a name. The language is a form of the language of the universe, which is a type of the English language. The notion of terms is dependent on the set F. If you change it, you change the set of terms. Variables are written u, v, w, x, y, z, . . . or x1, y3, u5. They can be thought of as place holders for concrete values like a student, or a program state. More complex terms are built from function symbols using as many previouslybuilt terms as required by such function symbols. For example, a variable can be written v, c, or f, depending on the state of the program at the time, and a function symbol can be used to represent a nullary function symbol or a function with arity n > 0. Using variables, we can now specify themeanings of S, I and Y more formally. The names of the variables are not important, provided that we                use them consistently. The availability of variables is still not suﬃcient for capturing the essence of the example sentence above. This is where we need to introduce quantiﬁers ∀(read: ‘for all x’) and  ‘there exists’ or ‘ for some’ (x, y) which always come attached to a variable, as in    x (‘ for all x) or    X (x is younger than y) Predicates can have a diﬀerent number of arguments. Predicate Y requires two arguments (it is called a binary predicate) Predicates with any ﬁnite number of argument are possible in predicate logic. Even 2⊥is true in x6. The parse tree of the formula scheme φ →23φ.below. The need for a richer language is discussed in the next section of this article. We will also look at the theory of agents in the context of a predicate logic scheme. We hope this article will help you understand some of the ideas behind predicate logic and the language we use. The next part of the article will focus on the theory and theory of agent logic. The grammar in (5.1) speciﬁes ex-actly the formulas of basic modal logic, given a set of atomic formulas. For example, p →23p is such a formula. It is sometimes useful to talk about a whole family of formulas which have the same ‘shape;’ these are called formula schemes. An example of a formula scheme of propositional logic is φ         (p  → 23p)  (p   → 23p) (p ∧3q) →23(p  √3) (q   → 23q) ( q   ■23) (k  ■3 A scheme can be thought of as the conjunction of all its instances. An instance being satisﬁed in a Kripke model does not imply that the whole scheme is satis ﬉ed. We say that a set of formulas  entails a formula of basic modal logic if, in any world x of any model, there is a formula for that world x. We may think of a formula scheme as an under-speciﬃed parse tree, where certain portions of the tree still need to be supplied – e.g. the tree of φ →23φ is found in Figure 5.4.7 1.9.2. Let φ and ψ and η be sentences of predicate logic. If ψ is semantically entailed by φ, is it necessarily the case that ω is not? Explain why ω iﬀφ is valid. Justify your answer. For each set of formulas below, show that they are consistent. If you disagree with one of these answers, you should change the answer to the other. If the answer is the same, then the original answer is correct. If it is not, then you should ask for a new answer. If there is no answer, you must accept that the previous answer was correct. The answer is that the first one is correct and the second one is not. For each of the formulas of predicate logic below, either ﬁnd a model which does not satisfy it, or prove it is valid. For each formula, either the model which doesn't satisfy it is not valid, or it can be proved to be valid. Exercises 2.5 and 2.6 are given in the section \"Exercises 1.5\" and \"2.5,\" respectively. For the rest of the section, see \"Exercise 1.6\" and \"Exercise 2.1\" for details. For more information on the exercises, see the expert guideline. Our linear and cubic SAT solvers are variants of St˚almarck’s method[SS90], a SAT solver which is patented in Sweden and in the United States of America. Gentzen invented the idea of working with assumptions(used by the rules →i, ¬i and ∨e) and by treating all the connectives sepa-ishly. Propositional and predicate logic can be found in the bibliographicremarks at the end of Chapter 2. For example, in the section on propositional logic, we use the term ‘propositional logic’ to refer to a particular type of logic. We use the terms ‘principal’ and ‘ In the ﬁrst chapter, we developed propositional logic by examining it from three angles: its proof theory, its syntax and its semantics. We begin this second chapter by pointing out the limitations of propo-centric logic with respect to encoding declarative sentences. What can we do with modiﬁers like not, and, or                and if . . . then, then, and so on? And how can we create a richer language for these modi-propositional-logic terms? We conclude this chapter by asking: What do we want to say in a language that is richer than propositional-proprietary-logics? In propositional logic, we could identify this assertion with a propositional assertion. The desire to express more subtle declarative sentences led to the design of predicate logic, also called ﬁrst-order logic. Just like in the propositional case, the semantics should provide a separate, but ultimately equivalent, characterisation of the logic. By ‘sepa-rate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent way. In semantics, we expect something like truth tables. In proof theory, the basic object which is constructed is a proof. To show that a formula is valid, we need to provide a proof of ψ from the formula. In predicate logic, we should be able to prove soundness and completeness, as we did for propositional logic. However, a fully ﬂedged proof of soundness is beyond the scope of this book. The semantics of predicate logic can be viewed as a kind of ‘synthesis’ of propositional and categorical logic. 2.4.4 Semantics of predicate logic. For propositional logic, you need to show that everyvaluation (an assignment of truth values to all atoms involved) that makes. every assertion true is true. To show that ψ is not a consequence of Γ is the ‘easy’ bit. Showing that it isn’t is harder in principle. The ‘positive’ characterisation of the logic is not useful for establishing evidence for assertions of the form ‘Γ ⊢φ is notvalid.’2.5.2.3. Propositional logic in terms of propositional semantics. For more information, see 2.6.1 and 2",
                            "children": []
                        },
                        {
                            "id": "chapter-6-section-4-subsection-2",
                            "title": "Coding CTL Models and Specifications",
                            "content": "‘New Symbolic Model Veriﬁer.’ NuSMV is an Open Source product, is ac-\ntively supported and has a substantial user community. For details on how\nto obtain it, see the bibliographic notes at the end of the chapter.\nNuSMV (sometimes called simply SMV) provides a language for describ-\ning the models we have been drawing as diagrams and it directly checks the\nvalidity of LTL (and also CTL) formulas on those models. SMV takes as\ninput a text consisting of a program describing a model and some speciﬁca-\ntions (temporal logic formulas). It produces as output either the word ‘true’\nif the speciﬁcations hold, or a trace showing why the speciﬁcation is false\nfor the model represented by our program.\nSMV programs consist of one or more modules. As in the programming\nlanguage C, or Java, one of the modules must be called main. Modules can\ndeclare variables and assign to them. Assignments usually give the initial\nvalue of a variable and its next value as an expression in terms of the current\nvalues of variables. This expression can be non-deterministic (denoted by\nseveral expressions in braces, or no assignment at all). Non-determinism is\nused to model the environment and for abstraction.\n192\n3 Verification by model checking\nThe following input to SMV:\nMODULE main\nVAR\nrequest : boolean;\nstatus : {ready,busy};\nASSIGN\ninit(status) := ready;\nnext(status) := case\nrequest : busy;\n1 : {ready,busy};\nesac;\nLTLSPEC\nG(request -> F status=busy)\nconsists of a program and a speciﬁcation. The program has two variables,\nrequest of type boolean and status of enumeration type {ready, busy}:\n0 denotes ‘false’ and 1 represents ‘true.’ The initial and subsequent values\nof variable request are not determined within this program; this conserva-\ntively models that these values are determined by an external environment.\nThis under-speciﬁcation of request implies that the value of variable status\nis partially determined: initially, it is ready; and it becomes busy whenever\n3.6.1 The CTL model-checking algorithm\nHumans may ﬁnd it easier to do model checks on the unwindings of models\ninto inﬁnite trees, given a designated initial state, for then all possible paths\nare plainly visible. However, if we think of implementing a model checker\non a computer, we certainly cannot unwind transition systems into inﬁ-\nnite trees. We need to do checks on ﬁnite data structures. For this reason,\nwe now have to develop new insights into the semantics of CTL. Such a\ndeeper understanding will provide the basis for an eﬃcient algorithm which,\ngiven M, s ∈S and φ, computes whether M, s ⊨φ holds. In the case that\nφ is not satisﬁed, such an algorithm can be augmented to produce an ac-\ntual path (= run) of the system demonstrating that M cannot satisfy φ.\nThat way, we may debug a system by trying to ﬁx what enables runs which\nrefute φ.\nThere are various ways in which one could consider\nM, s0\n?\n⊨φ\nas a computational problem. For example, one could have the model M, the\nformula φ and a state s0 as input; one would then expect a reply of the form\n‘yes’ (M, s0 ⊨φ holds), or ‘no’ (M, s0 ⊨φ does not hold). Alternatively, the\ninputs could be just M and φ, where the output would be all states s of the\nmodel M which satisfy φ.\nIt turns out that it is easier to provide an algorithm for solving the second\nof these two problems. This automatically gives us a solution to the ﬁrst one,\nsince we can simply check whether s0 is an element of the output set.\nThe labelling algorithm\nWe present an algorithm which, given a model\nand a CTL formula, outputs the set of states of the model that satisfy the\nformula. The algorithm does not need to be able to handle every CTL con-\nnective explicitly, since we have already seen that the connectives ⊥, ¬ and\n∧form an adequate set as far as the propositional connectives are concerned;\nand AF , EU and EX form an adequate set of temporal connectives. Given\nan arbitrary CTL formula φ, we would simply pre-process φ in order to write\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nthat φ is inﬁnitely often true, we check G F φ →ψ. This means: all paths\nsatisfying inﬁnitely often φ also satisfy ψ. It is not possible to express this\nin CTL. In particular, any way of adding As or Es to G F φ →ψ will result\nin a formula with a diﬀerent meaning from the intended one. For example,\nAG AF φ →ψ means that if all paths are fair then ψ holds, rather than what\nwas intended: ψ holds along all paths which are fair.\n3.6.3 The LTL model-checking algorithm\nThe algorithm presented in the sections above for CTL model checking\nis quite intuitive: given a system and a CTL formula, it labels states of\nthe system with the subformulas of the formula which are satisﬁed there.\nThe state-labelling approach is appropriate because subformulas of the for-\nmula may be evaluated in states of the system. This is not the case for\nLTL: subformulas of the formula must be evaluated not in states but along\npaths of the system. Therefore, LTL model checking has to adopt a diﬀerent\nstrategy.\nThere are several algorithms for LTL model checking described in the\nliterature. Although they diﬀer in detail, nearly all of them adopt the same\n3.6 Model-checking algorithms\n233\nbasic strategy. We explain that strategy ﬁrst; then, we describe some algo-\nrithms in more detail.\nThe basic strategy\nLet M = (S, →, L) be a model, s ∈S, and φ an LTL\nformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along\nall paths of M starting at s. Almost all LTL model checking algorithms\nproceed along the following three steps.\n1.\nConstruct an automaton, also known as a tableau, for the formula ¬φ. The\nautomaton for ψ is called Aψ. Thus, we construct A¬φ. The automaton has a\nnotion of accepting a trace. A trace is a sequence of valuations of the proposi-\ntional atoms. From a path, we can abstract its trace. The construction has the\nproperty that for all paths π: π ⊨ψ iﬀthe trace of π is accepted by Aψ. In other\nwords, the automaton Aψ encodes precisely the traces which satisfy ψ.\nsystem description language as CMU SMV, but it has an improved user in-\nterface and a greater variety of algorithms. For example, whereas CMU SMV\nchecks only CTL speciﬁcation, NuSMV supports LTL and CTL. NuSMV im-\nplements bounded model checking [BCCZ99]. Cadence SMV8 is an entirely\nnew model checker focused on compositional systems and abstraction as\nways of addressing the state explosion problem. It was also developed by\nK. McMillan and its description language resembles but much extends the\noriginal SMV.\nA website which gathers frequently used speciﬁcation patterns in various\nframeworks (such as CTL, LTL and regular expressions) is maintained by\nM. Dwyer, G. Avrunin, J. Corbett and L. Dillon9.\nCurrent research in model checking includes attempts to exploit abstrac-\ntions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to\nreduce the impact of the state explosion problem.\nThe model checker Spin, which is geared towards asynchronous systems\nand is based on the temporal logic LTL, can be found at the Spin website10. A\nmodel checker called FDR2 based on the process algebra CSP is available11.\n6 www.cs.cmu.edu/~modelcheck/\n7 nusmv.irst.itc.it\n8 www-cad.eecs.berkeley.edu/~kenmcmil/\n9 patterns.projects.cis.ksu.edu/\n10 netlib.bell-labs.com/netlib/spin/whatispin.html\n11 www.fsel.com.fdr2 download.html\n3.9 Bibliographic notes\n255\nThe Edinburgh Concurrency Workbench12 and the Concurrency Workbench\nof North Carolina13 are similar software tools for the design and analysis of\nconcurrent systems. An example of a customisable and extensible modular\nmodel checking frameworks for the veriﬁcation of concurrent software is\nBogor14.\nThere are many textbooks about veriﬁcation of reactive systems; we men-\ntion [MP91, MP95, Ros97, Hol90]. The SMV code contained in this chapter\ncan be downloaded from www.cs.bham.ac.uk/research/lics/.\n12 www.dcs.ed.ac.uk/home/cwb\n13 www.cs.sunysb.edu/~cwb\n14 http://bogor.projects.cis.ksu.edu/\n4\nProgram verification\n(b) (x1, x2, x3) ⇒(0, 1, 0).\n10. Prove\nTheorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula\nfrom an adequate fragment. Then [[φ]] corresponds to the set of valuations ρ such\nthat ρ ⊨f φ.\nby structural induction on φ. You may ﬁrst want to show that the evaluation of\nρ ⊨f φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns\nto x′\ni or Z.\n11. Argue that Theorem 6.19 above remains valid for arbitrary CTL formulas as\nlong as we translate formulas φ which are not in the adequate fragment into\nsemantically equivalent formulas ψ in that fragment and deﬁne f φ to be f ψ.\n12. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) on page 407\nand evaluate it for the valuation corresponding to state s2 to determine whether\ns2 ⊨AF (¬x1 ∧x2) holds.\n13. Repeat the last exercise with f E[x1∨¬x2Ux1].\n14. Recall the way the two labelling algorithms operate in Chapter 3. Does our\nsymbolic coding mimic either or both of them, or neither?\nExercises 6.16\n1. Consider the equations in (6.22) and (6.27). The former deﬁnes fair in terms of\nf ECG⊤, whereas the latter deﬁnes f ECG φ for general φ. Why is this unproblem-\natic, i.e. non-circular?\n2. Given a ﬁxed CTL model M = (S, →, L), we saw how to code formulas f φ\nrepresenting the set of states s ∈S with s ⊨φ, φ being a CTL formula of an\nadequate fragment.\n(a) Assume the coding without consideration of simple fairness constraints. Use\nstructural induction on the CTL formula φ to show that\ni. the free variables of f φ are among ˆx, where the latter is the vector of\nboolean variables which code states s ∈S;\nii. all ﬁxed-point subformulas of f φ are formally monotone.\n412\n6 Binary decision diagrams\n(b) Show these two assertions if f φ also encodes simple fairness constraints.\n3. Consider the pseudo-code for the function SAT on page 227. We now want to\nmodify it so that the resulting output is not a set, or an OBDD, but a formula",
                            "summary": "New Symbolic Model Veriﬁer. ‘NuSMV’ is an Open Source product, is ac-                tively supported and has a substantial user community. SMV takes as input a program describing a model and some speciﬃca-tions (temporal logic formulas) It produces as output either the word ‘true’ or ‘false’ if the formulas hold, or a trace showing why the speci ﬁcation is false for the model represented by our program. For details on how to obtain SMV, see the bibliographic notes at the end of the chapter. Back to the page you came from. Non-determinism is used to model the environment and for abstraction. This expression can be non-deterministic (denoted by several expressions in braces, or no assignment at all) Verification by model checking is done by using SMV's model checking function. For example, the following input to SMV would look like this: The program has two variables, request of type boolean and status of enumeration type {ready, busy}: 0 denotes ‘false’ and 1 represents ‘true’ The initial and subsequent values of variable request are not determined within this program. This conserva-                tively models that these values are determined by an external environment. This under-speciﬁcation of request implies that the value of variable statusis partially determined: initially, it is ready; and it becomes busy whenever. We need to do checks on data structures. For this reason, we now have to develop new insights into the semantics of CTL. The CTL model-checking algorithm can be used to develop a new model checker There are various ways in which one could consider a computational problem. For example, one could have the model M, theformula φ and a state s0 as input. Alternatively, the input could be just M and φ, where the output would be all states s of the model which satisfy φ. It turns out that it is easier to provide an algorithm for solving the second                of these two problems. Such a deeper understanding will provide the basis for an eﬃcient algorithm which computes whether M, s ⊨φ holds. In the case that that is not satisﬁed, such an algorithm can be augmented to produce an ac-                tual path (= run) The labelling algorithm is based on a CTL formula. It produces the set of states of the model that satisfy the formula. The algorithm does not need to be able to handle every CTL con-nective explicitly, since we have already seen that the connectives ⊥, ¬ and                formula form an adequate set as far as the propositional connectives are concerned. We can simply check whether s0 is an element of the output set. Given an arbitrary CTL formula φ, we would simply pre-process φ in order to write the NuSMV model checker. Given G F, we check G F φ →ω, and G F is inﬁnitely often true. We check the correctness of SATEG, SATEU, and CTL's model-checking algorithms. We also look at the stock of valid formulas and the properties of the accessibility relation. We conclude with a review of the literature on programming languages and the theory of programming languages. The book is published by Oxford University Press, London, priced £16.99 with p&p of £9.99. The algorithm presented in the sections above for CTL model checking is quite intuitive. It labels states of the system with the subformulas of the formula which are satisﬁed there. The state-labelling approach is appropriate because subformula of the for-rivemula may be evaluated in states. This is not the case for LTL, which must be evaluated not in states but along the system's paths. Therefore, LTL model Checking has to adopt a diﬀerentstrategy. There are several algorithms for L TL model checking described in the literature. For example, the algorithm described in section 3.6.3 is called the LTL-model-checking algorithm. Model-checking algorithms adopt the same basic strategy. We explain that strategy ﬁrst; then, we describe some algo-rithms in more detail. Almost all LTL model checking algorithms proceed along the following three steps. The basic strategy is: Let M = (S, →, L) be a model and φ an LTLformula. We determine whether M, s ⊨φ, i.e., whether φ is satisﬁed along                all paths of M starting at s. The construction has theproperty that for all paths π: π ⋅ iﬀthe trace of π is accepted by Aψ. Cadence SMV8 is an entirely new model checker focused on compositional systems and abstraction. It was also developed by K. McMillan and its description language resembles but much extends SMV. NuSMV im-                plements bounded model checking [BCCZ99]. A website which gathers frequently used speciﬁcation patterns in variousframeworks (such as CTL, LTL and regular expressions) is maintained by M. Dwyer, G. Avrunin, J. Corbett and L. Dwyer. Current research in model checking includes attempts to exploit abstrac-                tions, symmetries and compositionality [CGL94, Lon83, Dam96] in order to reduce the impact of the state explosion problem. The model checker Spin, which is geared towards asynchronous systems, can be found at the Spin website. The Edinburgh Concurity Workbench12 and the Concurrency Workbenchof North Carolina13 are similar software tools for the design and analysis of concurrent systems. The SMV code contained in this chapter can be downloaded from www.cs.bham.ac.uk/research/lics/. An example of a customisable and extensible modular model checking framework for the veriﬁcation of concurrent software is Bogor14. Theorem 6.19 Given a coding for a ﬁnite CTL model, let φ be a CTL formula                from an adequate fragment. Prove the evaluation of φ depends only on the values ρ(xi), i.e. it does not matter what ρ assigns to x′ or Z. Theorem 6.19 above remains valid for arbitrary CTL formulas as long as we translate formulas not in the adequate fragment intosemantically equivalent formulas in that fragment. Derive the formula f AF (¬x1∧x2) for the model in Figure 6.32(b) and evaluate it for the valuation corresponding to state s2 to determine whether it holds. Recall the way the two labelling algorithms operate in Chapter 3. Does oursymbolic coding mimic either or both of them, or neither? Exercises 6.16 and 6.17 are designed to test the correctness of the above arguments and to prove that the Theorem is valid. Given a CTL model M = (S, →, L), we saw how to code formulas f φrepresenting the set of states s ∈S with s ⊨φ. We now want to modify it so that the resulting output is not a set, or an OBDD, but a formula. We use inductive induction on the CTL formula φ to show that the free variables of f f are among ˆx, where the latter is the vector ofolean variables which code states s   S. All ﬁxed-point subformulas of ff are formally monotone.",
                            "children": []
                        }
                    ]
                }
            ]
        }
    ]
}