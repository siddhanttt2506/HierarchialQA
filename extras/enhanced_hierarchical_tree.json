{
  "id": "root",
  "title": "Textbook",
  "content": null,
  "summary": null,
  "children": [
    {
      "id": "chapter_1",
      "title": "Propositional Logic",
      "content": null,
      "summary": "Declarative statements can be made in any natural, or artiﬁcial, language. The kind of sentences we won’t consider here are non-declarative ones, like ‘Could you please pass me the salt?’ The logics we intend to design are symbolic in nature. We translate a subset of all English declarative sentences into strings of symbols. This gives us a compressed but still complete encoding of declar-ative sentences.",
      "children": [
        {
          "id": "chapter_1_1",
          "title": "Declarative Sentences",
          "content": "(4) will do. Et alors, qu’est-ce qu’on pense des phrases (5) et (6)? Sentences\n(5) and (6) are ﬁne if you happen to read French and German a bit. Thus,\ndeclarative statements can be made in any natural, or artiﬁcial, language.\nThe kind of sentences we won’t consider here are non-declarative ones,\nlike\nr Could you please pass me the salt?\nr Ready, steady, go!\nr May fortune come your way.\nPrimarily, we are interested in precise declarative sentences, or statements\nabout the behaviour of computer systems, or programs. Not only do we\nwant to specify such statements but we also want to check whether a given\nprogram, or system, fulﬁls a speciﬁcation at hand. Thus, we need to develop\na calculus of reasoning which allows us to draw conclusions from given as-\nsumptions, like initialised variables, which are reliable in the sense that they\npreserve truth: if all our assumptions are true, then our conclusion ought to\nbe true as well. A much more diﬃcult question is whether, given any true\nproperty of a computer program, we can ﬁnd an argument in our calculus\nthat has this property as its conclusion. The declarative sentence (3) above\nmight illuminate the problematic aspect of such questions in the context of\nnumber theory.\nThe logics we intend to design are symbolic in nature. We translate a cer-\ntain suﬃciently large subset of all English declarative sentences into strings\nof symbols. This gives us a compressed but still complete encoding of declar-\native sentences and allows us to concentrate on the mere mechanics of our\nargumentation. This is important since speciﬁcations of systems or software\nare sequences of such declarative sentences. It further opens up the possibil-\nity of automatic manipulation of such speciﬁcations, a job that computers\njust love to do1. Our strategy is to consider certain declarative sentences as\n1 There is a certain, slightly bitter, circularity in such endeavours: in proving that a certain",
          "summary": "Declarative statements can be made in any natural, or artiﬁcial, language. The kind of sentences we won’t consider here are non-declarative ones, like ‘Could you please pass me the salt?’ The logics we intend to design are symbolic in nature. We translate a subset of all English declarative sentences into strings of symbols. This gives us a compressed but still complete encoding of declar-ative sentences.",
          "children": []
        },
        {
          "id": "chapter_1_2",
          "title": "Natural Deduction",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_1_3",
          "title": "Semantics of Propositional Logic",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_1_4",
          "title": "Normal Forms",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_1_5",
          "title": "SAT Solvers",
          "content": null,
          "summary": null,
          "children": []
        }
      ]
    },
    {
      "id": "chapter_2",
      "title": "Predicate Logic",
      "content": null,
      "summary": "In Figure 2.5, state s2 is reachable from state s0, e.g. through the path. By convention, every state reaches itself by a path of length 0.0. Given the evident importance of this concept, can we express reachability in predicate logic – which is so expressive that it is undecidable? Theorem 2.24 (Compactness Theorem) Let Γ be a set of sentences of predicate logic. If all ﬁnite subsets of Γ are satisﬁable, then so is Γ. From this theorem one may derive a number of useful techniques. For example, given A, the interpretation =M of equality is forced to be {(a, a), (b, b), (c, c)}. The problem of determining whether a predicate logic formula is valid is known as a decision problem. A solution to a decision Problem is a program that takes problem instances as input and always terminates, producing a correct ‘yes’ or ‘no’ output. We will give a formal proof of this negative result, though we rely on an informal notion of computability. Given a logical formula φ in predicate logic, does it hold, yes or no? We show that this problem is not solvable. We cannot write a correct C or Java program that works for all φ. There is no way out of this peculiarity. Where would you draw the line between a model that makes sense and one that doesn’t? Given a logical formula φ in predicate logic, does it hold, yes or no? We show that this problem is not solvable; we cannot write a correct program that works for all φ. Every φ can, in principle, be uncovered to be valid or not, if you are prepared to work arbitrarily hard at it. But there is no uniform mechanical procedure for determining whether φ is valid which will work for all φ. We prove this by a well-known technique called problem reduction. The problem is the concatenation of strings si1si2 . . . sin equals ti1ti2. The solution is the sequence of indices (1, 3, 2, 3) since s1s3s2s3 and t1t3t2t3 both equal 101110011. Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’. In Section 2.3, we extend our natural deduction calculus of propositional logic so that it covers logical formulas of predicate logic as well. In this way, we are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar way to that in the ﬁrst chapter. In Section. 4, we generalize the valuations of Chapter 1 to a proper. notion of models, real or artiﬁcial worlds in which formulas of. predicate logic can be true or false.  semantics should provide aseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-                rate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent way. In proof theory, the basic object which is constructed is a proof. 2.4.4 Semantics of predicate logic. For propositional logic, you need to show that everyvaluation (an assignment of truth values to all atoms involved) that makes. every assertion true is true. To show that ψ is not a consequence of Γ is the ‘easy’ bit. Showing that it is not is harder in principle.",
      "children": [
        {
          "id": "chapter_2_1",
          "title": "The Need for a Richer Language",
          "content": "",
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_2_2",
          "title": "Predicate Logic as a Formal Language",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_2_3",
          "title": "Proof Theory of Predicate Logic",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_2_4",
          "title": "Semantics of Predicate Logic",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_2_5",
          "title": "Undecidability of Predicate Logic",
          "content": "In Figure 2.5, state s2 is reachable from state s0, e.g. through the path\ns0 →s1 →s2. By convention, every state reaches itself by a path of length\n0. State s3, however, is not reachable from s0; only states s0, s1, and s2\nare reachable from s0. Given the evident importance of this concept, can\nwe express reachability in predicate logic – which is, after all, so expressive\nthat it is undecidable? To put this question more precisely: can we ﬁnd a\npredicate-logic formula φ with u and v as its only free variables and R as\nits only predicate symbol (of arity 2) such that φ holds in directed graphs\niﬀthere is a path in that graph from the node associated to u to the node\nassociated to v? For example, we might try to write:\nu = v ∨∃x(R(u, x) ∧R(x, v)) ∨∃x1∃x2(R(u, x1) ∧R(x1, x2) ∧R(x2, v)) ∨. . .\nThis is inﬁnite, so it’s not a well-formed formula. The question is: can we\nﬁnd a well-formed formula with the same meaning?\nSurprisingly, this is not the case. To show this we need to record an im-\nportant consequence of the completeness of natural deduction for predicate\nlogic.\nTheorem 2.24 (Compactness Theorem) Let Γ be a set of sentences of\npredicate logic. If all ﬁnite subsets of Γ are satisﬁable, then so is Γ.\nPROOF:\nWe use proof by contradiction: Assume that Γ is not satisﬁable.\nThen the semantic entailment Γ ⊨⊥holds as there is no model in which\nall φ ∈Γ are true. By completeness, this means that the sequent Γ ⊢⊥\nis valid. (Note that this uses a slightly more general notion of sequent in\nwhich we may have inﬁnitely many premises at our disposal. Soundness and\n138\n2 Predicate logic\ncompleteness remain true for that reading.) Thus, this sequent has a proof\nin natural deduction; this proof – being a ﬁnite piece of text – can use\nonly ﬁnitely many premises ∆from Γ. But then ∆⊢⊥is valid, too, and\nso ∆⊨⊥follows by soundness. But the latter contradicts the fact that all\nﬁnite subsets of Γ are consistent.\n2\nFrom this theorem one may derive a number of useful techniques. We men-\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nto be {(a, a), (b, b), (c, c)}. Hence the semantics of equality is easy, for it is\nalways modelled extensionally.\n2.5 Undecidability of predicate logic\nWe continue our introduction to predicate logic with some negative results.\nGiven a formula φ in propositional logic we can, at least in principle, de-\ntermine whether ⊨φ holds: if φ has n propositional atoms, then the truth\ntable of φ contains 2n lines; and ⊨φ holds if, and only if, the column for φ\n(of length 2n) contains only T entries.\nThe bad news is that such a mechanical procedure, working for all for-\nmulas φ, cannot be provided in predicate logic. We will give a formal proof\nof this negative result, though we rely on an informal (yet intuitive) notion\nof computability.\nThe problem of determining whether a predicate logic formula is valid is\nknown as a decision problem. A solution to a decision problem is a program\n(written in Java, C, or any other common language) that takes problem\ninstances as input and always terminates, producing a correct ‘yes’ or ‘no’\noutput. In the case of the decision problem for predicate logic, the input to\nthe program is an arbitrary formula φ of predicate logic and the program\n132\n2 Predicate logic\nis correct if it produces ‘yes’ whenever the input formula is valid and ‘no’\nwhenever it is not. Note that the program which solves a decision problem\nmust terminate for all well-formed input: a program which goes on thinking\nabout it for ever is not allowed. The decision problem at hand is this:\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\n= {a, b}, P M′ def\n= {a} and QM′ def\n=\n{b}. Then M′ ⊨∀x P(x) →∀x Q(x) holds, but M′ ⊨∀x (P(x) →Q(x)) does\nnot.\n2.4.3 The semantics of equality\nWe have already pointed out the open-ended nature of the semantics of\npredicate logic. Given a predicate logic over a set of function symbols F and\na set of predicate symbols P, we need only a non-empty set A equipped with\nconcrete functions or elements fM (for f ∈F) and concrete predicates P M\n(for P ∈P) in A which have the right arities agreed upon in our speciﬁcation.\nOf course, we also stressed that most models have natural interpretations of\n2.5 Undecidability of predicate logic\n131\nfunctions and predicates, but central notions like that of semantic entailment\n(φ1, φ2, . . . , φn ⊨ψ) really depend on all possible models, even the ones that\ndon’t seem to make any sense.\nApparently there is no way out of this peculiarity. For example, where\nwould you draw the line between a model that makes sense and one that\ndoesn’t? And would any such choice, or set of criteria, not be subjective? Such\nconstraints could also forbid a modiﬁcation of your model if this alteration\nwere caused by a slight adjustment of the problem domain you intended to\nmodel. You see that there are a lot of good reasons for maintaining such a\nliberal stance towards the notion of models in predicate logic.\nHowever, there is one famous exception. Often one presents predicate logic\nsuch that there is always a special predicate = available to denote equality\n(recall Section 2.3.1); it has two arguments and t1 = t2 has the intended\nmeaning that the terms t1 and t2 compute the same thing. We discussed its\nproof rule in natural deduction already in Section 2.3.1.\nSemantically, one recognises the special role of equality by imposing on\nan interpretation function =M to be actual equality on the set A of M.\nThus, (a, b) is in the set =M iﬀa and b are the same elements in the set A.\nFor example, given A\ndef\n= {a, b, c}, the interpretation =M of equality is forced\nValidity in predicate logic.\nGiven a logical formula φ in predicate logic, does\n⊨φ hold, yes or no?\nWe now show that this problem is not solvable; we cannot write a correct\nC or Java program that works for all φ. It is important to be clear about\nexactly what we are stating. Naturally, there are some φ which can easily be\nseen to be valid; and others which can easily be seen to be invalid. However,\nthere are also some φ for which it is not easy. Every φ can, in principle, be\ndiscovered to be valid or not, if you are prepared to work arbitrarily hard at\nit; but there is no uniform mechanical procedure for determining whether φ\nis valid which will work for all φ.\nWe prove this by a well-known technique called problem reduction. That\nis, we take some other problem, of which we already know that it is not\nsolvable, and we then show that the solvability of our problem entails the\nsolvability of the other one. This is a beautiful application of the proof rules\n¬i and ¬e, since we can then infer that our own problem cannot be solvable\nas well.\nThe problem that is known not to be solvable, the Post correspondence\nproblem, is interesting in its own right and, upon ﬁrst reﬂection, does not\nseem to have a lot to do with predicate logic.\nThe Post correspondence problem.\nGiven a ﬁnite sequence of pairs\n(s1, t1), (s2, t2), . . . , (sk, tk) such that all si and ti are binary strings of pos-\nitive length, is there a sequence of indices i1, i2, . . . , in with n ≥1 such that\nthe concatenation of strings si1si2 . . . sin equals ti1ti2 . . . tin?\nHere is an instance of the problem which we can solve successfully: the\nconcrete correspondence problem instance C is given by a sequence of three\npairs C\ndef\n= ((1, 101), (10, 00), (011, 11)) so\ns1\ndef\n= 1\ns2\ndef\n= 10\ns3\ndef\n= 011\nt1\ndef\n= 101\nt2\ndef\n= 00\nt3\ndef\n= 11.\nA solution to the problem is the sequence of indices (1, 3, 2, 3) since s1s3s2s3\nand t1t3t2t3 both equal 101110011. Maybe you think that this problem must\ncates S and I have just one (they are called unary predicates), but predicate\nY requires two arguments (it is called a binary predicate). Predicates with\nany ﬁnite number of arguments are possible in predicate logic.\nAnother example is the sentence\nNot all birds can ﬂy.\nFor that we choose the predicates B and F which have one argument ex-\npressing\nB(x) :\nx is a bird\nF(x) :\nx can ﬂy.\nThe sentence ‘Not all birds can ﬂy’ can now be coded as\n¬(∀x (B(x) →F(x)))\nsaying: ‘It is not the case that all things which are birds can ﬂy.’ Alterna-\ntively, we could code this as\n∃x (B(x) ∧¬F(x))\nmeaning: ‘There is some x which is a bird and cannot ﬂy.’ Note that the\nﬁrst version is closer to the linguistic structure of the sentence above. These\ntwo formulas should evaluate to T in the world we currently live in since, for\nexample, penguins are birds which cannot ﬂy. Shortly, we address how such\nformulas can be given their meaning in general. We will also explain why\nformulas like the two above are indeed equivalent semantically.\nCoding up complex facts expressed in English sentences as logical formulas\nin predicate logic is important – e.g. in software design with UML or in\nformal speciﬁcation of safety-critical systems – and much more care must be\ntaken than in the case of propositional logic. However, once this translation\nhas been accomplished our main objective is to reason symbolically (⊢) or\nsemantically (⊨) about the information expressed in those formulas.\nIn Section 2.3, we extend our natural deduction calculus of propositional\nlogic so that it covers logical formulas of predicate logic as well. In this way\nwe are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar\nway to that in the ﬁrst chapter.\n96\n2 Predicate logic\nIn Section 2.4, we generalize the valuations of Chapter 1 to a proper\nnotion of models, real or artiﬁcial worlds in which formulas of predicate\nlogic can be true or false, which allows us to deﬁne semantic entailment\nto predicate logic, let’s now look at how the semantics of predicate logic\nworks. Just like in the propositional case, the semantics should provide a\nseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-\nrate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent\nway; in proof theory, they were deﬁned by proof rules providing an oper-\native explanation. In semantics, we expect something like truth tables. By\n‘equivalent,’ we mean that we should be able to prove soundness and com-\npleteness, as we did for propositional logic – although a fully ﬂedged proof\nof soundness and completeness for predicate logic is beyond the scope of this\nbook.\nBefore we begin describing the semantics of predicate logic, let us look\nmore closely at the real diﬀerence between a semantic and a proof-theoretic\naccount. In proof theory, the basic object which is constructed is a proof.\nLet us write Γ as a shorthand for lists of formulas φ1, φ2, . . . , φn. Thus, to\nshow that Γ ⊢ψ is valid, we need to provide a proof of ψ from Γ. Yet,\nhow can we show that ψ is not a consequence of Γ? Intuitively, this is\nharder; how can you possibly show that there is no proof of something?\nYou would have to consider every ‘candidate’ proof and show it is not one.\nThus, proof theory gives a ‘positive’ characterisation of the logic; it pro-\nvides convincing evidence for assertions like ‘Γ ⊢ψ is valid,’ but it is not\nvery useful for establishing evidence for assertions of the form ‘Γ ⊢φ is not\nvalid.’\n2.4 Semantics of predicate logic\n123\nSemantics, on the other hand, works in the opposite way. To show that ψ\nis not a consequence of Γ is the ‘easy’ bit: ﬁnd a model in which all φi are\ntrue, but ψ isn’t. Showing that ψ is a consequence of Γ, on the other hand,\nis harder in principle. For propositional logic, you need to show that every\nvaluation (an assignment of truth values to all atoms involved) that makes",
          "summary": "In Figure 2.5, state s2 is reachable from state s0, e.g. through the path. By convention, every state reaches itself by a path of length 0.0. Given the evident importance of this concept, can we express reachability in predicate logic – which is so expressive that it is undecidable? Theorem 2.24 (Compactness Theorem) Let Γ be a set of sentences of predicate logic. If all ﬁnite subsets of Γ are satisﬁable, then so is Γ. From this theorem one may derive a number of useful techniques. For example, given A, the interpretation =M of equality is forced to be {(a, a), (b, b), (c, c)}. The problem of determining whether a predicate logic formula is valid is known as a decision problem. A solution to a decision Problem is a program that takes problem instances as input and always terminates, producing a correct ‘yes’ or ‘no’ output. We will give a formal proof of this negative result, though we rely on an informal notion of computability. Given a logical formula φ in predicate logic, does it hold, yes or no? We show that this problem is not solvable. We cannot write a correct C or Java program that works for all φ. There is no way out of this peculiarity. Where would you draw the line between a model that makes sense and one that doesn’t? Given a logical formula φ in predicate logic, does it hold, yes or no? We show that this problem is not solvable; we cannot write a correct program that works for all φ. Every φ can, in principle, be uncovered to be valid or not, if you are prepared to work arbitrarily hard at it. But there is no uniform mechanical procedure for determining whether φ is valid which will work for all φ. We prove this by a well-known technique called problem reduction. The problem is the concatenation of strings si1si2 . . . sin equals ti1ti2. The solution is the sequence of indices (1, 3, 2, 3) since s1s3s2s3 and t1t3t2t3 both equal 101110011. Predicates with any number of arguments are possible in predicate logic. For example, the sentence ‘Not all birds can ﬂy’ can now be coded as ‘It is not the case that all things which are birds can’. In Section 2.3, we extend our natural deduction calculus of propositional logic so that it covers logical formulas of predicate logic as well. In this way, we are able to prove the validity of sequents φ1, φ2, . . . , φn ⊢ψ in a similar way to that in the ﬁrst chapter. In Section. 4, we generalize the valuations of Chapter 1 to a proper. notion of models, real or artiﬁcial worlds in which formulas of. predicate logic can be true or false.  semantics should provide aseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-                rate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent way. In proof theory, the basic object which is constructed is a proof. 2.4.4 Semantics of predicate logic. For propositional logic, you need to show that everyvaluation (an assignment of truth values to all atoms involved) that makes. every assertion true is true. To show that ψ is not a consequence of Γ is the ‘easy’ bit. Showing that it is not is harder in principle.",
          "children": []
        },
        {
          "id": "chapter_2_6",
          "title": "Expressiveness of Predicate Logic",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_2_7",
          "title": "Micromodels of Software",
          "content": null,
          "summary": null,
          "children": []
        }
      ]
    },
    {
      "id": "chapter_3",
      "title": "Verification by Model Checking",
      "content": null,
      "summary": null,
      "children": [
        {
          "id": "chapter_3_1",
          "title": "Motivation for Verification",
          "content": "",
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_3_2",
          "title": "Linear-Time Temporal Logic",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_3_3",
          "title": "Model Checking: Systems, Tools, Properties",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_3_4",
          "title": "Branching-Time Logic",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_3_5",
          "title": "CTL* and the Expressive Powers of LTL and CTL",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_3_6",
          "title": "Model-Checking Algorithms",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_3_7",
          "title": "The Fixed-Point Characterisation of CTL",
          "content": null,
          "summary": null,
          "children": []
        }
      ]
    },
    {
      "id": "chapter_4",
      "title": "Program Verification",
      "content": null,
      "summary": "There is a great advantage in being able to verify the correctness of computer systems. Verification methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. In this chapter and the next one, we examine two applications of logics to the question of verifying the correctness of computer systems, or programs. Formal veriﬁcation techniques can be thought of as comprising three parts: a framework for modelling systems, a description language of some sort, and a method to establish whether the description is correct. The domain of application in this chapter is transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems. The techniques of this chapter should be used during the coding process for small fragments of program that perform identiﬁable tasks. The logical structure of the formal speciﬃcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation in which it holds. In the previous section, we pointed out that only the syntactic construct while B {C} could be responsible for non-termination. In this section we extend our proof calculus for partial correctness so that it also proves that programs terminate. We identify an integer expression whose value can be shown to decrease every time we execute the body of the while-statement in question. The value of this expression is always non-negative. Such integer expressions are called variants. When it is 0, the while-statement terminates. We can codify this intuition in the following rule for total correctness. It replaces the rule for the while statement. Use the proof rule for assignment and logical implication as appropriate to showthe validity of the program. Give useful examples of such pro-                gram fragments in application programming. Prove the validity of the sequent in the partial-correctness calculus we develop in this chapter. Prove that any instance of the modiﬁed rule If-Statement in a proof can be replaced by one of the original If-statement. If our calculus is any good, then the relation ⊢par should be contained in par. We say that a calculus is complete if it is able to prove everything that is true. In Chapters 1 and 2, we said that soundness is relatively easy to show, since typically the soundness of individual proof rules can be established independently of the others. Formally, ⊢par is complete if it is valid whenever all of its parts are complete. Establishing its soundness is simply a matter of considering each rule in turn. Completeness, on the other hand, is harder to prove since it depends on the entire set of proof rules cooperating together. Proving properties of programs which are longer than Fac1 would be very diﬃcult in this style. The rule for sequentialcomposition suggests a more convenient way of presenting proofs in pro-                gram logic. A proof calcu-lus which presents a proof of the correctness of a program. The proof tableaux consist of the program code interleaved with midconditions. Prove the validity of the following total-correctness sequents. Prove total correctness of S1 and S2 for Min Sum. Implement program Collatz in a language of your choice. A function over integers f : I →I is a function with a = 3 and b = 1. The else-branch of the program Collatz assigns to c the value f(c), where f is an aﬃne function. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This expression is called a sequent; it is valid if a proof for it can be found. It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas. Upper-case Letters are used for sets of formulas.",
      "children": [
        {
          "id": "chapter_4_1",
          "title": "Why Should We Specify and Verify Code?",
          "content": "analyzer [JSS01] have been developed by D. Jackson and his Software\nDesign Group at the Laboratory for Computer Science at the Massachusetts\nInstitute of Technology. The tool has a dedicated repository website at\nalloy.mit.edu.\nMore information on typed higher-order logics and their use in the\nmodelling and verifying of programming frameworks can be found on F.\nPfenning’s course homepage7 on Computation and Deduction.\n7 www-2.cs.cmu.edu/~fp/courses/comp-ded/\n3\nVerification by model checking\n3.1 Motivation for verification\nThere is a great advantage in being able to verify the correctness of computer\nsystems, whether they are hardware, software, or a combination. This is most\nobvious in the case of safety-critical systems, but also applies to those that\nare commercially critical, such as mass-produced chips, mission critical, etc.\nFormal veriﬁcation methods have quite recently become usable by industry\nand there is a growing demand for professionals able to apply them. In this\nchapter, and the next one, we examine two applications of logics to the\nquestion of verifying the correctness of computer systems, or programs.\nFormal veriﬁcation techniques can be thought of as comprising three\nparts:\nr a framework for modelling systems, typically a description language of some sort;\nr a speciﬁcation language for describing the properties to be veriﬁed;\nr a veriﬁcation method to establish whether the description of a system satisﬁes\nthe speciﬁcation.\nApproaches to veriﬁcation can be classiﬁed according to the following\ncriteria:\nProof-based vs. model-based. In a proof-based approach, the system\ndescription is a set of formulas Γ (in a suitable logic) and the speciﬁcation\nis another formula φ. The veriﬁcation method consists of trying to ﬁnd\na proof that Γ |−φ. This typically requires guidance and expertise from\nthe user.\nIn a model-based approach, the system is represented by a model M for\nan appropriate logic. The speciﬁcation is again represented by a formula\nmically by a computer. As we will see, there are often good heuristics\nto help the programmer complete these tasks. This contrasts with the\nsituation of the last chapter, which was fully automatic.\nProperty-oriented. Just like in the previous chapter, we verify proper-\nties of a program rather than a full speciﬁcation of its behaviour.\n256\n4.1 Why should we specify and verify code?\n257\nApplication domain. The domain of application in this chapter is se-\nquential transformational programs. ‘Sequential’ means that we assume\nthe program runs on a single processor and that there are no concur-\nrency issues. ‘Transformational’ means that the program takes an input\nand, after some computation, is expected to terminate with an output.\nFor example, methods of objects in Java are often programmed in this\nstyle. This contrasts with the previous chapter which focuses on reactive\nsystems that are not intended to terminate and that react continually\nwith their environment.\nPre/post-development. The techniques of this chapter should be used\nduring the coding process for small fragments of program that perform\nan identiﬁable (and hence, speciﬁable) task and hence should be used\nduring the development process in order to avoid functional bugs.\n4.1 Why should we specify and verify code?\nThe task of specifying and verifying code is often perceived as an unwel-\ncome addition to the programmer’s job and a dispensable one. Arguments\nin favour of veriﬁcation include the following:\nr Documentation: The speciﬁcation of a program is an important component\nin its documentation and the process of documenting a program may raise or\nresolve important issues. The logical structure of the formal speciﬁcation, written\nas a formula in a suitable logic, typically serves as a guiding principle in trying\nto write an implementation in which it holds.\nr Time-to-market: Debugging big systems during the testing phase is costly and",
          "summary": "There is a great advantage in being able to verify the correctness of computer systems. Verification methods have quite recently become usable by industry. There is a growing demand for professionals able to apply them. In this chapter and the next one, we examine two applications of logics to the question of verifying the correctness of computer systems, or programs. Formal veriﬁcation techniques can be thought of as comprising three parts: a framework for modelling systems, a description language of some sort, and a method to establish whether the description is correct. The domain of application in this chapter is transformational programs. ‘Transformational’ means that the program takes an input and, after some computation, is expected to terminate with an output. This contrasts with the previous chapter which focuses on reactivesystems. The techniques of this chapter should be used during the coding process for small fragments of program that perform identiﬁable tasks. The logical structure of the formal speci ﬁcation, written as a formula in a suitable logic, typically serves as a guiding principle in trying to write an implementation.",
          "children": []
        },
        {
          "id": "chapter_4_2",
          "title": "A Framework for Software Verification",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_4_3",
          "title": "Proof Calculus for Partial Correctness",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_4_4",
          "title": "Proof Calculus for Total Correctness",
          "content": "thing if P ‘loops’ indeﬁnitely. In this section, we extend our proof calculus\nfor partial correctness so that it also proves that programs terminate. In the\nprevious section, we already pointed out that only the syntactic construct\nwhile B {C} could be responsible for non-termination.\n4.4 Proof calculus for total correctness\n293\nTherefore, the proof calculus for total correctness is the same as\nfor partial correctness for all the rules except the rule for while-\nstatements.\nA proof of total correctness for a while-statement will consist of two parts:\nthe proof of partial correctness and a proof that the given while-statement\nterminates. Usually, it is a good idea to prove partial correctness ﬁrst since\nthis often provides helpful insights for a termination proof. However, some\nprograms require termination proofs as premises for establishing partial cor-\nrectness, as can be seen in exercise 1(d) on page 303.\nThe proof of termination usually has the following form. We identify an\ninteger expression whose value can be shown to decrease every time we\nexecute the body of the while-statement in question, but which is always\nnon-negative. If we can ﬁnd an expression with these properties, it follows\nthat the while-statement must terminate; because the expression can only\nbe decremented a ﬁnite number of times before it becomes 0. That is because\nthere is only a ﬁnite number of integer values between 0 and the initial value\nof the expression.\nSuch integer expressions are called variants. As an example, for the pro-\ngram Fac1 of Example 4.2, a suitable variant is x −z. The value of this\nexpression is decremented every time the body of the while-statement is\nexecuted. When it is 0, the while-statement terminates.\nWe can codify this intuition in the following rule for total correctness\nwhich replaces the rule for the while statement:\n\u0001\nη ∧B ∧0 ≤E = E0\n\u0002\nC\n\u0001\nη ∧0 ≤E < E0\n\u0002\n\u0001\nη ∧0 ≤E\n\u0002\nwhile B {C}\n\u0001\nη ∧¬B\n\u0002\nTotal-while.\n(4.15)\nbelow hold; justify your answers:\n(a)\n*\nl ⊨(x + y < z) →¬(x ∗y = z)\n(b) l ⊨∀u (u < y) ∨(u ∗z < y ∗z)\n(c)\n*\nl ⊨x + y −z < x ∗y ∗z.\n2.\n*\nFor any φ, ψ and P explain why ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever the relation\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds.\n3. Let the relation P ⊢l ; l′ hold iﬀP’s execution in store l terminates, resulting\nin store l′. Use this formal judgment P ⊢l ; l′ along with the relation l ⊨φ to\ndeﬁne ⊨par and ⊨tot symbolically.\n4. Another reason for proving partial correctness in isolation is that some program\nfragments have the form while (true) {C}. Give useful examples of such pro-\ngram fragments in application programming.\n5.\n*\nUse the proof rule for assignment and logical implication as appropriate to show\nthe validity of\n(a) ⊢par\n\u0001\nx > 0\n\u0002\ny = x + 1\n\u0001\ny > 1\n\u0002\n(b) ⊢par\n\u0001\n⊤\n\u0002\ny = x; y = x + x + y\n\u0001\ny = 3 · x\n\u0002\n(c) ⊢par\n\u0001\nx > 1\n\u0002\na = 1; y = x; y = y - a\n\u0001\ny > 0 ∧x > y\n\u0002\n.\n6.\n*\nWrite down a program P such that\n(a)\n\u0001\n⊤\n\u0002\nP\n\u0001\ny = x + 2\n\u0002\n(b)\n\u0001\n⊤\n\u0002\nP\n\u0001\nz > x + y + 4\n\u0002\nholds under partial correctness; then prove that this is so.\n7. For all instances of Implied in the proof on page 274, specify their corresponding\n⊢AR sequents.\n8. There is a safe way of relaxing the format of the proof rule for assignment: as\nlong as no variable occurring in E gets updated in between the assertion ψ[E/x]\nand the assignment x = E we may conclude ψ right after this assignment. Ex-\nplain why such a proof rule is sound.\n9. (a) Show, by means of an example, that the ‘reversed’ version of the rule Implied\n⊢AR φ →φ′\n\u0001\nφ\n\u0002\nC\n\u0001\nψ\n\u0002\n⊢AR ψ′ →ψ\n\u0001\nφ′\u0002\nC\n\u0001\nψ′\u0002\nImplied Reversed\nis unsound for partial correctness.\n(b) Explain why the modiﬁed rule If-Statement in (4.7) is sound with respect\nto the partial and total satisfaction relation.\n4.6 Exercises\n301\n(c)\n*\nShow that any instance of the modiﬁed rule If-Statement in a proof can\nbe replaced by an instance of the original If-statement and instances of the\nrule Implied. Is the converse true as well?\n10.\n*\nProve the validity of the sequent ⊢par\n\u0001\nin the partial-correctness calculus we develop in this chapter, we say that the\nsequent ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\n2.\nSimilarly, if it can be proved in the total-correctness calculus to be developed\nin this chapter, we say that the sequent ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid.\nThus, ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds if P is partially correct, while the validity of\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nmeans that P can be proved to be partially-correct by our\ncalculus. The ﬁrst one means it is actually correct, while the second one\nmeans it is provably correct according to our calculus.\nIf our calculus is any good, then the relation ⊢par should be contained in\n⊨par! More precisely, we will say that our calculus is sound if, whenever it\ntells us something can be proved, that thing is indeed true. Thus, it is sound\nif it doesn’t tell us that false things can be proved. Formally, we write that\n⊢par is sound if\n⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P; and, similarly, ⊢tot is sound if\n⊨tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds whenever ⊢tot\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid\nfor all φ, ψ and P. We say that a calculus is complete if it is able to prove\neverything that is true. Formally, ⊢par is complete if\n⊢par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nis valid whenever ⊨par\n\u0001\nφ\n\u0002\nP\n\u0001\nψ\n\u0002\nholds\nfor all φ, ψ and P; and similarly for ⊢tot being complete.\nIn Chapters 1 and 2, we said that soundness is relatively easy to show,\nsince typically the soundness of individual proof rules can be established\nindependently of the others. Completeness, on the other hand, is harder to\n268\n4 Program verification\nshow since it depends on the entire set of proof rules cooperating together.\nThe same situation holds for the program logic we introduce in this chapter.\nEstablishing its soundness is simply a matter of considering each rule in\nturn – done in exercise 3 on page 303 – whereas establishing its (relative)\ncompleteness is harder and beyond the scope of this book.\n4.2.4 Program variables and logical variables\nc\n\u0001\ny = z! ∧z ̸= x\u0002\nz = z+1; y = y*z\u0001\ny = z!\u0002\nw\n\u0001\ny = z!\u0002\nwhile (z\n!=\nx) {z = z+1; y = y*z}\u0001\ny = z! ∧z = x\u0002\ni\n\u0001\ny = 1 ∧z = 0\u0002\nwhile (z\n!=\nx) {z = z+1; y = y*z}\u0001\ny = x!\u0002\nc\n\u0001\n⊤\u0002\ny = 1; z = 0; while (z\n!=\nx) {z = z+1; y = y*z}\u0001\ny = x!\u0002\nFigure 4.2. A partial-correctness proof for Fac1 in tree form.\n4.3 Proof calculus for partial correctness\n275\nIt should be clear that proofs in this form are unwieldy to work with.\nThey will tend to be very wide and a lot of information is copied from one\nline to the next. Proving properties of programs which are longer than Fac1\nwould be very diﬃcult in this style. In Chapters 1, 2 and 5 we abandon\nrepresentation of proofs as trees for similar reasons. The rule for sequential\ncomposition suggests a more convenient way of presenting proofs in pro-\ngram logic, called proof tableaux. We can think of any program of our core\nprogramming language as a sequence\nC1;\nC2;\n·\n·\n·\nCn\nwhere none of the commands Ci is a composition of smaller programs, i.e. all\nof the Ci above are either assignments, if-statements or while-statements. Of\ncourse, we allow the if-statements and while-statements to have embedded\ncompositions.\nLet P stand for the program C1; C2; . . . ; Cn−1; Cn. Suppose that we want\nto show the validity of ⊢par\n\u0001\nφ0\n\u0002\nP\n\u0001\nφn\n\u0002\nfor a precondition φ0 and a postcon-\ndition φn. Then, we may split this problem into smaller ones by trying to\nﬁnd formulas φj (0 < j < n) and prove the validity of ⊢par\n\u0001\nφi\n\u0002\nCi+1\n\u0001\nφi+1\n\u0002\nfor i = 0, 1, . . . , n −1. This suggests that we should design a proof calcu-\nlus which presents a proof of ⊢par\n\u0001\nφ0\n\u0002\nP\n\u0001\nψn\n\u0002\nby interleaving formulas with\ncode as in\n\u0001\nφ0\n\u0002\nC1;\u0001\nφ1\n\u0002\njustification\nC2;\n·\n·\n· \u0001\nφn−1\n\u0002\njustification\nCn;\u0001\nφn\n\u0002\njustification\n276\n4 Program verification\nAgainst each formula, we write a justiﬁcation, whose nature will be clariﬁed\nshortly. Proof tableaux thus consist of the program code interleaved with\nformulas, which we call midconditions, that should hold at the point they\nare written.\nan array.\n(a) Adapt the program from page 289 so that it computes the maximal sum of\nthese sections.\n(b) Prove the partial correctess of your modiﬁed program.\n(c) Which aspects of the correctness proof given in Figure 4.3 (page 291) can\nbe ‘re-used?’\nExercises 4.4\n1. Prove the validity of the following total-correctness sequents:\n(a)\n*\n⊢tot\n\u0001\nx ≥0\n\u0002\nCopy1\n\u0001\nx = y\n\u0002\n(b)\n*\n⊢tot\n\u0001\ny ≥0\n\u0002\nMulti1\n\u0001\nz = x · y\n\u0002\n(c) ⊢tot\n\u0001\n(y = y0) ∧(y ≥0)\n\u0002\nMulti2\n\u0001\nz = x · y0\n\u0002\n(d)\n*\n⊢tot\n\u0001\nx ≥0\n\u0002\nDownfac\n\u0001\ny = x!\n\u0002\n(e)\n*\n⊢tot\n\u0001\nx ≥0\n\u0002\nCopy2\n\u0001\nx = y\n\u0002\n, does your invariant have an active part in secur-\ning correctness?\n(f) ⊢tot\n\u0001\n¬(y = 0)\n\u0002\nDiv\n\u0001\n(x = d · y + r) ∧(r < y)\n\u0002\n.\n2. Prove total correctness of S1 and S2 for Min Sum.\n3. Prove that ⊢par is sound for ⊨par. Just like in Section 1.4.3, it suﬃces to assume\nthat the premises of proof rules are instances of ⊨par. Then, you need to prove\nthat their respective conclusion must be an instance of ⊨par as well.\n4. Prove that ⊢tot is sound for ⊨tot.\n5. Implement program Collatz in a programming language of your choice such\nthat the value of x is the program’s input and the ﬁnal value of c its output.\nTest your program on a range of inputs. Which is the biggest integer for which\nyour program terminates without raising an exception or dumping the core?\n6. A function over integers f : I →I is aﬃne iﬀthere are integers a and b such that\nf(x) = a · x + b for all x ∈I. The else-branch of the program Collatz assigns to\nc the value f(c), where f is an aﬃne function with a = 3 and b = 1.\n(a) Write an parameterized implementation of Collatz in which you can initially\nspecify the values of a and b either statically or through keyboard input such\nthat the else-branch assigns to c the value of f(c).\n(b) Determine for which pairs (a, b) ∈I × I the set Pos\ndef\n= {x ∈I | 0 < x} is in-\nvariant under the aﬃne function f(x) = a · x + b: for all x ∈Pos, f(x) ∈Pos.\n(c)\n*\nFind an aﬃne function that leaves Pos invariant, but not the set Odd\ndef\n= {x ∈\nbind more tightly than →. Implication →is right-associative: expressions of\nthe form p →q →r denote p →(q →r).\n1.2 Natural deduction\nHow do we go about constructing a calculus for reasoning about proposi-\ntions, so that we can establish the validity of Examples 1.1 and 1.2? Clearly,\nwe would like to have a set of rules each of which allows us to draw a con-\nclusion given a certain arrangement of premises.\nIn natural deduction, we have such a collection of proof rules. They al-\nlow us to infer formulas from other formulas. By applying these rules in\nsuccession, we may infer a conclusion from a set of premises.\nLet’s see how this works. Suppose we have a set of formulas4 φ1, φ2,\nφ3, . . . , φn, which we will call premises, and another formula, ψ, which we\nwill call a conclusion. By applying proof rules to the premises, we hope\nto get some more formulas, and by applying more proof rules to those, to\neventually obtain the conclusion. This intention we denote by\nφ1, φ2, . . . , φn ⊢ψ.\nThis expression is called a sequent; it is valid if a proof for it can be found.\nThe sequent for Examples 1.1 and 1.2 is p ∧¬q →r, ¬r, p ⊢q. Construct-\ning such a proof is a creative exercise, a bit like programming. It is not\nnecessarily obvious which rules to apply, and in what order, to obtain the\ndesired conclusion. Additionally, our proof rules should be carefully chosen;\notherwise, we might be able to ‘prove’ invalid patterns of argumentation. For\n4 It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas\nand upper-case letters are used for sets of formulas. Here are some of the more commonly used\nGreek letters, together with their pronunciation:\nLower-case\nφ\nphi\nψ\npsi\nχ\nchi\nη\neta\nα\nalpha\nβ\nbeta\nγ\ngamma\nUpper-case\nΦ\nPhi\nΨ\nPsi\nΓ\nGamma\n∆\nDelta\n6\n1 Propositional logic\nexample, we expect that we won’t be able to show the sequent p, q ⊢p ∧¬q.\nFor example, if p stands for ‘Gold is a metal.’ and q for ‘Silver is a metal,’",
          "summary": "In the previous section, we pointed out that only the syntactic construct while B {C} could be responsible for non-termination. We extend our proof calculus for partial correctness so that it also proves that programs terminate. We identify an integer expression whose value can be shown to decrease every time we execute the body of the while-statement in question. The value of this expression is always non-negative. Such integer expressions are called variants. When it is 0, the while-statement terminates. We can codify this intuition in the following rule for total correctness. It replaces the rule for the while statement. Use the proof rule for assignment and logical implication as appropriate to showthe validity of the program. Give useful examples of such pro-                gram fragments in application programming. Prove the validity of the sequent in the partial-correctness calculus we develop in this chapter. Prove that any instance of the modiﬁed rule If-Statement in a proof can be replaced by one of the original If-statement. If our calculus is any good, then the relation ⊢par should be contained in par. We say that a calculus is complete if it is able to prove everything that is true. In Chapters 1 and 2, we said that soundness is relatively easy to show, since typically the soundness of individual proof rules can be established independently of the others. Formally, ⊢par is complete if it is valid whenever all of its parts are complete. Establishing its soundness is simply a matter of considering each rule in turn. Completeness, on the other hand, is harder to prove since it depends on the entire set of proof rules cooperating together. Proving properties of programs which are longer than Fac1 would be very diﬃcult in this style. The rule for sequentialcomposition suggests a more convenient way of presenting proofs in pro-                gram logic. A proof calcu-lus which presents a proof of the correctness of a program. The proof tableaux consist of the program code interleaved with midconditions. Prove the validity of the following total-correctness sequents. Prove total correctness of S1 and S2 for Min Sum. Implement program Collatz in a language of your choice. A function over integers f : I →I is a function with a = 3 and b = 1. The else-branch of the program Collatz assigns to c the value f(c), where f is an aﬃne function. In natural deduction, we have such a collection of proof rules. They al-                low us to infer formulas from other formulas. By applying these rules in succession, we may infer a conclusion from a set of premises. This expression is called a sequent; it is valid if a proof for it can be found. It is traditional in logic to use Greek letters. Lower-case letters are used to stand for formulas. Upper-case Letters are used for sets of formulas.",
          "children": []
        },
        {
          "id": "chapter_4_5",
          "title": "Programming by Contract",
          "content": "",
          "summary": null,
          "children": []
        }
      ]
    },
    {
      "id": "chapter_5",
      "title": "Modal Logics and Agents",
      "content": null,
      "summary": "In computer science, it is often useful to reason about modes of truth. The sentence George W. Bush is president of the United States of America is not necessarily true. The cube root of 27 is 3 is also necessarily true and true in the future. Modal logic is a special case of temporal logic. It allows us to express a host of computational behaviour of systems. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed. Each agent may have diﬀerent knowledge about the environment. The basic rules of natural deduction are: to prove ¬φ, prove ⊥from φ (and the other prevailing premises). More sophisticated modal logics other prevailing premise). Propositional logic is the same. Phenomenon 1.1.2 Natural deduction. Phenomenon 2.2.3 Natural deduction and deduction from a hypothesis to a hypothesis. New rules for quantiﬁers and equality will come in two ﬂavours: introduction andelimination rules. We are overloading the previously established proof rules for the propositional connectives. The rule t = t=i(2.5) is an axiom, as it does not depend on any premises. The rule is quite evidently sound, but it is not very useful on its own. We need a principle that allows us to substitute equals for equalsrepeatedly. In the exercises, we apply this to show that a se-                quent does not have a proof. Completeness comprised a much more powerful state-                ment. No matter what (semantically) valid sequents there are, they all have proofs in the proof system of natural deduction. Two formulas φ and ψ are said to be equivalent if they have the same ‘meaning’ This suggestion is vague and needs to be reﬁned. ’Coincidence of truth tables’ is not good enough for what we have in mind. Show that the following sequents are not valid. Find a formula of propositional logic which is true only when p and q are false. Use mathematical induction on n to prove the theorem. Prove the validity of the following sequents needed to secure the completeness of propositional logic. Exercises 1.5: Show that a formula φ is valid iﬀ. The proof rules for natural deduction are summarised in Figure 1.2. The Explanation of the rules we have given so far in this chapter is declarative;we have presented each rule and justiﬁed it in terms of our intuition about logical connectives. When you try to use the rules yourself, you will find yourself looking for a more procedural interpretation. Proving φ will probably be harder than proving φ alone. This rule is useful only if you’ve already managed to prove φ. The basic rules of natural deduction are: introduction, elimination, and derivation. The proof rule modus tollens (MT) can be derived from some of the other rules. The argument of Examples 1.1 and 1.2 can be coded up by the sequent p ∧¬q →r, ¬r, p |−q. There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy. The two derived rules we now introduce are extremely useful. The rule says: if from ¬φ we obtain a contradiction, then we are entitled to deduce φ. In the case of the second one, its derivation from the primitive proof rules is not very obvious.",
      "children": [
        {
          "id": "chapter_5_1",
          "title": "Modes of Truth",
          "content": "possibilities. From many points of view, however, this is inadequate. In nat-\nural language, for example, we often distinguish between various ‘modes’ of\ntruth, such as necessarily true, known to be true, believed to be true and true\nin the future. For example, we would say that, although the sentence\nGeorge W. Bush is president of the United States of America.\nis currently true, it will not be true at some point in the future. Equally, the\nsentence\nThere are nine planets in the solar system.\nwhile true, and maybe true for ever in the future, is not necessarily true, in\nthe sense that it could have been a diﬀerent number. However, the sentence\nThe cube root of 27 is 3.\nas well as being true is also necessarily true and true in the future. It does\nnot enjoy all modes of truth, however. It may not be known to be true by\nsome people (children, for example); it may not be believed by others (if\nthey are mistaken).\nIn computer science, it is often useful to reason about modes of truth. In\nChapter 3, we studied the logic CTL in which we could distinguish not only\nbetween truth at diﬀerent points in the future, but also between diﬀerent\nfutures. Temporal logic is thus a special case of modal logic. The modalities\nof CTL allow us to express a host of computational behaviour of systems.\nModalities are also extremely useful in modelling other domains of com-\nputer science. In artiﬁcial intelligence, for example, scenarios with several\n306\n5.2 Basic modal logic\n307\ninteracting agents are developed. Each agent may have diﬀerent knowledge\nabout the environment and also about the knowledge of other agents. In this\nchapter, we will look in depth at modal logics applied to reasoning about\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics",
          "summary": "In computer science, it is often useful to reason about modes of truth. The sentence George W. Bush is president of the United States of America is not necessarily true. The cube root of 27 is 3 is also necessarily true and true in the future. Modalities of CTL allow us to express a host of computational behaviour of systems. They are also extremely useful in modelling other domains of com-puter science. In artiﬁcial intelligence, for example, scenarios with several interacting agents are developed.",
          "children": []
        },
        {
          "id": "chapter_5_2",
          "title": "Basic Modal Logic",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_5_3",
          "title": "Logic Engineering",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_5_4",
          "title": "Natural Deduction",
          "content": "other prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\nφ ∨ψ\n∨i1\nψ\nφ ∨ψ\n∨i2\nφ ∨ψ\nφ\n...\nχ\nψ\n...\nχ\nχ\n∨e\n→\nφ\n...\nψ\nφ →ψ\n→i\nφ\nφ →ψ\nψ\n→e\n¬\nφ\n...\n⊥\n¬φ\n¬i\nφ\n¬φ\n⊥\n¬e\n⊥\n(no introduction rule for ⊥)\n⊥\nφ\n⊥e\n¬¬\n¬¬φ\nφ\n¬¬e\nSome useful derived rules:\nφ →ψ\n¬ψ\n¬φ\nMT\nφ\n¬¬φ\n¬¬i\n¬φ\n...\n⊥\nφ\nPBC\nφ ∨¬φ\nLEM\nFigure 1.2. Natural deduction rules for propositional logic.\n28\n1 Propositional logic\nAt any stage of a proof, it is permitted to introduce any formula as as-\nsumption, by choosing a proof rule that opens a box. As we saw, natural\ndeduction employs boxes to control the scope of assumptions. When an as-\nsumption is introduced, a box is opened. Discharging assumptions is achieved\nby closing a box according to the pattern of its particular proof rule. It’s\nuseful to make assumptions by opening boxes. But don’t forget you have to\nclose them in the manner prescribed by their proof rule.\nOK, but how do we actually go about constructing a proof?\nGiven a sequent, you write its premises at the top of your page and\nits conclusion at the bottom. Now, you’re trying to ﬁll in the gap,\nwhich involves working simultaneously on the premises (to bring them to-\nwards the conclusion) and on the conclusion (to massage it towards the\npremises).\nLook ﬁrst at the conclusion. If it is of the form φ →ψ, then apply6 the\nrule →i. This means drawing a box with φ at the top and ψ at the bottom.\nSo your proof, which started out like this:\n...\npremises\n...\nφ →ψ\nnow looks like this:\n...\npremises\n...\nφ\nassumption\nψ\nφ →ψ\n→i\nYou still have to ﬁnd a way of ﬁlling in the gap between the φ and the ψ.\nBut you now have an extra formula to work with and you have simpliﬁed\nthe conclusion you are trying to reach.\n6 Except in situations such as p →(q →¬r), p ⊢q →¬r where →e produces a simpler proof.\n1.2 Natural deduction\n29\nx\ny\nS\nQ\n∧\nFigure 2.4. A parse tree for which a substitution has dire consequences.\n2.3 Proof theory of predicate logic\n2.3.1 Natural deduction rules\nProofs in the natural deduction calculus for predicate logic are similar to\nthose for propositional logic in Chapter 1, except that we have new proof\nrules for dealing with the quantiﬁers and with the equality symbol. Strictly\nspeaking, we are overloading the previously established proof rules for the\npropositional connectives ∧, ∨etc. That simply means that any proof rule\nof Chapter 1 is still valid for logical formulas of predicate logic (we origi-\nnally deﬁned those rules for logical formulas of propositional logic). As in\nthe natural deduction calculus for propositional logic, the additional rules\nfor the quantiﬁers and equality will come in two ﬂavours: introduction and\nelimination rules.\nThe proof rules for equality\nFirst, let us state the proof rules for\nequality. Here equality does not mean syntactic, or intensional, equality,\nbut equality in terms of computation results. In either of these senses, any\nterm t has to be equal to itself. This is expressed by the introduction rule\nfor equality:\nt = t\n=i\n(2.5)\nwhich is an axiom (as it does not depend on any premises). Notice that it\n108\n2 Predicate logic\nmay be invoked only if t is a term, our language doesn’t permit us to talk\nabout equality between formulas.\nThis rule is quite evidently sound, but it is not very useful on its own.\nWhat we need is a principle that allows us to substitute equals for equals\nrepeatedly. For example, suppose that y ∗(w + 2) equals y ∗w + y ∗2; then\nit certainly must be the case that z ≥y ∗(w + 2) implies z ≥y ∗w + y ∗2\nand vice versa. We may now express this substitution principle as the rule\n=e:\nt1 = t2\nφ[t1/x]\nφ[t2/x]\n=e.\nNote that t1 and t2 have to be free for x in φ, whenever we want to apply\nthe rule =e; this is an example of a side condition of a proof rule.\nConvention 2.10 Throughout this section, when we write a substitution\nthe truth-table semantics. In the exercises, we apply this to show that a se-\nquent does not have a proof: simply show that φ1, φ2, . . . , φ2 does not seman-\ntically entail ψ; then soundness implies that the sequent φ1, φ2, . . . , φ2 ⊢ψ\ndoes not have a proof. Completeness comprised a much more powerful state-\nment: no matter what (semantically) valid sequents there are, they all have\nsyntactic proofs in the proof system of natural deduction. This tight cor-\nrespondence allows us to freely switch between working with the notion of\nproofs (⊢) and that of semantic entailment (⊨).\nUsing natural deduction to decide the validity of instances of ⊢is only\none of many possibilities. In Exercise 1.2.6 we sketch a non-linear, tree-like,\nnotion of proofs for sequents. Likewise, checking an instance of ⊨by apply-\ning Deﬁnition 1.34 literally is only one of many ways of deciding whether\nφ1, φ2, . . . , φn ⊨ψ holds. We now investigate various alternatives for deciding\nφ1, φ2, . . . , φn ⊨ψ which are based on transforming these formulas syntac-\ntically into ‘equivalent’ ones upon which we can then settle the matter by\npurely syntactic or algorithmic means. This requires that we ﬁrst clarify\nwhat exactly we mean by equivalent formulas.\n1.5.1 Semantic equivalence, satisfiability and validity\nTwo formulas φ and ψ are said to be equivalent if they have the same\n‘meaning.’ This suggestion is vague and needs to be reﬁned. For example,\np →q and ¬p ∨q have the same truth table; all four combinations of T and F\nfor p and q return the same result. ’Coincidence of truth tables’ is not good\nenough for what we have in mind, for what about the formulas p ∧q →p\nand r ∨¬r? At ﬁrst glance, they have little in common, having diﬀerent\natomic formulas and diﬀerent connectives. Moreover, the truth table for\np ∧q →p is four lines long, whereas the one for r ∨¬r consists of only two\nlines. However, both formulas are always true. This suggests that we deﬁne\nthe summary of natural deduction rules in Figure 1.2 on page 27 to see which\ncases are still missing. Do you need to include derived rules?\n12. Show that the following sequents are not valid by ﬁnding a valuation in which\nthe truth values of the formulas to the left of ⊢are T and the truth value of\nthe formula to the right of ⊢is F.\n(a) ¬p ∨(q →p) ⊢¬p ∧q\n(b) ¬r →(p ∨q), r ∧¬q ⊢r →q\n(c)\n*\np →(q →r) ⊢p →(r →q)\n(d) ¬p, p ∨q ⊢¬q\n(e) p →(¬q ∨r), ¬r ⊢¬q →¬p.\n13. For each of the following invalid sequents, give examples of natural language\ndeclarative sentences for the atoms p, q and r such that the premises are true,\nbut the conclusion false.\n(a)\n*\np ∨q ⊢p ∧q\n(b)\n*\n¬p →¬q ⊢¬q →¬p\n(c) p →q ⊢p ∨q\n(d) p →(q ∨r) ⊢(p →q) ∧(p →r).\n14. Find a formula of propositional logic φ which contains only the atoms p, q\nand r and which is true only when p and q are false, or when ¬q ∧(p ∨r) is\ntrue.\n1.7 Exercises\n87\n15. Use mathematical induction on n to prove the theorem ((φ1 ∧(φ2 ∧(· · · ∧\nφn) . . . ) →ψ) →(φ1 →(φ2 →(. . . (φn →ψ) . . . )))).\n16. Prove the validity of the following sequents needed to secure the completeness\nresult for propositional logic:\n(a) φ1 ∧¬φ2 ⊢¬(φ1 →φ2)\n(b) ¬φ1 ∧¬φ2 ⊢φ1 →φ2\n(c) ¬φ1 ∧φ2 ⊢φ1 →φ2\n(d) φ1 ∧φ2 ⊢φ1 →φ2\n(e) ¬φ1 ∧φ2 ⊢¬(φ1 ∧φ2)\n(f) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(g) φ1 ∧¬φ2 ⊢¬(φ1 ∧φ2)\n(h) ¬φ1 ∧¬φ2 ⊢¬(φ1 ∨φ2)\n(i) φ1 ∧φ2 ⊢φ1 ∨φ2\n(j) ¬φ1 ∧φ2 ⊢φ1 ∨φ2\n(k) φ1 ∧¬φ2 ⊢φ1 ∨φ2.\n17. Does ⊨φ hold for the φ below? Please justify your answer.\n(a) (p →q) ∨(q →r)\n(b)\n*\n((q →(p ∨(q →p))) ∨¬(p →q)) →p.\nExercises 1.5\n1. Show that a formula φ is valid iﬀ⊤≡φ, where ⊤is an abbreviation for an\ninstance p ∨¬p of LEM.\n2. Which of these formulas are semantically equivalent to p →(q ∨r)?\n(a) q ∨(¬p ∨r)\n(b)\n*\nq ∧¬r →p\n(c) p ∧¬r →q\n(d)\n*\n¬q ∧¬r →¬p.\n3. An adequate set of connectives for propositional logic is a set such that for every\nformula of propositional logic there is an equivalent formula with only connectives\nfrom that set. For example, the set {¬, ∨} is adequate for propositional logic,\n1\np →q\npremise\n2\n¬p ∨p\nLEM\n3\n¬p\nassumption\n4\n¬p ∨q\n∨i1 3\n5\np\nassumption\n6\nq\n→e 1, 5\n7\n¬p ∨q\n∨i2 6\n8\n¬p ∨q\n∨e 2, 3−4, 5−7\nIt can be diﬃcult to decide which instance of LEM would beneﬁt the progress\nof a proof. Can you re-do the example above with q ∨¬q as LEM?\n1.2.3 Natural deduction in summary\nThe proof rules for natural deduction are summarised in Figure 1.2. The\nexplanation of the rules we have given so far in this chapter is declarative;\nwe have presented each rule and justiﬁed it in terms of our intuition about\nthe logical connectives. However, when you try to use the rules yourself,\nyou’ll ﬁnd yourself looking for a more procedural interpretation; what does\na rule do and how do you use it? For example,\nr ∧i says: to prove φ ∧ψ, you must ﬁrst prove φ and ψ separately and then use\nthe rule ∧i.\nr ∧e1 says: to prove φ, try proving φ ∧ψ and then use the rule ∧e1. Actually,\nthis doesn’t sound like very good advice because probably proving φ ∧ψ will\nbe harder than proving φ alone. However, you might ﬁnd that you already have\nφ ∧ψ lying around, so that’s when this rule is useful. Compare this with the\nexample sequent in Example 1.15.\nr ∨i1 says: to prove φ ∨ψ, try proving φ. Again, in general it is harder to prove\nφ than it is to prove φ ∨ψ, so this will usually be useful only if you’ve already\nmanaged to prove φ. For example, if you want to prove q |−p ∨q, you certainly\nwon’t be able simply to use the rule ∨i1, but ∨i2 will work.\nr ∨e has an excellent procedural interpretation. It says: if you have φ ∨ψ, and you\nwant to prove some χ, then try to prove χ from φ and from ψ in turn. (In those\nsubproofs, of course you can use the other prevailing premises as well.)\nr Similarly, →i says, if you want to prove φ →ψ, try proving ψ from φ (and the\nother prevailing premises).\nr ¬i says: to prove ¬φ, prove ⊥from φ (and the other prevailing premises).\n1.2 Natural deduction\n27\nThe basic rules of natural deduction:\nintroduction\nelimination\n∧\nφ\nψ\nφ ∧ψ\n∧i\nφ ∧ψ\nφ\n∧e1\nφ ∧ψ\nψ\n∧e2\n∨\nφ\n1\np →(q →r)\npremise\n2\np\npremise\n3\n¬r\npremise\n4\nq\nassumption\n5\nq →r\n→e 1, 2\n6\nr\n→e 5, 4\n7\n⊥\n¬e 6, 3\n8\n¬q\n¬i 4−7\nExample 1.23 Finally, we return to the argument of Examples 1.1 and 1.2,\nwhich can be coded up by the sequent p ∧¬q →r, ¬r, p |−q whose validity\nwe now prove:\n1\np ∧¬q →r\npremise\n2\n¬r\npremise\n3\np\npremise\n4\n¬q\nassumption\n5\np ∧¬q\n∧i 3, 4\n6\nr\n→e 1, 5\n7\n⊥\n¬e 6, 2\n8\n¬¬q\n¬i 4−7\n9\nq\n¬¬e 8\n1.2.2 Derived rules\nWhen describing the proof rule modus tollens (MT), we mentioned that it\nis not a primitive rule of natural deduction, but can be derived from some\nof the other rules. Here is the derivation of\nφ →ψ\n¬ψ\n¬φ\nMT\n24\n1 Propositional logic\nfrom →e, ¬e and ¬i:\n1\nφ →ψ\npremise\n2\n¬ψ\npremise\n3\nφ\nassumption\n4\nψ\n→e 1, 3\n5\n⊥\n¬e 4, 2\n6\n¬φ\n¬i 3−5\nWe could now go back through the proofs in this chapter and replace applica-\ntions of MT by this combination of →e, ¬e and ¬i. However, it is convenient\nto think of MT as a shorthand (or a macro).\nThe same holds for the rule\nφ\n¬¬φ\n¬¬i.\nIt can be derived from the rules ¬i and ¬e, as follows:\n1\nφ\npremise\n2\n¬φ\nassumption\n3\n⊥\n¬e 1, 2\n4\n¬¬φ\n¬i 2−3\nThere are (unboundedly) many such derived rules which we could write\ndown. However, there is no point in making our calculus fat and unwieldy;\nand some purists would say that we should stick to a minimum set of rules,\nall of which are independent of each other. We don’t take such a purist view.\nIndeed, the two derived rules we now introduce are extremely useful. You will\nﬁnd that they crop up frequently when doing exercises in natural deduction,\nso it is worth giving them names as derived rules. In the case of the second\none, its derivation from the primitive proof rules is not very obvious.\nThe ﬁrst one has the Latin name reductio ad absurdum. It means ‘reduc-\ntion to absurdity’ and we will simply call it proof by contradiction (PBC\nfor short). The rule says: if from ¬φ we obtain a contradiction, then we are\nentitled to deduce φ:\n¬φ\n...\n⊥\nφ\nPBC.\n1.2 Natural deduction\n25",
          "summary": "At any stage of a proof, it is permitted to introduce any formula as as- as-sumption, by choosing a proof rule that opens a box. Discharging assumptions is achievedby closing a box according to the pattern of its particular proof rule. Phenomenon 1.1.2 Natural deduction. Phenomenon 2.2.3 Natural deduction and deduction from a hypothesis to a hypothesis. New rules for quantiﬁers and equality will come in two ﬂavours: introduction andelimination rules. We are overloading the previously established proof rules for the propositional connectives. The rule t = t=i(2.5) is an axiom, as it does not depend on any premises. The rule is quite evidently sound, but it is not very useful on its own. We need a principle that allows us to substitute equals for equalsrepeatedly. In the exercises, we apply this to show that a se-                quent does not have a proof. Completeness comprised a much more powerful state-                ment. No matter what (semantically) valid sequents there are, they all have proofs in the proof system of natural deduction. Two formulas φ and ψ are said to be equivalent if they have the same ‘meaning’ This suggestion is vague and needs to be reﬁned. ’Coincidence of truth tables’ is not good enough for what we have in mind. Show that the following sequents are not valid. Find a formula of propositional logic which is true only when p and q are false. Use mathematical induction on n to prove the theorem. Prove the validity of the following sequents needed to secure the completeness of propositional logic. Exercises 1.5: Show that a formula φ is valid iﬀ. The proof rules for natural deduction are summarised in Figure 1.2. The Explanation of the rules we have given so far in this chapter is declarative;we have presented each rule and justiﬁed it in terms of our intuition about logical connectives. When you try to use the rules yourself, you will find yourself looking for a more procedural interpretation. Proving φ will probably be harder than proving φ alone. This rule is useful only if you’ve already managed to prove φ. The basic rules of natural deduction are: introduction, elimination, and derivation. The proof rule modus tollens (MT) can be derived from some of the other rules. The argument of Examples 1.1 and 1.2 can be coded up by the sequent p ∧¬q →r, ¬r, p |−q. There are (unboundedly) many such derived rules which we could write down. However, there is no point in making our calculus fat and unwieldy. The two derived rules we now introduce are extremely useful. The rule says: if from ¬φ we obtain a contradiction, then we are entitled to deduce φ. In the case of the second one, its derivation from the primitive proof rules is not very obvious.",
          "children": []
        },
        {
          "id": "chapter_5_5",
          "title": "Reasoning About Knowledge in a Multi-Agent System",
          "content": null,
          "summary": null,
          "children": []
        }
      ]
    },
    {
      "id": "chapter_6",
      "title": "Binary Decision Diagrams",
      "content": null,
      "summary": null,
      "children": [
        {
          "id": "chapter_6_1",
          "title": "Representing Boolean Functions",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_6_2",
          "title": "Algorithms for Reduced OBDDs",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_6_3",
          "title": "Symbolic Model Checking",
          "content": null,
          "summary": null,
          "children": []
        },
        {
          "id": "chapter_6_4",
          "title": "A Relational Mu-Calculus",
          "content": null,
          "summary": null,
          "children": []
        }
      ]
    }
  ]
}