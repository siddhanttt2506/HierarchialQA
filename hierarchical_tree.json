{
    "id": "root",
    "title": "Textbook",
    "content": null,
    "children": [
        {
            "id": "chapter-1",
            "title": "Propositional Logic",
            "content": null,
            "children": [
                {
                    "id": "chapter-1-section-1",
                    "title": "Declarative Sentences",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-2",
                    "title": "Natural Deduction",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-2-subsection-1",
                            "title": "Rules for Natural Deduction",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-2",
                            "title": "Derived Rules",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-3",
                            "title": "Natural Deduction in Summary",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-4",
                            "title": "Provable Equivalence",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-5",
                            "title": "Proof by Contradiction",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-3",
                    "title": "Semantics of Propositional Logic",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-3-subsection-1",
                            "title": "Meaning of Logical Connectives",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-2",
                            "title": "Mathematical Induction",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-3",
                            "title": "Soundness of Propositional Logic",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-4",
                            "title": "Completeness of Propositional Logic",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-4",
                    "title": "Normal Forms",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-4-subsection-1",
                            "title": "Semantic Equivalence, Satisfiability and Validity",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-2",
                            "title": "Conjunctive Normal Forms and Validity",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-3",
                            "title": "Horn Clauses and Satisfiability",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-5",
                    "title": "SAT Solvers",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-5-subsection-1",
                            "title": "A Linear Solver",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-5-subsection-2",
                            "title": "A Cubic Solver",
                            "content": "",
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-1",
            "title": "Predicate Logic",
            "content": null,
            "children": [
                {
                    "id": "chapter-1-section-1",
                    "title": "The Need for a Richer Language",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-2",
                    "title": "Predicate Logic as a Formal Language",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-2-subsection-1",
                            "title": "Terms",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nexamples, as are variables such as x and v. Function symbols also allow us\nto refer to objects: thus, m(a) and g(x, y) are also objects. Expressions in\npredicate logic which denote objects are called terms.\nThe other sort of things in predicate logic denotes truth values; expres-\nsions of this kind are formulas: Y (x, m(x)) is a formula, though x and m(x)\nare terms.\nA predicate vocabulary consists of three sets: a set of predicate symbols\nP, a set of function symbols F and a set of constant symbols C. Each pred-\nicate symbol and each function symbol comes with an arity, the number of\narguments it expects. In fact, constants can be thought of as functions which\ndon’t take any arguments (and we even drop the argument brackets) – there-\nfore, constants live in the set F together with the ‘true’ functions which do\ntake arguments. From now on, we will drop the set C, since it is convenient to\ndo so, and stipulate that constants are 0-arity, so-called nullary, functions.\n2.2.1 Terms\nThe terms of our language are made up of variables, constant symbols\nand functions applied to those. Functions may be nested, as in m(m(x))\nor g(m(a), c): the grade obtained by Andy’s mother in the course c.\nDeﬁnition 2.1 Terms are deﬁned as follows.\nr Any variable is a term.\nr If c ∈F is a nullary function, then c is a term.\nr If t1, t2, . . . , tn are terms and f ∈F has arity n > 0, then f(t1, t2, . . . , tn) is a\nterm.\nr Nothing else is a term.\nIn Backus Naur form we may write\nt ::= x | c | f(t, . . . , t)\nwhere x ranges over a set of variables var, c over nullary function symbols\nin F, and f over those elements of F with arity n > 0.\nIt is important to note that\nr the ﬁrst building blocks of terms are constants (nullary functions) and variables;\nr more complex terms are built from function symbols using as many previously\nbuilt terms as required by such function symbols; and\nr the notion of terms is dependent on the set F. If you change it, you change the\nset of terms.\n100",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-2",
                            "title": "Formulas",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nlong as they match the pattern required by the respective rule. For example,\n32\n1 Propositional logic\nthe application of the proof rule →e in\n1\np →q\npremise\n2\np\npremise\n3\nq\n→e 1, 2\nis equally valid if we substitute p with p ∨¬r and q with r →p:\n1\np ∨¬r →(r →p)\npremise\n2\np ∨¬r\npremise\n3\nr →p\n→e 1, 2\nThis is why we expressed such rules as schemes with Greek symbols stand-\ning for generic formulas. Yet, it is time that we make precise the notion of\n‘any formula we may form.’ Because this text concerns various logics, we will\nintroduce in (1.3) an easy formalism for specifying well-formed formulas. In\ngeneral, we need an unbounded supply of propositional atoms p, q, r, . . ., or\np1, p2, p3, . . . You should not be too worried about the need for inﬁnitely\nmany such symbols. Although we may only need ﬁnitely many of these\npropositions to describe a property of a computer program successfully, we\ncannot specify how many such atomic propositions we will need in any con-\ncrete situation, so having inﬁnitely many symbols at our disposal is a cheap\nway out. This can be compared with the potentially inﬁnite nature of En-\nglish: the number of grammatically correct English sentences is inﬁnite, but\nﬁnitely many such sentences will do in whatever situation you might be in\n(writing a book, attending a lecture, listening to the radio, having a dinner\ndate, . . . ).\nFormulas in our propositional logic should certainly be strings over the\nalphabet {p, q, r, . . . } ∪{p1, p2, p3, . . . } ∪{¬, ∧, ∨, →, (, )}. This is a trivial\nobservation and as such is not good enough for what we are trying to capture.\nFor example, the string (¬)() ∨pq →is a word over that alphabet, yet, it\ndoes not seem to make a lot of sense as far as propositional logic is concerned.\nSo what we have to deﬁne are those strings which we want to call formulas.\nWe call such formulas well-formed.\nDeﬁnition 1.27 The well-formed formulas of propositional logic are those\nThe application of IMPL FREE might introduce double negations into the\noutput formula. More importantly, negations whose scopes are non-atomic\nformulas might still be present. For example, the formula p ∧¬(p ∧q) has\nsuch a negation with p ∧q as its scope. Essentially, the question is whether\none can eﬃciently compute a CNF for ¬φ from a CNF for φ. Since nobody\nseems to know the answer, we circumvent the question by translating ¬φ\n60\n1 Propositional logic\ninto an equivalent formula that contains only negations of atoms. Formulas\nwhich only negate atoms are said to be in negation normal form (NNF). We\nspell out such a procedure, NNF, in detail later on. The key to its speciﬁcation\nfor implication-free formulas lies in the de Morgan rules. The second phase\nof the preprocessing, therefore, calls NNF with the implication-free output of\nIMPL FREE to obtain an equivalent formula in NNF.\nAfter all this preprocessing, we obtain a formula φ′ which is the result of\nthe call NNF (IMPL FREE (φ)). Note that φ′ ≡φ since both algorithms only\ntransform formulas into equivalent ones. Since φ′ contains no occurrences\nof →and since only atoms in φ′ are negated, we may program CNF by an\nanalysis of only three cases: literals, conjunctions and disjunctions.\nr If φ is a literal, it is by deﬁnition in CNF and so CNF outputs φ.\nr If φ equals φ1 ∧φ2, we call CNF recursively on each φi to get the respective output\nηi and return the CNF η1 ∧η2 as output for input φ.\nr If φ equals φ1 ∨φ2, we again call CNF recursively on each φi to get the respective\noutput ηi; but this time we must not simply return η1 ∨η2 since that formula is\ncertainly not in CNF, unless η1 and η2 happen to be literals.\nSo how can we complete the program in the last case? Well, we may resort\nto the distributivity laws, which entitle us to translate any disjunction of\nconjunctions into a conjunction of disjunctions. However, for this to result in\na CNF, we need to make certain that those disjunctions generated contain\nr more complex terms are built from function symbols using as many previously\nbuilt terms as required by such function symbols; and\nr the notion of terms is dependent on the set F. If you change it, you change the\nset of terms.\n100\n2 Predicate logic\nExample 2.2 Suppose n, f and g are function symbols, respectively\nnullary, unary and binary. Then g(f(n), n) and f(g(n, f(n))) are terms, but\ng(n) and f(f(n), n) are not (they violate the arities). Suppose 0, 1, . . . are\nnullary, s is unary, and +, −, and ∗are binary. Then ∗(−(2, +(s(x), y)), x)\nis a term, whose parse tree is illustrated in Figure 2.14 (page 159). Usually,\nthe binary symbols are written inﬁx rather than preﬁx; thus, the term is\nusually written (2 −(s(x) + y)) ∗x.\n2.2.2 Formulas\nThe choice of sets P and F for predicate and function symbols, respectively,\nis driven by what we intend to describe. For example, if we work on a\ndatabase representing relations between our kin we might want to consider\nP = {M, F, S, D}, referring to being male, being female, being a son of . . .\nand being a daughter of . . . . Naturally, F and M are unary predicates (they\ntake one argument) whereas D and S are binary (taking two). Similarly, we\nmay deﬁne F = {mother-of, father-of}.\nWe already know what the terms over F are. Given that knowledge, we\ncan now proceed to deﬁne the formulas of predicate logic.\nDeﬁnition 2.3 We deﬁne the set of formulas over (F, P) inductively, using\nthe already deﬁned set of terms over F:\nr If P ∈P is a predicate symbol of arity n ≥1, and if t1, t2, . . . , tn are terms over\nF, then P(t1, t2, . . . , tn) is a formula.\nr If φ is a formula, then so is (¬φ).\nr If φ and ψ are formulas, then so are (φ ∧ψ), (φ ∨ψ) and (φ →ψ).\nr If φ is a formula and x is a variable, then (∀x φ) and (∃x φ) are formulas.\nr Nothing else is a formula.\nNote how the arguments given to predicates are always terms. This can also\nbe seen in the Backus Naur form (BNF) for predicate logic:\nconstants. Let φn be the formula expressing that there is a path of length n\nfrom c to c′: we deﬁne φ0 as c = c′, φ1 as R(c, c′) and, for n > 1,\nφn\ndef\n= ∃x1 . . . ∃xn−1(R(c, x1) ∧R(x1, x2) ∧· · · ∧R(xn−1, c′)).\nLet ∆= {¬φi | i ≥0} ∪{φ[c/u][c′/v]}. All formulas in ∆are sentences and\n∆is unsatisﬁable, since the ‘conjunction’ of all sentences in ∆says that\nthere is no path of length 0, no path of length 1, etc. from the node denoted\nby c to the node denoted by c′, but there is a ﬁnite path from c to c′ as\nφ[c/u][c′/v] is true.\n2.6 Expressiveness of predicate logic\n139\nHowever, every ﬁnite subset of ∆is satisﬁable since there are paths of any\nﬁnite length. Therefore, by the Compactness Theorem, ∆itself is satisﬁable.\nThis is a contradiction. Therefore, there cannot be such a formula φ.\n2\n2.6.1 Existential second-order logic\nIf predicate logic cannot express reachability in graphs, then what can, and\nat what cost? We seek an extension of predicate logic that can specify such\nimportant properties, rather than inventing an entirely new syntax, seman-\ntics and proof theory from scratch. This can be realized by applying quan-\ntiﬁers not only to variables, but also to predicate symbols. For a predicate\nsymbol P with n ≥1 arguments, consider formulas of the form\n∃P φ\n(2.11)\nwhere φ is a formula of predicate logic in which P occurs. Formulas of that\nform are the ones of existential second-order logic. An example of arity 2 is\n∃P ∀x∀y∀z (C1 ∧C2 ∧C3 ∧C4)\n(2.12)\nwhere each Ci is a Horn clause4\nC1\ndef\n= P(x, x)\nC2\ndef\n= P(x, y) ∧P(y, z) →P(x, z)\nC3\ndef\n= P(u, v) →⊥\nC4\ndef\n= R(x, y) →P(x, y).\nIf we think of R and P as two transition relations on a set of states, then\nC4 says that any R-edge is also a P-edge, C1 states that P is reﬂexive, C2\nspeciﬁes that P is transitive, and C3 ensures that there is no P-path from\nthe node associated to u to the node associated to v.\nGiven a model M with interpretations for all function and predicate sym-\nin plain English.\n3. Consider the set of LTL/CTL formulas F = {F p →F q, AF p →AF q, AG (p →\nAF q)}.\n(a) Is there a model such that all formulas hold in it?\n(b) For each φ ∈F, is there a model such that φ is the only formula in F satisﬁed\nin that model?\n(c) Find a model in which no formula of F holds.\n4. Consider the CTL formula AG (p →AF (s ∧AX (AF t))). Explain what exactly\nit expresses in terms of the order of occurrence of events p, s and t.\n5. Extend the algorithm NNF from page 62 which computes the negation normal\nform of propositional logic formulas to CTL*. Since CTL* is deﬁned in terms\nof two syntactic categories (state formulas and path formulas), this requires two\nseparate versions of NNF which call each other in a way that is reﬂected by the\nsyntax of CTL* given on page 218.\n6. Find a transition system which distinguishes the following pairs of CTL* formu-\nlas, i.e., show that they are not equivalent:\n(a) AF G p and AF AG p\n(b)\n*\nAG F p and AG EF p\n(c) A[(p U r) ∨(q U r)] and A[(p ∨q) U r)]\n3.8 Exercises\n251\n(d)\n*\nA[X p ∨X X p] and AX p ∨AX AX p\n(e) E[G F p] and EG EF p.\n7. The translation from CTL with boolean combinations of path formulas to plain\nCTL introduced in Section 3.5.1 is not complete. Invent CTL equivalents for:\n(a)\n*\nE[F p ∧(q U r)]\n(b)\n*\nE[F p ∧G q].\nIn this way, we have dealt with all formulas of the form E[φ ∧ψ]. Formulas of the\nform E[φ ∨ψ] can be rewritten as E[φ] ∨E[ψ] and A[φ] can be written ¬E[¬φ].\nUse this translation to write the following in CTL:\n(c) E[(p U q) ∧F p]\n(d)\n*\nA[(p U q) ∧G p]\n(e)\n*\nA[F p →F q].\n8. The aim of this exercise is to demonstrate the expansion given for AW at the\nend of the last section, i.e., A[p W q] ≡¬E[¬q U ¬(p ∨q)].\n(a) Show that the following LTL formulas are valid (i.e., true in any state of any\nmodel):\n(i) ¬q U (¬p ∧¬q) →¬G p\n(ii) G ¬q ∧F ¬p →¬q U (¬p ∧¬q).\n(b) Expand ¬((p U q) ∨G p) using de Morgan rules and the LTL equivalence\n¬(φ U ψ) ≡(¬ψ U (¬φ ∧¬ψ)) ∨¬F ψ.\n312\n5 Modal logics and agents\n→\nφ\nφ\n3\n2\nFigure 5.4. The parse tree of the formula scheme φ →23φ.\nbelow. Even 2⊥is true in x6. If you wanted to convince someone that 2⊥\nwas not true in x6, you’d have to show that there is a world accessible from\nx6 in which ⊥is not true; but you can’t do this, for there are no worlds\naccessible from x6. So again, although ⊥is false in every world, 2⊥might\nnot be false. In fact, x ⊩2⊥holds iﬀx has no accessible worlds.\nFormulas and formula schemes\nThe grammar in (5.1) speciﬁes ex-\nactly the formulas of basic modal logic, given a set of atomic formulas. For\nexample, p →23p is such a formula. It is sometimes useful to talk about\na whole family of formulas which have the same ‘shape;’ these are called\nformula schemes. For example, φ →23φ is a formula scheme. Any formula\nwhich has the shape of a certain formula scheme is called an instance of the\nscheme. For example,\nr p →23p\nr q →23q\nr (p ∧3q) →23(p ∧3q)\nare all instances of the scheme φ →23φ. An example of a formula scheme\nof propositional logic is φ ∧ψ →ψ. We may think of a formula scheme as\nan under-speciﬁed parse tree, where certain portions of the tree still need to\nbe supplied – e.g. the tree of φ →23φ is found in Figure 5.4.\n5.2 Basic modal logic\n313\nSemantically, a scheme can be thought of as the conjunction of all its\ninstances – since there are generally inﬁnitely many such instances, this\ncannot be carried out syntactically! We say that a world/model satisﬁes a\nscheme if it satisﬁes all its instances. Note that an instance being satisﬁed\nin a Kripke model does not imply that the whole scheme is satisﬁed. For\nexample, we may have a Kripke model in which all worlds satisfy ¬p ∨q,\nbut at least one world does not satisfy ¬q ∨p; the scheme ¬φ ∨ψ is not\nsatisﬁed.\nEquivalences between modal formulas\nDeﬁnition 5.7 1.\nWe say that a set of formulas Γ of basic modal logic seman-\ntically entails a formula ψ of basic modal logic if, in any world x of any model\nbelling function L with L(x) = ∅and L(y) = {p}, we claim that x ̸⊩p ∨¬p.\n(Recall that p ∨¬p is an instance of LEM which we proved in Chapter 1 with\nthe full natural deduction calculus.) We do not have x ⊩p, for p is not in\nthe set L(x) which is empty. Thus, Deﬁnition 5.4 for the case ∨implies that\nx ⊩p ∨¬p can hold only if x ⊩¬p holds. But x ⊩¬p simply does not hold,\nsince there is a world y with R(x, y) such that y ⊩p holds, for p ∈L(y). The\navailability of possible worlds in the models of KT4 together with a ‘modal\ninterpretation’ of →and ¬ breaks down the validity of the theorem LEM in\nclassical logic.\nOne can now deﬁne semantic entailment in the same manner as for modal\nlogics. Then, one can prove soundness and completeness of the reduced nat-\nural deduction system with respect to this semantic entailment, but those\nproofs are beyond the scope of this book.\n5.4 Natural deduction\nVerifying semantic entailment Γ ⊨L ψ by appealing to its deﬁnition directly\nwould be rather diﬃcult. We would have to consider every Kripke model\n5.4 Natural deduction\n329\nthat satisﬁes all formulas of Γ and every world in it. Fortunately, we have a\nmuch more usable approach, which is an extension, respectively adaptation,\nof the systems of natural deduction met in Chapters 1 and 2. Recall that\nwe presented natural deduction proofs as linear representations of proof\ntrees which may involve proof boxes which control the scope of assumptions,\nor quantiﬁers. The proof boxes have formulas and/or other boxes inside\nthem. There are rules which dictate how to construct proofs. Boxes open\nwith an assumption; when a box is closed – in accordance with a rule –\nwe say that its assumption is discharged. Formulas may be repeated and\nbrought into boxes, but may not be brought out of boxes. Every formula\nmust have some justiﬁcation to its right: a justiﬁcation can be the name\nof a rule, or the word ‘assumption,’ or an instance of the proof rule copy;\nsee e.g. page 13.\nwe cannot simply insert ∧between the two formulas, because the result will\nnot in general be in DNF, so we have to perform lengthy applications of\nthe distributivity rule φ ∧(ψ1 ∨ψ2) ≡(φ ∧ψ1) ∨(φ ∧ψ1). Computing the\nnegation of a DNF formula is also expensive. The DNF formula φ may be\n6.1 Representing boolean functions\n361\nRepresentation of\ntest for\nboolean operations\nboolean functions\ncompact?\nsatisf’ty\nvalidity\n·\n+\n¯\nProp. formulas\noften\nhard\nhard\neasy\neasy\neasy\nFormulas in DNF\nsometimes\neasy\nhard\nhard\neasy\nhard\nFormulas in CNF\nsometimes\nhard\neasy\neasy\nhard\nhard\nOrdered truth tables\nnever\nhard\nhard\nhard\nhard\nhard\nReduced OBDDs\noften\neasy\neasy\nmedium\nmedium\neasy\nFigure 6.1. Comparing efficiency of five representations of boolean formulas.\ny\ny\n0\n1\n0\n0\nx\nFigure 6.2. An example of a binary decision tree.\nquite short, whereas the length of the disjunctive normal form of ¬φ can be\nexponential in the length of φ.\nThe situation for representation in conjunctive normal form is the dual. A\nsummary of these remarks is contained in Figure 6.1 (for now, please ignore\nthe last row).\n6.1.2 Binary decision diagrams\nBinary decision diagrams (BDDs) are another way of representing boolean\nfunctions. A certain class of such diagrams will provide the implementational\nframework for our symbolic model-checking algorithm. Binary decision di-\nagrams were ﬁrst considered in a simpler form called binary decision trees.\nThese are trees whose non-terminal nodes are labelled with boolean vari-\nables x, y, z, . . . and whose terminal nodes are labelled with either 0 or 1.\nEach non-terminal node has two edges, one dashed line and one solid line.\nIn Figure 6.2 you can see such a binary decision tree with two layers of\nvariables x and y.\nDeﬁnition 6.3 Let T be a ﬁnite binary decision tree. Then T determines\na unique boolean function of the variables in non-terminal nodes, in the\nfollowing way. Given an assignment of 0s and 1s to the boolean variables\n362\n6 Binary decision diagrams\n1\n0\ny\nx\ny\n1\n0\ny",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-3",
                            "title": "Free and Bound Variables",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-4",
                            "title": "Substitution",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nbound since they are in the scope of ∀x, but the leaf x in the right subtree of\n→is free since it is not in the scope of any quantiﬁer ∀x or ∃x. Note, however,\nthat a single leaf either is under the scope of a quantiﬁer, or it isn’t. Hence\nindividual occurrences of variables are either free or bound, never both at\nthe same time.\n2.2.4 Substitution\nVariables are place holders so we must have some means of replacing them\nwith more concrete information. On the syntactic side, we often need to\nreplace a leaf node x by the parse tree of an entire term t. Recall from the\ndeﬁnition of formulas that any replacement of x may only be a term; it\ncould not be a predicate expression, or a more complex formula, for x serves\nas a term to a predicate symbol one step higher up in the parse tree (see\nDeﬁnition 2.1 and the grammar in (2.2)). In substituting t for x we have to\n2.2 Predicate logic as a formal language\n105\nleave untouched the bound leaves x since they are in the scope of some ∃x\nor ∀x, i.e. they stand for some unspeciﬁed or all values respectively.\nDeﬁnition 2.7 Given a variable x, a term t and a formula φ we deﬁne φ[t/x]\nto be the formula obtained by replacing each free occurrence of variable x\nin φ with t.\nSubstitutions are easily understood by looking at some examples. Let f be a\nfunction symbol with two arguments and φ the formula with the parse tree\nin Figure 2.1. Then f(x, y) is a term and φ[f(x, y)/x] is just φ again. This\nis true because all occurrences of x are bound in φ, so none of them gets\nsubstituted.\nNow consider φ to be the formula with the parse tree in Figure 2.2. Here\nwe have one free occurrence of x in φ, so we substitute the parse tree of\nf(x, y) for that free leaf node x and obtain the parse tree in Figure 2.3.\nNote that the bound x leaves are unaﬀected by this operation. You can see\nthat the process of substitution is straightforward, but requires that it be\napplied only to the free occurrences of the variable to be substituted.",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-3",
                    "title": "Proof Theory of Predicate Logic",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-3-subsection-1",
                            "title": "Natural Deduction Rules",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-2",
                            "title": "Quantifier Equivalences",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-4",
                    "title": "Semantics of Predicate Logic",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-4-subsection-1",
                            "title": "Models",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\ntrue, but ψ isn’t. Showing that ψ is a consequence of Γ, on the other hand,\nis harder in principle. For propositional logic, you need to show that every\nvaluation (an assignment of truth values to all atoms involved) that makes\nall φi true also makes ψ true. If there is a small number of valuations, this\nis not so bad. However, when we look at predicate logic, we will ﬁnd that\nthere are inﬁnitely many valuations, called models from hereon, to consider.\nThus, in semantics we have a ‘negative’ characterisation of the logic. We ﬁnd\nestablishing assertions of the form ‘Γ ̸⊨ψ’ (ψ is not a semantic entailment of\nall formulas in Γ) easier than establishing ‘Γ ⊨ψ’ (ψ is a semantic entailment\nof Γ), for in the former case we need only talk about one model, whereas in\nthe latter we potentially have to talk about inﬁnitely many.\nAll this goes to show that it is important to study both proof theory and\nsemantics. For example, if you are trying to show that ψ is not a consequence\nof Γ and you have a hard time doing that, you might want to change your\nstrategy for a while by trying to prove the validity of Γ ⊢ψ. If you ﬁnd a\nproof, you know for sure that ψ is a consequence of Γ. If you can’t ﬁnd a\nproof, then your attempts at proving it often provide insights which lead\nyou to the construction of a counter example. The fact that proof theory\nand semantics for predicate logic are equivalent is amazing, but it does not\nstop them having separate roles in logic, each meriting close study.\n2.4.1 Models\nRecall how we evaluated formulas in propositional logic. For example, the\nformula (p ∨¬q) →(q →p) is evaluated by computing a truth value (T or\nF) for it, based on a given valuation (assumed truth values for p and q).\nThis activity is essentially the construction of one line in the truth table of\n(p ∨¬q) →(q →p). How can we evaluate formulas in predicate logic, e.g.\n∀x ∃y ((P(x) ∨¬Q(y)) →(Q(x) →P(y)))\nwhich ‘enriches’ the formula of propositional logic above? Could we simply\nby classifying them according to their particular view of ‘time.’ Linear-\ntime logics think of time as a set of paths, where a path is a sequence of\ntime instances. Branching-time logics represent time as a tree, rooted at the\npresent moment and branching out into the future. Branching time appears\nto make the non-deterministic nature of the future more explicit. Another\nquality of time is whether we think of it as being continuous or discrete.\nThe former would be suggested if we study an analogue computer, the latter\nmight be preferred for a synchronous network.\n3.2 Linear-time temporal logic\n175\nTemporal logics have a dynamic aspect to them, since the truth of a\nformula is not ﬁxed in a model, as it is in predicate or propositional logic,\nbut depends on the time-point inside the model. In this chapter, we study\na logic where time is linear, called Linear-time Temporal Logic (LTL), and\nanother where time is branching, namely Computation Tree Logic (CTL).\nThese logics have proven to be extremely fruitful in verifying hardware and\ncommunication protocols; and people are beginning to apply them to the\nveriﬁcation of software. Model checking is the process of computing an answer\nto the question of whether M, s ⊨φ holds, where φ is a formula of one of\nthese logics, M is an appropriate model of the system under consideration,\ns is a state of that model and ⊨is the underlying satisfaction relation.\nModels like M should not be confused with an actual physical system.\nModels are abstractions that omit lots of real features of a physical system,\nwhich are irrelevant to the checking of φ. This is similar to the abstractions\nthat one does in calculus or mechanics. There we talk about straight lines,\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nScience. Addison Wesley, 1991.\nSch92. U. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag, 1992.\nSch94. D. A. Schmidt. The Structure of Typed Programming Languages.\nFoundations of Computing. The MIT Press, 1994.\nSim94. A. K. Simpson. The Proof Theory and Semantics of Intuitionistic\nModal Logic. PhD thesis, The University of Edinburgh, Department of\nComputer Science, 1994.\nSS90. G. St˚almarck and M. S˚aﬂund. Modeling and verifying systems and\nsoftware in propositional logic. In B. K. Daniels, editor, Safety of\nComputer Control Systems (SAFECOMP’90), pages 31–36. Pergamon\nPress, 1990.\nBibliography\n417\nTay98. R. G. Taylor. Models of Computation and Formal Languages. Oxford\nUniversity Press, 1998.\nTen91. R. D. Tennent. Semantics of Programming Languages. Prentice Hall,\n1991.\nTur91. R. Turner. Constructive Foundations for Functional Languages.\nMcGraw Hill, 1991.\nvD89. D. van Dalen. Logic and Structure. Universitext. Springer-Verlag, 3rd\nedition, 1989.\nVW84. M. Y. Vardi and Pierre Wolper. Automata-theoretic techniques for\nmodal logics of programs. In Proc. 16th ACM Symposium on Theory\nof Computing, pages 446–456, 1984.\nWei98. M. A. Weiss. Data Structures and Problem Solving Using Java.\nAddison-Wesley, 1998.\nIndex\nABP, 203\nacknowledgement channel, 203\nalternating the control bit, 203\nfairness, 203\nmain SMV program, 207\nabsorption laws, 88\nabstract data type\nsets, 226\nabstraction, 175, 229, 247\nand non-determinism, 191\naccessibility relation, 309, 320, 336\nadequate set of connectives\nfor CTL, 216, 222, 231, 397\nfor LTL, 186\nfor propositional logic, 69, 87, 91\nagent, 307, 319, 327\nalgebraic speciﬁcation, 170\nalgorithm\ndeterministic, 59\nalgorithm apply, 373\ncomplexity, 380\ncontrol structure, 374\nrecursive descent, 375\nalgorithm CNF, 59\nalgorithm reduce, 372\ncomplexity, 380\nalgorithm restrict, 377\ncomplexity, 380\nalgorithm reduce\nexample execution, 373\nAlloy\n[], 153\nfun-statement, 155\nwith, 146\nassertion, 144\ncheck directive, 144\nconsistency check, 144",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-2",
                            "title": "Semantic Entailment",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-3",
                            "title": "The Semantics of Equality",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-5",
                    "title": "Undecidability of Predicate Logic",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-6",
                    "title": "Expressiveness of Predicate Logic",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-6-subsection-1",
                            "title": "Existential Second-Order Logic",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-6-subsection-2",
                            "title": "Universal Second-Order Logic",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-7",
                    "title": "Micromodels of Software",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-7-subsection-1",
                            "title": "State Machines",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-7-subsection-2",
                            "title": "Alma – Revisited",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-7-subsection-3",
                            "title": "A Software Micromodel",
                            "content": "",
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-1",
            "title": "Verification by Model Checking",
            "content": null,
            "children": [
                {
                    "id": "chapter-1-section-1",
                    "title": "Motivation for Verification",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-2",
                    "title": "Linear-Time Temporal Logic",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-2-subsection-1",
                            "title": "Syntax of LTL",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-2",
                            "title": "Semantics of LTL",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-3",
                            "title": "Practical Patterns of Specifications",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-4",
                            "title": "Important Equivalences Between LTL Formulas",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-5",
                            "title": "Adequate Sets of Connectives for LTL",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-3",
                    "title": "Model Checking: Systems, Tools, Properties",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-3-subsection-1",
                            "title": "Example: Mutual Exclusion",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-2",
                            "title": "The NuSMV Model Checker",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-3",
                            "title": "Running NuSMV",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nVAR\ncarry_out : boolean;\nASSIGN\ncarry_out := value & carry_in;\nNotice that, in this assignment, the current value of the variable is assigned.\nDeﬁned symbols are usually preferable to variables, since they don’t increase\nthe state space by declaring new variables. However, they cannot be assigned\nnon-deterministically since they refer only to another expression.\nSynchronous and asynchronous composition\nBy default, modules\nin SMV are composed synchronously: this means that there is a global clock\nand, each time it ticks, each of the modules executes in parallel. By use of\nthe process keyword, it is possible to compose the modules asynchronously.\nIn that case, they run at diﬀerent ‘speeds,’ interleaving arbitrarily. At each\ntick of the clock, one of them is non-deterministically chosen and executed\nfor one cycle. Asynchronous interleaving composition is useful for describing\ncommunication protocols, asynchronous circuits and other systems whose\nactions are not synchronised to a global clock.\nThe bit counter above is synchronous, whereas the examples below of\nmutual exclusion and the alternating bit protocol are asynchronous.\n3.3.3 Running NuSMV\nThe normal use of NuSMV is to run it in batch mode, from a Unix shell or\ncommand prompt in Windows. The command line\nNuSMV counter3.smv\n3.3 Model checking: systems, tools, properties\n195\nwill analyse the code in the ﬁle counter3.smv and report on the speciﬁca-\ntions it contains. One can also run NuSMV interactively. In that case, the\ncommand line\nNuSMV -int counter3.smv\nenters NuSMV’s command-line interpreter. From there, there is a variety\nof commands you can use which allow you to compile the description and\nrun the speciﬁcation checks, as well as inspect partial results and set various\nparameters. See the NuSMV user manual for more details.\nNuSMV also supports bounded model checking, invoked by the command-\nline option -bmc. Bounded model checking looks for counterexamples in\nare carried or not is determined by the ferryman’s choice, represented by the\nnon-deterministic assignment to carry; these values follow the same pattern.\nNote how the boolean guards refer to state bits at the next state. The\nSMV compiler does a dependency analysis and rejects circular dependencies\non next values. (The dependency analysis is rather pessimistic: sometimes\nNuSMV complains of circularity even in situations when it could be resolved.\nThe original CMU-SMV is more liberal in this respect.)\nRunning NuSMV\nWe seek a path satisfying φ U ψ, where ψ asserts the\nﬁnal goal state, and φ expresses the safety condition (if the goat is with\nthe cabbage or the wolf, then the ferryman is there, too, to prevent any\nuntoward behaviour). Thus, we assert that all paths satisfy ¬(φ U ψ), i.e.,\nno path satisﬁes φ U ψ. We hope this is not the case, and NuSMV will give\nus an example path which does satisfy φ U ψ. Indeed, running NuSMV gives\nus the path of Figure 3.13, which represents a solution to the puzzle.\nThe beginning of the generated path represents the usual solution to this\npuzzle: the ferryman takes the goat ﬁrst, then goes back for the cabbage. To\navoid leaving the goat and the cabbage together, he takes the goat back, and\npicks up the wolf. Now the wolf and the cabbage are on the destination side,\nand he goes back again to get the goat. This brings us to State 1.9, where\nthe ferryman appears to take a well-earned break. But the path continues.\nStates 1.10 to 1.15 show that he takes his charges back to the original side\nof the bank; ﬁrst the cabbage, then the wolf, then the goat. Unfortunately\nit appears that the ferryman’s clever plan up to state 1.9 is now spoiled,\nbecause the goat meets an unhappy end in state 1.11.\nWhat went wrong? Nothing, actually. NuSMV has given us an inﬁnite\npath, which loops around the 15 illustrated states. Along the inﬁnite path,\nthe ferryman repeatedly takes his goods across (safely), and then back again",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-4",
                            "title": "Mutual Exclusion Revisited",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-5",
                            "title": "The Ferryman",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-6",
                            "title": "The Alternating Bit Protocol",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-4",
                    "title": "Branching-Time Logic",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-4-subsection-1",
                            "title": "Syntax of CTL",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-2",
                            "title": "Semantics of CTL",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-3",
                            "title": "Practical Patterns of Specifications",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-4",
                            "title": "Important Equivalences Between CTL Formulas",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-5",
                            "title": "Adequate Sets of CTL Connectives",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-5",
                    "title": "CTL* and the Expressive Powers of LTL and CTL",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-5-subsection-1",
                            "title": "Boolean Combinations of Temporal Formulas in CTL",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-5-subsection-2",
                            "title": "Past Operators in LTL",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-6",
                    "title": "Model-Checking Algorithms",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-6-subsection-1",
                            "title": "The CTL Model-Checking Algorithm",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-6-subsection-2",
                            "title": "CTL Model Checking with Fairness",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-6-subsection-3",
                            "title": "The LTL Model-Checking Algorithm",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-7",
                    "title": "The Fixed-Point Characterisation of CTL",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-7-subsection-1",
                            "title": "Monotone Functions",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-7-subsection-2",
                            "title": "The Correctness of SATEG",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-7-subsection-3",
                            "title": "The Correctness of SATEU",
                            "content": "",
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-1",
            "title": "Program Verification",
            "content": null,
            "children": [
                {
                    "id": "chapter-1-section-1",
                    "title": "Why Should We Specify and Verify Code?",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-2",
                    "title": "A Framework for Software Verification",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-2-subsection-1",
                            "title": "A Core Programming Language",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-2",
                            "title": "Hoare Triples",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-3",
                            "title": "Partial and Total Correctness",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-4",
                            "title": "Program Variables and Logical Variables",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-3",
                    "title": "Proof Calculus for Partial Correctness",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-3-subsection-1",
                            "title": "Proof Rules",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-2",
                            "title": "Proof Tableaux",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-3",
                            "title": "A Case Study: Minimal-Sum Section",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-4",
                    "title": "Proof Calculus for Total Correctness",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-5",
                    "title": "Programming by Contract",
                    "content": null,
                    "children": []
                }
            ]
        },
        {
            "id": "chapter-1",
            "title": "Modal Logics and Agents",
            "content": null,
            "children": [
                {
                    "id": "chapter-1-section-1",
                    "title": "Modes of Truth",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-2",
                    "title": "Basic Modal Logic",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-2-subsection-1",
                            "title": "Syntax",
                            "content": "29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nBinary decision diagrams\n358\n6.1\nRepresenting boolean functions\n358\n6.1.1\nPropositional formulas and truth tables\n359\n6.1.2\nBinary decision diagrams\n361\n6.1.3\nOrdered BDDs\n366\n6.2\nAlgorithms for reduced OBDDs\n372\n6.2.1\nThe algorithm reduce\n372\n6.2.2\nThe algorithm apply\n373\n6.2.3\nThe algorithm restrict\n377\n6.2.4\nThe algorithm exists\n377\n6.2.5\nAssessment of OBDDs\n380\n6.3\nSymbolic model checking\n382\n6.3.1\nRepresenting subsets of the set of states\n383\n6.3.2\nRepresenting the transition relation\n385\n6.3.3\nImplementing the functions pre∃and pre∀\n387\n6.3.4\nSynthesising OBDDs\n387\n6.4\nA relational mu-calculus\n390\n6.4.1\nSyntax and semantics\n390\n6.4.2\nCoding CTL models and speciﬁcations\n393\n6.5\nExercises\n398\n6.6\nBibliographic notes\n413\nBibliography\n414\nIndex\n418\nForeword to the first edition\nby\nEdmund M. Clarke\nFORE Systems Professor of Computer Science\nCarnegie Mellon University\nPittsburgh, PA\nFormal methods have ﬁnally come of age! Speciﬁcation languages, theorem\nprovers, and model checkers are beginning to be used routinely in industry.\nMathematical logic is basic to all of these techniques. Until now textbooks\non logic for computer scientists have not kept pace with the development\nof tools for hardware and software speciﬁcation and veriﬁcation. For exam-\nple, in spite of the success of model checking in verifying sequential circuit\ndesigns and communication protocols, until now I did not know of a sin-\ngle text, suitable for undergraduate and beginning graduate students, that\nattempts to explain how this technique works. As a result, this material is\nrarely taught to computer scientists and electrical engineers who will need to\nperfect circles, or an experiment without friction. These abstractions are\nvery powerful, for they allow us to focus on the essentials of our particular\nconcern.\n3.2 Linear-time temporal logic\nLinear-time temporal logic, or LTL for short, is a temporal logic, with con-\nnectives that allow us to refer to the future. It models time as a sequence of\nstates, extending inﬁnitely into the future. This sequence of states is some-\ntimes called a computation path, or simply a path. In general, the future is\nnot determined, so we consider several paths, representing diﬀerent possible\nfutures, any one of which might be the ‘actual’ path that is realised.\nWe work with a ﬁxed set Atoms of atomic formulas (such as p, q, r, . . . , or\np1, p2, . . . ). These atoms stand for atomic facts which may hold of a system,\nlike ‘Printer Q5 is busy,’ or ‘Process 3259 is suspended,’ or ‘The content of\nregister R1 is the integer value 6.’ The choice of atomic descriptions obvi-\nously depends on our particular interest in a system at hand.\n3.2.1 Syntax of LTL\nDeﬁnition 3.1 Linear-time temporal logic (LTL) has the following syntax\ngiven in Backus Naur form:\nφ ::= ⊤| ⊥| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ)\n| (X φ) | (F φ) | (G φ) | (φ U φ) | (φ W φ) | (φ R φ)\n(3.1)\nwhere p is any propositional atom from some set Atoms.\n176\n3 Verification by model checking\n→\nr\n∨\nF\np\nG\nq\n¬\nU\np\nFigure 3.1. The parse tree of (F (p →G r) ∨((¬q) U p)).\nThus, the symbols ⊤and ⊥are LTL formulas, as are all atoms from Atoms;\nand ¬φ is an LTL formula if φ is one, etc. The connectives X, F, G, U, R,\nand W are called temporal connectives. X means ‘neXt state,’ F means ‘some\nFuture state,’ and G means ‘all future states (Globally).’ The next three, U,\nR and W are called ‘Until,’ ‘Release’ and ‘Weak-until’ respectively. We will\nlook at the precise meaning of all these connectives in the next section; for\nnow, we concentrate on their syntax.\nHere are some examples of LTL formulas:\nr (((F p) ∧(G q)) →(p W r))\nLTL we also have quantiﬁers A and E which express ‘all paths’ and ‘exists\na path’, respectively. For example, we can write:\nr There is a reachable state satisfying q: this is written EF q.\nr From all reachable states satisfying p, it is possible to maintain p continuously\nuntil reaching a state satisfying q: this is written AG (p →E[p U q]).\nr Whenever a state satisfying p is reached, the system can exhibit q continuously\nforevermore: AG (p →EG q).\nr There is a reachable state from which all reachable states satisfy p: EF AG p.\n3.4.1 Syntax of CTL\nComputation Tree Logic, or CTL for short, is a branching-time logic, mean-\ning that its model of time is a tree-like structure in which the future is not\ndetermined; there are diﬀerent paths in the future, any one of which might\nbe the ‘actual’ path that is realised.\nAs before, we work with a ﬁxed set of atomic formulas/descriptions (such\nas p, q, r, . . . , or p1, p2, . . . ).\nDeﬁnition 3.12 We deﬁne CTL formulas inductively via a Backus Naur\nform as done for LTL:\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | AX φ | EX φ |\nAF φ | EF φ | AG φ | EG φ | A[φ U φ] | E[φ U φ]\nwhere p ranges over a set of atomic formulas.\nNotice that each of the CTL temporal connectives is a pair of symbols.\nThe ﬁrst of the pair is one of A and E. A means ‘along All paths’ (inevitably)\nand E means ‘along at least (there Exists) one path’ (possibly). The second\none of the pair is X, F, G, or U, meaning ‘neXt state,’ ‘some Future state,’\n‘all future states (Globally)’ and Until, respectively. The pair of symbols\nin E[φ1 U φ2], for example, is EU. In CTL, pairs of symbols like EU are\n3.4 Branching-time logic\n209\nindivisible. Notice that AU and EU are binary. The symbols X, F, G and\nU cannot occur without being preceded by an A or an E; similarly, every A\nor E must have one of X, F, G and U to accompany it.\nUsually weak-until (W) and release (R) are not included in CTL, but they\nare derivable (see Section 3.4.5).\nknowledge.\nModal logic adds unary connectives to express one, or more, of these\ndiﬀerent modes of truth. The simplest modal logics just deal with one con-\ncept – such as knowledge, necessity, or time. More sophisticated modal logics\nhave connectives for expressing several modes of truth in the same logic; we\nwill see some of these towards the end of this chapter.\nWe take a logic engineering approach in this chapter, in which we address\nthe following question: given a particular mode of truth, how may we develop\na logic capable of expressing and formalising that concept? To answer this\nquestion, we need to decide what properties the logic should have and what\nexamples of reasoning it should be able to express. Our main case study will\nbe the logic of knowledge in a multi-agent system. But ﬁrst, we look at the\nsyntax and semantics of basic modal logic.\n5.2 Basic modal logic\n5.2.1 Syntax\nThe language of basic modal logic is that of propositional logic with two\nextra connectives, 2 and 3. Like negation (¬), they are unary connectives\nas they apply themselves to a single formula only. As done in Chapters 1\nand 3, we write p, q, r, p3 . . . to denote atomic formulas.\nDeﬁnition 5.1 The formulas of basic modal logic φ are deﬁned by the\nfollowing Backus Naur form (BNF):\nφ ::= ⊥| ⊤| p | (¬φ) | (φ ∧φ) | (φ ∨φ) | (φ →φ) | (φ ↔φ) | (2φ) | (3φ)\n(5.1)\nwhere p is any atomic formula.\nExample formulas of basic modal logic are (p ∧3(p →2¬r)) and 2((3q ∧\n¬r) →2p), having the parse trees shown in Figure 5.1. The following strings\nare not formulas, because they cannot be constructed using the grammar\nin (5.1): (p2 →q) and (p →3(q 3 r)).\nConvention 5.2 As done in Chapter 1, we assume that the unary connec-\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nouter product, whereas the interleaving model has an outer sum. The latter,\nif used in ∃ˆx′.f (‘for some next state’), can be optimised since sums distribute\nover existential quantiﬁcation; in Chapter 2 this was the equivalence ∃x.(φ ∨\nψ) ≡∃x.φ ∨∃x.ψ. Thus, global states reachable in one step are the ‘union’\nof all the states reachable in one step in the local components; compare the\nformulas in (6.8) and (6.9) with (6.6).\n6.4 A relational mu-calculus\nWe saw in Section 3.7 that evaluating the set of states satisfying a CTL for-\nmula in a model may involve the computation of a ﬁxed point of an operator.\nFor example, [[EF φ]] is the least ﬁxed point of the operator F : P(S) →P(S)\ngiven by F(X) = [[φ]] ∪pre∃(X).\nIn this section, we introduce a syntax for referring to ﬁxed points in the\ncontext of boolean formulas. Fixed-point invariants frequently occur in all\nsorts of applications (for example, the common-knowledge operator CG in\nChapter 5), so it makes sense to have an intermediate language for express-\ning such invariants syntactically. This language also provides a formalism\nfor describing interactions and dependences of such invariants. We will see\nshortly that symbolic model checking in the presence of simple fairness con-\nstraints exhibits such more complex relationships between invariants.\n6.4.1 Syntax and semantics\nDeﬁnition 6.14 The formulas of the relational mu-calculus are given by\nthe grammar\nv ::= x | Z\nf ::= 0 | 1 | v | f | f1 + f2 | f1 · f2 | f1 ⊕f2 |\n∃x.f | ∀x.f | µZ.f | νZ.f | f[ˆx := ˆx′]\n(6.10)\nwhere x and Z are boolean variables, and ˆx is a tuple of variables. In the\nformulas µZ.f and νZ.f, any occurrence of Z in f is required to fall within an\neven number of complementation symbols ¯; such an f is said to be formally\nmonotone in Z. (In exercise 7 on page 410 we consider what happens if we\ndo not require formal monotonicity.)\n6.4 A relational mu-calculus\n391\nConvention 6.15 The binding priorities for the grammar in (6.10) are that",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-2",
                            "title": "Semantics",
                            "content": "This page intentionally left blank\nLOGIC IN COMPUTER SCIENCE\nModelling and Reasoning about Systems\nLOGIC IN COMPUTER SCIENCE\nModelling and Reasoning about Systems\nMICHAEL HUTH\nDepartment of Computing\nImperial College London, United Kingdom\nMARK RYAN\nSchool of Computer Science\nUniversity of Birmingham, United Kingdom\nCAMBRIDGE UNIVERSITY PRESS\nCambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo\nCambridge University Press\nThe Edinburgh Building, Cambridge CB2 8RU, UK\nFirst published in print format\nISBN-13\n978-0-521-54310-1\nISBN-13\n978-0-511-26401-6\n© Cambridge University Press 2004\n2004\nInformation on this title: www.cambridge.org/9780521543101\nThis publication is in copyright. Subject to statutory exception and to the provision of\nrelevant collective licensing agreements, no reproduction of any part may take place\nwithout the written permission of Cambridge University Press.\nISBN-10\n0-511-26401-1\nISBN-10\n0-521-54310-X\nCambridge University Press has no responsibility for the persistence or accuracy of urls\nfor external or third-party internet websites referred to in this publication, and does not\nguarantee that any content on such websites is, or will remain, accurate or appropriate.\nPublished in the United States of America by Cambridge University Press, New York\nwww.cambridge.org\npaperback\neBook (EBL)\neBook (EBL)\npaperback\nContents\nForeword to the ﬁrst edition\npage ix\nPreface to the second edition\nxi\nAcknowledgements\nxiii\n1\nPropositional logic\n1\n1.1\nDeclarative sentences\n2\n1.2\nNatural deduction\n5\n1.2.1\nRules for natural deduction\n6\n1.2.2\nDerived rules\n23\n1.2.3\nNatural deduction in summary\n26\n1.2.4\nProvable equivalence\n29\n1.2.5\nAn aside: proof by contradiction\n29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\n29\n1.3\nPropositional logic as a formal language\n31\n1.4\nSemantics of propositional logic\n36\n1.4.1\nThe meaning of logical connectives\n36\n1.4.2\nMathematical induction\n40\n1.4.3\nSoundness of propositional logic\n45\n1.4.4\nCompleteness of propositional logic\n49\n1.5\nNormal forms\n53\n1.5.1\nSemantic equivalence, satisﬁability and validity\n54\n1.5.2\nConjunctive normal forms and validity\n58\n1.5.3\nHorn clauses and satisﬁability\n65\n1.6\nSAT solvers\n68\n1.6.1\nA linear solver\n69\n1.6.2\nA cubic solver\n72\n1.7\nExercises\n78\n1.8\nBibliographic notes\n91\n2\nPredicate logic\n93\n2.1\nThe need for a richer language\n93\nv\nvi\nContents\n2.2\nPredicate logic as a formal language\n98\n2.2.1\nTerms\n99\n2.2.2\nFormulas\n100\n2.2.3\nFree and bound variables\n102\n2.2.4\nSubstitution\n104\n2.3\nProof theory of predicate logic\n107\n2.3.1\nNatural deduction rules\n107\n2.3.2\nQuantiﬁer equivalences\n117\n2.4\nSemantics of predicate logic\n122\n2.4.1\nModels\n123\n2.4.2\nSemantic entailment\n129\n2.4.3\nThe semantics of equality\n130\n2.5\nUndecidability of predicate logic\n131\n2.6\nExpressiveness of predicate logic\n136\n2.6.1\nExistential second-order logic\n139\n2.6.2\nUniversal second-order logic\n140\n2.7\nMicromodels of software\n141\n2.7.1\nState machines\n142\n2.7.2\nAlma – re-visited\n146\n2.7.3\nA software micromodel\n148\n2.8\nExercises\n157\n2.9\nBibliographic notes\n170\n3\nVeriﬁcation by model checking\n172\n3.1\nMotivation for veriﬁcation\n172\n3.2\nLinear-time temporal logic\n175\n3.2.1\nSyntax of LTL\n175\n3.2.2\nSemantics of LTL\n178\n3.2.3\nPractical patterns of speciﬁcations\n183\n3.2.4\nImportant equivalences between LTL formulas\n184\n3.2.5\nAdequate sets of connectives for LTL\n186\n3.3\nModel checking: systems, tools, properties\n187\n3.3.1\nExample: mutual exclusion\n187\n3.3.2\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nThe NuSMV model checker\n191\n3.3.3\nRunning NuSMV\n194\n3.3.4\nMutual exclusion revisited\n195\n3.3.5\nThe ferryman\n199\n3.3.6\nThe alternating bit protocol\n203\n3.4\nBranching-time logic\n207\n3.4.1\nSyntax of CTL\n208\nContents\nvii\n3.4.2\nSemantics of CTL\n211\n3.4.3\nPractical patterns of speciﬁcations\n215\n3.4.4\nImportant equivalences between CTL formulas\n215\n3.4.5\nAdequate sets of CTL connectives\n216\n3.5\nCTL* and the expressive powers of LTL and CTL\n217\n3.5.1\nBoolean combinations of temporal formulas in CTL\n220\n3.5.2\nPast operators in LTL\n221\n3.6\nModel-checking algorithms\n221\n3.6.1\nThe CTL model-checking algorithm\n222\n3.6.2\nCTL model checking with fairness\n230\n3.6.3\nThe LTL model-checking algorithm\n232\n3.7\nThe ﬁxed-point characterisation of CTL\n238\n3.7.1\nMonotone functions\n240\n3.7.2\nThe correctness of SATEG\n242\n3.7.3\nThe correctness of SATEU\n243\n3.8\nExercises\n245\n3.9\nBibliographic notes\n254\n4\nProgram veriﬁcation\n256\n4.1\nWhy should we specify and verify code?\n257\n4.2\nA framework for software veriﬁcation\n258\n4.2.1\nA core programming language\n259\n4.2.2\nHoare triples\n262\n4.2.3\nPartial and total correctness\n265\n4.2.4\nProgram variables and logical variables\n268\n4.3\nProof calculus for partial correctness\n269\n4.3.1\nProof rules\n269\n4.3.2\nProof tableaux\n273\n4.3.3\nA case study: minimal-sum section\n287\n4.4\nProof calculus for total correctness\n292\n4.5\nProgramming by contract\n296\n4.6\nExercises\n299\n4.7\nBibliographic notes\n304\n5\nModal logics and agents\n306\n5.1\nModes of truth\n306\n5.2\nBasic modal logic\n307\n5.2.1\nSyntax\n307\n5.2.2\nSemantics\n308\n5.3\nLogic engineering\n316\n5.3.1\nThe stock of valid formulas\n317\nviii\nContents\n5.3.2\nImportant properties of the accessibility relation\n320\n5.3.3\nCorrespondence theory\n322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nThe tree in Figure 1.21 on page 82, however, does not represent a well-\nformed formula for two reasons. First, the leaf ∧(and a similar argument\napplies to the leaf ¬), the left subtree of the node →, is not a propositional\natom. This could be ﬁxed by saying that we decided to leave the left and\nright subtree of that node unspeciﬁed and that we are willing to provide\nthose now. However, the second reason is fatal. The p node is not a leaf\nsince it has a subtree, the node ¬. This cannot make sense if we think of\nthe entire tree as some logical formula. So this tree does not represent a\nwell-formed logical formula.\n1.4 Semantics of propositional logic\n1.4.1 The meaning of logical connectives\nIn the second section of this chapter, we developed a calculus of reasoning\nwhich could verify that sequents of the form φ1, φ2, . . . , φn ⊢ψ are valid,\nwhich means: from the premises φ1, φ2, . . . , φn, we may conclude ψ.\nIn this section we give another account of this relationship between the\npremises φ1, φ2, . . . , φn and the conclusion ψ. To contrast with the sequent\n1.4 Semantics of propositional logic\n37\nabove, we deﬁne a new relationship, written\nφ1, φ2, . . . , φn ⊨ψ.\nThis account is based on looking at the ‘truth values’ of the atomic formu-\nlas in the premises and the conclusion; and at how the logical connectives\nmanipulate these truth values. What is the truth value of a declarative sen-\ntence, like sentence (3) ‘Every even natural number > 2 is the sum of two\nprime numbers’? Well, declarative sentences express a fact about the real\nworld, the physical world we live in, or more abstract ones such as computer\nmodels, or our thoughts and feelings. Such factual statements either match\nreality (they are true), or they don’t (they are false).\nIf we combine declarative sentences p and q with a logical connective, say\n∧, then the truth value of p ∧q is determined by three things: the truth value\nof p, the truth value of q and the meaning of ∧. The meaning of ∧is captured\nFigure 1.6. The truth tables for all the logical connectives discussed so far.\ntruth values of φ. Actually we list them twice since we also have to deal\nwith another formula ψ, so the possible number of combinations of truth\nvalues for φ and ψ equals 2 · 2 = 4. Notice that the four pairs of φ and ψ\nvalues in the ﬁrst two columns really exhaust all those possibilities (TT, TF,\nFT and FF). In the third column, we list the result of φ ∧ψ according to the\ntruth values of φ and ψ. So in the ﬁrst line, where φ and ψ have value T,\nthe result is T again. In all other lines, the result is F since at least one of\nthe propositions φ or ψ has value F.\nIn Figure 1.6 you ﬁnd the truth tables for all logical connectives of propo-\nsitional logic. Note that ¬ turns T into F and vice versa. Disjunction is the\nmirror image of conjunction if we swap T and F, namely, a disjunction re-\nturns F iﬀboth arguments are equal to F, otherwise (= at least one of the\narguments equals T) it returns T. The behaviour of implication is not quite\nas intuitive. Think of the meaning of →as checking whether truth is being\npreserved. Clearly, this is not the case when we have T →F, since we infer\nsomething that is false from something that is true. So the second entry\nin the column φ →ψ equals F. On the other hand, T →T obviously pre-\nserves truth, but so do the cases F →T and F →F, because there is no truth\nto be preserved in the ﬁrst place as the assumption of the implication is\nfalse.\nIf you feel slightly uncomfortable with the semantics (= the meaning)\nof →, then it might be good to think of φ →ψ as an abbreviation of the\nformula ¬φ ∨ψ as far as meaning is concerned; these two formulas are very\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\ndiﬀerent syntactically and natural deduction treats them diﬀerently as well.\nBut using the truth tables for ¬ and ∨you can check that φ →ψ evaluates\n1.4 Semantics of propositional logic\n39\nto T iﬀ¬φ ∨ψ does so. This means that φ →ψ and ¬φ ∨ψ are semantically\nequivalent; more on that in Section 1.5.\nGiven a formula φ which contains the propositional atoms p1, p2, . . . , pn,\nwe can construct a truth table for φ, at least in principle. The caveat is that\nthis truth table has 2n many lines, each line listing a possible combination\nof truth values for p1, p2, . . . , pn; and for large n this task is impossible to\ncomplete. Our aim is thus to compute the value of φ for each of these 2n\ncases for moderately small values of n. Let us consider the example φ in\nFigure 1.3. It involves three propositional atoms (n = 3) so we have 23 = 8\ncases to consider.\nWe illustrate how things go for one particular case, namely for the val-\nuation in which q evaluates to F; and p and r evaluate to T. What does\n¬p ∧q →p ∧(q ∨¬r) evaluate to? Well, the beauty of our semantics is that\nit is compositional. If we know the meaning of the subformulas ¬p ∧q and\np ∧(q ∨¬r), then we just have to look up the appropriate line of the →\ntruth table to ﬁnd the value of φ, for φ is an implication of these two sub-\nformulas. Therefore, we can do the calculation by traversing the parse tree\nof φ in a bottom-up fashion. We know what its leaves evaluate to since we\nstated what the atoms p, q and r evaluated to. Because the meaning of p is\nT, we see that ¬p computes to F. Now q is assumed to represent F and the\nconjunction of F and F is F. Thus, the left subtree of the node →evaluates\nto F. As for the right subtree of →, r stands for T so ¬r computes to F and q\nmeans F, so the disjunction of F and F is still F. We have to take that result,\nF, and compute its conjunction with the meaning of p which is T. Since the\nconjunction of T and F is F, we get F as the meaning of the right subtree\nHere is a little anecdote about the German mathematician Gauss who, as a\npupil at age 8, did not pay attention in class (can you imagine?), with the\nresult that his teacher made him sum up all natural numbers from 1 to 100.\nThe story has it that Gauss came up with the correct answer 5050 within\nseconds, which infuriated his teacher. How did Gauss do it? Well, possibly\nhe knew that\n1 + 2 + 3 + 4 + · · · + n = n · (n + 1)\n2\n(1.5)\n1.4 Semantics of propositional logic\n41\nfor all natural numbers n.9 Thus, taking n = 100, Gauss could easily calcu-\nlate:\n1 + 2 + 3 + 4 + · · · + 100 = 100 · 101\n2\n= 5050.\nMathematical induction allows us to prove equations, such as the one\nin (1.5), for arbitrary n. More generally, it allows us to show that every\nnatural number satisﬁes a certain property. Suppose we have a property M\nwhich we think is true of all natural numbers. We write M(5) to say that\nthe property is true of 5, etc. Suppose that we know the following two things\nabout the property M:\n1.\nBase case: The natural number 1 has property M, i.e. we have a proof of\nM(1).\n2.\nInductive step: If n is a natural number which we assume to have property\nM(n), then we can show that n + 1 has property M(n + 1); i.e. we have a proof\nof M(n) →M(n + 1).\nDeﬁnition 1.30 The principle of mathematical induction says that, on the\ngrounds of these two pieces of information above, every natural number n\nhas property M(n). The assumption of M(n) in the inductive step is called\nthe induction hypothesis.\nWhy does this principle make sense? Well, take any natural number k.\nIf k equals 1, then k has property M(1) using the base case and so we are\ndone. Otherwise, we can use the inductive step, applied to n = 1, to infer\nthat 2 = 1 + 1 has property M(2). We can do that using →e, for we know\nthat 1 has the property in question. Now we use that same inductive step on\nn = 2 to infer that 3 has property M(3) and we repeat this until we reach\nof our proof we write LHSn for the expression 1 + 2 + 3 + 4 + · · · + n and\nRHSn for n · (n + 1)/2. Thus, we need to show LHSn = RHSn for all n ≥1.\nBase case: If n equals 1, then LHS1 is just 1 (there is only one summand),\nwhich happens to equal RHS1 = 1 · (1 + 1)/2.\nInductive step: Let us assume that LHSn = RHSn. Recall that this as-\nsumption is called the induction hypothesis; it is the driving force of\nour argument. We need to show LHSn+1 = RHSn+1, i.e. that the longer\nsum 1 + 2 + 3 + 4 + · · · + (n + 1) equals (n + 1) · ((n + 1) + 1)/2. The key\nobservation is that the sum 1 + 2 + 3 + 4 + · · · + (n + 1) is nothing but\nthe sum (1 + 2 + 3 + 4 + · · · + n) + (n + 1) of two summands, where the\nﬁrst one is the sum of our induction hypothesis. The latter says that\n1 + 2 + 3 + 4 + · · · + n equals n · (n + 1)/2, and we are certainly entitled\nto substitute equals for equals in our reasoning. Thus, we compute\nLHSn+1\n= 1 + 2 + 3 + 4 + · · · + (n + 1)\n= LHSn + (n + 1) regrouping the sum\n1.4 Semantics of propositional logic\n43\n= RHSn + (n + 1) by our induction hypothesis\n= n·(n+1)\n2\n+ (n + 1)\n= n·(n+1)\n2\n+ 2·(n+1)\n2\narithmetic\n= (n+2)·(n+1)\n2\narithmetic\n= ((n+1)+1)·(n+1)\n2\narithmetic\n= RHSn+1.\nSince we successfully showed the base case and the inductive step, we can\nuse mathematical induction to infer that all natural numbers n have the\nproperty stated in the theorem above.\n2\nActually, there are numerous variations of this principle. For example, we\ncan think of a version in which the base case is n = 0, which would then\ncover all natural numbers including 0. Some statements hold only for all\nnatural numbers, say, greater than 3. So you would have to deal with a\nbase case 4, but keep the version of the inductive step (see the exercises for\nsuch an example). The use of mathematical induction typically suceeds on\nproperties M(n) that involve inductive deﬁnitions (e.g. the deﬁnition of kl\nwith l ≥0). Sentence (3) on page 2 suggests there may be true properties\nsuch a structure has a certain property. For example, the well-formed for-\nmulas of Deﬁnition 1.27 have the property that the number of ‘(’ brackets\nin a particular formula equals its number of ‘)’ brackets. We can use mathe-\nmatical induction on the domain of natural numbers to prove this. In order\nto succeed, we somehow need to connect well-formed formulas to natural\nnumbers.\nDeﬁnition 1.32 Given a well-formed formula φ, we deﬁne its height to be\n1 plus the length of the longest path of its parse tree.\nFor example, consider the well-formed formulas in Figures 1.3, 1.4\nand 1.10. Their heights are 5, 6 and 5, respectively. In Figure 1.3, the\nlongest path goes from →to ∧to ∨to ¬ to r, a path of length 4, so\nthe height is 4 + 1 = 5. Note that the height of atoms is 1 + 0 = 1. Since\nevery well-formed formula has ﬁnite height, we can show statements about\nall well-formed formulas by mathematical induction on their height. This\ntrick is most often called structural induction, an important reasoning tech-\nnique in computer science. Using the notion of the height of a parse tree,\nwe realise that structural induction is just a special case of course-of-values\ninduction.\n1.4 Semantics of propositional logic\n45\nTheorem 1.33 For every well-formed propositional logic formula, the num-\nber of left brackets is equal to the number of right brackets.\nProof: We proceed by course-of-values induction on the height of well-\nformed formulas φ. Let M(n) mean ‘All formulas of height n have the same\nnumber of left and right brackets.’ We assume M(k) for each k < n and try\nto prove M(n). Take a formula φ of height n.\nr Base case: Then n = 1. This means that φ is just a propositional atom. So there\nare no left or right brackets, 0 equals 0.\nr Course-of-values inductive step: Then n > 1 and so the root of the parse tree\nof φ must be ¬, →, ∨or ∧, for φ is well-formed. We assume that it is →, the other\nthree cases are argued in a similar way. Then φ equals (φ1 →φ2) for some well-\nlogic formulas. If φ1, φ2, . . . , φn ⊢ψ is valid, then φ1, φ2, . . . , φn ⊨ψ holds.\nProof:\nSince φ1, φ2, . . . , φn ⊢ψ is valid we know there is a proof of ψ\nfrom the premises φ1, φ2, . . . , φn. We now do a pretty slick thing, namely,\nwe reason by mathematical induction on the length of this proof! The length\nof a proof is just the number of lines it involves. So let us be perfectly\nclear about what it is we mean to show. We intend to show the assertion\nM(k):\n‘For all sequents φ1, φ2, . . . , φn ⊢ψ (n ≥0) which have a proof of\nlength k, it is the case that φ1, φ2, . . . , φn ⊨ψ holds.’\nby course-of-values induction on the natural number k. This idea requires\n1.4 Semantics of propositional logic\n47\nsome work, though. The sequent p ∧q →r ⊢p →(q →r) has a proof\n1\np ∧q →r\npremise\n2\np\nassumption\n3\nq\nassumption\n4\np ∧q\n∧i 2, 3\n5\nr\n→e 1, 4\n6\nq →r\n→i 3−5\n7\np →(q →r)\n→i 2−6\nbut if we remove the last line or several of the last lines, we no longer\nhave a proof as the outermost box does not get closed. We get a complete\nproof, though, by removing the last line and re-writing the assumption of\nthe outermost box as a premise:\n1\np ∧q →r\npremise\n2\np\npremise\n3\nq\nassumption\n4\np ∧q\n∧i 2, 3\n5\nr\n→e 1, 4\n6\nq →r\n→i 3−5\nThis is a proof of the sequent p ∧q →r, p ⊢p →r. The induction hypothesis\nthen ensures that p ∧q →r, p ⊨p →r holds. But then we can also reason\nthat p ∧q →r ⊨p →(q →r) holds as well – why?\nLet’s proceed with our proof by induction. We assume M(k′) for each\nk′ < k and we try to prove M(k).\nBase case: a one-line proof.\nIf the proof has length 1 (k = 1), then it must\nbe of the form\n1\nφ\npremise\nsince all other rules involve more than one line. This is the case when n = 1\nand φ1 and ψ equal φ, i.e. we are dealing with the sequent φ ⊢φ. Of course,\nsince φ evaluates to T so does φ. Thus, φ ⊨φ holds as claimed.\n48\n1 Propositional logic\nCourse-of-values inductive step:\nLet us assume that the proof of the se-\nsumed or given as a premise some formula η1 ∨η2 in some line k′ with\nk′ < k, which was referred to via ∨e in the justiﬁcation of line k. Thus,\nwe have a shorter proof of the sequent φ1, φ2, . . . , φn ⊢η1 ∨η2 within that\nproof, obtained by turning all assumptions of boxes that are open at\nline k′ into premises. In a similar way we obtain proofs of the sequents\nφ1, φ2, . . . , φn, η1 ⊢ψ and φ1, φ2, . . . , φn, η2 ⊢ψ from the case analysis of ∨e.\nBy our induction hypothesis, we conclude that the relations φ1, φ2, . . . , φn ⊨\nη1 ∨η2, φ1, φ2, . . . , φn, η1 ⊨ψ and φ1, φ2, . . . , φn, η2 ⊨ψ hold. But together\nthese three relations then force that φ1, φ2, . . . , φn ⊨ψ holds as well –\nwhy?\n3.\nYou can guess by now that the rest of the argument checks each possible proof\nrule in turn and ultimately boils down to verifying that our natural deduction\n1.4 Semantics of propositional logic\n49\nrules behave semantically in the same way as their corresponding truth tables\nevaluate. We leave the details as an exercise.\n2\nThe soundness of propositional logic is useful in ensuring the non-existence of\na proof for a given sequent. Let’s say you try to prove that φ1, φ2, . . . , φ2 ⊢ψ\nis valid, but that your best eﬀorts won’t succeed. How could you be sure that\nno such proof can be found? After all, it might just be that you can’t ﬁnd\na proof even though there is one. It suﬃces to ﬁnd a valuation in which φi\nevaluate to T whereas ψ evaluates to F. Then, by deﬁnition of ⊨, we don’t\nhave φ1, φ2, . . . , φ2 ⊨ψ. Using soundness, this means that φ1, φ2, . . . , φ2 ⊢ψ\ncannot be valid. Therefore, this sequent does not have a proof. You will\npractice this method in the exercises.\n1.4.4 Completeness of propositional logic\nIn this subsection, we hope to convince you that the natural deduction rules\nof propositional logic are complete: whenever φ1, φ2, . . . , φn ⊨ψ holds, then\nthere exists a natural deduction proof for the sequent φ1, φ2, . . . , φn ⊢ψ.\ndoes not concern us here.\nStep 1:\nDeﬁnition 1.36 A formula of propositional logic φ is called a tautology iﬀ\nit evaluates to T under all its valuations, i.e. iﬀ⊨φ.\nSupposing that φ1, φ2, . . . , φn ⊨ψ holds, let us verify that φ1 →(φ2 →\n(φ3 →(. . . (φn →ψ) . . . ))) is indeed a tautology. Since the latter formula is\na nested implication, it can evaluate to F only if all φ1, φ2,. . .,φn evaluate to T\nand ψ evaluates to F; see its parse tree in Figure 1.11. But this contradicts the\nfact that φ1, φ2, . . . , φn ⊨ψ holds. Thus, ⊨φ1 →(φ2 →(φ3 →(. . . (φn →\nψ) . . . ))) holds.\nStep 2:\nTheorem 1.37 If ⊨η holds, then ⊢η is valid. In other words, if η is a\ntautology, then η is a theorem.\nThis step is the hard one. Assume that ⊨η holds. Given that η contains\nn distinct propositional atoms p1, p2, . . . , pn we know that η evaluates to T\nfor all 2n lines in its truth table. (Each line lists a valuation of η.) How can\nwe use this information to construct a proof for η? In some cases this can\nbe done quite easily by taking a very good look at the concrete structure of\nη. But here we somehow have to come up with a uniform way of building\nsuch a proof. The key insight is to ‘encode’ each line in the truth table of η\n1.4 Semantics of propositional logic\n51\nas a sequent. Then we construct proofs for these 2n sequents and assemble\nthem into a proof of η.\nProposition 1.38 Let φ be a formula such that p1, p2, . . . , pn are its only\npropositional atoms. Let l be any line number in φ’s truth table. For all\n1 ≤i ≤n let ˆpi be pi if the entry in line l of pi is T, otherwise ˆpi is ¬pi.\nThen we have\n1.\nˆp1, ˆp2, . . . , ˆpn ⊢φ is provable if the entry for φ in line l is T\n2.\nˆp1, ˆp2, . . . , ˆpn ⊢¬φ is provable if the entry for φ in line l is F\nProof: This proof is done by structural induction on the formula φ, that\nis, mathematical induction on the height of the parse tree of φ.\n1.\nIf φ is a propositional atom p, we need to show that p ⊢p and ¬p ⊢¬p. These\nhave one-line proofs.\n2.\n121\nNotice that the use of ∧i in the last line is permissible, because ψ was obtained\nfor any instantiation of the formula in line 1; although a formal tool for proof\nsupport may complain about such practice.\n3.\n(b) The sequent (∃x φ) ∨(∃x ψ) ⊢∃x (φ ∨ψ) is proved valid using the rule\n∨e; so we have two principal cases, each of which requires the rule\n∃x i:\n1\n(∃x φ) ∨(∃x ψ)\npremise\n2\n∃x φ\nx0\n3\nφ[x0/x]\n4\nφ[x0/x]∨ψ[x0/x]\n5\n(φ ∨ψ)[x0/x]\n6\n∃x (φ ∨ψ)\n7\n∃x (φ ∨ψ)\n∃x ψ\nassumpt.\nx0\nψ[x0/x]\nassumpt.\nφ[x0/x]∨ψ[x0/x]\n∨i 3\n(φ ∨ψ)[x0/x]\nidentical\n∃x (φ ∨ψ)\n∃x i 5\n∃x (φ ∨ψ)\n∃x e 2, 3−6\n8\n∃x (φ ∨ψ)\n∨e 1, 2−7\nThe converse sequent has ∃x (φ ∨ψ) as premise, so its proof has to use ∃x e\nas its last rule; for that rule, we need φ ∨ψ as a temporary assumption and\nneed to conclude (∃x φ) ∨(∃x ψ) from those data; of course, the assumption\nφ ∨ψ requires the usual case analysis:\n1\n∃x (φ ∨ψ)\npremise\nx0\n2\n(φ ∨ψ)[x0/x]\nassumption\n3\nφ[x0/x] ∨ψ[x0/x]\nidentical\n4\nφ[x0/x]\n5\n∃x φ\n6\n∃x φ ∨∃x ψ\nψ[x0/x]\nassumption\n∃x ψ\n∃x i 4\n∃x φ ∨∃x ψ\n∨i 5\n7\n∃x φ ∨∃x ψ\n∨e 3, 4−6\n8\n∃x φ ∨∃x ψ\n∃x e 1, 2−7\n4.\n(b) Given the premise ∃x ∃y φ, we have to nest ∃x e and ∃y e to conclude ∃y ∃x φ.\nOf course, we have to obey the format of these elimination rules as done\nbelow:\n122\n2 Predicate logic\n1\n∃x ∃y φ\npremise\nx0\n2\n(∃y φ)[x0/x]\nassumption\n3\n∃y (φ[x0/x])\nidentical, since x, y diﬀerent variables\ny0\n4\nφ[x0/x][y0/y]\nassumption\n5\nφ[y0/y][x0/x]\nidentical, since x, y, x0, y0 diﬀerent variables\n6\n∃x φ[y0/y]\n∀x i 5\n7\n∃y ∃x φ\n∀y i 6\n8\n∃y ∃x φ\n∃y e3, 4−7\n9\n∃y ∃x φ\n∃x e1, 2−8\nThe validity of the converse sequent is proved in the same way by swapping\nthe roles of x and y.\n2\n2.4 Semantics of predicate logic\nHaving seen how natural deduction of propositional logic can be extended\nto predicate logic, let’s now look at how the semantics of predicate logic\nworks. Just like in the propositional case, the semantics should provide a\nseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-\nto predicate logic, let’s now look at how the semantics of predicate logic\nworks. Just like in the propositional case, the semantics should provide a\nseparate, but ultimately equivalent, characterisation of the logic. By ‘sepa-\nrate,’ we mean that the meaning of the connectives is deﬁned in a diﬀerent\nway; in proof theory, they were deﬁned by proof rules providing an oper-\native explanation. In semantics, we expect something like truth tables. By\n‘equivalent,’ we mean that we should be able to prove soundness and com-\npleteness, as we did for propositional logic – although a fully ﬂedged proof\nof soundness and completeness for predicate logic is beyond the scope of this\nbook.\nBefore we begin describing the semantics of predicate logic, let us look\nmore closely at the real diﬀerence between a semantic and a proof-theoretic\naccount. In proof theory, the basic object which is constructed is a proof.\nLet us write Γ as a shorthand for lists of formulas φ1, φ2, . . . , φn. Thus, to\nshow that Γ ⊢ψ is valid, we need to provide a proof of ψ from Γ. Yet,\nhow can we show that ψ is not a consequence of Γ? Intuitively, this is\nharder; how can you possibly show that there is no proof of something?\nYou would have to consider every ‘candidate’ proof and show it is not one.\nThus, proof theory gives a ‘positive’ characterisation of the logic; it pro-\nvides convincing evidence for assertions like ‘Γ ⊢ψ is valid,’ but it is not\nvery useful for establishing evidence for assertions of the form ‘Γ ⊢φ is not\nvalid.’\n2.4 Semantics of predicate logic\n123\nSemantics, on the other hand, works in the opposite way. To show that ψ\nis not a consequence of Γ is the ‘easy’ bit: ﬁnd a model in which all φi are\ntrue, but ψ isn’t. Showing that ψ is a consequence of Γ, on the other hand,\nis harder in principle. For propositional logic, you need to show that every\nvaluation (an assignment of truth values to all atoms involved) that makes\nIf variables can take on only ﬁnitely many values, we can write a program\nthat evaluates formulas in a compositional way. If the root node of φ is ∧,\n∨, →or ¬, we can compute the truth value of φ by using the truth table of\nthe respective logical connective and by computing the truth values of the\nsubtree(s) of that root, as discussed in Chapter 1. If the root is a quantiﬁer,\nwe have sketched above how to proceed. This leaves us with the case of the\nroot node being a predicate symbol P (in propositional logic this was an\natom and we were done already). Such a predicate requires n arguments\nwhich have to be terms t1, t2, . . . , tn. Therefore, we need to be able to assign\ntruth values to formulas of the form P(t1, t2, . . . , tn).\nFor formulas P(t1, t2, . . . , tn), there is more going on than in the case of\npropositional logic. For n = 2, the predicate P could stand for something\nlike ‘the number computed by t1 is less than, or equal to, the number com-\nputed by t2.’ Therefore, we cannot just assign truth values to P directly\nwithout knowing the meaning of terms. We require a model of all function\nand predicate symbols involved. For example, terms could denote real num-\nbers and P could denote the relation ‘less than or equal to’ on the set of real\nnumbers.\nDeﬁnition 2.14 Let F be a set of function symbols and P a set of predicate\nsymbols, each symbol with a ﬁxed number of required arguments. A model\nM of the pair (F, P) consists of the following set of data:\n1.\nA non-empty set A, the universe of concrete values;\n2.\nfor each nullary function symbol f ∈F, a concrete element f M of A\n3.\nfor each f ∈F with arity n > 0, a concrete function f M : An →A from An, the\nset of n-tuples over A, to A; and\n4.\nfor each P ∈P with arity n > 0, a subset P M ⊆An of n-tuples over A.\n2.4 Semantics of predicate logic\n125\nThe distinction between f and fM and between P and P M is most im-\nportant. The symbols f and P are just that: symbols, whereas fM and\nset of n-tuples over A, to A; and\n4.\nfor each P ∈P with arity n > 0, a subset P M ⊆An of n-tuples over A.\n2.4 Semantics of predicate logic\n125\nThe distinction between f and fM and between P and P M is most im-\nportant. The symbols f and P are just that: symbols, whereas fM and\nP M denote a concrete function (or element) and relation in a model M,\nrespectively.\nExample 2.15 Let F\ndef\n= {i} and P\ndef\n= {R, F}; where i is a constant, F a\npredicate symbol with one argument and R a predicate symbol with two\narguments. A model M contains a set of concrete elements A – which may be\na set of states of a computer program. The interpretations iM, RM, and F M\nmay then be a designated initial state, a state transition relation, and a set\nof ﬁnal (accepting) states, respectively. For example, let A\ndef\n= {a, b, c}, iM def\n=\na, RM def\n= {(a, a), (a, b), (a, c), (b, c), (c, c)}, and F M def\n= {b, c}. We informally\ncheck some formulas of predicate logic for this model:\n1.\nThe formula\n∃y R(i, y)\nsays that there is a transition from the initial state to some state; this is true\nin our model, as there are transitions from the initial state a to a, b, and c.\n2.\nThe formula\n¬F(i)\nstates that the initial state is not a ﬁnal, accepting state. This is true in our\nmodel as b and c are the only ﬁnal states and a is the intitial one.\n3.\nThe formula\n∀x∀y∀z (R(x, y) ∧R(x, z) →y = z)\nmakes use of the equality predicate and states that the transition relation is\ndeterministic: all transitions from any state can go to at most one state (there\nmay be no transitions from a state as well). This is false in our model since\nstate a has transitions to b and c.\n4.\nThe formula\n∀x∃y R(x, y)\nstates that the model is free of states that deadlock: all states have a transition\nto some state. This is true in our model: a can move to a, b or c; and b and c\ncan move to c.\nExample 2.16 Let F\ndef\n= {e, ·} and P\ndef\n= {≤}, where e is a constant, · is a\nsays that every word has a preﬁx. This is clearly the case and there are in\ngeneral multiple choices for y, which are dependent on x.\n4.\nIn our model, the formula ∀x ∀y ∀z ((x ≤y) →(x · z ≤y · z)) says that when-\never a word s1 is a preﬁx of s2, then s1s has to be a preﬁx of s2s for every word\ns. This is clearly not the case. For example, take s1 as 01, s2 as 011 and s to\nbe 0.\n5.\nIn our model, the formula\n¬∃x ∀y ((x ≤y) →(y ≤x))\nsays that there is no word s such that whenever s is a preﬁx of some other word\ns1, it is the case that s1 is a preﬁx of s as well. This is true since there cannot\nbe such an s. Assume, for the sake of argument, that there were such a word s.\nThen s is clearly a preﬁx of s0, but s0 cannot be a preﬁx of s since s0 contains\none more bit than s.\nIt is crucial to realise that the notion of a model is extremely liberal and\nopen-ended. All it takes is to choose a non-empty set A, whose elements\n2.4 Semantics of predicate logic\n127\nmodel real-world objects, and a set of concrete functions and relations, one\nfor each function, respectively predicate, symbol. The only mild requirement\nimposed on all of this is that the concrete functions and relations on A have\nthe same number of arguments as their syntactic counterparts.\nHowever, you, as a designer or implementor of such a model, have the\nresponsibility of choosing your model wisely. Your model should be a suf-\nﬁciently accurate picture of whatever it is you want to model, but at the\nsame time it should abstract away (= ignore) aspects of the world which are\nirrelevant from the perspective of your task at hand.\nFor example, if you build a database of family relationships, then it would\nbe foolish to interpret father-of(x, y) by something like ‘x is the daughter\nof y.’ By the same token, you probably would not want to have a predicate\nfor ‘is taller than,’ since your focus in this model is merely on relationships\ndeﬁned by birth. Of course, there are circumstances in which you may want\nwe conclude that M ⊨l φ holds, or does not hold, regardless of the choice of\nl. Thus, for sentences φ we often elide l and write M ⊨φ since the choice of\nan environment l is then irrelevant.\nExample 2.19 Let us illustrate the deﬁnitions above by means of an-\nother simple example. Let F\ndef\n= {alma} and P\ndef\n= {loves} where alma is a\nconstant and loves a predicate with two arguments. The model M we\nchoose here consists of the privacy-respecting set A\ndef\n= {a, b, c}, the constant\nfunction almaM def\n= a and the predicate lovesM def\n= {(a, a), (b, a), (c, a)}, which\nhas two arguments as required. We want to check whether the model M\nsatisﬁes\nNone of Alma’s lovers’ lovers love her.\nFirst, we need to express the, morally worrying, sentence in predicate logic.\nHere is such an encoding (as we already discussed, diﬀerent but logically\nequivalent encodings are possible):\n∀x ∀y (loves(x, alma) ∧loves(y, x) →¬loves(y, alma)) .\n(2.8)\n2.4 Semantics of predicate logic\n129\nDoes the model M satisfy this formula? Well, it does not; for we may choose\na for x and b for y. Since (a, a) is in the set lovesM and (b, a) is in the\nset lovesM, we would need that the latter does not hold since it is the\ninterpretation of loves(y, alma); this cannot be.\nAnd what changes if we modify M to M′, where we keep A and almaM,\nbut redeﬁne the interpretation of loves as lovesM′ def\n= {(b, a), (c, b)}? Well,\nnow there is exactly one lover of Alma’s lovers, namely c; but c is not one\nof Alma’s lovers. Thus, the formula in (2.8) holds in the model M′.\n2.4.2 Semantic entailment\nIn propositional logic, the semantic entailment φ1, φ2, . . . , φn ⊨ψ holds iﬀ:\nwhenever all φ1, φ2, . . . , φn evaluate to T, the formula ψ evaluates to T as well.\nHow can we deﬁne such a notion for formulas in predicate logic, considering\nthat M ⊨l φ is indexed with an environment?\nDeﬁnition 2.20 Let Γ be a (possibly inﬁnite) set of formulas in predicate\nlogic and ψ a formula of predicate logic.\n1.\nquite diﬀerent.\nThe following are not well-formed formulas:\nr U r – since U is binary, not unary\nr p G q – since G is unary, not binary.\n178\n3 Verification by model checking\nDeﬁnition 3.3 A subformula of an LTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\nThe subformulas of p W (q U r), e.g., are p, q, r, q U r and p W (q U r).\n3.2.2 Semantics of LTL\nThe kinds of systems we are interested in verifying using LTL may be\nmodelled as transition systems. A transition system models a system by\nmeans of states (static structure) and transitions (dynamic structure). More\nformally:\nDeﬁnition 3.4 A transition system M = (S, →, L) is a set of states S\nendowed with a transition relation\n→(a binary relation on S), such\nthat every s ∈S has some s′ ∈S with s →s′, and a labelling function\nL: S →P(Atoms).\nTransition systems are also simply called models in this chapter. So a model\nhas a collection of states S, a relation →, saying how the system can move\nfrom state to state, and, associated with each state s, one has the set of\natomic propositions L(s) which are true at that particular state. We write\nP(Atoms) for the power set of Atoms, a collection of atomic descriptions.\nFor example, the power set of {p, q} is {∅, {p}, {q}, {p, q}}. A good way of\nthinking about L is that it is just an assignment of truth values to all the\npropositional atoms, as it was the case for propositional logic (we called\nthat a valuation). The diﬀerence now is that we have more than one state,\nso this assignment depends on which state s the system is in: L(s) contains\nall atoms which are true in state s.\nWe may conveniently express all the information about a (ﬁnite) tran-\nsition system M using directed graphs whose nodes (which we call states)\ncontain all propositional atoms that are true in that state. For example, if\nour system has only three states s0, s1 and s2; if the only possible transi-\ntions between states are s0 →s1, s0 →s2, s1 →s0, s1 →s2 and s2 →s2;\nhave to write EF E[r U q] or EF A[r U q].\n210\n3 Verification by model checking\nAU\nEU\nAX\n¬\n¬\nEX\np\np\n∧\nq\np\nFigure 3.18. The parse tree of a CTL formula without infix notation.\nNotice that we use square brackets after the A or E, when the paired\noperator is a U. There is no strong reason for this; you could use ordinary\nround brackets instead. However, it often helps one to read the formula\n(because we can more easily spot where the corresponding close bracket is).\nAnother reason for using the square brackets is that SMV insists on it.\nThe reason A[(r U q) ∧(p U r)] is not a well-formed formula is that the\nsyntax does not allow us to put a boolean connective (like ∧) directly inside\nA[ ] or E[ ]. Occurrences of A or E must be followed by one of G, F, X or U;\nwhen they are followed by U, it must be in the form A[φ U ψ]. Now, the φ\nand the ψ may contain ∧, since they are arbitrary formulas; so A[(p ∧q) U\n(¬r →q)] is a well-formed formula.\nObserve that AU and EU are binary connectives which mix inﬁx and\npreﬁx notation. In pure inﬁx, we would write φ1 AU φ2, whereas in pure\npreﬁx we would write AU(φ1, φ2).\nAs with any formal language, and as we did in the previous two chapters,\nit is useful to draw parse trees for well-formed formulas. The parse tree for\nA[AX ¬p U E[EX (p ∧q) U ¬p]] is shown in Figure 3.18.\nDeﬁnition 3.14 A subformula of a CTL formula φ is any formula ψ whose\nparse tree is a subtree of φ’s parse tree.\n3.4 Branching-time logic\n211\n3.4.2 Semantics of computation tree logic\nCTL formulas are interpreted over transition systems (Deﬁnition 3.4). Let\nM = (S, →, L) be such a model, s ∈S and φ a CTL formula. The deﬁnition\nof whether M, s ⊨φ holds is recursive on the structure of φ, and can be\nroughly understood as follows:\nr If φ is atomic, satisfaction is determined by L.\nr If the top-level connective of φ (i.e., the connective occurring top-most in the\nparse tree of φ) is a boolean connective (∧, ∨, ¬, ⊤etc.) then the satisfaction\ntives (¬, 2 and 3) bind most closely, followed by ∧and ∨and then followed\nby →and ↔.\n308\n5 Modal logics and agents\n∧\np\n3\n→\np\n2\n¬\nr\n2\n→\n2\n¬\n3\n∧\nr\np\nq\nFigure 5.1. Parse trees for (p ∧3(p →2¬r)) and 2((3q ∧¬r) →2p).\nThis convention allows us to remove many sets of brackets, retaining them\nonly to avoid ambiguity, or to override these binding priorities. For example,\n2((3q ∧¬r) →2p) can be written 2(3q ∧¬r →2p). We cannot omit the\nremaining brackets, however, for 23q ∧¬r →2p has quite a diﬀerent parse\ntree (see Figure 5.2) from the one in Figure 5.1.\nIn basic modal logic, 2 and 3 are read ‘box’ and ‘diamond,’ but, when\nwe apply modal logics to express various modes of truth, we may read them\nappropriately. For example, in the logic that studies necessity and possibility,\n2 is read ‘necessarily’ and 3 ‘possibly;’ in the logic of agent Q’s knowledge,\n2 is read ‘agent Q knows’ and 3 is read ‘it is consistent with agent Q’s\nknowledge that,’ or more colloquially, ‘for all Q knows.’ We will see why\nthese readings are appropriate later in the chapter.\n5.2.2 Semantics\nFor a formula of propositional logic, a model is simply an assignment of\ntruth values to each of the atomic formulas present in that formula – we\ncalled such models valuation in Chapter 1. However, this notion of model is\ninadequate for modal logic, since we want to distinguish between diﬀerent\nmodes, or degrees, of truth.\n5.2 Basic modal logic\n309\n→\n2\n¬\n∧\np\nr\nq\n3\n2\nFigure 5.2. The parse tree for 23q ∧¬r →2p.\nDeﬁnition 5.3 A model M of basic modal logic is speciﬁed by three\nthings:\n1.\nA set W, whose elements are called worlds;\n2.\nA relation R on W (R ⊆W × W), called the accessibility relation;\n3.\nA function L : W →P(Atoms), called the labelling function.\nWe write R(x, y) to denote that (x, y) is in R.\nThese models are often called Kripke models, in honour of S. Kripke who\ninvented them and worked extensively in modal logic in the 1950s and 1960s.\nLee59. C. Y. Lee. Representation of switching circuits by binary-decision\nprograms. Bell System Technical Journal, 38:985–999, 1959.\nLon83. D. E. Long. Model Checking, Abstraction, and Compositional\nVeriﬁcation. PhD thesis, School of Computer Science, Carnegie Mellon\nUniversity, July 1983.\nMar01. A. Martin. Adequate sets of temporal connectives in CTL. Electronic\nNotes in Theoretical Computer Science 52(1), 2001.\nMcM93. K. L. McMillan. Symbolic Model Checking. Kluwer Academic\nPublishers, 1993.\nMP91. Z. Manna and A. Pnueli. The Temporal Logic of Reactive and\nConcurrent Systems: Speciﬁcation. Springer-Verlag, 1991.\nMP95. Z. Manna and A. Pnueli. Temporal Veriﬁcation of Reactive Systems:\nSafety. Springer-Verlag, 1995.\nMvdH95. J.-J. Ch. Meyer and W. van der Hoek. Epistemic Logic for AI and\nComputer Science, volume 41 of Cambridge Tracts in Theoretical\nComputer Science. Cambridge University Press, 1995.\nPap94. C. H. Papadimitriou. Computational Complexity. Addison Wesley,\n1994.\nPau91. L.C. Paulson. ML for the Working Programmer. Cambridge University\nPress, 1991.\nPnu81. A. Pnueli. A temporal logic of programs. Theoretical Computer\nScience, 13:45–60, 1981.\nPop94. S. Popkorn. First Steps in Modal Logic. Cambridge University Press,\n1994.\nPra65. D. Prawitz. Natural Deduction: A Proof-Theoretical Study. Almqvist &\nWiksell, 1965.\nQS81. J. P. Quielle and J. Sifakis. Speciﬁcation and veriﬁcation of concurrent\nsystems in CESAR. In Proceedings of the Fifth International\nSymposium on Programming, 1981.\nRos97. A. W. Roscoe. The Theory and Practice of Concurrency. Prentice\nHall, 1997.\nSA91. V. Sperschneider and G. Antoniou. Logic, A Foundation for Computer\nScience. Addison Wesley, 1991.\nSch92. U. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag, 1992.\nSch94. D. A. Schmidt. The Structure of Typed Programming Languages.\nFoundations of Computing. The MIT Press, 1994.\nSim94. A. K. Simpson. The Proof Theory and Semantics of Intuitionistic\nScience. Addison Wesley, 1991.\nSch92. U. Schoening. Logik f¨ur Informatiker. B. I. Wissenschaftsverlag, 1992.\nSch94. D. A. Schmidt. The Structure of Typed Programming Languages.\nFoundations of Computing. The MIT Press, 1994.\nSim94. A. K. Simpson. The Proof Theory and Semantics of Intuitionistic\nModal Logic. PhD thesis, The University of Edinburgh, Department of\nComputer Science, 1994.\nSS90. G. St˚almarck and M. S˚aﬂund. Modeling and verifying systems and\nsoftware in propositional logic. In B. K. Daniels, editor, Safety of\nComputer Control Systems (SAFECOMP’90), pages 31–36. Pergamon\nPress, 1990.\nBibliography\n417\nTay98. R. G. Taylor. Models of Computation and Formal Languages. Oxford\nUniversity Press, 1998.\nTen91. R. D. Tennent. Semantics of Programming Languages. Prentice Hall,\n1991.\nTur91. R. Turner. Constructive Foundations for Functional Languages.\nMcGraw Hill, 1991.\nvD89. D. van Dalen. Logic and Structure. Universitext. Springer-Verlag, 3rd\nedition, 1989.\nVW84. M. Y. Vardi and Pierre Wolper. Automata-theoretic techniques for\nmodal logics of programs. In Proc. 16th ACM Symposium on Theory\nof Computing, pages 446–456, 1984.\nWei98. M. A. Weiss. Data Structures and Problem Solving Using Java.\nAddison-Wesley, 1998.\nIndex\nABP, 203\nacknowledgement channel, 203\nalternating the control bit, 203\nfairness, 203\nmain SMV program, 207\nabsorption laws, 88\nabstract data type\nsets, 226\nabstraction, 175, 229, 247\nand non-determinism, 191\naccessibility relation, 309, 320, 336\nadequate set of connectives\nfor CTL, 216, 222, 231, 397\nfor LTL, 186\nfor propositional logic, 69, 87, 91\nagent, 307, 319, 327\nalgebraic speciﬁcation, 170\nalgorithm\ndeterministic, 59\nalgorithm apply, 373\ncomplexity, 380\ncontrol structure, 374\nrecursive descent, 375\nalgorithm CNF, 59\nalgorithm reduce, 372\ncomplexity, 380\nalgorithm restrict, 377\ncomplexity, 380\nalgorithm reduce\nexample execution, 373\nAlloy\n[], 153\nfun-statement, 155\nwith, 146\nassertion, 144\ncheck directive, 144\nconsistency check, 144",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-3",
                    "title": "Logic Engineering",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-3-subsection-1",
                            "title": "The Stock of Valid Formulas",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-2",
                            "title": "Important Properties of the Accessibility Relation",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-3",
                            "title": "Correspondence Theory",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-4",
                            "title": "Some Modal Logics",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-4",
                    "title": "Natural Deduction",
                    "content": null,
                    "children": []
                },
                {
                    "id": "chapter-1-section-5",
                    "title": "Reasoning About Knowledge in a Multi-Agent System",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-5-subsection-1",
                            "title": "Some Examples",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-5-subsection-2",
                            "title": "The Modal Logic KT45n",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-5-subsection-3",
                            "title": "Natural Deduction for KT45n",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-5-subsection-4",
                            "title": "Formalising the Examples",
                            "content": "",
                            "children": []
                        }
                    ]
                }
            ]
        },
        {
            "id": "chapter-1",
            "title": "Binary Decision Diagrams",
            "content": null,
            "children": [
                {
                    "id": "chapter-1-section-1",
                    "title": "Representing Boolean Functions",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-1-subsection-1",
                            "title": "Propositional Formulas and Truth Tables",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-1-subsection-2",
                            "title": "Binary Decision Diagrams",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-1-subsection-3",
                            "title": "Ordered BDDs",
                            "content": "322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nBinary decision diagrams\n358\n6.1\nRepresenting boolean functions\n358\n6.1.1\nPropositional formulas and truth tables\n359\n6.1.2\nBinary decision diagrams\n361\n6.1.3\nOrdered BDDs\n366\n6.2\nAlgorithms for reduced OBDDs\n372\n6.2.1\nThe algorithm reduce\n372\n6.2.2\nThe algorithm apply\n373\n6.2.3\nThe algorithm restrict\n377\n6.2.4\nThe algorithm exists\n377\n6.2.5\nAssessment of OBDDs\n380\n6.3\nSymbolic model checking\n382\n6.3.1\nRepresenting subsets of the set of states\n383\n6.3.2\nRepresenting the transition relation\n385\n6.3.3\nImplementing the functions pre∃and pre∀\n387\n6.3.4\nSynthesising OBDDs\n387\n6.4\nA relational mu-calculus\n390\n6.4.1\nSyntax and semantics\n390\n6.4.2\nCoding CTL models and speciﬁcations\n393\n6.5\nExercises\n398\n6.6\nBibliographic notes\n413\nBibliography\n414\nIndex\n418\nForeword to the first edition\nby\nEdmund M. Clarke\nFORE Systems Professor of Computer Science\nCarnegie Mellon University\nPittsburgh, PA\nFormal methods have ﬁnally come of age! Speciﬁcation languages, theorem\nprovers, and model checkers are beginning to be used routinely in industry.\nMathematical logic is basic to all of these techniques. Until now textbooks\non logic for computer scientists have not kept pace with the development\nof tools for hardware and software speciﬁcation and veriﬁcation. For exam-\nple, in spite of the success of model checking in verifying sequential circuit\ndesigns and communication protocols, until now I did not know of a sin-\ngle text, suitable for undergraduate and beginning graduate students, that\nattempts to explain how this technique works. As a result, this material is\nrarely taught to computer scientists and electrical engineers who will need to\nall its 1-terminals by Bg. To see why this is so, consider how to get to a\n1-terminal in the resulting BDD. You have to satisfy the requirements for\ngetting to a 1 imposed by both of the BDDs. Similarly, a BDD for f + g\ncan be obtained by replacing all 0 terminals of Bf by Bg. Note that these\noperations are likely to generate BDDs with multiple occurrences of variables\nalong a path. Later, in Section 6.2, we will see deﬁnitions of + and · on BDDs\nthat don’t have this undesirable eﬀect.\nThe complementation operation ¯ is also possible: a BDD representing f\ncan be obtained by replacing all 0-terminals in Bf by 1-terminals and vice\nversa. Figure 6.8 shows the complement of the BDD in Figure 6.2.\n6.1.3 Ordered BDDs\nWe have seen that the representation of boolean functions by BDDs is often\ncompact, thanks to the sharing of information aﬀorded by the reductions\nC1–C3. However, BDDs with multiple occurrences of a boolean variable\nalong a path seem rather ineﬃcient. Moreover, there seems no easy way to\ntest for equivalence of BDDs. For example, the BDDs of Figures 6.7 and 6.9\nrepresent the same boolean function (the reader should check this). Neither\nof them can be optimised further by applying the rules C1–C3. However,\n6.1 Representing boolean functions\n367\nx\ny\ny\n0\n1\n1\n1\nFigure 6.8. The complement of the BDD in Figure 6.2.\ny\n0\n1\nx\ny\nz\nFigure 6.9. A BDD representing the same function as the BDD of\nFigure 6.7, but having the variable ordering [x, y, z].\ntesting whether they denote the same boolean function seems to involve as\nmuch computational eﬀort as computing the entire truth table for f(x, y, z).\nWe can improve matters by imposing an ordering on the variables occur-\nring along any path. We then adhere to that same ordering for all the BDDs\nwe manipulate.\nDeﬁnition 6.6 Let [x1, . . . , xn] be an ordered list of variables without du-\nplications and let B be a BDD all of whose variables occur somewhere in",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-2",
                    "title": "Algorithms for Reduced OBDDs",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-2-subsection-1",
                            "title": "The Algorithm Reduce",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-2",
                            "title": "The Algorithm Apply",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-3",
                            "title": "The Algorithm Restrict",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-2-subsection-4",
                            "title": "The Algorithm Exists",
                            "content": "",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-3",
                    "title": "Symbolic Model Checking",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-3-subsection-1",
                            "title": "Representing Subsets of the Set of States",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-2",
                            "title": "Representing the Transition Relation",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-3",
                            "title": "Implementing the Functions pre∃ and pre∀",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-3-subsection-4",
                            "title": "Synthesising OBDDs",
                            "content": "322\n5.3.4\nSome modal logics\n326\n5.4\nNatural deduction\n328\n5.5\nReasoning about knowledge in a multi-agent system\n331\n5.5.1\nSome examples\n332\n5.5.2\nThe modal logic KT45n\n335\n5.5.3\nNatural deduction for KT45n\n339\n5.5.4\nFormalising the examples\n342\n5.6\nExercises\n350\n5.7\nBibliographic notes\n356\n6\nBinary decision diagrams\n358\n6.1\nRepresenting boolean functions\n358\n6.1.1\nPropositional formulas and truth tables\n359\n6.1.2\nBinary decision diagrams\n361\n6.1.3\nOrdered BDDs\n366\n6.2\nAlgorithms for reduced OBDDs\n372\n6.2.1\nThe algorithm reduce\n372\n6.2.2\nThe algorithm apply\n373\n6.2.3\nThe algorithm restrict\n377\n6.2.4\nThe algorithm exists\n377\n6.2.5\nAssessment of OBDDs\n380\n6.3\nSymbolic model checking\n382\n6.3.1\nRepresenting subsets of the set of states\n383\n6.3.2\nRepresenting the transition relation\n385\n6.3.3\nImplementing the functions pre∃and pre∀\n387\n6.3.4\nSynthesising OBDDs\n387\n6.4\nA relational mu-calculus\n390\n6.4.1\nSyntax and semantics\n390\n6.4.2\nCoding CTL models and speciﬁcations\n393\n6.5\nExercises\n398\n6.6\nBibliographic notes\n413\nBibliography\n414\nIndex\n418\nForeword to the first edition\nby\nEdmund M. Clarke\nFORE Systems Professor of Computer Science\nCarnegie Mellon University\nPittsburgh, PA\nFormal methods have ﬁnally come of age! Speciﬁcation languages, theorem\nprovers, and model checkers are beginning to be used routinely in industry.\nMathematical logic is basic to all of these techniques. Until now textbooks\non logic for computer scientists have not kept pace with the development\nof tools for hardware and software speciﬁcation and veriﬁcation. For exam-\nple, in spite of the success of model checking in verifying sequential circuit\ndesigns and communication protocols, until now I did not know of a sin-\ngle text, suitable for undergraduate and beginning graduate students, that\nattempts to explain how this technique works. As a result, this material is\nrarely taught to computer scientists and electrical engineers who will need to\n[x1, x′\n1, x2, x′\n2] rather than [x1, x2, x′\n1, x′\n2]. Figure 6.27 (right) shows the truth\ntable redrawn with the interleaved ordering of the columns and the rows\nreordered lexicographically. The resulting OBDD is shown in Figure 6.28.\n6.3.3 Implementing the functions pre∃and pre∀\nIt remains to show how an OBDD for pre∃(X) and pre∀(X) can be com-\nputed, given OBDDs BX for X and B→for the transition relation →. First\nwe observe that pre∀can be expressed in terms of complementation and\npre∃, as follows: pre∀(X) = S −pre∃(S −X), where we write S −Y for the\nset of all s ∈S which are not in Y . Therefore, we need only explain how to\ncompute the OBDD for pre∃(X) in terms of BX and B→. Now (6.4) suggests\nthat one should proceed as follows:\n1.\nRename the variables in BX to their primed versions; call the resulting OBDD\nBX′.\n2.\nCompute the OBDD for exists(ˆx′, apply(·, B→, BX′)) using the apply and\nexists algorithms (Sections 6.2.2 and 6.2.4).\n6.3.4 Synthesising OBDDs\nThe method used in Example 6.13 for producing an OBDD for the transi-\ntion relation was to compute ﬁrst the truth table and then an OBDD which\nmight not be in its fully reduced form; hence the need for a ﬁnal call to\n388\n6 Binary decision diagrams\nthe reduce function. However, this procedure would be unacceptable if ap-\nplied to realistically sized systems with a large number of variables, for the\ntruth table’s size is exponential in the number of boolean variables. The\nkey idea and attraction of applying OBDDs to ﬁnite systems is therefore to\ntake a system description in a language such as SMV and to synthesise the\nOBDD directly, without having to go via intermediate representations (such\nas binary decision trees or truth tables) which are exponential in size.\nSMV allows us to deﬁne the next value of a variable in terms of the\ncurrent values of variables (see the examples of code in Section 3.3.2)3. This\ncan be compiled into a set of boolean functions fi, one for each variable xi,",
                            "children": []
                        }
                    ]
                },
                {
                    "id": "chapter-1-section-4",
                    "title": "A Relational Mu-Calculus",
                    "content": null,
                    "children": [
                        {
                            "id": "chapter-1-section-4-subsection-1",
                            "title": "Syntax and Semantics",
                            "content": "",
                            "children": []
                        },
                        {
                            "id": "chapter-1-section-4-subsection-2",
                            "title": "Coding CTL Models and Specifications",
                            "content": "",
                            "children": []
                        }
                    ]
                }
            ]
        }
    ]
}